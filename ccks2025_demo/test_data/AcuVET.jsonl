{
  "query": "DeepSeek新模型发布，引发AI创新浪潮",
  "id": "AcuVET",
  "granularity": 30,
  "time_range": [
      "2025-01-19",
      "2025-02-01"
  ],
  "articles": [
    {
      "doc_id": 49725,
      "title": "加速大模型多维度创新 DeepSeek为AI产业带来新浪潮与新机遇",
      "time": "2024-02-19T00:00:00+00:00",
      "content": "2025年开年，DeepSeek就向AI市场投入了一枚重磅炸弹(包括基座模型DeepSeek V3、推理模型R1、多模态模型JanusPro)。凭借工程创新，利用多项技术优化训练、推理，降低大模型开发、部署成本，并通过开源策略降低了行业门槛，加速了技术迭代和生态建设。 如果用一句话来概括就是DeepSeek加速了AI普惠，多维度创新助力行业发展。 DeepSeek让行业与企业在结合大模型进行业务、产品创新时投入成本更低，且带来的体验更出色。从1月份开始，包括行业解决方案、终端设备、汽车以及云服务等各个领域均有多家企业宣布接入DeepSeek，还有大批用户即使受限于“服务器繁忙”也在紧跟这股热潮。可以说，DeepSeek从模型、平台、基础设施、应用及商业化落地等多个层面为AI产业带来新浪潮、新机遇。 日前，IDC公布了最新报告《IDC Market Glance: 中国生成式AI市场概览， 1Q25》，围绕模型层、平台层、基础设施层、应用层来分析DeepSeek爆火后对于大模型与生成式AI市场生态带来的潜在影响。 在模型层，DeepSeek为基础大模型开启另一开发新范式，引入多令牌预测(MTP)技术可在训练、推理过程中降低对算力的需求，提升效率;采用FP8精度进行训练，并成功构建混合专家模型，通过高效的“门控网络”实现令牌的路由，进一步削减推理成本;多头潜在注意力机制(MLA)降低KV缓存需求，减少了硬件资源消耗;DeepSeek还通过开发内部工具生成训练数据，并使用“蒸馏”技术(去噪、降维、提炼等)进一步压缩计算资源;DeepSeek在模型训练中广泛应用强化学习技术，通过试错机制和环境反馈优化模型的决策能力，特别是在推理和复杂问题解决方面。 还有一点十分关键，DeepSeek将包括代码和模型权重在内的技术开源，在降低用户体验大模型门槛的同时，也吸引了开发者，有利于技术迭代和生态局建设。 经过IDC分析师初步试验，DeepSeek R1在数学、推理、代码任务上不乏优势，但其性能并非在所有任务及指标上均领先。从短期来看，未来无论是开源还是商业的基础大模型还会进行进一步的差异化竞争，国内外大模型的生成效果差距会趋于收敛。从长期来看，NLP大模型会朝着经济高效、上下文准确、高质量、安全可靠演进，技术供应商需要在成本、不同任务与应用领域的生成质量、用户体验及安全性等多方面寻找产品差异化优势。 IDC在报告中还提到，从2024年以来，随着大模型基础能力的提升，以及应用形态的不断创新，连接大模型和应用侧的平台产品演变出现了多种形式，预计未来大模型平台会分化成底层平台以及智能体开发平台等产品。 平台层产品往往跟模型层深度绑定，使得大模型更加易用、普惠。随着大模型的日益普及，平台中多种模型选择、如何将大模型高效且可靠地部署于生产环境，已成为当前备受瞩目的核心议题。当前，全球技术供应商如英伟达、微软、英特尔、AMD、AWS以及国内技术供应商如阿里云、百度智能云、华为云、腾讯云、火山引擎、京东云、天翼云、用友、360、云轴科技等已接入了DeepSeek模型。 同时，大模型的部署过程需同时满足高并发与低延迟的严苛要求，并需全面考量数据安全、隐私保障、资源弹性扩展以及系统维护等多重因素，DeepSeek推出了多种部署模式许可也挑战了全球大模型技术提供商的主要商业化方法，目前推出的方式有云端部署、本地及内网部署、边缘部署、混合部署、容器化/微服务部署，以及联邦部署模式等。 DeepSeek一系列技术创新与开源策略对于算力影响最为直接，降低了单位算力需求，让企业及行业除“大力出奇迹(大规模投入算力资源)”路径外，还可以尝试“四两拨千斤”，配合算法、框架等软硬件协同创新，引发行业对算力的重新思考。另外，DeepSeek也会增加大模型应用与落地，驱动更多企业部署AI、将AI融入业务流程，必然会带来总体算力需求增长，而且在Scaling Law技术路线仍旧有效的情况下，“卷算力”也会给基础设施层面带来新机遇。例如埃隆·马斯克旗下人工智能公司xAI最新发布的AI大模型产品——Grok 3，在20万个GPU上进行训练，只用了214天就完成构建。根据官方公布的测试数据，Grok-3和Grok-3 mini在数学、科学、代码等领域的性能都超过或媲美Gemini、DeepSeek和ChatGPT等大模型。 DeepSeek创新带来的一系列优势将助力打造更广泛的应用场景，加速商业化落地。IDC指出，大模型的更新升级将有助于加速应用场景的创新及商业化落地，未来无论是面向个人生产效率提升的应用，还是面向企业业务与行业场景的商业化落地都将会是今年市场关注的重点。 IDC中国研究经理程荫表示，DeepSeek引领基础大模型开启另一开发新范式——以一系列降低成本与复杂性的创新优化技术、手段，降低门槛，未来差异化竞争的结果是NLP大模型的进一步更新升级，软件及硬件供应商应提供多模型选择、高效且可靠地部署方式的大模型开发平台或应用开发工具，并进行软硬件协同创新。2025年产业界也更加关注大模型和生成式AI的落地，整个生态系统应通力合作加速应用场景的创新及商业化。 举报/反馈"
    },
    {
      "doc_id": 49727,
      "title": "DeepSeek有望激发新一波AI创新浪潮",
      "time": "2024-01-29T00:00:00+00:00",
      "content": "来源：北京日报客户端 记者 吴晓凌 中国人工智能（AI）企业深度求索（DeepSeek）日前发布其最新开源模型DeepSeek-R1，用较低的成本达到了接近于美国开放人工智能研究中心（OpenAI）开发的GPT-o1的性能。这一进展破解了全球人工智能产业长期以来“堆算力”的路径依赖，其影响波及资本市场。业界人士认为，DeepSeek模型有望激发一波创新浪潮，推动全球AI继续进步。 摩根士丹利认为，DeepSeek的模型表明，前沿AI能力可能不需要大量计算资源就能实现。通过巧妙的工程设计和高效的训练方法，高效利用资源可能比纯粹的计算能力更重要。这可能会激发一波创新浪潮，各家企业会探索具有成本效益的AI开发和部署方法。 DeepSeek的模型是开源共享的。近日，全球知名开源平台抱抱脸公司等多个团队已宣布复现了DeepSeek-R1的训练过程。美国“元”公司首席AI科学家杨立昆在社交媒体上发文说，Deep-Seek-R1的面世，意味着开源模型正在超越闭源模型。 英国《金融时报》的评论文章说，开源模型DeepSeek-R1对全球用户产生极大吸引力，有利于推动人工智能技术的开发和应用。文章说，对于大多数商业用户来说，拥有一款足够可靠并且好用的模型比拥有绝对领先的模型更重要。 瑞士瑞银集团指出，如果AI训练和推理成本显著降低，预计更多终端用户将利用AI来改善他们的业务或开发新的用途。（据新华社旧金山1月27日电） 举报/反馈"
    },
    {
      "doc_id": 49728,
      "title": "大模型之家2025年5月热力榜:智能体正成为通往AGI的路径",
      "time": "2024-06-04T00:00:00+00:00",
      "content": "2025年5月，智能体再次成为行业热议的焦点。以DeepSeek、腾讯、阿里等为代表的中国企业，正在推动智能体从概念走向实用，成为大模型产业化的重要突破口。 智能体作为具备感知、规划、执行能力的AI系统，正在从单点任务执行者演进为多智能体协作体，具备自主决策、任务分解与工具调用能力。随着多模态感知、MCP等关键技术的成熟，智能体正逐步跨越“可用”与“好用”的门槛，成为AI落地的关键路径。 在《2025年5月大模型热力榜》中，共收录了260家大型模型及其所属企业。在其中，百度、阿里、字节跳动等头部科技企业，纷纷加大在智能体领域的投入，推出多款应用产品，巩固了在榜单中的排名。DeepSeek凭借R1全新版本再次冲进榜单前列，腾讯凭借发布多款大模型以及应用产品成功进入榜单前三名。 5月，百度在AI和大模型领域多项技术突破与商业进展引发行业关注。2025Q1财报显示，智能云业务同比增速达42%，核心营收超市场预期，智能云千帆大模型平台升级后支持多模态与深度思考模型训练，接入超100个主流模型，显著降低企业AI应用门槛。萝卜快跑无人驾驶服务累计提供超1100万次出行，全球化布局加速。 21日，百度在万象AI开发者大会上发布全球首个千亿参数多模态大模型“文心·灵眸”，该模型集成视觉Transformer、语音编码器与语义理解模块，支持图像生成、视频理解等12种模态处理，并与美团合作推出智能配送大脑，使配送路径规划效率提升40%，异常订单处理时间缩短至15秒。 同期，文心大模型X1 Turbo在5月20日百度AI Day上获中国信通院最高级“4+级”评级，成为国内首款通过该测评的大模型，其在逻辑推理、代码生成等24项能力评估中16项获满分，综合性能超越DeepSeek R1等国际模型，调用成本仅为后者的25%。 不仅如此，百度旗下“通用超级智能体”心响App于5月悄然迎来了iOS端上线，与市面上以对话、写作或翻译为主的单功能AI应用不同，心响能够通过主智能体调度多个子智能体，在复杂任务处理中实现自主规划、执行与优化，“一站式”解决复杂任务。用户仅需用自然语言表达目标，系统便可自动分解需求并完成执行，不仅提升了智能体的能力边界，还大大降低了AI使用门槛。 此外，百度智能云千帆平台升级后接入超100个主流模型，调用成本行业最低，企业已通过该平台精调3.3万个模型、开发77万应用，形成“模型超市”生态。在应用落地层面，百度与昆仑芯合作的“文心一体机”集成AI加速芯片，推理延迟降至10毫秒，支持本地化部署；灵眸API平台开放30余项多模态能力，日均调用量突破10亿次，接入携程、贝壳等200余家企业。 2025年5月，阿里云飞天企业版平台通过融合智算能力，为金融、政务、能源等领域超千家头部客户提供“云+AI”协同服务，显著提升GPU利用率与任务执行效率。同期，阿里云推出百炼专属版平台，集成飞天架构与多模态数据解析能力，支持政务、医药等垂直领域快速构建智能体应用，加速AI价值释放。 在模型研发层面，阿里巴巴开源新一代混合推理模型Qwen3，性能超越Deepseek-R1、OpenAI-o1等模型，登顶全球开源模型榜单。此外，通义千问VL-Max模型优化数学推理与回复风格，并开放抢先体验。 此外，阿里云通义万相Wan2.1-VACE模型开源，成为业界功能最全的视频生成与编辑模型。AI技术深度赋能淘宝天猫广告工具、高德导航智能体、飞猪旅行AI等产品，覆盖电商、物流、文旅等多场景。 DeepSeek在技术层面，R1模型完成R1-0528版本重要升级，该版本基于DeepSeek V3 Base模型，通过追加算力投入优化后训练算法，显著提升了推理深度与思维链能力，优化代码生成、逻辑推理能力，上下文长度翻倍至128K，支持超长文本处理，数值计算精度显著提升，推理深度大幅增强，逻辑链更贴近人类思维。同时，R1-0528将幻觉率降低45-50%。此外，DeepSeek与华为昇腾集群深度适配，海外开发团队训练成本降低50%以上，并携手IBM、蓝美视讯等推动“存储+AI”解决方案落地，进一步拓展生态版图。 5月，腾讯全面加速技术迭代与产业落地：21日，腾讯云AI产业应用峰会首次全景披露大模型战略，宣布混元大模型矩阵全面升级，包括推出视觉深度推理模型混元T1 Vision和端到端语音通话模型混元Voice，并计划上线实时视频通话AI体验。 混元大模型多模态能力显著突破，上线图像生成实现“毫秒级”生图，3D生成技术凭借稀疏原生架构在可控性与超高清效果上实现代际飞跃，开源后Hugging Face下载量超160万次。 此外，腾讯云智能体开发平台同步升级，支持零代码多Agent协同与工作流模式，大幅降低企业智能体搭建门槛；知识库系列产品基于腾讯乐享和ima完成迭代，强化知识管理与应用能力。 字节跳动在火山引擎FORCE LINK AI创新巡展上发布了视觉语言多模态模型Seed1.5-VL，显著提升了视觉定位与推理能力，并新增视频理解及多模态智能体功能，进一步拓展了AI应用场景。同时，字节跳动的Seed团队开源了基于模型为中心的代码预训练数据构建流水线，并推出了Seed-Coder系列模型，推动了代码生成技术的进步。此外，字节跳动还推出了集成火山引擎豆包大模型的AI视频编辑应用“剪小影”，降低了视频创作门槛。 商汤科技多模态大模型「日日新V6」凭借62.96分的综合得分，在通用语言能力榜单上与豆包1.5并列国内第一；在OpenCompass多模态测评中更以80.4分超越Gemini 2.5 Pro，登顶全球。依托多模态长思维链、全局记忆等技术，日日新V6在处理文本、图像、视频等复杂任务时展现出极高效率与低推理成本，已落地至具身智能、智慧教育等多个场景。 在行业生态上，商汤加速“模型+应用”一体化：与广汽联合量产落地辅助驾驶方案，与听力熊共推教育AI助手，并联合麒麟软件打造国产办公AI一体机，为政企客户提供全栈式支持。面向开发者，商汤开源低代码框架LazyLLM，十行代码即可构建多Agent应用，其API性能排名全行业首位。 算力基建方面，SenseCore2.0大装置算力规模达到2.3万PetaFlops，全面支持大模型效率跃升。与声网合作也将日日新嵌入音视频服务，赋能智能面试等场景，2024年生成式AI业务收入同比翻倍，商汤正逐步从“技术领先”走向“生态主导”。 360在AI和大模型领域动作频频，展现出其在安全、技术落地与生态合作方面的多重布局。360纳米AI连续3个月登顶国内AI产品增速榜，成为全球AI搜索引擎三强，其升级版“纳米AI超级搜索”实现跨平台搜索、多模态生成及闭环任务执行，最新版本强化“AI搜索”“智能体”等模块的对话体验。360集团创始人周鸿祎在公开演讲中强调，2025年将是智能体爆发之年，大模型需进化为智能体以实现具体任务执行，360正通过智能体构建、生态协作与硬件融合，加速AI技术普惠与应用深化。 生态合作方面，360与智谱AI达成战略合作，共研千亿级大模型“360GLM”，形成“双引擎”驱动布局，并推动大模型技术开源与场景化落地。 5月，科大讯飞在AI与大模型领域持续深耕教育场景并加速全球化布局。在武汉举办的2025世界数字教育大会上，科大讯飞展示了基于星火X1深度推理大模型的创新成果，包括支持3D立体图形智能识别的AI黑板、具备跨时空资源匹配功能的“奇思妙问”竖屏，并联合中国教科院正式启动中小学科学教育智能导师项目，旨在通过构建“教学思维链”驱动的专用模型，实现智能辅教与个性化导学。 同期，科大讯飞公布其智慧教育业务已覆盖全国32个省级行政区、超5万所学校的1.3亿师生，2024年相关营收达72.29亿元，同比增长29.94%。此外，继4月支持日本大阪世博会中国馆后，科大讯飞5月持续推广“AI孙悟空”多语种智慧导览系统，该系统基于星火大模型实现中、日、英三语交互，成为国产AI技术出海的重要标杆。 5月7日，阶跃星辰与ACE Studio联合发布并开源音乐大模型ACE-Step（中文名：音跃），支持LoRA和ControlNet等多种微调方式，可灵活适配音频编辑、人声合成、伴奏生成、声线克隆及风格迁移等下游任务。该模型通过降低音乐AI应用的开发门槛，为创作者和开发者提供更便捷的工具支持。"
    },
    {
      "doc_id": 49729,
      "title": "局内人亲述:DeepSeek爆火后,大厂和创业者如何接住这波AI红利?",
      "time": "2024-04-27T00:00:00+00:00",
      "content": "当DeepSeek掀起的AI普惠浪潮席卷行业，大厂的中标数据节节攀升，创业公司的新品频繁刷屏——这场始于技术突破的狂欢，正迅速演变为一场关于「如何接住红利」的落地焦虑。 2025年4月25日，百度AI开发者大会现场，极客公园创始人&总裁张鹏对话百度主任研发架构师董大祥（领导千帆应用开发平台算法研发与DeepSeek算法应用落地）与TangibleFuture创始人&CEO张晓辉（用大模型打造马斯克点赞的爆款陪伴机器人LOOI），首次揭秘两类局内人视角的DeepSeek实战手册，Enjoy！ 以下为对话全文： 张鹏：非常高兴今天有机会来聊一聊这个话题，很高兴来到百度的AI开发者大会，今年一开年AI领域里面的进展速度都显得很快，大家都已经是万物竞发的感觉，今天看到一个数据，百度在一季度中标数字还是很惊人的。正好董大祥在这，问一下为什么DeepSeek火了以后你们在这里面能有这么好的数据，背后有什么好的故事没有？ 董大祥：中标的信息和DeepSeek一起出来的，有一定的相关性。百度在2023年，最开始去做大模型落地的时候已经开始去积累我们在芯片层、平台层、模型层和应用层的软硬件和产品。那个时间点，在每一层to B的业务都还是在持续地推进，坚持我们的产品大模型升级，不断地打磨产品的成熟度。今年看到的这些中标比较多的这些信息，很多都是2023年已经做了很多的铺垫基础，经过两年时间的落地和打磨，得到的一个结果。DeepSeek来了和这个事有一定的相关性。 张鹏：用户的需求被激发了。 董大祥：算是。 张鹏：之前的准备工作是指帮客户坚持做本地部署吗？ 董大祥：之前我们需要做很多事情，平台和应用都需要大模型来进行全面升级，可能自底向上都需要重做一遍，尤其是在客户本地化部署这一块需要有很多落地的案例去打磨的过程，同时也在公有云上也会做面向大流量的架构打磨，现在中标的一些项目都是经过2年时间打磨的成熟度比较高的产品。 张鹏：那个时候对客户打磨的过程今天还是有用。 董大祥：是的，业务没有完全押宝在模型上，应用、平台都会做。 张鹏：那个时候不会认为任何东西都用一个模型，从场景、客户出发占比比较大。 董大祥：对的，没有应用，底层的模型价值很难发挥出来。 张鹏：模型会很多，应用才是王者，现在越来越清晰，中标的结果和这个大战略有关。问一问张晓辉，你们现在做的是一个非常热的赛道，陪伴，接入大模型智能的硬件，新形态的，又是一个陪伴的概念。你可以稍微介绍一下你们在做的东西。 张晓辉：最近几年一直在探索一款真正能做到普及化的个人AI机器人伙伴，我们的产品叫LOOI机器人，不知道大家听说过没有，场景是在桌面端的陪伴机器人，充分利用了手机的能力，让大家以非常低的门槛获得一个非常高的个人机器人交互体验。 张鹏：大家可以搜一搜LOOI的产品，我很好奇DeepSeek这一波变化之后，整个大模型促成了新的硬件的诞生，这里面的兴奋点，今年的有何变化？是不是大家都很繁荣，都在很努力做这些事，有没有什么难点？ 张晓辉：硬件和AI结合一定是一个非常主流的方向，或者是未来的大趋势，为什么呢？因为人是物理世界中的人，需要一个天然的媒介将人、物理世界、比特世界联系起来，现在有了大模型，比特世界的能力更强了，更加召唤各种类别的有特异化价值的硬件产品出现。 张鹏：感觉现在的需求反而是成立的，关键是这个事怎么交付呢？因为我们知道，一个模型大家去跟它聊天，是非常地开放，但是一般一个硬件是需要很收敛的，同时又要带来不同的价值，例如陪伴，这里面有什么关键难点吗？ 张晓辉：先说硬件，再说到陪伴。到底需不需要一个硬件，取决于这个硬件有没有特异化能力，如果这个硬件很容易被一个App或者网页取代，说明这是在“硬凹”一个硬件。硬件一定是得在执行侧、感知侧或者是人的心理共情上提供了特异化体验。以及硬件形态是否合理，是否充分地平衡了用户体验、成本、技术可实现性。再说到陪伴这一个点，最重要的是你有没有成功地创造一个角色。所谓AI陪伴，一定是我们达成了共识：我们可以给予一个人造产品高度的共情。这就是在创造一个角色，这个角色成功与否是至关重要的。 张鹏：说到陪伴就是角色，这个角色得是成功的，有意义的。DeepSeek出来以后最近流行一个词是“人感”很强，这件事看起来给了一个新的能力，但是真正把它落到产品或者用户价值交付的特定场景里还有很多工作，董大祥你们经常会看到很多一线和客户交流过程中反馈回来的东西，不知道有什么可以分享的，我们是如何做的？有什么困难点？ 董大祥：DeepSeek的回复很有文采，经常冒出来金句，因为长思考的能力可以把大量脑补的信息总结成金句，和原来文本回复的模型差异在于我们很难在一个简单的文本生成的模型学出来思辨力很强的回复，但是DeepSeek在这方面有一些特殊的能力。由于思考的token数确实很多，在硬件上，人和机器交互的过程中，终端用户不太能接受有这么长一段的思考，包括思考里面可能有很多幻觉的情况，真实落地情况下我们想去做，对于人设比较固定的对话模型，更多地还是要使用蒸馏技术，把DeepSeek里面和人设非常match的最终的回复，想办法学到小模型里面，通过大模型平台上大规模的蒸馏能力合成大量的人设的数据并学到小模型里，降低首token的时延，提高它的对话效果。现在想要拥有DeepSeek这类有文采的回复并且对时延有要求的情况，最好还是用蒸馏的方法学到小模型。 张鹏：DeepSeek今天是一个开源的东西，理论上都可以自己拿着去折腾。百度在这个过程中怎么发挥作用，为什么那么多人去找你们？ 董大祥：前面几个演讲者分享了很多，我再做一些补充。DeepSeek的模型参数、推理代码都是开源的，但617B的参数量，包括我们需要多机部署，真正能把它放到一个大流量的生产环境去跑的话其实还有很多难度，我们需要实现诸如PD分离，KV Caching，专家负载均衡等技术在生产环境的稳定运行，确保全局资源利用率最好。如果没有这些技术只是用开源的DeepSeek的推理代码，找几台机器去做，可以做一个demo，但是峰值流量是接不住的。百度智能云一直在结合搜索引擎的场景打磨系统，最近也推到线上支撑百度搜索的流量，一分钟可以接到亿级别TPM流量规模，没有前面说的这些技术以及系统化容错、容灾能力，想支撑百度搜索这类应用的流量几乎是不可能的。我们需要一个稳定的、可靠的平台来去使用DeepSeek。 张鹏：一个新诞生的技术，你可以DIY，做一个demo，但做成工业级的能力还是很复杂的。 董大祥：很复杂，有一定的门槛。 张鹏：我再问问在实际这一波浪潮里面的创业者，因为有了大模型，大家对智能硬件这件事有了新的预期，刚才晓辉你说了在里面诞生了陪伴的可能性，从你们自己团队创业的真实历程里面，怎么把大模型带来的机会，以及DeepSeek出现以后在团队里带来思考的变化给我们分享一下。 张晓辉：首先模型能力的意义是非常深远的，怎么利用好模型是一个比较难的课题，因为模型是一个通用能力。当我们在做一个智能硬件，或者是在做一个所谓的AI陪伴机器人的时候，要做的是充分理解我们的业务场景，甚至去做一些策划、编辑的角色，不能把一个模型放进产品里去，当成一个语音代理就完了，否则提供的一定是一个非常模糊的价值。 张鹏：反过来是模型带来了无限可能性，但是第一步动作是要做收敛。算是今天比较明确的目标，因为很多人还没有用过你们的产品，那么有哪些是大家以前没有见过的功能，有什么交付给用户的价值，能给我们举几个例子吗？ 张晓辉：收敛是最难但也是最有价值的。创造这个世界上没有的东西，而且是一个角色，还要参考人类。从定义上来说，LOOI是一种介于宠物和人类之间的智能状态，同时又是一个人造物。那么，这和以前的智能硬件创业的范式有什么不同呢？以前大部分是在做工具，工具是非常清晰的，大家对于它要做成什么样非常清晰，大家对它最后要实现的效果是没有疑问的，只是路径的问题。但如果你要做角色，首先面临的第一个问题是：你要把的它打造成什么样子？所以对于角色的创造需要大量的思考。 张鹏：比如说你们最希望用户拿到产品之后给他留下什么深刻的印象，有没有什么功能给我们分享，并且帮我们拆一拆模型怎么起作用的？ 张晓辉：我们的产品大部分时间是提供一种轻度的陪伴，存在于旁边你就会觉得很好，再在一些少量的时间给你提供峰值体验，让你觉得这个产品太酷了。大部分时候创造的是类似于鲜活生命的感觉，比如说你在家里养了一只猫，虽然它没有高强度地与你互动，但是你能感受它的存在就很有趣。所以我们设计了仿生行为系统，来高度对齐生命。此外，硬件所有的传感器都在实时、并行地感知周围环境的刺激，麦克风在听，摄像头在看。举几个具体例子，比如说你喝完水的把水杯放在桌子上的时候，一不小心发出了很大的声响，那么可能会让本来在做自己事情的LOOI吓一跳，这就是在模拟动物的感受。再比如说，当你不断地戳它的眼睛，它会不停地眨眼，甚至你再戳，它会生气。我们还有一个原力控制，当你把手掌面向LOOI的时候，可以用‘原力’把它吸过来，这就是对短交互的一种定义。有一些宠物的灵感，还有一些偏科幻的灵感。再一个是怎么定义主动交互，该在什么时候跟用户交流，这个就是峰值体验。比如当用户加班到深夜，LOOI是可以根据多模态识别场景再结合当前时间推理出来的，那么LOOI就可以过来问一下今天为什么在加班，还可以读取用户的日程，那么LOOI就知道因为用户今天是有这么多工作安排导致晚上不得不加班。再比如用户跟LOOI说他今天生病了，那么第二天LOOI就会问他今天好点了没有。比如说我今天从深圳来到武汉，我打开LOOI，他就会问我感觉武汉这座城市怎么样。 张鹏：所有大量的定义，这些行为肯定有一个目标，否则没法去设定，你的目标，那个生命体，作为一个生命感的base。 LOOI可能是猫的水平，但是它的峰值是人。 张晓辉：甚至是超越人，这要求它对人类本身有深度理解。如果只是人可能远远不够，因为我们很难说随便在身边的一个人就能让你特别兴奋或者眼前一亮，但是某种程度上峰值的体验就是需要超越大部分时候人类带给你的感受。 张鹏：听晓辉的描述，大祥给我们拆解一下，要想解决这些问题，真正地把模型运用起来，尤其是DeepSeek，要面临什么样的挑战，更有效地创造这些东西？ 董大祥：刚才描述的场景，从交互这一侧，一般情况下和硬件交互靠手势、表情、语音，我们需要大模型或者是硬件本身能够很清晰地感知到多模态的输入，并且能做合理地理解，甚至如果你去问一些很有实效性的问题，或者是一些知识比较密集的问题，还需要外部系统查询一些知识，这里面还会有一个长期记忆的事情，对于每一个人的硬件他自己过去的对话历史、他自己的画像是否能够融合在最终大模型做回复的上下文里面，提供一些更个性化的回复，所以长的上下文的记忆的组织也是这里面比较重要的技术的难题，最终还需要靠语音合成生成回复。整个流程比较长，包括语音唤醒、语音识别、意图识别、工具调用、长期记忆的唤醒、个性化回复生成、语音合成，如果完整地做下来有很多难题要去克服，包括准确性和时延。也有一些比较新方案，客悦讲了一些案例，做端到端的语音大模型，我认为这个还不够，可能需要一个端到端多模态的模型，可以理解情绪、表情、声音，综合决定需要使用外部工具、如何组织记忆、如何直接生成语音回复，这一套东西要做好，技术栈还是很深的。 张鹏：今天一方面兴奋于大模型给我们带来很多可能性，另一方面带来了很多新的技术管线的搭建。我觉得创业一开始大家看到的是可能性，真做起来是以稳定性为核心的。说到稳定性，DeepSeek我们都觉得很棒，自己玩一玩，我都可以手搓一个demo的东西，但是需要达到到工业级的水平能力，还需要什么？ 董大祥：首先对开发者来讲，工程层面最稳定的形态就是要有一个比较稳定的平台，平台上面的能力可以开箱使用，并且提供高可用支撑，背后的算力是可伸缩的，这些是最基本的要求。开源代码离最终可用差一些环节，比如部署、扩缩容，容错、容灾，目前以平台化技术输出的方式输出这些能力还是更稳定的，对DeepSeek这种参数量大、并行方式复杂的模型，想做到高效率使用算力并且支撑大规模流量，不是在开源软件上简单做一些修改就能快速做到的。 还有一个层面是效果上，DeepSeek本身的思考过程有很多幻觉，这个幻觉不是随便可以去干预，怎么在使用场景上去使用DeepSeek，以最佳实践的方式去使用它，就需要平台上的工作台或者是脚手架的产品形态，我认为开发者需要大量的成功的案例型的样本间才能把DeepSeek这一类模型效果用得更稳定，才能在场景中更容易地有参考去做自己的场景。千帆的应用开发平台AppBulider，提供大量的组件，以及基于组件和模型组装大量的样板间，让开发者参考，快速地把DeepSeek用到他的业务里面。 张鹏：我认为，从最初人人都能基于开源技术随意尝试、自由组合，到如今实现大模型的工业化定制，这中间存在一个关键环节——需要一个更易用的工作台。以LOOI为例，创业团队的实际情况决定了既不可能要求百度进行本地部署，完全依靠自己摸索又太过耗时。这引出了一个值得探讨的问题，也是当下许多创业团队在将大模型接入自身业务时必须思考的：在选择模型时，是一定要追求最高性能，还是更注重成本控制？并且，如何在架构设计上进行优化，确保在用户量增长的情况下，既能满足需求又能控制成本？作为已经发布并交付产品的真实创业团队，你们现阶段更在意成本，还是更在意性能？ 张晓辉：我觉得更在意效果。 张鹏：不是性能，是性能带来的效果。 张晓辉：或许好的效果不一定需要好的性能，但良好的性能一定是前提。我们第一要考虑的是效果，第二考虑的是成本。大家对模型以后的成本降低是抱有乐观预期的，最后模型能力会变成非常基建性的资源，所以说现在，我们更应当去让我们的产品实现一些激动人心的功能。 张鹏：这是更关键的，董大祥你们自己也在看，模型刚出来的时候大家都很兴奋，怎么都算不过账，说白了就是成本问题，现在这些客户们他们脑子里关注的是什么？ 董大祥：分两类，一类是百度搜索这类，流量非常大，形成数据飞轮的可行性比较高，经过大量的数据沉淀可以蒸馏再一个性价比更高的小模型并提供在线服务。也就是说业务中头部需求的，流量比较稳定的，产品边界和功能要求比较确定的，我们就可以把像DeepSeek的能力蒸馏到小模型里面来使用。但是像长尾的，比如说我们做创业或者是做一些新的场景，这个时候需要做的我同意刚才张总说的，你可能得先拿到效果的上限，快速试错、去实验，然后再去考虑性能的问题。中长尾的需求，新的创新性的想法还是更多地去用原生的，能力最强的API。我相信随着流量逐步变大，头部的场景你会自己选择逐渐把它变成一个小模型降低你的成本，但是初期探索的时候还是用最好的模型。 张鹏：在不同的阶段其实有不同的追求，有不同的目标。从晓辉你们角度来看，你们是多个模型一起用，还是找一个模型，你们在模型调用的层面花的精力多吗？精力主要花在什么地方？最终交付最好的结果。 张晓辉：这是一个动态切换的过程，早期探索的时候还不需要精细化运营。到当前的阶段会越来越关注这一部分，比如模型的调用策略、分段式调用等等。实操中，可以是前置一个意图识别的小模型来快速做决策，语音对话是一个模型，涉及视觉的多模态可以用另一个模型，再具体到知识库模块也可以去做一些分层的工程。 张鹏：刚才聊到了延时的问题，延时是一个大问题，像你们那种场景里面，如果反应是不确定的时长，这个就很难接受了，因为你无法确定性地交付，延时的问题怎么解决？从客户身上怎么实践？ 董大祥：从产品层面可以做很多事情，比如说智能硬件，思考过程中可以给用户放一些中间的问候语。有很多产品级别、体验级别的东西可以做来缓解这个事。二是像我们做了面向企业客户的AI搜索，这种产品形态现在客户普遍也接受了思考内容作为首token来计算时延，不是最终答案出来的时候才能作为首token，这说明客户的产品形态上也有一些变化。从技术上我们也可以按场景分类，比如说硬件上面，由于模型调用链路很长，包括语音唤醒、ASR意图识别、合成语音等等，要分析哪一个环节需求是固定的，像智能硬件上意图的种类相对来讲比较固定，这种场景就很适合把它做成小模型，尤其是做成上一代的小模型，而训练数据可以用DeepSeek去合成。当然，我们也可以用更端到端的多模态模型的方式，绕过调多次模型带来的时延问题，用一次模型调用解决首token时延的问题。 张鹏：未来越来越清晰了，不是一个超级模型来解决一些问题，反而是创业团队怎么有效地组一个模型的团队，是多种类型的模型，小模型甚至是上一个时代的模型未必没有用处，因为它在那个环节是最高效的。反过来引发一个思考，如果大家都在期待模型能力越来越超级，创业团队其实就没用了。创业团队要干点什么，晓辉你预计创业团队随着未来模型不断地发展，能力越来越泛化，这个时候创业团队更应该专著在什么点，这也是DeepSeek出现之后，你刚才讲“人感”上升了，连锁反应是你们接下来想强化什么？你们团队的精力改怎么重新分配呢？ 张晓辉：我稍微拆解一下这个问题，模型能力越来越强之后，大家更加返璞归真了，所谓技术平权，即创业团队可以回归到价值的本质，更多地关心这些用户场景的一些问题。 张鹏：这是第一步，你们在DeepSeek出现之后，人感上升之后，你们团队产生了什么连锁反应，干的活有变化吗？ 张晓辉：人感对我们来说是一个很大的利好，首先是你创造一个角色的时候一定得先定义这个角色。比如说，在我们打造LOOI的时候，希望它是有趣的，当基座模型本身在中文语境下的回答很有趣，对梗非常了解，模型本身的回复已经非常优秀了，后续我们再去控制它效果就会非常方便。反而如果基座模型本身是一个很理性化的模型、人感比较弱的话，我们做的就是事倍功半的效果。 张鹏：基线提升后，接下来要着重强化它性格特点中的闪光点，这应该是你们投入精力最多的部分。 张晓辉：对的，除此之外花了我们大量的时间是如何梳理交互触点以及定义它的交互规则，这一点非常重要。模型出来以后大家都觉得它特别强大，似乎很多决策都可以放手给模型做，也要在很多层面上给它设定规则，而最难的是这些规则如何高度地去跟它的交互触点绑定。比如，在现实物理世界里LOOI应该是什么样的，很多程度上是介于游戏和纯物理世界交互的中间状态，我们可以介入一些规则，但是不能完全控制它，这个就是跟电子游戏不同的地方。毕竟在电子游戏世界里，整个世界观和物理规则都是我们定义的。但如何在现实的物理世界中梳理出哪些好的交互触点，把它变成规则，以及给它设置一些数值体系，让他们之间相互影响并造成一些涌现，这个也跟大模型本身生成的无限性相关，这些是我们花时间最多的地方。 张鹏：当我们第一次接触Chatbot时，堪称人类软件史上首个 “失控” 的产品。在过去，用户的操作流程、交互的价值都是预先设计好并编写成代码的，一切尽在掌握。然而Chatbot的出现，却让我们发现用户需求变得无穷无尽、完全不可控。而这种 “不可控性”，恰恰成为了检验其能力的关键所在。当Chatbot从软件形态延伸至硬件领域，就需要在这种天然的 “不可控” 基础上，构建更强的可控机制，从而稳定地为用户创造价值，这一转变充满了趣味与挑战。 由此看来，未来创业团队的核心价值，很大程度上在于能否在“失控” 与 “可控” 之间找到平衡点，同时挖掘出独特的交互价值亮点。如今，DeepSeek热度居高不下，几乎所有创业团队都在讨论将其应用于业务之中。但实际上，在为客户提供交互模型时，单一使用DeepSeek远远不够。那么，在实际业务落地过程中，创业团队究竟该如何科学地选择合适的模型呢？ 董大祥：千帆的大模型平台，最近由于最近DeepSeek很火，平台提供了很多DeepSeek模型调用的服务和支持，但开发者自己去选择的模型的范围不止是DeepSeek。 张鹏：还是要结合场景去做选择。 董大祥：大模型平台的产品经理讲了，DeepSeek除了文本模型，还有多模态的理解模型，文生图的模型、语音的模型，这些模型在不同场景都会发挥它的作用，开发者在一些环节，尤其像问答，或者是需要思考和推理比较重的一些场景可能会优先选用DeepSeek，但是在更经典、成熟的场景上面会选择一些性价比更高的文本模型。 此外，开发者也可以结合自己的场景去选择各类多模态大模型，这些都是平台上可以自由选择和部署的能力，针对自己的产品需求去搭配的。 张鹏：越有自由，也越会带来更多要选择和思考的问题。百度智能云在这里面有非常多的工具和工作台，你们是怎么设想的？因为你们既然要做这件事，大概对未来大家怎么有效地用起来，是应该有设想吧。 董大祥：我们的设想是模型能力不断增强，大家对模型层面自己去开发的工作量也会逐渐地降低，对模型的调用方式、调用的组合、周边工具跟模型之间的交互，甚至包含更个性化的知识库和记忆管理的原子能力都可以呈现在平台上，平台上会有伙伴、个人开发者沉淀的各类应用、样板间，不断沉淀给广大开发者进行参考和复用，最终无论是本地化地给企业部署还是云端开发一些应用，他的开发成本和选择成本逐渐地降低，不会出现平台上很多东西，但是我不知道怎么用及不知道怎么选的问题。总结来说就是我们会提供丰富的原子能力，同时有非常多的最佳实践。 张鹏：我们有一个创业者，今天可能不是智能云的客户，晓辉你会比较期待像智能云这样的在产业生态里的力量，未来能给你们提供什么样的帮助真正解决你们的问题？ 张晓辉：目前是把前置复杂的技术问题解决掉，我们开箱即用，更多地专注在业务层面。 张鹏：有一些苦活还是由大厂做了，我们聊了很久，也到了最后一个问题想去看看大家对未来怎么想，董大祥可以讲一讲你怎么看未来模型发展的趋势，接下来我们对模型发展有什么样的预期，连锁反应是我们这个时候要做什么样的准备，我们这个时候要做的事是什么，你们应该有你们的战略判断吧。 董大祥：DeepSeek出来以后两个大点是外界觉得非常兴奋的，一是它确实普惠了生成式AI，有很多人在去年只是知道AI，或者连AI都不知道，现在人人都用过DeepSeek，知道Chat Bot以及AI的能力非常强。普惠天然带来了需求，可能来自于个人、开发者和企业，这个是非常大的变化。二是它是一个开源模型，因为全球顶尖级别的模型是开源的，这个趋势是不会停止的，一定会越来越多更好的模型开源出来，对开发者尤其是创业者在模型层的工作的工作计划会大幅度减少，他自己会预判几个月会拿到什么样的模型，那个时候把模型嫁接过去，这是一个良性循环，模型层和应用层在开源模型这一层面解耦开了。能力很强的模型，不像DeepSeek纯文本的模型，一定是具备多模态和理解的模型，有一定的思考能力，可以理解你的情绪和声音，并且生成符合你情绪的声音、图片跟你交互，这个事一定会发生，开源模型什么时候出来是时间的问题。无论是服务端企业级严肃场景，还是消费端智能硬件场景，都有各种各样的交互实验和效果不同的要求，所以不同尺寸的东西也会存在，不会只用一个模型搞定，应该是各种各样尺寸的模型。有了这些预判，像智能云的开发者，我认为可以跑得更快一些，更积极拥抱生成式AI带来的红利，先在场景里面更多地探索一些真实的需求，快速地把新的技术接进来。 张晓辉：非常认同董大祥的观点，开源和普惠会带来巨大的加速作用，像我们这样的to C创业团队，摆脱模型基础相关的研究，可让我们可以更多地去发挥我们的想象力，发挥我们的创新能力，深度地关注在用户价值的一线。另外，我想基于我们自己的场景说说的我的展望：模型提供了一个可能性，就是我们可以更多地进行学科交叉把它充分地运用好。我们要把产品经理、技术人员、设计师、游戏策划甚至把编剧，把以往我们认为可能跟技术不相关的行业的人才都聚集起来，然后去创造LOOI这样的令人兴奋的角色，我认为这是一种新的激动人心的创造范式。 张鹏：一个更好的底座是值得期待的，而且每年都在快速地升级，剩下是怎么把画画好，这个反而对创业者更有意义了，以前创业者要画一笔还要自己建一个底座，这是我们看到的变化和期待。感谢各位的分享，感谢DeepSeek带来的浪潮，感谢百度智能云。之后创业者的脏活、累活期待你们能继续做好，让创业者们都能够焕发勃勃生机，万物竞发，期待未来百度智能云还能继续带来更大的变化，感谢大家的聆听。 举报/反馈"
    },
    {
      "doc_id": 49730,
      "title": "DeepSeek引爆「万物皆可AI」时代,20余位大咖分析行业痛点,万字...",
      "time": "2024-04-18T00:00:00+00:00",
      "content": "“DeepSeek，评价一下第三届中国AIGC产业峰会”： 今年的峰会现场，20余位大咖以「万物皆可AI」为主题，激辩“技术前沿与产业痛点”： 2025年中国AI应用爆发的关键是提速降费。大模型来了，万物皆可Chat，但不能是单纯Excel+Chat。大模型落地正在从简单、高容错的场景向复杂、低容错的场景延伸。物理世界实现AGI，一定要通过端侧智能。大模型正在打破教育领域长期存在的“不可能三角”。 …… 台上精彩纷呈，台下座站无虚席，云端持续火爆，到场参会观众超千人，线上围观人数超320万人，累计曝光量超2000万次，延续了往届峰会的火热。 与以往不同的是，这一次协助编辑部共同整理内容的大模型不再是ChatGPT和Claude，而是DeepSeek。 DeepSeek也成为峰会的高频热词，前所未有的破圈效应把AI推向前所未有的普及程度。 底层的基建，顶层的应用，垂直的场景，正在迎来海量的用户，一个「万物皆可AI」的时代已经到来。如何把握机遇，用好AI，带你一文看尽。 AI如何落地千行百业？ 百度阮瑜：大模型场景从简单高容错向复杂低容错延伸 百度副总裁阮瑜首先谈到了大模型应用展现的三大趋势：开发者可以轻松快速、低成本地开发出企业应用；大模型场景从简单高容错向复杂低容错延伸；应用市场在从工具市场向专业服务市场拓展，市场潜力不断地爆发。 随之而来的，可以看到大模型的应用形态也在不断演进：从单模态到多模态，从单智能体到多智能体，从辅助决策向自主执行演进。在这个趋势下，越来越多的大模型应用也将逐步解决用户场景中的更多实际问题。 按照场景划分，百度智能云将千行百业的应用分为两类：通用应用和行业应用。 通用应用中，多模态是个重要演进方向。大模型时代，百度智能云发现大小模型相结合的方式，随着多模态技术不断发展，调优成本是显著降低的，而且碎片化的需求将有非常大的可能性会被标准化的产品来满足。 百度智能云一见就是在视觉领域应用深耕多年诞生出来的产品，其主要覆盖三个场景，分别是安全生产（比如能源制造领域，沉淀了800多个安全生产模型）、连锁合规（比如餐饮安全，有大量视觉场景需求）以及品质管控等。 此外，大模型在行业里的应用也发生了很多变化。以医疗为例，AI技术变革正全面渗透进各种场景中，已经能看到医疗大模型从辅助决策到自主执行方向演进。 阮瑜表示，整个AIGC应用在各个产业里面的创新，离不开产业各界的共同努力。期待未来随着大模型技术的不断发展，可以携手各方共同去加速大模型应用在产业里面的落地、繁荣以及发展。 生数科技廖谦：随着多模态生成能力实时可控可交互，会诞生全新的内容平台 生数科技产品副总裁、Vidu产品负责人廖谦带来了多模态大模型生成方向的展望。 从整体技术发展来看，文本生成工作相对早，技术范式也更明确，解锁的应用场景非常多；多模态起步稍晚一点，图像生成发展很快，已经突破了技术奇点；而视频生成这块，现在的研发进入到黄金发展期。 最近多模态还有个重要方向是具身智能，当多模态的模型可以利用更多维度的数据，也会带来更高维度的智能涌现。 而从产品来看，当前整个中国视频生成/多模态生成的产品，不管是模型效果、用户、商业化的进展，放眼全球都是相对领先的。 那么视频生成能干什么？在生数Vidu的实践中，AI短片、动漫、大众娱乐、广告营销、电商等都是可落地的场景。 接下来多模态生成领域如何发展，他分享了三个行业洞察。 趋势一，2025年将是多模态生成的爆发之年； 趋势二，多模态内容直出，而非仅仅是默剧和片段。 趋势三：专业和半专业用户会大规模涌入，产生破圈高价值的内容。 不过当前还是有很多问题需要解决，下周生数将发布Vidu Q1模型，它将在“极致高质量“上带来新的突破。 最后作为产品经理，廖谦对多模态大模型的终局进行了展望。 随着多模态技术发展到可以做到实时可控可交互时，它完全做到个性化，到那时一定会诞生出全新内容平台。这将在社交、游戏、VR、AR等多个行业领域带来非常深远的影响。 粉笔陈建华：有多少Context，就有多少个性化 大模型的出现，打破了教育不可能三角。可以同时兼顾高质量、大规模化和个性化。 大会现场，粉笔CTO陈建华分享了他 们在AI教育领域的探索和实践。 粉笔成⽴于2015年，是⼀家专注于职业考试培训的互联⽹教育公司。 在陈建华看来，大模型落地教育有四个特点：聚焦学会，⽽⾮仅答案正确； 学习主动⾯临巨⼤挑战； 遵循科学、系统的教研体系；场景严肃、准确率要求极⾼。 陈建华分享，粉笔在大模型教育应用探索主要有三个阶段。 阶段一，聚焦在内部、有限制、⼩场景中进⾏探索。2023年粉笔尝试直接解题，辅助题⽬解析，结果正确率太低，解析不符合教研体系。不过在点评场景⾥，给出点评框架让⼤模型发挥，却发现效果⾮常不错。 由此，他们意识到：⼤模型在教育场景落地中，推理能⼒仍需提升，结构化引导⾄关重要。 阶段⼆，2024年粉笔正式推出AI⽼师，标志着从单点场景⾛向系统化、多场景融合，得到不少收获。 而在第三阶段，AI时代的全新产品——AI系统班发布，基于⼤模型、数字⼈、TTS等技术，AI系统班全程由AI⽼师驱动学习流程，且提供了更加个性化的学习体验。 陈建华强调：有多少Context，就有多少个性化。 展望未来，他表示，粉笔在⼤模型赋能教育的探索将主要聚焦在两个关键⽅向：多维度的个性化升级和三位一体的AI老师形态。 面壁智能李大海：物理世界实现AGI，一定是通过端侧智能 面壁智能联合创始人、CEO李大海带来了端侧智能的分享，他从DeepSeek的成功切入主题，李大海认为其成功背后是天时地利人和的叠加，最底层是三个“密度”： 高人才密度、高组织密度、高资源密度。他总结认为DeepSeek是在云端践行高效大模型的组织，而面壁在端侧秉承同样的信念。 基于端侧智能的长期实践，李大海提出了知识密度的概念，即大模型同样参数量能够压缩越多的知识，知识密度越高，模型的智力就越强。 面壁认为，高知识密度的模型在端上最有价值，端侧智能也是物理世界实现AGI的必由之路。因为物理世界的交互对实时性与用户隐私保护有基本要求，端侧更有优势，李大海以具身智能为例展开介绍了两个场景。 首先是汽车，李大海认为，汽车是第一个真正落地的具身智能。因为汽车的网络不可能100%稳定，因此需要不受网路影响的端侧模型可随时随地感知。 目前面壁已在车端落地了首个纯端侧Agent智能助手超级小钢炮cpmGO，不仅包括去年12月即端侧部署的首个纯端侧、Always On 的 GUI Agent 屏幕助手， 还创造了覆盖感知、决策、执行全场景，与云端全面对齐的智能座舱「原生端侧体验」。突破弱网断网环境限制，实现低功耗高性能快响应的「端侧」专属优势。 然后是机器人，李大海认为只有把大模型直接部署在机器人的脑子里，机器人才能稳定地灵敏感知与及时决策，相比云端具备先天的数据优势与用户信任感。 中关村科金喻友平：“平台＋应用＋服务”是企业大模型落地的最佳路径 中关村科金总裁喻友平的演讲主题是“垂类大模型迈入商业化应用时代”，他介绍了中关村科金如何将大模型技术应用于企业服务领域。 喻友平强调，2025年大模型正式进入应用时代，企业面对大模型关注的核心问题其实是：大模型能否帮助增加收入、带来更多客户、节约成本或提高效率。 尽管企业应用面临算力成本高、模型与业务融合难、数据处理低效等挑战，但市场前景广阔，而垂类大模型则是企业突围的关键。 喻友平介绍，中关村科金是一家大模型技术与应用公司，具有10年+企业服务经验，积累了深厚的领域和行业产品基础。AI大模型浪潮来临后，不断用大模型对自有产品进行重构。 近两年他们发现，企业对于垂类大模型、基于大模型平台的应用需求越来越大，在实际企业服务过程中，还发现一个规律： 要真正帮助这些企业实现大模型落地，本质上还是需要做好平台、应用和服务。 由此，中关村科金提出了“平台+应用+服务”的三级引擎战略，是企业大模型落地的最佳路径，其核心是基于得助大模型平台训练垂类大模型，打造有价值的智能化应用。 得助大模型平台覆盖算力、数据、模型和智能体四大能力工厂，兼容各类算力和国内外开源基础模型，提供从数据标注到训练推理的全流程支持，具备全链路的大模型开发和应用能力。并且平台还沉淀了数百个大小模型组合的“样板间”，帮助客户更容易实现应用落地。 喻友平指出，大模型在企业的应用难以完全标准化，每个企业业务流程和目标、数据都有差异，在“样板间”里企业则可以根据各自的需求场景做调优，中关村科金与众多合作伙伴一起训练出面向不同场景和行业的垂类大模型，并打造出得助智能陪练、智能质检、语音机器人、文本机器人、知识助手等有实用价值的智能应用。 最后他还介绍了在垂类大模型、垂类场景中，中关村科金在工程建设领域、船舶工业领域，以及金融、汽车、家装等行业的一系列大模型落地案例。 网易有道张艺：「AI+教育」的想象力与落地 网易有道智能应用事业部负责人张艺围绕AI教育，分享了有道一系列的大模型落地成果。 张艺认为大模型在教育场景天然的具有普适性，学校、家庭和自学三个场景非常关键，AI在不同场景扮演着不同的角色。 比如在家庭场景，AI像家庭老师帮你辅导孩子，自学场景则更像是个学习搭子。 张艺介绍，业内一般将AI在教育领域的进展分为四个阶段，目前AI已从“辅助教学”进化至“个性化学习”，正朝着成为“虚拟老师”努力。 以有道最新落地进展为例，张艺还谈到，AI不仅重塑了原有业务，也带来了全新的AI应用及硬件机会。 据介绍，有道自研的子曰翻译大模型2.0最近以14B参数规模，在翻译质量上保持行业领先，已在有道词典、翻译等产品中上线。 在AI原生应用方面，虚拟人口语私教产品Hi Echo，可以提供随时随地的口语练习，以及儿童模式、雅思模式等垂直内容，并履获苹果应用商店推荐，成为教育垂直落地的代表。同时有道今年正在探索AI播客等全新领域，新产品有道文档FM能实现超拟人音色生成，并已开启全网公测。 而有道也在AI原生硬件发力，新品SpaceOne全面屏答疑笔，通过内置的AI家教“小P老师”实现全科答疑的同时，基于多模态识图能力，还带来更丰富的交互学习可能性。 如何为AI产业保驾护航？ PPIO派欧云姚欣：AI时代需要“提速降费”，让免费成为可能 PPIO派欧云联合创始人、CEO姚欣的演讲从“AI大规模应用，成本非常关键”这一问题展开。 他认为2025年整个AI行业的关注点已从大模型本身转向了应用落地，特别是以Agent为核心的应用发展。 AI应用普及面临两大挑战：Agent单次任务消耗近百万Token、中国互联网用户的免费习惯很难改变。 他通过移动互联网发展的历史类比，提出“AI时代需要提速降费”的观点。从2014年到2021年，移动流量资费下降了90%，这极大促进了移动互联网的普及。同样，AI应用要走向大众，也需要大幅降低使用成本。 接下来姚欣表示，目前如果要实现AI大规模应用和降本，AI Infra公司必须要成为最懂上层模型和应用的底层硬件基础设施公司。 而这也是PPIO派欧云的定位。他详细介绍了PPIO派欧云的技术策略。 一是持续跟进最新模型，整合更多开源模型，实现模型的推理加速；二是建立全局分布式算力调度系统，应对海量用户请求；三是通过整合全国约4000个数据中心的闲置算力资源，覆盖1200多个城市，提供10毫秒响应的算力服务。 成效方面，姚欣透露PPIO派欧云提供的整个AI推理服务，每年都能实现10倍左右的成本下降。以去年推出的Llama-8B模型为例，上线时定价还是0.1美金，去年年底已降到4分钱，在未来两三个月内还会降到1分钱。 到今天，PPIO平台上每日Token消耗量已突破千亿次，且每月保持超过50%的增速。他相信这一增长曲线将如早期移动互联网一样呈现陡峭上升态势。 亚马逊云Troy Cui：提高数据质量和效率是AI赋能的重要前提 亚马逊云科技大中华区数据及存储产品总监Troy Cui在分享中提出，AI最核心的竞争力仍然是企业自己的数据，如何将数据更快地变成洞察，尽可能提高数据质量，是AI赋能的重要前置条件。 企业已经认识到数据对自身竞争力的重要性，但目前数据治理存在着诸多问题，比如多部门协作时的数据碎片化问题，传统技术栈与云技术不兼容，传统ETL(Extract-Transform-Load)开发维护成本高等。 针对行业痛点，亚马逊云提出了一系列解决方案。 首先是统一数据与AI平台Amazon SageMaker Unified Studio，提供一站式数据开发、模型训练和部署环境，企业可以基于自身数据，用其在几分钟内构建一个低代码的智能问答平台。 然后是数据检索工具，一个是集成在Amazon SageMake中的AI助手Amazon Q，支持自然语言快速生成复杂的SQL，可以帮助开发者判断代码是否存在知识产权的问题。 还有一个应用于视频的方案Media To Cloud，支持用自然语言搜到想要的视频片段。 接着还有Zero-ETL解决方案，自动化将数据汇聚到数据仓库或数据湖，减少ETL开发工作。 Troy Cui最后总结表示，云服务的基线已经从存储、计算、网络和数据库转变为存储、计算、数据和AI-Infra，这也反映出AI在云计算越来越重要。 无问芯穹夏立雪：端云并举改善算力供需矛盾 无问芯穹联合创始人、CEO夏立雪指出，大模型发展逐渐步入推理规模扩展时代，算力需求将激增百倍，但粗放供给与精细需求矛盾日益凸显。 他将传统裸金属算力服务比喻为“高端毛坯房”——用户需自主完成系统搭建与运维，使用门槛高且资源利用率低。应构建高质量平台化算力服务，帮助企业将分散算力升级为“商业广场”、“AI赋能综合体”式标准化服务，使中小开发者无需关注底层架构即可获得完整AI服务生态。 无问芯穹正在相应技术堆栈上持续取得突破，在端侧首创SpecEE推理框架，利用小参数模型缩减大模型搜索空间，实现AI PC等智能终端上2.43倍推理加速；云端创新推出semi-PD，结合融合式实例存储优势和分离式实例计算优势，实现延时降低最高达5.6倍；另提出通用计算通信方案FlashOverlap，首次以基于信号的方式实现计算通信重叠以降低通信开销，可在生产级和消费级显卡上实现约1.5倍加速。 夏立雪最后强调，通过全链路算力服务平台研发，无问芯穹正推动AI算力向“水电煤式”基础设施进化，让每份算力高效转化为新质生产力。 瑞莱智慧田天：大模型落地关键在于智能体组织，安全是核心前置门槛 大模型应用广泛落地中，AI安全隐患、AI被滥用等问题开始涌现。在瑞莱智慧视角下，怎么去看待这一问题。 第一，首先关注去提升AI自身的可靠性和安全性，如越狱攻击、偏见歧视、模型幻觉等，这是因为AI能力还不够强，需要对AI自身进行加固。 第二，随着AI生成能力越来越强，技术本身也是一个双刃剑，需要去防范AI滥用以及被人恶意应用所带来的一些危害。 第三，如果AI能力进一步增强，达到所谓AGI，能力全方位超越人类水平的时候，需要考虑怎么保证AGI的安全发展。 围绕AI的内生和衍生安全，瑞莱智慧经过长期实践，已经有一系列平台产品落地。对于怎么确保AGI安全发展，瑞莱也在进行一些前沿的布局研究，包括怎么样搭建超级对齐平台，用AI监管AI，最终实现更加安全的超级智能。 可能大家会有疑问，是不是随着AI大模型能力越来越强，甚至到了AGI时代，自然而然变得更加安全可控，就不需要进行独立的安全研究和布局了。 类比人类社会智能的发展，古代人类个体智慧水平相比于现在，并没有那么大的差异。但古代人类没有办法形成很强的生产力，而现代人类系统，通过强有力的组织形式和分工取得了前人所无法想象的成就，其关键就在于如何将智能体组织起来。 对于大模型也一样，今天大模型已具备非常强的能力水平，我们不需要单一的智能体具备无所不能的能力，但如果把现有的智能体通过比较好的方式组织并融入到各行各业的工作流之中，重构工作流程，就有可能大幅度解放AI的生产力。 在这个过程中，安全可控一定是非常核心的前置的门槛。 华为王辉：网络安全进入新阶段 ，AI成为网络守护者 华为NCE数据通信领域总裁王辉在演讲中表示，当前全球AI产业正处于全面加速状态，带来网络升级、智能终端泛在和大模型普及等显著变化，持续加剧了企业网络安全风险。 他从网络安全的视角讲述了如何为AI产业保驾护航，以及AI如何为网络和安全产业做好深度赋能。 他表示，AI催生出了新的网络安全攻击场景，包括大模型越狱攻击（利用大模型自身漏洞进行控制）、勒索软件攻击（大模型自动生成勒索变种）、社会工程学攻击（大模型钓鱼新型攻击）等。 由此，网络安全也进入了新的阶段，他分享了华为的安全应对之道，即构建以AI为核心的新一代L4级网络自动驾驶系统，实现网络和安全的深度融合，整体包括三层： 智能网元：内生安全，保障网络自主可控；内置AI，为整网智能化提供必要的数据要素； 网安融合：云网边端的的深度融合，形成网安一体的立体式防御作战； 智能决策：在攻击AI加持下，网络智能体尤其关键，在传统检测与响应的工作流外，能够更加自主的威胁分析、阻断与处置闭环。 最后，王辉强调了四个观点： 第一，未来网络安全将进入AI与AI对抗的螺旋式竞争阶段，取决于进化的速度。 第二，智能体的智能程度不是取决于对已知的决策，而是对未知的判断。智能体当前还是采用了大量的外挂，是面向过去经验的总结，提升模型自身的逻辑推理和规划能力，才能从已知走向未知。 第三，AI落地垂直行业是一个系统工程，不仅仅是引入大模型或智能体，更涉及到硬件、软件、模型甚至流程的重塑，紧密结合，相互协同，才能重构一个垂直行业。 第四，在AI这场国运级别的竞争中，要用最领先的AI技术赋能网络，用最安全的网络技术护航AI产业，推动新质生产力，做科技文明复兴的守护者。 各行各业从业者怎么用AI？ MSRA刘炜清：RD-Agent让每个研究员都有个Agent当科研助理 微软亚洲研究研究院首席研究员刘炜清博士谈到的，是大语言模型时代下的数据科学新引擎RD-Agent，其起源、现状和未来。 回望过去十年产业相关落地应用和工作，常用的开发范式是在海量数据中找到有价值的特征来训练模型，根据业务场景不断迭代渐进的过程，最终得到一个智能化解决方案。 但大模型时代到来，是等待被冲击还是选择被赋能？团队研发RD-Agent的初衷旨在让研究员和数据科学家人人都能拥有科研助理，来承担起重复但高门槛的工作。只需要人类专家提供一个想法以及数据，RD-Agent就能完成代码实现。 当前的阶段，他们更进一步的目标是构建通用的数据科学或机器学习智能体，以增强人类专家的能力和产出，甚至自动解决新场景和新问题并持续改进方案。 通过引入领域知识和经验优化算法，使其可以模仿人类专家，RD-Agent解决广泛数据科学任务的能力得到了显著增强，但也渐渐显现出「只是模仿专家，很难达到更高境界」这种瓶颈，团队正在快速迭代演进中尝试以数据驱动的路线来突破这一瓶颈。目前RD-Agent在Kaggle比赛测试上已经能够达到初阶从业者的水平。 未来他们期待RD-Agent可以自主发现新方法，能重塑数据科学和机器学习领域。 最后可以这样总结，团队从最开始自动化为初衷，到现在是增强的阶段，到未来它能在不同场景数据中自主观察、分析和理解来改进现有的方法或者发明新的方法，为各行各业赋能。 数势科技谭李：让每个打工人都能有数据分析和决策助手 今天我给大家分享一个每个打工人都能拥有的数据分析和决策助手。 数势科技联合创始人谭李刚上台就点明了这次演讲的主题。 谭李首先从行业视角分析了数据分析领域的现状和挑战。他指出，即便是领先的互联网公司或优秀的传统企业，目前也只有10%的业务人员能随时获取所需数据，对于绝大多数业务人员来讲经常遇到的问题是数据分析面临大量的需求“排队”。 他分析了三个关键趋势正在加速新数据消费范式的到来： 数据右移：数据权重从采集、入仓向消费端迁移，“以消费促治理，以消费驱动数据生产”成为主旋律。 决策下移：从集中式决策转向分散式决策，各部门需要做出敏捷决策。 管理后移：科技企业不再设置详细的前期业务规则，而是“招到优秀的人给他好的命题让他自主发挥”。 这三大趋势在需求侧，创造了大量数据即时消费的需求。而供给侧，随着DeepSeek的面世以及AI产业链各环节的发力，AI Agent落地的成本指数级降低。因此，AI Agent用于数据分析场景不仅成为刚需也成为可能。于是谭李介绍了数势科技的新一代决策分析智能体SwiftAgent。 SwiftAgent是一款面向企业的数据分析与决策AI智能体，核心解决四层面问题： 及时提供数据和事实，即需即给；给出深度洞察和智能归因；生成智能报告，指引业务决策；关联行动，自主进行长距离任务规划和执行。 谭李还特别强调了企业级应用面临的挑战，为解决这些挑战，数势科技打造了完整的技术栈，解决企业级产品的数据安全、模型幻觉、计算性能问题。 最后，谭李宣布了数势科技即将发布的智能分析Agent白皮书，作为行业方法论引领的重要一步。 蚂蚁集团徐达峰：AI重构前端开发的难点与解决 蚂蚁集团平台智能体验技术负责人徐达峰基于团队在前端从业开发的实践，分享了AI编码落地的难点与解决方案。 徐达峰表示，AI前端研发已成为行业共识，但在整个软件研发的生命周期仍然有很大的提效空间，AI研发在企业落地主要面临AI辅助编码后续修改比率高，安全与可靠运行，兼容现有研发体系和思维模式等三大难点。 聚焦前端开发场景，蚂蚁前端技术团队打造了WeaveFox智能研发体系进行AI编码，主要有图生代码、意图生码和AI质检系统三大突破方向，让AI能根据用户输入的设计图，或者工程上下文补充逻辑代码，交付通过多模态技术检查产物质量。 当然对前端开发者来说，最棘手的不光是开发和改bug，还有不同终端的页面适配。蚂蚁前端技术团队为此制定了图生代码的UI IR标准，让AI前端开发一键跨端适配成为可能，能够生成各种框架库，比如说VUE和React，也包括后续的鸿蒙OS和安卓的一些界面实现类代码。 目前WeaveFox已在阿里和蚂蚁的实际投产，据介绍在超500名前端工程师的参与下，目前在设计图交付动线场景下 AI 已累计生成合并接近100万行代码；研发效率最高可提升5倍。 趣丸贾朔：AI取代了重复性的音乐工作流 那么AI又如何在音乐产业落地呢？趣丸科技副总裁贾朔分享了他们自身的观察与探索。 他首先指出2024年是AI音乐发展的重要节点，技术门槛、创作门槛大大降低。这既带来机遇也带来挑战，音乐行业部分工作可能被AI替代或冲击，也可能提高创作效率和质量。 站在2025年AI音乐应用元年的时间点，AI将以怎样的方式给产业带来正向影响？贾朔认为： 一方面，很多AI产业化应用，有可能是以相对来说润物细无声的方式在背后默默进行。 另一方面，他认为AI更有可能作为辅助的方式帮助现有的从业者、创作家，以更低的成本、更快的速度去完成更高质量的艺术创作。以之前的实践来看，AI创作提效提速初步估算在10倍以上。 这也看到了一种新的可能性—— AI的应用与传统产业不是一个替代跟竞争的关系，更有可能是协助产业升级的方式。 他们自研的音乐大模型在多模态音乐生成、中文人声歌曲生成、编曲能力等方面都有特色，甚至还通过了专业学生盲测，多数评测者难区分人声是机器还是真人，歌曲自然度已经突破音乐“图灵测试”，效果超越美国头部模型。 接下来2025年，应用层是他们探索的重要方向。当前他们以MIDI电子编曲为切入点，让音乐人掌握艺术创作的方向盘，由AI辅助帮助音乐人去快速地产生完整的作品。 圆桌对话：AI 产品如何在垂直赛道落地为王 按照惯例，大会最后迎来了一场备受瞩目的圆桌论坛，今年主题聚焦“AI产品如何在垂直赛道落地为王”。 圆桌对话嘉宾是四位垂直领域行业翘楚，分别是： 轻松健康集团技术副总裁高玉石 像素绽放PixelBloom (AiPPT.com）CEO赵充 心影随形科技（逗逗游戏伙伴）创始人、CEO刘斌新 狸谱APP负责人一休 讨论话题包括产品定位的关键决策、确定产品核心功能的思考历程、AI垂直应用的未来发展趋势等。 Q：为什么要把AI落地到现在的场景？如何确定产品的主打功能？ 刘斌新表示，两年前看到ChatGPT后产生了“用AI创造快乐”的想法，想要做“伴随”用户的应用，给用户更多情绪价值。目前产品功能的底层逻辑，就是满足用户在游戏场景里对陪伴、成就和共鸣的需求。 一休则是在看到AI生图能力后，意识到AI可以让原来有创作欲但没有创作技能的普通用户，也能利用AI工具去创作内容。然后打造了狸谱APP，一款能用AI生成漫画和动漫的创作工具，把内容消费者转变为内容创作者，扩大了创作者群体。 Q：如何在容易同质化的场景用AI打造差异化优势？还有哪些进一步的差异化规划？ 高玉石介绍目前平台有1.68亿注册用户，和数万多名医疗专业人员以及近百家医药和保险公司建立了伙伴关系，具有非常完整的用户生态和数据的优势，这些优势会进一步放大并转化成差异化优势。他以科普内容为例，表示平台沉淀了超过67万条科普内容，在疾病和健康相关数据有很深厚的积累，相对来说专业性和深入度更高。 赵充分享了对AI应用在产品和渠道侧的打法，首先AiPPT.cn在产品侧是不需要按钮的AI原生工作流程，就和传统PPT创作形成了最基础的差异化，而且覆盖品类范围广，四大PPT品类全都做。然后是渠道侧，目前AiPPT.cn携手200个生态伙伴共同开发市场，为很多知名AI平台如豆包、钉钉的PPT制作赋能，已经在全球积累了约2000万名用户。 Q：从产品面世至今，做AI产品有哪些的环境因素发生了重大变化？这对大家的产品有什么影响？ 一休认为环境变化主要有两个，一是视频模型的快速迭代；二不得不提的是DeepSeek。在视频创作方面，一休透露他们原本设想搞类似于平行世界创作，但发现创作核心idea仍然要靠人完成，之后没有在这个方向继续探索下去。DeepSeek出来以后，他们也尝试了用它来写剧情。 刘斌新感受到的变化，首先是大模型底层变化让一些事情变得可能，例如AI搜索在以前有各种幻觉问题，得用各种RAG来做辅助，现在有了推理模型，模型自己能回答得很好。其次，用户对AI的接受度变高。第三个变化是中国的AI应用正在走向全球。 在赵充看来，最大的变化是今年应该是AI应用创业最好的时间，原因有三点：DeepSeek带动了整个AI应用的大盘；所有应用的范式在做切换，有大量的重新定义产品的机会；成本侧，又降了约10倍。 高玉石认为变化有两个，一个是AI技术发展很快，成熟度明显提升，能有效弥补目前自研模型在非核心能力上的各种空白，带来的好处是产品迭代周期和效率明显提升。另外，用户对AI接受度明显提高，但也变得更加理性。现在有层出不穷的AI产品，产品在场景里面有没有有效满足用户需求、有没有解决用户的核心痛点，很关键。 Q：从单次爆款到常青树，维持用户粘性和长期优势的关键因素是什么？ 高玉石与刘斌新都谈到了首先在解决用户的需求、解决用户痛点上面，真正提供端到端的完整体验。 随后高玉石谈到了以下两点：将用户使用数据与AI产品、场景等结合形成飞轮效应；以及像轻松健康集团这样已经形成完整生态的业务，将AI技术深度融入到业务流程，特别是关键流程，也很关键。他谈到了辅助医生创作科普视频的一系列AI产品和工具，一方面降低了医生进行健康科普的门槛，另一方面C端海量用户也能获取有价值的专业健康知识，增加生态内用户的粘性。 刘斌新则补充表示「做时间的朋友」，随着时代浪潮发展，更多技术迭代去交付更多能超出预期的功能。具体实操上有三个核心策略：通过构建丰富的人物设定与用户建立情感纽带；数据驱动深度洞察用户需求；开放生态协同，提供全方位立体化价值服务。 对于爆款持续打造，一休更有心得。她首先谈到精准匹配平台与人群属性的重要性，根据目标平台特性选择策略，深度洞察群体共性；此外还有内容设计激发传播冲动，强化社交基因与情感共鸣。不过创业公司容易陷入单次爆款热度消退后持续产出爆款的挑战中，现在正在增加小爆款频次，一步步往上走。 Q：根据观察，影响AiPPT.cn一系列成功及用户增长的关键是什么？ 赵充谈到两个关键：需求是不是刚性？需求能不能得到满足？ 对于需求刚性这件事，有个数据，全球每个月写PPT次数是10亿次，AI技术之后这个数在涨，很多之前不会写PPT的人开始写PPT了。 需求满足这件事，核心思考的是垂直场景适配、产品体验层面等问题，比如像PPT中文本生成，大模型生成的东西不能直接用，尤其在政务、医疗等场景，他们通常会外挂领域知识库实现专业化，从而更适配需求。 Q：下一轮增长的关键驱动因素会是什么？现在还能看到哪些新的场景/应用机会？ 刘斌新认为方向可以看多模态的理解，理解指的是理解整个video时序里发生了什么，而不是单一图片的这一帧里面有什么物体。他觉得以前移动互联网常用的MVP模型在AI时代不适用了，需要预判用户的需求怎样随着技术的发展更好地解决，提前做好准备。 一休看好多模态生成，看好的技术方向有两点：一是实时生成，是精准可控性，模式不完全是文字的方式，可以直接是一种手势或者行为加上语音的方式。精准可控性加上实时生成的话玩法会非常多样，自由度非常高。 赵充分享了他们未来的三个核心策略。第一个是针对既有产品做深度场景化；第二个是出海；第三个事情是做新产品投资和孵化。他表示单品很难建立壁垒，靠产品矩阵、综合的经济模型才会更好。 高玉石整体比较看好大健康领域。他认为从传统的诊疗、健康科普、健康管理，甚至临床研究，药物研发，都存在着大量的机会。他还详细介绍了个性化和动态化的健康管理服务，以及基于此，针对特定用户群体提供定制化的保险产品和个性化的保险定价。 （本文来源：河北网络广播电视台。本网转发此文章，旨在为读者提供更多信息资讯，所涉内容不构成投资、消费建议。对文章事实有疑问，请与有关方核实或与本网联系。文章观点非本网观点，仅供读者参考。） 举报/反馈"
    },
    {
      "doc_id": 49731,
      "title": "AI产业进入新阶段 大模型竞争或激发创新浪潮",
      "time": "2024-02-05T00:00:00+00:00",
      "content": "近段时间，随着深度求索公司（DeepSeek）发布其最新开源模型DeepSeek-R1在国内外引发热烈关注，百度智能云、腾讯云、阿里云、华为云等多平台宣布上线DeepSeek旗下模型。业内人士认为，DeepSeek的新进展透露出2025年大模型竞争的新动向，有望激发一波创新浪潮，各家企业将探索具有成本效益的AI开发和部署方法，推动全球AI继续进步。 据深度求索公司官网介绍，DeepSeek-R1在后训练阶段大规模使用了强化学习技术，在仅有很少标注数据的情况下极大提升了模型的推理能力，在数学、代码、自然语言推理等任务上，测评性能与美国开放人工智能研究中心（OpenAI）开发的GPT-o1模型正式版接近。 赛智产业研究院人工智能研究所副所长安赟在接受记者采访时表示，DeepSeek-R1通过开源策略、低成本高效推理及强化学习结合混合专家架构（MoE）等创新，实现了突破性的技术进展。“开源打破了大企业的技术垄断，促进了AI技术的普惠化。其低成本的算法优化模式改变了长期以来对算力堆砌的依赖，推动了效率导向的竞争格局。” “DeepSeek将开启全球大模型开发和应用的新阶段。”北京前沿未来科技产业发展研究院院长陆峰认为，DeepSeek的高性价比和低训练成本极大地降低了大模型的投资、开发、运营成本，开放开源性降低了融合应用的技术门槛，为大模型的千行百业广泛落地普及应用提供了更多可能。 记者注意到，DeepSeek凭借其强大的语言处理能力和技术优势吸引了众多国内外企业的关注。连日来，百度智能云、华为云、阿里云、腾讯云、360数字安全集团等多个平台宣布上线DeepSeek旗下大模型。此外，在1月31日，英伟达、亚马逊和微软这三家美国科技巨头在同一天宣布接入DeepSeek-R1。 例如，腾讯云方面表示，腾讯云TI平台全面支持DeepSeek系列模型的一键部署。作为企业级机器学习平台，TI平台还提供模型服务管理、监控运营、资源伸缩等能力，帮助企业和开发者将DeepSeek模型高效、稳定地接入实际业务中。 与此同时，DeepSeek的低成本和高效推理模式也影响到AI产业的上下游，并波及资本市场。春节前已有不少投资机构对多家AI、芯片、机器人等产业链相关领域的上市公司展开调研。 陆峰表示，随着DeepSeek带来AI模型的优化，本地设备上的AI计算能力有望得到提升，推动个人计算机、智能手机、智能音箱、智能手表等智能终端产业更新换代，获得更强大的智能交互能力和功能升级，拓展市场应用空间。此外，以DeepSeek为代表的中国大模型崛起，有望带动软件、芯片、操作系统、云平台等人工智能产业链上下游发展，推动国产人工智能大模型产业生态构建。 在安赟看来，未来的大模型竞争将从单纯的算力竞赛转向算法效率和推理能力的提升，深度优化算法成为新的焦点。其中，随着开源生态的崛起，更多企业将借助开源模式吸引开发者和创新者。同时，硬件与软件的协同创新将加速，特别是专用AI芯片和边缘计算设备的发展，有望推动行业的全链条协作。 安赟还表示，伦理和安全问题的关注也将伴随技术进步而加强，确保AI的透明性和数据隐私保护成为未来发展的重要方向。（记者 郭倩） 【责任编辑:冉晓宁】 部级领导干部历史文化讲座20周年纪念版 定位就是聊个天 金融市场技术分析 疗愈的饮食与断食 写作教练在你家 注音详解古文观止"
    },
    {
      "doc_id": 49732,
      "title": "大模型之家2025年3月热力榜:BAT齐发力,DeepSeek迎来挑战者",
      "time": "2024-04-02T00:00:00+00:00",
      "content": "随着DeepSeek-R1推理模型在年初掀起的技术风暴持续发酵，整个AI产业正经历着以“推理能力革新”和“规模化落地”为核心的深度变革。作为首个完整展示思维链推理过程的国产大模型，其在2月创下的“7天用户破亿”纪录仍令人记忆犹新。而进入3月，行业竞争格局迎来新变量——百度、阿里、腾讯等互联网巨头加速释放技术储备，DeepSeek自身也推出了新一代V3模型，共同勾勒出大模型赛道的全新图景。 在《2025年2月大模型热力榜》中，共收录了234家大型模型及其所属企业。其中，BAT三家巨头搞个猛进，全面挑战深度求索的DeepSeek行业地位，百度推出了文心大模型4.5和X1两款全新大模型，阿里则凭借QwQ-32B强大的推理能力与轻量化部署方式提供了新的思路，此外腾讯旗下推理模型混元T1的上线，让推理模型的赛道更加热闹。同时，360、智谱、商汤科技等企业则在垂直领域构筑技术壁垒，正形成“多元竞争、生态协同” 的行业格局。 2025年3月，百度在人工智能领域动作频频，展现出技术实力与战略转型的决心。16日，百度正式发布文心大模型4.5及X1，并宣布用户可通过官网免费使用，不仅兑现了此前“4月1日免费”的承诺，还提前了时间表，同时文心4.5与X1两款大模型也全面应用到旗下产品之中，标志着百度从“技术领先”向“生态主导”的战略转型，试图通过技术、价格和生态的三重布局，应对国产大模型DeepSeek的崛起以及国际巨头OpenAI的免费策略，重新夺回AI竞赛的主动权。 阿里巴巴则在月初正式宣布全面“AI化”，CEO吴泳铭要求所有业务部门以AI促进增长。18日，阿里开源推理模型QwQ-32B，该模型以320亿参数规模在LiveBench测评中跻身全球前五，推理成本仅为同类模型的1/5，支持消费级显卡本地部署，显著降低了企业应用门槛。20日，阿里启动“T项目”，研发下一代AI引擎，聚焦多模态未知领域技术突破，持续深化其在AI技术前沿的布局。 腾讯则更为注重生态布局的双重优势。8日，腾讯混元开源图生视频模型，推动多模态生成技术向影视、广告等领域渗透，加速产业应用落地。12日，腾讯混元团队发布全球首个Transformer-Mamba混合模型Hunyuan-TurboS，21日，腾讯发布推理模型T1，首次进入全球Top15榜单，支持复杂逻辑推理和低代码开发，进一步丰富了其AI模型矩阵，正式加入到推理模型的“混战”之中。 面对BAT巨头们用全新模型带来的挑战，24日，DeepSeek发布混合专家（MoE）语言模型DeepSeek-V3-0324，引发了行业的高度关注，该模型总参数6710亿，每次激活370亿参数，显著提升了推理性能，同时增强了前端Web开发能力，优化了中文写作和搜索能力，适合中长篇写作和报告分析。 除了基础模型能力的快速迭代，智能体也正在成为行业的新风潮。 3月31日，智谱在2025中关村论坛上发布最新智能体产品“AutoGLM沉思”，该智能体集深度研究和操作执行于一体，能像人类一样打开并浏览网页，完成从数据检索、分析到生成报告的任务，推动AI智能体进入“边想边干”阶段。这款智能体的能力实现依托于智能体的“大脑”——沉思模型，即通过强化学习，让模型学会自我批评、反思，甚至沉思，并通过更长的深度思考时间换取更优的效果。此外，智谱还与金融、教育、医疗、政务等领域的合作伙伴共同推进Agentic LLM的落地应用，并计划搭建AgenticLLM平台，助力生态合作伙伴构建行业、地域与场景深度融合的智能体应用。同时，智谱在本月也获得了资本市场的积极响应，先后宣布获得杭州、珠海、成都等三地国资的战略投资，融资金额达18亿元。 3月26日，商汤发布财报，生成式AI收入突破24亿元，同比增长103.1%，成为集团最大业务。商汤坚持“AI基础设施（大装置）-大模型（日日新）-应用”三位一体战略，持续投入建设并自持全国首个5A级智算中心上海临港AIDC，算力总规模提升至23,000PFlops，同比增长92%。商汤表示将计划开发面向未来的AI助手智能体创新应用，加速多模态大模型在机器人、智能眼镜、智能座舱等智能硬件的应用布局，开放测试以来已接入超过70家企业，展现出全面的业务布局和增长潜力。 火山引擎在3月通过开源合作、战略签约、降价让利及人事调整等多维度布局，持续强化其在AI领域的竞争力。具体来看，3月，火山引擎宣布将大模型应用开源，并正式上线“大模型应用实验室”平台，推动AI生态共建，并同期宣布对Doubao1.5系列和DeepSeek系列部分模型的批量推理价格调整为原价的50%，降低企业AI应用门槛，进一步拓展市场份额。然而，在人事层面，3月12日，火山引擎AI解决方案负责人骆怡航离职，加入生数科技出任CEO，引发行业关注。 3月13日，360智慧商业在厦门举办2025全国合作伙伴战略启动会，提出“打响AI卫国战争”的战略蓝图。会上，360集团副总裁、商业化总裁黄剑表示，将以纳米AI搜索、360AI办公两大战略级产品为核心，加速AI与商业场景的深度融合，与代理商合作伙伴携手锻造“超强组织力”，共筑PC营销新生态。 3月20日，百川智能与北京儿童医院、小儿方健康共同发布全球首个儿科大模型——“福棠·百川”儿科大模型。该模型不仅覆盖了儿童常见病与疑难病症的立体化知识体系，具备强大的儿科临床推理能力，还首创了儿科“循证模式”，能像专业儿科医生一样整合最佳医学证据，为患儿制定科学、个性化的诊疗方案，将覆盖北京市海淀区、经济技术开发区社区医院以及河北省150余家县级医院，提升儿科医疗服务水平。 3月26日，昆仑万维正式发布Mureka O1与Mureka V6两款AI音乐模型。其中，Mureka O1被定位为全球首款音乐推理大模型，首次引入MusiCoT（Music Chain-of-Thought）技术，使AI具备自我优化能力，能推理旋律、编曲和歌词，提高音乐创作质量。此外，其“歌曲参考”与“音色克隆”功能支持个性化音乐风格定制。测试结果显示，Mureka O1在旋律结构、混音质量及人声质感方面均超越Suno V4。此次发布不仅推动AI音乐从辅助创作向智能创作演进，也为个性化音乐生成开辟新路径。"
    },
    {
      "doc_id": 49733,
      "title": "DeepSeek走红三个月,第一批想靠它赚钱的怎么样了?",
      "time": "2024-04-23T00:00:00+00:00",
      "content": "\" 作者丨安晓 编辑丨坚果 封面来源丨Unsplash \" 如果你在2023年躲过了Chatgpt，在2024年又躲过了Sora，那么2025年你也很有可能成为DeepSeek的潜在受众，逃不出它天罗密布织下的网。 张蕾还记得，那是1月下旬的某一天，睁开眼刷小红书，被满屏的DeepSeek和它标志性的蓝色图标袭击，一时间上到七八十的老年人，下到刚上小学的小朋友，都把DeepSeek入门教程熟记于心，好像只有会用DeepSeek的人才拥有了赛博世界的最新入场券。 各类账号也没少跟风，比如说卖货的，会预先断开联网搜索功能，把准备好的卖点信息植入给DeepSeek，然后再来一个“给我推荐一款XXX”的问题，让AI替自己卖货。 做情感博主的，会把如何选到25+优质男的问题交给DeepSeek回答，然后卖着自己的心理疗愈课。连母婴赛道也没放过DeepSeek，不是DeepSeek教鸡娃就是DeepSeek给娃安排时间规划。 DeepSeek是块砖，哪里需要往哪搬。张蕾发现，最近互联网语境下的DeepSeek就像爆款推文里的“互联网+”，什么都能往上套个公式，真正演绎了“上善若水任方圆”的包容性。反正这场真人秀里没人是输家，DeepSeek公司接到了热度，而博主们、品牌们也能分一杯羹，总归自得其乐。 但更高级的“流量密码”，是教别人怎么用DeepSeek。这是最近新兴的一类博主，他们不直接卖货，也不乐意接广告，而是摆出一幅 赛博救世主的姿态，售卖DeepSeek课程，包括如何向AI提问以及怎么写提示词；教你用 DeepSeek 赚钱，比如用它生产文案、剧本、笔记和短视频脚本。 比如张蕾最近关注的一个博主，教大家用DeepSeek玩转3个副业，视频开头就很有紧迫感地喊出“现在还不会用DeepSeek的姐妹，活该你赚不到钱”，然后大篇幅讲起DeepSeek门槛有多么低，有多容易写出爆款文案，现在做自媒体有多么合适。 但她越看越不对，这篇视频文案不会也是DeepSeek写的吧？往下一滑，连这条视频才勉勉强强破了200点赞，博主发了30多条教大家用AI的视频，自己的粉丝量也没过万。这不就是活生生的“教会徒弟饿死师傅”的当代案例？ 张蕾清楚地知道，想吃互联网这碗饭的，没那么多人愿意当甘愿献祭农夫，等着“农夫与蛇”的故事反复上演。其实这些人本质与蹭热点无疑，吃第一波信息差赚快钱，等大家都知道DeepSeek了，就发现大部分人对它的利用跟百度没什么区别——想知道某个东西的时候随手搜一下，然后就忘掉。 但初生的DeepSeek有个“天残技能点”，就是交互三四次过后便出现“服务器繁忙”，于是张蕾再次遇事不决小红书，发现很多人都在推广一种本地部署、满血版、不限制对话次数的新型DeepSeek。 被哄着填了评论区的邀请码后，她发现自己也成了博主们play的一环——邀请码按填写人头数给佣金，自己神不知鬼不觉又助力了DeepSeek博主们的发财梦。 1 算法牢笼里的赛博劳工 “你的账号已被永久封禁。”很多利用DeepSeek批量复刻爆款视频文案、流水线生产脚本的博主们，养成RPG游戏走到最后大概也只能收获这样的结局。用DeepSeek批量生产中式养生视频的账号，在突破上万播放量过后，便会触发平台审查机制。 在这场席卷全民的AI淘金热中，博主们的遭遇揭开了流量产业链的残酷真相：真正暴富的从不是使用工具的人，而是贩卖淘金铲的商人。 生成批量视频的博主，尚未意识到自己已沦为AI流水线上的数字劳工。在AI教学账号的指引下，先熟练掌握了实操教程：将DeepSeek生成的养生文案输入即梦AI，用模板化指令批量生产水墨风视频，最终借剪映完成工业化组装。这套组合拳能实现日均五更的恐怖产能，运气好点的一条爆红，运气不好的发了上百条，不是被封禁就是被降低权重。 与其说是内容创作，不如说是测试参数。他们的电脑里存着上百个被平台判定审核不通过的视频废稿，但每个标题、“黄金10秒开头”和标签都精准命中所属赛道的热词。 比如养生赛道，充斥着“低成本养生”“把折寿上班换成带薪养生”“打工人不进医院”等等公式模版，美食赛道是“分手饭”“天塌了也要来吃的餐厅”“XX不宣传这个糊涂啊”等等夸张话术，改个词换个地点又是一条新视频。 有博主说“DeepSeek打破了他们的认知”，不用再辛辛苦苦想爆点，只要提取别人的文案，再让AI模仿这个风格，随便投喂一点观点素材，一天几十条不是问题。 除去服务器繁忙的可能性，DeepSeek大概率写着写着就开始“永恒”“褶皱”，不管是写脚本还是输出回答，不管是古代背景还是数理问题，都一定要和它的赛博机械量子纠缠，丢掉了最重要的“人味”。它习惯于把一些很平庸的答案包装成高大上的教科书，但其实没多少人会真正买账。 于是，当博主们发现某10万粉账号用更粗糙的内容狂揽流量时，终于窥见流量场的潜规则：那些宣称“九条视频涨粉十万”的案例，不过是DOU+推广与历史粉丝积累共同制造的流量假象。 将原有万粉账号改头换面转型新领域的博主，发现AI来AI去，最后只是旧数据在借尸还魂。橱窗里的带货成绩，还不及转型前好物分享的零头。那些被AI批量生产的“亥时养肝”“中式养生”视频，看似击中了全民养生焦虑，实则制造出大量无效流量——算法推荐来的老年用户习惯免费观看，年轻群体则将此类内容视为老一套，很难转化为购买力。 以抖音平台上一个名为“中式养生道”的账号为例，其粉丝量高达53.5万，账号第一条视频是去年12月24日发布，可已更新的162个作品中，没有出现广告商务，带货橱窗中已售出501件商品，带货佣金即使按照较高的10元/件算，总共也就是五千多块钱。 “如果真的不怎么赚钱，为什么这个内容会突然这么火？网上的那些博主又为什么要拼命鼓吹？”其实所谓“2025年不是AI淘汰人类，而是会用AI的人淘汰不会用AI的人”的言论，不过是卖课人的焦虑说辞，他们不需要真正懂AI，就已经能利用AI致富。 恐怕AI自己都没想到，自己也成了卖课人play中的一环。 2 名为DeepSeek的淘金热 当DeepSeek意外走红后，一场裹挟着技术狂热与财富焦虑的商业风暴正在互联网上酝酿成型。 这个被称为“中国版ChatGPT”的AI，不仅掀起了技术应用的“嬗变革命”，更意外激活了互联网经济中最为活跃的“淘金基因”。 此时，一个隐秘的黄金赛道正在野蛮生长——当科技巨头们还在为模型参数厮杀时，早有人在知识付费的土壤里疯狂收割韭菜。 这个被业内人士戏称为“认知税”的产业，永远不会亏本的就是卖课事业。 2023年，标榜着清华大学博士的李一舟以《人人AI课零基础入门》迅速拿下5000万元销售额，直接封神，“粥左罗”在知识付费APP“知识星球”上推出课程《ChatGPT AI变现圈》，仅17天斩获了279万元销售额。 而现在，抖音平台上销量第一《超级流量营销课-IP+AI》的基础课程定价399元，销量高达7.8万件，收入超过3000万。Boss直聘上月薪5万的AI讲师岗位还在持续招新，衍生出针对某一具体赛道的一对一课程服务。 从电商平台的9.9元速成课到短视频里千万级创富神话，从“定制版”私有化部署到MCN机构的AI内容工厂，这个世界永远不变的就是一直在变。 在淘宝搜索框输入“DeepSeek教程”，瞬间超过2000个商品链接如潮水般涌来。花一杯奶茶钱就能实现“知识付费”，它们正在演绎着技术民主化的另类叙事。所有封面清一色写着“从入门到精通”，不少都标注了“清华出品 保姆教程”的高校背书，还有商家承诺“一次购买免费更新”。 点开淘宝评论区，有不少买家晒出自己收到的百度网盘资料——文件夹里分为四大板块，分别为“DeepSeek从入门到精通pdf+视频”“DeepSeek保姆级新手教程”“DeepSeek使用技巧大全”“DeepSeek指令大合集（喂饭保姆级）”，还贴心附赠了“DeepSeek7大场景+50大案例+全套提示词 从入门到精通干货”，这套标价16.4元的课程，已在一个月内售出200份，买家只需要动动手指分享链接，就能实现“躺赚”千元。 也有买家给出了差评，表示“三天精通DeepSeek”课程框架，实则是前几年ChatGPT课程模板的换皮产物——只需将案例中的英文提示词替换成中文，把OpenAI接口教程改成国产API接入指南，就能在技术迭代的浪潮中持续收割认知税。更精明的玩家则将本地化部署方案打包进199元的“一对一套餐”，在技术小白对私人订制朦胧向往中，悄悄完成从信息贩子到解决方案提供商的角色跃迁。 还有博主宣传，能用DeepSeek炒股赚钱，只要将炒股软件接入DeepSeek，就能控制电脑全自动分析股票，在直播间下方还附上了教程和软件的购买链接。 在这场全民参与的AI淘金热中，技术本身反而退居为背景板。当某个技术论坛还在争论模型参数的优劣时，市井街巷的早市摊主已在讨论如何用AI写促销文案。 越是易用的技术，越需要庞大的中间服务层来填补认知鸿沟。就像十九世纪加州的淘金潮催生了李维斯牛仔裤的传奇，今天DeepSeek掀起的AI浪潮，也在批量制造着新时代的“信息差商人”。 但只卖给个体户，已经不能填补商家们的野心了。中小企业在数字化浪潮中，也非常渴望利用 AI 提升竞争力，但因技术门槛望而却步。有人在猪八戒、淘宝等平台，专门承接AI 代运营、AI 方案等业务。他们熟练运用DeepSeek，为客户撰写营销文案、进行竞品分析、生成专业报表。 从火锅店促销文案到美容院客户管理方案，形成覆盖实体经济的“焦虑解决方案库”。当运动鞋品牌老板下单竞品分析报告，店家只需在“运动鞋品类模板.xlsx”中替换品牌名称，10分钟即可生成价值500元的定制化文档。 这套工业化生产体系里，真正值钱的不是AI技术，而是精心设计的套利模型，当业务量有所突破后，操盘手们开始执行第二阶段收割计划。他们在高校招募大学生兼职，将文科生训练成数字流水线工人。 第三阶段则是推出“AI 私教课”，定价1980元，录制好课程视频就能无限售卖，实现知识变现。私教课若能卖出 100 份，就能直接变现 20 万。 3 全民AI的卖课时代 “最后3个名额！原价1999元的AI课，今天限时99元！”当这类标语在直播间高频轰炸时，一场针对知识焦虑者的精准收割已然启动。在这场流量游戏中，AI课程卖家构建起环环相扣的收割系统，将普通人的求知欲转化为真金白银的暴利。 带货博主们的第一招，是人设包装。自媒体做不做得好、号起不起得来，说白了是粉丝信不信任你，所以一个好的人设能让博主成功99%，这是他们成功的根本，却也是从来不会说出口的行业潜规则。 从BOSS直聘就能看出来，AI讲师招聘页上，“对课程转化率负责”被列为优先级，而真正的AI专业知识却沦为可选项。某教育机构开出35k月薪的岗位要求，仅需候选人具备直播销讲经验与流量敏感度。 这种用人逻辑催生出批量制造的“AI权威专家”：李一舟的“清华博士”人设遭校方打假后，仍有模仿者用ChatGPT速成的“智能体开发证书”作为专业背书。讲师们熟练运用虚拟背景墙、学术名词矩阵和抓马话术，在30秒短视频里完成从素人到专家的身份蜕变。 当百元课程销量停滞后，李一舟又将入门课降至49元，单月销量再次突破5000份，看似亏本的引流策略，实则只是在筛选高净值用户。 购买低价课程的学员会立即被拉入“AI创富群”，助教持续推送3980元私董会课程的学员成功案例，群内机器人每小时自动发送限时优惠倒计时。有学员发现，其购买的399元《AI流量密码》课程中，大部分时长都在推介万元级VIP服务，形成“买课即入套”的消费陷阱。 “再不学AI就会被淘汰“的恐吓配合“接单平台保底收入”的黄金承诺，构成完整的焦虑变现闭环，最后学员当上博主的没几个，反倒是15元/单的PPT美化需求多了不少，更精明的玩家与招聘平台合谋，将免费修改简历服务包装成“AI岗位内推资格”，利用BOSS直聘的流量接口完成收割链条的最后一环。 在这场全民AI狂欢中，普通人能守护的只有两样东西：捂紧的钱包，以及保持清醒的认知。要相信，这是个人人都能用上几次DeepSeek的时代，却不是人人都能在自媒体下半场成功当上变现博主，大海一样的流水线视频赛道里，靠质量比靠数量永远可信得多。 第一届想靠DeepSeek发财的人，就像在玩一场巨大的大富翁游戏，走走停停买房想赚笔观众的过路费，结果一个走神的功夫，房子被查封了，账户里的钱全留到卖课商家的手中。结局清算，笑到最后的人从不生产视频，只不过是视频课程的搬运工。"
    },
    {
      "doc_id": 49734,
      "title": "中国企业开源浪潮重塑全球AI版图",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "参考消息网7月21日报道 据香港《南华早报》网站7月19日报道，2024年7月9日或许会被称为中国人工智能（AI）界的“羞辱日”。从当天起，美国初创企业、全球人工智能模型开发领军企业开放人工智能研究中心(OpenAI)禁止中国开发者使用其模型。 与之形成鲜明对比的是，大部分国家的开发者均可正常访问，这无声地传达了该公司的立场：其宝贵的模型必须提防中国使用。 如今风向已变。2024年12月，深度求索推出面向所有人免费的DeepSeek-V3大语言模型；2025年1月，深度求索又发布推理模型DeepSeek-R1，能力媲美OpenAI的o1模型。中国企业掀起的这场开源浪潮，已在硅谷和华尔街掀起冲击波。 这一趋势不仅在中国催生了一波人工智能应用大爆发，也重塑了全球人工智能版图，并赢得世界各地开发者的拥护。中国开源模型为美国科技巨头所力推的封闭系统，提供了切实可行的替代方案。 报道称，开源人工智能模型的源代码和模型权重对所有人公开，可自由使用、修改和分发，倡导一种协作式开发模式。 以往，类似Linux的开源计算机操作系统未能取代微软Windows等专有系统，但分析师指出，这一次，中国免费开放的人工智能模型正对美国同类产品构成重大挑战。 英伟达公司创始人兼首席执行官黄仁勋称赞中国在开源人工智能方面的成就，表示将继续深化与中国企业的合作。 黄仁勋说中国公司开发的大语言模型是“世界级”的，对全球人工智能进步至关重要。 这几天在北京举行的中国国际供应链促进博览会上，他表示，中国的开源人工智能发展已成为“全球进步的催化剂”，让每个国家和行业都有机会加入人工智能变革。 报道称，与中国企业快速推出开源模型形成鲜明对比的是，OpenAI创始人兼首席执行官萨姆·奥尔特曼近日宣布，原定数日内发布的开源大模型将推迟上线，理由是出于安全考量，还需进一步测试。 科技行业投资人凯文·徐(音)指出，对深度求索等中国初创公司而言，采用开源策略是追赶的有效手段，因为这让它们能够借力更广泛的开发者社区。 自2022年底OpenAI推出聊天生成预训练转换器(ChatGPT)以来，中国开源人工智能开发者的模型开发取得显著进展。凯文·徐说：“现在大多数中国开源人工智能模型已处于或接近前沿水平……最新一波开放权重模型的发布，显示出中国在开源采用与贡献上的日益成熟。” 报道称，中国模型的先进能力已获得用户广泛认可。 截至7月中旬，深度求索在全球人工智能模型市场平台“开放路由器”上的份额达到24%，成为第二大受欢迎的模型开发商，仅次于占据37%份额的谷歌。 与此同时，世界最大开源人工智能社区抱抱脸公司网站的数据显示，阿里巴巴的千问模型家族已成为全球最大的开源人工智能生态系统，衍生模型数量超过10万个，超越元宇宙平台公司的模型社区。 中国科学院下属的多模态人工智能系统全国重点实验室研究员郑晓龙指出，中国庞大的开源生态系统应用场景遍及智能制造、数字政务等各个领域。 郑晓龙认为，技术演进与产业需求汇聚，在中国形成了独特的发展模式——应用需求驱动创新，开源生态又反哺产业成长。 他表示，中国的开源发展体现了“技术平权”的趋势，正在挑战闭源模型的地位。（编译/郭骏） 【责任编辑:郭晓婷】 部级领导干部历史文化讲座20周年纪念版 定位就是聊个天 金融市场技术分析 疗愈的饮食与断食 写作教练在你家 注音详解古文观止"
    },
    {
      "doc_id": 49735,
      "title": "抢先DeepSeek R2,开源万亿参数Kimi K2:月之暗面生死突围",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "来源：青橙财经资讯 作者丨青风 编辑丨六子 中国AI领域一场悲壮的科技突围战正式打响！7月11日深夜，AI初创公司月之暗面发布全球首个开源的万亿参数大模型Kimi K2。该模型在多项基准测试中达到开源模型的SOTA（当前最高水平），API调用成本与DeepSeek R1持平，仅为Claude 4的五分之一。 这款被寄予\"生死突围\"厚望的模型，在发布后48小时内引爆市场：Kimi官网访问量激增36亿，开源社区Hugging Face下载量突破10万次，GitHub相关项目数量飙升200%。在OpenRouter平台上，K2的token消耗量迅速超越马斯克的Grok 4，登顶全球API调用榜。 抢在DeepSeek R2之前推出万亿参数大模型，并同样采取开源策略，这不仅是月之暗面的一次技术发布，更是这家被逼至悬崖边缘的明星创业公司，押上全部命运的一场豪赌——要么一战封神，要么黯然退场。 01「坠落神坛」 曾几何时，凭借独树一帜的长文本处理能力和AI搜索功能，Kimi风光无限。QuestMobile数据显示，截至2024年12月，Kimi月活跃用户（MAU）达2101万，稳居国产AI原生应用前三。 然而2025年市场风云突变。年初，DeepSeek凭借低成本、高性能的开源模型强势入场，几乎零市场推广下，用户访问量7天破亿，迅速重塑全球AI格局，给包括月之暗面在内的众多玩家带来巨大冲击。 *图源QuestMobile 在DeepSeek的刺激下，AI大厂们也随之加速布局：字节对豆包持续重金投入，稳守头部；阿里通义大模型频繁更新，打造全球最大开源模型，并将夸克推为C端旗舰；腾讯元宝借鸡生蛋，借势“接入DeepSeek”疯狂推广；百度急转开源免费，联动文库、网盘全力助阵。 巨头们挟资金优势、海量用户生态与强大工程化能力，在模型迭代、场景落地、生态构建上全面挤压创业公司的生存空间。月之暗面首当其冲。 用户数据最能体现冲击。QuestMobile数据显示，截至5月，DeepSeek移动端MAU为1.69亿，虽较3月的1.94亿有所下滑，但仍是用户量最大的AI原生应用，超过字节跳动的豆包、腾讯的元宝，更远超Kimi。Kimi的MAU已滑落至1408万，不足DeepSeek的十分之一。 用户流失的同时，月之暗面此前火热的融资节奏也戛然而止。过去两年，红杉中国、美团、阿里、腾讯等接连投资，将其估值推至33亿美元。但自2024年初获得当时国内大模型最大笔融资后，月之暗面2025年再无新融资消息。对极度烧钱的大模型研发而言，这无疑是危险的信号。 在此背景下，月之暗面创始人杨植麟做出两个关键决策：全面停止营销投放，集中资源攻坚基础模型；放弃K1系列迭代，All in下一代架构研发。 Kimi K2由此诞生——这是一次破釜沉舟的突围尝试。 发布当晚，联合创始人张宇韬在朋友圈写下，\"Make Kimi Great Again\"。这句话清晰传递出，月之暗面内部对Kimi K2寄予厚望，将其视为抵御DeepSeek冲击的关键，希望凭借新模型的强大性能和开源策略，重新吸引用户目光，夺回失去的市场份额，重回大模型竞争的核心舞台。 02「背水一战」 从技术性能与市场反馈来看，Kimi K2确有突围的潜力。 *图源Kimi官网 在技术层面，Kimi K2的参数规模与架构设计颇具竞争力。其总参数达1万亿（1T），是当前大模型参数量的天花板，激活参数为320亿；采用MoE（混合专家模型）架构，代码能力与通用Agent（智能体）任务处理能力显著提升——能执行任务拆解、自主规划、工作流设计及工具调用等复杂多步骤任务。 性能测试更印证了其实力。在SWE Bench Verified、Tau2、AceBench等基准性能测试中，Kimi K2均取得开源模型中的SOTA成绩。在细分维度上，编程能力仅次于Claude 4 sonnet，智能体能力仅次于Claude 4和GPT-4.1，数学推理能力则在MATH、AIME、GPQA-Diamond等测评中得分最高。 价格上，Kimi K2 也延续了 \"高性价比\" 策略：每百万输入tokens收费4元，每百万输出tokens收费16元，与DeepSeek标准时段的API价格体系一致。 *图源月之暗面公众号 为突出Agent能力，月之暗面官方提供了一些内部测试环境中的实际演示，比如，K2可以帮助用户制定粉丝的追星计划，完成演唱会所在城市的机酒与旅游规划，并且生成日历，再用html概括完整行程规划并发送邮件。 这样的表现迅速引发海内外AI圈关注。OpenRouter平台上线仅两天，Token消耗量就超越xAI，登顶全球API调用增长榜；在Cline、Roo Code、Kilo Code等平台，API使用量在全球开源模型中排名最高。 独角兽Perplexity CEO在社交媒体表示，基于Kimi K2模型的出色表现，公司将会利用K2进行后训练，上一个被该公司用于技术训练的中国模型是DeepSeek R1。全球最大开源AI社区Hugging Face联合创始人表示，不断突破极限挑战闭源的K2模型令人难以置信。不少社区用户也给出了不错的评价，“性能不输Claude 4，但便宜80%”、“唯一超越R1的存在”。《自然》杂志网站更是将Kimi K2发布称为“世界迎来又一个DeepSeek时刻”。 月之暗面研发团队也全员在Hugging Face、知乎等平台发声助威，其背水一战的决心可见一斑。对他们而言，K2是一场生死攸关的救赎。如果Kimi K2能够在市场上获得良好的反响，将有助于月之暗面重新夺回市场份额，提升品牌形象，在AI大模型领域实现困境突围，重回行业第一梯队。 03「强敌环伺」 尽管Kimi K2在技术上表现亮眼，月之暗面仍面临诸多强劲对手与严峻挑战。 Kimi K2主打“模型即Agent”，重点强化代码与Agent能力。但目前智能体赛道的竞争已趋白热化，后来者既缺乏应用场景，更缺乏生态积累。 就在7月18日，OpenAI就推出了“ChatGPT Agent”，能够智能调用浏览器工具（Operator）、深度信息整合（Deep Research）与语言生成能力（ChatGPT），完成包括在线购物、订餐预约、撰写研究报告、制作PPT和财务分析在内的多步骤复杂任务。 而除了国际厂商，国内的阿里夸克、百度文库、字节扣子空间等也均已布局Agent，且坐拥上亿用户和更强的场景认知。不久前的高考填报志愿就是一个非常典型的AI应用场景，在这个细分领域，夸克和百度等均已经深耕多年，相关资源、高校数据和用户心智也都已建立起较高的壁垒。 “Kimi的努力方向是对的，但还不够，Kimi需要将自己的AI嵌入到一个生态当中。如今，互联网平台各大生态是封闭的，比如电商的AI可以帮助商家设计网站，自媒体的AI能够帮助自媒体制作视频，那么，Kimi的目标用户是谁？这方面，需要Kimi自己明确。”知名经济学者、工信部信息通信经济专家委员会委员盘和林，在接受媒体采访时如此表示。 *图源互联网 此外，DeepSeek R2仍然如同悬顶之剑。据称，R2将拥有超过1.2万亿参数，重点方向就是智能体和多模态能力的加强。媒体爆料，此前因英伟达H20芯片禁售，R2上线受阻；但7月15日英伟达创始人黄仁勋透露\"美国已批准H20对华出口\"。这意味着R2最大阻碍已消除，上线在即。对月之暗面而言，这款被期待为\"国运级\"应用的大版本更新，可能是又一次冲击。 月之暗面更现实的挑战是算力与资金。有用户称，刚测试不到10个问题，K2对话框便显示“当前模型对话次数已达到上限，可切换为其他模型继续对话”——这背后是大模型研发与运营的高成本，需要大量的AI芯片和巨大的计算资源消耗。在月之暗面迟迟没有新的投资入账的情况下，这一问题可能更为棘手。 而要想获得投资青睐，另一个更直击灵魂的深层问题也随之浮现：DeepSeek之后，市场是否还需要自研基础大模型？若已有全方位开源的领先模型，创业公司推进自研的融资合理性何在？ 巨头们拥有深厚的“血槽”，DeepSeek占据了用户心智和开源生态，月之暗面能否凭K2重新获得资本青睐，仍是未知数。 04「写在最后」 回望\"大模型六小龙\"的发展轨迹，令人唏嘘，也可做借鉴，或许能更清晰看到月之暗面的处境。 2023年全年，六小龙累计融资曾占到国产大模型厂商的逾50%。而如今，格局已然大变： 零一万物已退出基础大模型竞争；百川智能也放弃了基座模型训练，收缩战线聚焦医疗垂类，且创始团队持续动荡；跃阶星辰几近失声；仅智谱AI与MiniMax近期有融资消息，但前者聚焦政企市场，后者押注多模态和出海方向，都避开了与DeepSeek及大厂们的正面交锋。 月之暗面尝试用K2证明，硬实力是最好的市场通行证，AI竞赛还没有结束。然而，前有巨头与OpenAI的生态围堵，后有DeepSeek R2的虎视眈眈，加之算力掣肘与融资困局，其突围之路，注定比昔日更加崎岖难行。 - END - 举报/反馈"
    },
    {
      "doc_id": 49736,
      "title": "财通计算机 · 中美AI百花齐放,开启AI新时代",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "（来源：财通证券研究） 中国AI新浪潮：Kimi K2“开源冲击波”，“又一个DeepSeek时刻”。2025年全球AI高速发展，中美大模型竞争激烈。7月11日Moonshot AI发布的Kimi K2开源模型成焦点，被视为中国AI差异化竞争策略，获“又一个DeepSeek时刻”评价，标志中国开源大模型具世界级竞争力。该模型采用MoE架构，总参数量1万亿，激活参数约320亿，以“智能体潜能”见长，编码能力突出。技术上优化自DeepSeek-V3，擅长执行明确计划，是自动化工作流理想“执行者”，聚焦编码等场景极致表现。此前Kimi推出内测产品Kimi-Researcher，依托K1.5的Agent能力完成复杂研究，多项基准测试成绩良好，K2推出后其能力将升级。K2开源且API定价极低，远低于同类产品，通过低成本吸引开发者构建生态，未来可通过企业服务等盈利。综上，K2标志中国AI在大模型领域重大突破，开源策略能吸引开发者、挑战闭源巨头，提供高性价比替代方案。 美国AI双雄会：Grok 4与ChatGPT Agent的策略分野。马斯克旗下xAI于7月10日推出Grok 4，其训练量较Grok 2提升100倍。工具使用能力内化训练，20万张GPU超算支持，Colossus超算总内存带宽达194 PB/s，存储容量超1EB。Grok 4能力卓越，推理与多模态表现突出：SAT、GRE接近满分，HLE无工具解决率25.4%，Heavy版本超50%；GPQA等多个基准测试全面超越ClaudeOpus4等对手。多模态上，ARC-AGI-2刷新纪录达15.9%。xAI计划8月发布代码模型，9月推多模态智能体，10月出视频生成模型，明年有望推出AI生成游戏，将构建技术-场景-生态三级平台。7月18日，OpenAI发布ChatGPT Agent，这是基于GPT-4架构的先进多模态通用AI代理系统，实现从被动应达到主动代理的升级，能规划任务、调用工具并自主执行，具备强大多模态理解和超长上下文处理能力，结合Operator和Deep Research形成端到端通用Agent。其在复杂任务中表现出色：HLE评估Pass@1分数41.6；DSBench测试显著超越此前最先进模型，数据分析任务表现优于人类。 海内外大模型百花齐放，AI新时代悄然已至。我们认为，未来1-2年全球AI将以加速融合、能力跃升和应用深化为主线：Agent能力、多模态理解生成成标配，上下文窗口扩大，混合专家架构平衡性能与成本；开源闭源竞合加剧，推动技术进步与成本下降，伦理安全监管标准趋完善；AI深度渗透多行业，通过API服务和行业模型驱动转型，催生新商业模式。投资上，AI硬件与应用共谱新篇章。 风险提示：技术迭代不及预期的风险；商业化落地不及预期的风险；政策支持不及预期风险；全球宏观经济风险。 正文内容 01 中国AI新浪潮：Kimi K2“开源冲击波”，“又一个DeepSeek时刻” 月之暗面Moonshot AI发布Kimi K2基座模型吹响“又一个DeepSeek时刻”。2025年，全球人工智能领域持续经历着前所未有的高速发展与激烈竞争，中美大模型研发和产品迭代尤为引人注目。近日，一批业内领先的AI大模型相继涌现，正深刻地改变着人机交互的方式，并有望在各行各业催生创新应用。7月11日，Moonshot AI发布Kimi K2开源模型，成为全球AI领域的一大焦点。我们认为，它不仅是性能强大的模型，更代表中国AI力量在全球竞争中采取的一种差异化、高影响力的策略。Kimi K2的出现，被业界评价为“又一个DeepSeek时刻”，标志着中国在开源大模型领域已具备世界级的竞争力。 1.1 目前最大开源模型之一，基于DeepSeek-V3优化推进底层技术创新 Kimi K2具有庞大参数规模与高效MoE架构，擅长执行自动化工作流长任务。Kimi K2采用了混合专家（Mixture-of-Experts, MoE）架构，总参数量高达1万亿，在处理每个任务时激活约320亿参数。在模拟真实世界软件开发任务的SWE-bench上，Kimi K2的性能与闭源模型Claude 4 Opus非常接近；而在衡量实时互动编程能力的LiveCodeBench上，Kimi K2以53.7%的准确率超越了GPT-4.1和Claude 4 Opus。我们认为，综合以上数据，Kimi K2尤其擅长执行具体的、定义明确的计划，是构建自动化工作流的理想“执行者”。 Kimi K2的核心技术优势主要体现在以下几个方面： 基于DeepSeek-V3的继承与优化。在设计之初团队进行了大量模型结构相关的scaling实验，基于实验结果的准确有效性和成本的考量，模型结构的设计问题主要集中于如何在给定DeepSeek-V3结构的框架下选择合适的参数使得模型在训练、推理成本与DeepSeek-V3相当的前提下，获得明显更低的数据损失。为此，技术团队在复用DeepSeek的MLA（Multi-Head Latent Attention）的基础上进行优化，具体的改动主要包含： 减少注意力头：减半attention heads以降低Infra的压力，同时减少num_heads变数以实现时间和成本的平衡； 提升专家数量：将专家数量从256升到384，既为了补回没有double heads带来的损失，同时也能符合实测的Scaling Law。即在一定范围内，固定激活的专家数量，使得增加总专家数带来的效果收益，大于增加的Infra成本； 精简前期Dense层：将前置Dense层数由3降至1。与DeepSeek的观察类似，第一层MoE的router很难做到负载均衡，但第二层之后则未出现问题；为了更充分利用MoE优势，技术团队只保留第一层Dense，其余全用MoE； MoE Router简化，n_group=1：在当前模型参数规模下，为保证MoE计算耗时在合理范围内，采用更自由的router方案使得expert的组合空间显著增大，从而进一步提升模型能力。 总结来看，K2技术团队在DeepSeek-V3原有框架基础上进行优化，通过减少“注意力头”来降低服务器压力，同时增加专家数量以补回效果损失；此外还精简了前期固定层，仅保留一层，并让专家调度更灵活，取消分组搭配，从而使组合方式更多样，效果也更好。 底层技术创新提升训练稳定性：月之暗面团队自研“MuonClip”优化器，克服“训练崩溃”问题。根据其技术报告，MuonClip通过一种创新的“qk-clip”技术，在训练过程中动态调整权重，有效防止了注意力分数的爆炸，从而确保了在15.5万亿tokens的庞大数据集上训练过程的“零不稳定”。这一底层工程和算法的突破，是Kimi K2能够成功问世的核心技术保障之一。 1.2 Kimi：主打AI Agent与“高性价比”的实战派 Kimi K2作为优化AI Agent的实战模型，其功能并非追求在所有领域都做到顶尖，而是在开发者最需要的编码和工具调用等场景中做到极致，在智能体任务的完成速度与质量中进步。 工具调用及数学推理能力：在工具调用能力测试中表现接近行业领先水平，具备稳定的复杂指令解析能力，可将需求自动拆解为一系列格式规范、可直接执行的ToolCall结构；在AIME 2025中得分高达49.5，在数学定理和逻辑判断方面表现出色，是研究和教育用户的高性价比方案。 前端开发能力和APP兼容性：擅长生成兼具设计感与视觉表现力的代码，支持粒子系统、可视化和3D场景等表现形式，具备较强的图形能力与交互性。 性能与局限性的平衡视角：作为一个“非思考”模型，Kimi K2的优点在于响应速度快，拥有128K的长上下文处理能力，并且在编码等特定任务上表现优异。局限性在于，对于需要深度、多步、复杂逻辑推理的任务，其能力可能不及思考型模型。 Kimi-Researcher在应用场景、成本、生态全方位撬动市场格局。在Kimi K2发布前夕，Kimi发布Agent产品 Kimi-Researcher。其作为Moonshot AI在2025年6月底开启内测的垂直场景应用产品，其底层模型当前调用K1.5，通过K1.5的Agent能力，自动完成复杂研究任务，并输出交互式内容，而非传统文本对话。目前，Kimi Researcher在Humanity’s Last Exam (HLE)中获得了26.9%的Pass@1分数，Pass@4 准确率为40.17%。此外，在xbench-DeepSearch上实现了69%的通过率。在多轮搜索推理FRAMES，Seal-0和事实信息SimpleQA的基准测试中，Kimi-Researcher也取得了很好的表现。后续，随着Kimi K2模型的推出，Kimi-Researcher能力也将更上一层楼。 极具性价比的定价与生态驱动的商业模式。Kimi K2此次不仅以开源形式大方问世，同时采用极具性价比的API定价策略，其价格远低于OpenAI和Anthropic的同类产品，极大程度上吸引了对成本敏感的开发者和企业。与此同时，Kimi K2秉持生态驱动的商业模式，商业逻辑是通过免费和极低成本的API服务吸引海量开发者和用户，迅速扩大在AI应用层的基础，以此培养用户习惯并形成强大网络效应；随着生态成熟，月之暗面未来可通过提供企业级解决方案、定制化服务或与云厂商合作分润等方式实现盈利，而其宽松的商业使用条款则有望进一步加速这一进程。 综上，我们认为Kimi K2的发布标志着中国AI公司在大规模语言模型领域的重大突破，展示了其在万亿参数模型训练、MoE架构设计和代码能力方面的技术实力，同时也反映了开源AI模型在中国的快速发展和广泛应用。在OpenAI等巨头对核心模型愈发封闭的背景下，Kimi K2开源策略既能迅速吸引全球开发者的关注和使用，构建起一个庞大的开发者生态，亦能挑战顶级闭源模型的技术护城河，为开发者和企业提供了高性价比的替代方案。 02 美国AI双雄会：Grok 4与ChatGPT Agent的策略分野 2.1 Grok 4：专攻高难任务的“理科博士”，10x算力训练量延续Scaling Law跃迁奇迹 xAI构建全球顶级超算集群，刷新Grok 4模型训练新高度。马斯克旗下xAI公司于北京时间7月10日推出新一代旗舰模型Grok 4，代表了美国AI技术的最新发展方向。在训练规模上，相比Grok 2的训练量提升了100倍，特别是在强化学习（RL）阶段投入的算力是市面上其他任何模型的10倍以上；同时，构建了全球顶级超算集群（20万张H100 GPU）支持训练，总内存带宽达194 PB/s，存储容量超1 EB。 多项测评表现刷新SOTA，HLE超越50%。Grok 4在多个领域展现出卓越能力，在推理能力和多模态处理方面尤其突出。在SAT、GRE等高难度考试中接近满分，展现出超越人类的推理水平。马斯克称，Grok 4却在HLE的所有领域，都达到了博士级别，甚至胜过了大多数人类博士生。其在没有使用工具的情况下解决了HLE中25.4%的问题，多智能体版本Grok 4 Heavy解决率更是超过了50%，成为所有模型中的首次突破。Grok 4 及 Grok 4 Heavy 在 GPQA、AIME25、HMMT 等多个顶级基准测试中，表现全面超越所有竞争对手，包括 Claude Opus 4 与 Gemini 2.5 Pro。此外，在多模态理解方面，Grok 4能理解主观概念，搜索和分析图片，在ARC-AGI测试中，Grok 4在ARC-AGI-2大幅刷新纪录达15.9%，较第二名Claude Opus 4 (8.6%)接近翻倍。 Grok 4采取高端定价策略，同时积极拓展应用场景。Grok 4目前C端价格为$30/月（Grok 4）及$300/月（Grok 4 Heavy）。截至目前，SuperGrok的用户已经可以使用，Grok 4 API也已向所有开发者正式开放，并将登录第三方云平台。在未来，xAI宣布计划于2025年8月发布代码模型，9月发布多模态智能体，10月发布视频生成模型，并且在明年有望推出第一款AI生成的游戏。我们认为，此次阶梯式定价本质是以技术分层实现用户分层，既维持品牌高端形象，又为中低端产品留出空间。API的开放有望进一步降低基于Grok 4的企业大模型集成门槛。xAI的更新路线图进一步表明，尽管目前Grok 4存在一定的提升空间，其未来也将构建出技术-场景-生态的三级平台。 2.2 ChatGPT Agent：端到端任务的“全能管家” 端到端通用AI Agent近在咫尺。北京时间7月18日，OpenAI发布ChatGPT Agent。ChatGPT Agent是基于GPT-4架构构建的、具备高级推理和自主执行能力的智能代理模型，是目前最先进的多模态、具备类人任务规划和执行能力的通用人工智能代理系统之一。其核心进步在于从被动应答升级为主动代理，能规划任务、调用工具并自主执行目标，且具备强大的多模态理解和超长上下文处理能力。ChatGPT Agent结合Operator和Deep Research形成了统一的智能体，实现了端到端的通用Agent。 ChatGPT Agent实现从问答机器人到通用AI代理的跨越，能够完成复杂任务。在HLE中，支持ChatGPT Agent的模型在该评估中的Pass@1分数为41.6。在旨在评估智能体在涵盖数据分析和建模等现实数据科学任务中表现的DSBench⁠测试中，ChatGPT Agent显著超越了之前的最先进模型，尤其在数据分析任务中，其表现优于人类水平。在定位于评估模型在处理基于真实世界场景的电子表格编辑任务时的表现的SpreadsheetBench平台中，ChatGPT Agent也取得了SOTA，其性能较当前行业领先的GPT‑4o提升了超过一倍。当具备直接编辑电子表格的能力时，ChatGPT Agent的得分进一步提升至45.5%，大幅超越Copilot in Excel。在内部基准测试中展现出入门级投资银行分析师（1-3年工作经验）的能力，在Inverstment Banking Modeling Tasks测试中优于Deep Research和o3模型。 OpenAI将ChatGPT Agent作为其现有付费方案（Plus、Team和Enterprise）的一项增值功能推出，并对Plus和Team用户设置了每月40次的使用配额限制。Pro、Plus和Team用户可以通过聊天框下方的工具下拉菜单，选择\"agent mode\"（代理模式）来激活此功能。此外，ChatGPT Agent还集成了文本浏览器、GUI浏览器、终端和图像生成工具，为用户提供了全面的工具支持，同时也支持与用户进行交互式、多轮对话，允许用户实时指导和调整任务方向。 03 海内外大模型百花齐放，AI新时代悄然已至 AGI渐行渐近。对Kimi K2、Grok 4和ChatGPT Agent和的深入分析揭示了当前全球AI发展的核心图景：尽管中美顶尖参与者在战略、技术和商业模式上选择了迥异的道路，但他们正朝着殊途同归的大模型未来前进，预示着一个更加多元、竞争激烈且充满机遇的AI新时代的到来。 观察海内外近期的模型与产品进展，我们认为当前AI产业趋势可以归纳为以下几点： 混合专家（MoE）架构应用趋势显著：将模型拆分为多个相对独立的“专家”子网络，推理时仅激活部分专家，大幅降低计算成本与能耗，使得更大规模模型的训练与部署成为可能。 高效训练与轻量推理：除了MoE之外，还广泛采用模型量化、知识蒸馏等技术，在保证性能的前提下进一步压缩模型体积、提升推理速度并降低部署门槛。 强化逻辑推理与数学能力：模型不再仅靠模式匹配，而是具备更深层次的思考和分析能力，能够解答复杂逻辑问题、执行代码生成以及为科学研究和决策支持提供技术保障。 极长上下文窗口：支持处理数万乃至数十万Token的输入，使其在长文档理解、持续对话和大规模代码库分析等场景中表现更连贯、信息覆盖更全面。 跨模态理解成为多模态能力的核心： ■ 多模态输入／输出：不仅处理文本，还能理解并生成图像、音频、视频等多种数据形式。 ■ 跨模态融合：能够将不同模态的信息关联、融合并进行综合推理，支撑更自然的多模态人机交互。 从“被动响应”到“主动行动”的Agent能力：新一代大模型被赋予更强的自主性，能够理解复杂目标、制定执行计划、调用外部工具并完成多步任务，真正实现以目标驱动的智能代理。 从AI产业商业化程度看，我们认为海内外大模型将采取相似但又具市场特色的商业化方案。 商业策略日益多样化。从传统的API按调用次数收费，逐渐扩展到订阅模式、开源增值服务、平台生态构建等多种形式，反映了市场需求的差异化和厂商对不同商业模式可行性的探索。 市场采用速度在不同地区表现出差异。中国市场在AI大模型的应用和商业化方面呈现出快速增长的趋势，特别是在代理智能和本地化部署方面需求强烈。相比之下，美国市场虽然技术领先，但在某些传统行业的渗透和应用深化方面或将面临不同的挑战和机遇。 政府合作成为AI商业化的重要方向。AI公司与政府机构如国防、医疗、科研等部门的合作日益紧密。Grok 4明确将政府合作作为其商业化的重要一环。而在中国，商业化更侧重于消费市场和企业级应用，通过满足市场需求来驱动增长。 开源与闭源的商业模式并行发展。以Meta的Llama系列和月之暗面的Kimi K2为代表的开源策略通过降低技术门槛、构建开发者生态来推动技术普及和应用创新，并在此基础上探索商业机会。以OpenAI的GPT系列和xAI的Grok系列为代表的闭源或部分闭源策略更侧重于通过提供高性能的API和订阅产品来直接获取商业回报。 AI新时代：大模型融合跃升与应用深耕落地。我们认为，未来1-2年全球AI将以加速融合、能力跃升和应用深化为主线：在复杂推理、规划及与物理世界交互的Agent能力方面将取得重大突破，多模态理解与生成（文本、图像、音频、视频）成为标配，上下文窗口持续扩大支持更长程任务，而混合专家等高效架构则在提升性能与降低成本之间取得平衡；与此同时，开源与闭源的竞合格局将更加激烈，推动技术进步与成本下降，并在伦理、安全和监管领域形成更完善的国际标准；AI也将深度渗透金融、制造、科研、政府、医疗等行业，通过灵活多样的API服务和定制化行业模型驱动数字化转型，并在内容创作、软件开发、数据分析、教育娱乐等领域催生新商业模式和增长点。投资上，AI硬件与AI应用交相辉映的时代正在书写新篇章。 技术迭代不及预期的风险：若AI技术迭代不及预期，大模型优化受限，则相关产业发展进度会受到影响。 商业化落地不及预期的风险：大模型盈利模式尚处于探索阶段，后续商业化落地进展有待观察。 政策支持不及预期风险：新行业新技术的推广需要政策支持，存在政策支持不及预期风险。 全球宏观经济风险：垂直领域公司与下游经济情况相关，存在全球宏观经济风险。 注：文中报告节选自财通证券研究所已公开发布研究报告，具体报告内容及相关风险提示等详见完整版报告。 证券研究报告：《中美AI百花齐放，开启AI新时代》 对外发布时间：2025年7月20日 报告发布机构：财通证券股份有限公司（已获中国证监会许可的证券投资咨询业务资格） 分析师 杨 烨 SAC证书编号：S0160522050001 联系人 陈梦笔 团队介绍 首席分析师 杨烨 SAC证书编号：S0160522050001 清华大学计算机软件专业学士、中山大学MBA； 八年IT产业经历，曾就职于银行、互联网公司和券商，2021年新财富最佳分析师计算机行业第一名团队核心成员。 分析师 王妍丹 SAC证书编号：S0160524040002 上海交通大学工学学士、伦敦玛丽女王大学金融硕士； 研究方向为智能汽车、能源IT、工业软件。 分析师 李宇轩 SAC证书编号：S0160524080001 北京航空航天大学工学学士、上海交通大学工学硕士； 研究方向为AI应用、工业智能化、教育信息化、金融IT。 联系人 郑元昊 山东大学管理学学士、香港大学商业分析硕士； 研究方向为政务IT、AI应用、支付IT、银行IT。 联系人 陈梦笔 纽约大学经济学和环境学学士、哥伦比亚大学环境科学与政策MPA； 研究方向为AI大模型、AI应用等。 联系人 许思琪 渥太华大学学士、澳大利亚国立大学硕士； 研究方向为IDC、AI应用等。 举报/反馈"
    },
    {
      "doc_id": 49737,
      "title": "从小红书破圈到DeepSeek崛起——中国互联网创新的国际突围路径",
      "time": "2024-02-21T00:00:00+00:00",
      "content": "中国高科技企业的国际突围，要有迎难而上的心态，要把克服各种困难和挑战视为全球化进程中所必须经历的“洗礼”。 ——方兴东 DeepSeek的成功有望产生“灯塔效应”，激励我们向人工智能领域更多“无人区”进发。 ——王磊 要想方设法降低创业成本、运营成本和创新成本，着力建设便捷高效低成本的融资机制，消除中小微企业发展阻滞，全面释放民营经济创新活力。 ——臧志彭 图为DeepSeek人机交互页面。田晶娟制图 【专家沙龙】 ◎主持人：本报记者 毛 莉 嘉 宾：方兴东 浙江大学传媒与国际文化学院教授、常务副院长 王 磊 中国科学院自动化研究所研究员、北京中科闻歌科技股份有限公司董事长 臧志彭 同济大学艺术与文化产业系教授、中国文化产业协会文化元宇宙专委会常务副主任 观点速递 从社交平台小红书的破圈，再到人工智能领域DeepSeek(深度求索)的技术突破，近期中国互联网产品频频成为焦点。尤其DeepSeek以媲美ChatGPT的性能、开源模式、低成本优势震动全球。外媒纷纷感慨：“中国企业出人意料实现了赶超”“中国有可能让人工智能变得更便宜、更容易被每个人使用”……现象级产品的横空出世，让世界对中国创新能力有了新的理解和认识。 面对外部压力挑战，中国互联网企业何以破局？中国如何创造更多“DeepSeek”？科技日报特别邀请三位专家，共同探讨中国互联网创新的国际突围路径。 从应用创新到底层技术突破 主持人：近期，小红书、DeepSeek接连在美国苹果应用商店免费软件下载排行榜登顶，引发全球热议。当前中国互联网产品国际化呈现怎样的态势？ 臧志彭：中国互联网技术和应用产品获得国际竞争优势和国际社会关注，是中国1994年全功能接入国际互联网以来不懈努力和创新迭代的必然结果。30多年来，中国数字科技产业经历了从“模仿跟随”到“创新探索”再到“特色引领”的发展历程。 我们团队研究分析了二十国集团成员2021年至2023年12万余款文化类App的海外市场营收和下载情况，发布了《全球数字文化产业出海研究报告》。我们的研究显示，以App下载量和营业收入等指标衡量，中国综合排名已稳居全球第二。从具体个案看，社交领域的小红书、短视频领域的TikTok、跨境电商领域的Temu和SHEIN等已成为出海标杆。近期，DeepSeek更是成为史上最快突破3000万日活跃用户数的应用产品。 中国互联网产品的国际化进程，经历了从应用工具类产品出海到内容类产品出海，再到底层技术创新类产品出海的演进过程。这实际上反映了我国互联网产业出海的三个根本性转变：一是从单点、单类别突破向多行业出海的根本性转变；二是从应用工具开发能力向核心技术开发能力跃升的根本性转变；三是在全球价值链上从末端逐步向核心位置提升的根本性转变。 主持人：是什么力量支撑了这样的根本性转变？ 方兴东：这背后是开放中国的创新力量。中国互联网创新的国际突围并不是偶然和孤立的，而是一种水到渠成的“涌现”。成功出海的互联网企业有共同特点：代表新兴的创新力量，每一个突围故事都是小人物创造大历史；面向全球，不局限于中国市场，尽管中国市场本身很大，但都借助互联网广泛面向世界各国；创始人是年轻人，面向的主体用户也是年轻人，代表新的消费行为和社会趋势。更重要的是，这些代表性企业不局限于个别城市和区域，形成了“遍地开花”的局面：总部有的在北京，有的在上海，有的在广州，有的在杭州……它们共同构成了一个全局性“涌现”的新态势和新格局。 中国互联网创新的国际影响力，不仅自上而下地体现在全球媒体的广泛报道中，更自下而上地体现在全球广大用户的口碑中，更多人直接体验和感受到中国创新技术和产品的魅力。自上而下与自下而上的联动与协同，使中国互联网创新产生了前所未有的全球性影响。这既是以互联网为基础的数字技术演进到一定程度的结果，也是中国改革开放发展到一定阶段的产物，更是中国科技创新积累到一定高度的整体体现。 主持人：从中国互联网创新发展的长远视角看，DeepSeek的崛起意味着什么？ 王磊：在互联网的平台性应用方面，中国在国际上长期处于并跑或领先的位置。而DeepSeek的崛起尤其令人振奋，因为它意味着人工智能前沿领域的突破，涉及算力、算法、数据、人才等各方面的综合竞争。在外部封锁打压之下，一家中国初创公司独立自主研发出DeepSeek这样高性能的大模型，极大增强了从业者的创新自信。DeepSeek的成功有望产生“灯塔效应”，激励我们向人工智能领域更多“无人区”进发。 客观来看，中国仍然是一个发展中国家，在对原始创新的投入、顶尖人才的培育等方面，还存在一些约束条件。但中国人有一股劲儿，即便面临种种约束变量，也能以“咬定青山不放松”的韧劲干下去，最终还能干出不逊于国际顶尖水平的成果。 合力创造下一个“DeepSeek” 主持人：如何进一步探索人工智能领域“无人区”？ 王磊：ChatGPT的出现，引发了人们对人工智能的高度重视。而DeepSeek的问世，则让人工智能真正走进了普通人的生活。如果说去年大众对人工智能的态度是“观望与惊讶”的话，今年就是“接纳和拥抱”。过去我们讲互联网思维，以后要讲人工智能思维、大模型思维，这将是一个重要转变。 还要看到，DeepSeek的出现是一个里程碑式事件，但这并不意味着它是无法超越的巅峰之作。人工智能技术迭代更新非常快，还有很多创新性工作需要去做。从基础研究角度看，算法、算力、架构等方面的理论研究亟待突破。例如，DeepSeek虽然带来了算法效率提升，其算法新思路在深度思考方面减少了对大量标注数据的依赖，但大模型未来对算力和能源的要求仍然会很高，我们应该加快对低能耗框架的研发进程。从商业应用角度看，DeepSeek的生态圈还需进一步构建。连日来，诸多平台宣布接入DeepSeek大模型，这是一个可喜进展，但还停留在较浅层次的应用层面。问题的关键在于，各行各业能否将其作为基座大模型，开发出适用于垂直场景的示范性应用，真正实现生产效率提升、数字化转型。 我们期待，人工智能发展形成“基础科研突破—行业应用创新—社会生产力提升”的正向循环演进。我相信，在这个过程中，会诞生更多“DeepSeek”。 主持人：这引出了一个值得深思的话题，怎样创造下一个“DeepSeek”？ 方兴东：从不触及基础性创新的消费应用起步，到深入核心技术的底层技术突破，这既是一个不断演进的发展过程，也是市场竞争新陈代谢的结果，更是新一代企业家创新价值观自觉升级的体现。DeepSeek从成立伊始，就将“探索未至之境”理念作为坚定追求。DeepSeek的成功，会激励更多互联网企业将战略性资金和资源投入底层技术创新方面。 但总体而言，高科技产业是一个非常复杂的多样性生态，企业各有各的追求取向，不能一概而论。我认为，最重要的不是号召所有企业追求同一种模式，而是打造开放、自由的创新环境，让DeepSeek这样有强烈内在驱动力甚至特立独行的企业能更好、更快、更多地崭露头角。 中国互联网已经发展30多年，到今天有了一定厚度和深度，具备了系统性构建良好创新环境的条件。这次杭州因为DeepSeek等“六小龙”在全国乃至全球脱颖而出，引发了热烈讨论。而北京、深圳、上海、广州、成都、武汉等更多城市，在企业、人才、资金、政策等各个层面，都同样具备不断推陈出新的条件。全国上下都应该在科技创新方面再上新台阶，加快政策和制度创新。 王磊：所有的横空出世都是厚积薄发。DeepSeek的出现，既基于其自身长期的技术积累，也有赖于创新生态的托举。从国家科技政策的支持到算法等技术的进步，从创新人才的培育到社会资本的投入，共同为大模型突破性发展厚植创新土壤。 当前，一些城市在反思为什么自己未能孵化出DeepSeek，一些投资机构在追问为什么自己错过了DeepSeek，这样的自我审视与反思是有意义的，有利于全社会思考怎样创造更优的创新环境、培育更好的创新文化。很重要的一点是，我们要培育壮大多元创新主体，持续引导耐心资本为科创注入金融“活水”，鼓励高层次人才向企业、民营企业聚集。 此外，DeepSeek引发的全民关注热潮也有积极意义，当一个社会能让致力于硬核创新的人功成名就，就会产生正向反馈。在人人推崇创新的社会氛围下，今天的小朋友可能会想：“DeepSeek真厉害，我长大后要创造又一个‘DeepSeek’。”形成这样的导向，中国创新便未来可期。 臧志彭：我想重点谈谈民营企业。无论小红书还是杭州“六小龙”，都是民营企业。中国有庞大的创新创业群体和优秀民营企业，要想方设法降低其创业成本、运营成本和创新成本，着力建设便捷高效低成本的融资机制，消除中小微企业发展阻滞，全面释放民营经济创新活力。 同时，我们要加快构建以数据为基础的新型基础设施。数据是新一代数字经济的底层支撑，我们要着力打破数据的垄断与“孤岛”状态，加快建设数字经济的全国统一大市场，充分释放数据共享的创新策源力，努力构筑数据安全共享基础上的国家创新体系。 书写开放合作的中国叙事 主持人：连日来，国内外多家大模型厂商纷纷宣布免费开放其大模型服务。DeepSeek的开源策略是否将促使更多国家和企业寻求更加多元和开放的科技合作模式？ 方兴东：开放是创新力量的重要源泉。美国开放人工智能研究中心(OpenAI)首席执行官萨姆·奥尔特曼近日公开称赞DeepSeek“干得不错”，并承认OpenAI在开源方面“站在历史的错误一边”。2022年底，OpenAI以ChatGPT震惊世界，此前它也是以开放、开源为基本路径的。然而，在成功之后，OpenAI却选择闭源，走向了自己的反面。与之形成鲜明对比的是，DeepSeek坚定选择开源，书写了高科技开放合作的中国叙事。这告诉世界：中国高科技能以更开放的姿态、更包容的方式，去推动人工智能普惠发展，促进世界科技进步。 王磊：开源意味着与其他企业和研究人员共享资源，让其他人能用相同的技术构建和发布他们自己的产品。从事基于开源的大模型开发，实际上就是在与世界各地的人才合作。 过去，大部分有影响力的开源项目是美国科研团队发起的。不可否认，美国顶尖高校科研团队、硅谷创业者等，在区块链、人工智能、数据科技等领域的底层技术开源方面，做了很多引人注目的工作。实事求是地说，中国在开源领域还有很长一段路要走。但一个不争的事实是，近年来，在GitHub等开源社区中，中国开发者越来越活跃，中国贡献的开源项目越来越多。不仅DeepSeek，阿里云、清华大学、中国科学院等也发起了很多有影响力的开源项目。中国通信标准化协会云计算标准和开源推进委员会发布的《全球开源生态洞察报告(2024年)》显示，截至2023年，在全球活跃度排名前100的开源软件项目中，中国开源软件项目占比17%，排名第二，仅次于美国。 发展科技不能唱“独角戏”。DeepSeek会让越来越多全球科技界人士认识到：“脱钩断链”断的是机遇，“小院高墙”封的是自己。发展前沿科技，需要的是开放合作，而不是封锁孤立。 主持人：我们也要清醒地看到，中国互联网创新的国际突围之路绝非坦途，如何更好应对地缘政治压力等种种挑战？ 臧志彭：在很长一段时间，互联网产业全球价值链被美国的苹果、谷歌、Meta、亚马逊、微软等科技巨头主导，而一批中国互联网企业的成功出海，将加速重构互联网产业全球价值链。我们对这个进程中可能遭遇的风险挑战要有清醒预判。 打铁还需自身硬。应对风险挑战，最关键的是要在核心技术方面取得更多突破，从根本上增强“从0到1”的原始创新能力。同时，我们应该基于深厚的文化自信构筑差异化和特色化产业链，着力构建新一代互联网产业全球价值链体系。 王磊：我对这个问题比较乐观。真正好的创新、好的产品，是封锁不了的。举个简单的例子，智能手机好用，全世界一定会用，很少有人会愿意退回去用非智能手机。我们一定要在人工智能技术普惠这条路上坚定走下去，只要坚持以技术优势造福人类，短期内遭遇的偏见最终都会消除。 方兴东：我们必须认识到，从来没有轻轻松松、顺风顺水的全球化。中国高科技企业的国际突围，要有迎难而上的心态，要把克服各种困难和挑战视为全球化进程中所必须经历的“洗礼”。事实上，从华为到TikTok，从SHEIN到Temu，它们在国际化进程中，要么遭遇了极端打压，要么面临着各种政策壁垒，但都没有轻易退缩，而是不断学习在逆境中成长。现在我们看到了种种积极迹象，世界越来越正面看待中国高科技的崛起。 同时，对于中国高科技企业全球化这一历史进程，我们的政府、企业、社会要做好更充分的准备。“走出去”过程中，任何企业都可能面临来自市场、文化、地缘政治等方方面面的挑战。这些挑战既包括对各国文化传统、法律体系、技术标准的深度适配，也涉及国际规则衔接、跨国媒体沟通等软建设，还掺杂着地缘政治博弈等复杂变量。解决这些问题，只依靠企业单打独斗是行不通的。就像经济发展需要水通、电通、道路通和场地平整等配套条件，高科技企业全球化同样需要一系列基础设施和公共产品来“铺路架桥”。要在国家层面形成战略性顶层设计，整合政府、企业、行业协会、第三方服务机构等各方力量，打造持续投入、不断完善的系统性工程。只有这样，才能让中国高科技企业的全球化之路走得更加顺畅。 举报/反馈"
    },
    {
      "doc_id": 49738,
      "title": "DeepSeek平民化“破圈”之后",
      "time": "2024-02-13T00:00:00+00:00",
      "content": "“DeepSeek开源那天，我们小团队连夜下载了代码包。”90后创业人小林用DeepSeek批量处理短视频脚本，工作室每天产出了200条原创内容。而王燕（化名）则每天习惯性地打开DeepSeek对话框，输入自己和男友相处时的小问题，看到光标在输入栏规律闪烁，感觉“它真的懂我在说什么……” 2025年1月，DeepSeek（中文名：深度求索）在人工智能领域掀起一场风暴，给世界带来巨大的影响。这般一石激起千层浪的效应，是否被开发者梁文锋所预料，人们不得而知。和他低调隐身在喧嚣之外形成鲜明对比，这场技术爆炸带来的平民化“破圈”风暴余波未消，不断外延的涟漪涤荡着公众认知，也让圈内外共同审视风暴狂飙后的沉淀。 毋庸置疑，DeepSeek的故事已经成为AI进化史上不可忽视的重要注脚。 2024世界人工智能大会 资料图 风起 从“算力焦虑”到“算法革命” 从科技博主到普通网友，从外滩的游客到虹桥枢纽的春运旅客，人们口口相传的不仅是AI生成的“锐评段子”，还有背后那个“拒绝资本”“少年天才创业”的励志故事。这场始于技术圈、盛于春节档的“风暴”，不仅让DeepSeek成为国民级话题，更掀开了中国AI产业换道超车的一角帷幕。 “关键在于架构创新。”果壳产品研发总监陈岩评价道。DeepSeek的V3模型采用MOE（混合专家系统）架构，将600亿参数拆分为多个“专家模块”，每次推理仅激活少量模块，极大降低了算力消耗。而R1模型则通过强化学习技术，将大模型知识“蒸馏”至小模型，既保证了性能，又压缩了成本。 这种“算力不足，算法来补”的思路，被复旦大学复杂体系多尺度研究院院长、上海人工智能实验室领军科学家、国际著名计算生物学家马剑鹏教授称为“中国AI的换道超车”。“这意味着，未来构建先进的AI模型，不再需要耗费大量5纳米以下的芯片。AI发展创建了一个低成本的模式。”作为一名“AI+生物”的科学家，马剑鹏一直强调，在计算生物学AI前沿赛道上，中国不能输，重点在算法上要另辟蹊径。“这其实和DeepSeek研究团队思路不谋而合，他们创新了独特的算法，获得了成功。致力于发展复杂系统的人工智能计算方法，是中国人在AI世界赶超的重要手段，我们不能总是跟着别人的赛道走，不能弯道超车，而要换道超车。” 更具颠覆性的是，DeepSeek突破了英伟达CUDA生态的依赖。团队自研算法绕开传统GPU调度逻辑，甚至能在华为昇腾、AMD等非主流芯片上高效运行。一位工程师比喻：“就像用自行车链条驱动汽车，却跑出了赛车的速度。”这种“去英伟达化”尝试，直接导致美股芯片板块震荡，英伟达股价一度暴跌20%。 云涌 人工智能“卷”进市井烟火 2024年12月，V3模型因在GitHub开源社区表现亮眼，引发海外开发者热议；1月初，科技博主用其生成“锐评春晚”“吐槽春运”的段子，在小红书、微博疯狂传播；春节前夕，R1模型上线，“AI思考过程可视化”功能让普通用户直呼“像在和真人聊天”。自媒体津津乐道：DeepSeek是如何“突破技术封锁”，“只花了600万美金训练”。陈岩说，三次技术迭代与传播节点的精准卡位，或许也是DeepSeek完成了从极客圈到大众层的“三级跳”成功的关键。 除了传播学的丝滑外，更令人兴奋的，还是DeepSeek在行业内带来的震荡。上海人工智能研究院技术创新中心主任林圆圆介绍：“DeepSeek正在推动AI普惠化，通过技术创新、开源策略和低成本高效率模型，大大降低了AI使用门槛，促进中小企业参与行业多元化发展，加速AI应用普及。”DeepSeek-R1上线后不久，就有客户联系林圆圆，想要探索用新模型来实现垂直领域的智能问答应用。“此外，DeepSeek的出圈，也正在引发全球AI技术生态变革，并带动硬件和端侧应用发展，未来在消费电子、工业、车载等领域的渗透将进一步深化，形成‘端-边-云’协同的AI体系。 教育领域的变革同样令人期待。一位中学语文教师试用DeepSeek后感叹：“它不再只是生成教案，而是能引导学生追问‘为什么鲁迅用枣树象征孤独’。”这种启发式互动，让AI从“工具”升级为“学伴”。而在医疗领域，DeepSeek支持的“个性化健康管家”已进入临床测试阶段，未来或能通过基因数据分析，为每个人定制营养方案。 “与以往AI大模型特别不同之处在于，DeepSeek模型算法更鼓励AI程序进行‘开放式思维’，也就是RL强化学习训练法。训练没有标准答案，让AI有了自己的‘思维链’，不断尝试给人答复。当你每次根据它的答复给出反馈，鼓励它做对了或告诉它做错了，慢慢地，它就会总结出一个规律。”长期从事计算机行业的汪先生说，DeepSeek爆火，有技术的胜利，还有人文的共鸣。“大家都说跟DeepSeek对话感觉它在说人话。‘人味’的优点来源或许是因为其研发团队的年轻化使得他们更重视模型训练过程中的人文要素，让模型的对话更加符合年轻群体的对话习惯。” 技术不再高冷，DeepSeek有了人情味，也有了烟火气。如今，连63岁的上海陈阿姨都学会了用DeepSeek解决“今天吃什么”的问题，还能用AI检查孙女的寒假作业，只需要简单地拍照上传即可。“这波浪潮让技术不再是圈内自赏，而是席卷了每个普通人的生活。”陈岩说。 2024世界人工智能大会 资料图 雨骤 如何从“玩具”变成“工具”？ 当大自然里的风暴进入最猛烈的阶段时，通常伴有狂风呼啸，暴雨倾盆，整个世界仿佛都被风暴的力量所掌控。而DeepSeek的出现“搅动”了世界，也经受着来自外部的巨大压力和挑战。 1月23日，DeepSeek的服务器集群遭受了每秒超2.3亿次的DDoS攻击。打个比方，这就相当于全中国4.5亿台智能手机同时按下刷新键，攻击流量是双十一峰值流量的217倍，总量甚至达到整个欧洲三天网络流量的总和。如此强大的攻击，瞬间给DeepSeek的服务器带来了巨大的压力。这样的攻击，随后还在不断升级，从最初容易被清洗的放大攻击，逐渐演变为HTTP代理攻击，最后甚至出现了以僵尸网络为主的复杂攻击。每一次攻击模式的变化，都像是敌人变换了更锋利的武器，让DeepSeek的防御团队面临着前所未有的挑战，考验着它的应对能力。 “开源是把双刃剑。”“技术被海外复制怎么办？”物理的“攻击”之外，更多是关于技术的冷思考。对DeepSeek“开源”，梁文锋的前同事、艾麒信息创始人和董事长周朝恩表示，一点也不意外。“梁文锋尽管看着不善言辞，但在技术交流中，往往观点清晰，逻辑思维强大。他对产品和技术有着极高的追求，是典型的技术男风格。也因此，他不仅在技术上追求卓越，还富有情怀。”创业后，梁文锋就曾开放了万卡免费提供给各大学用于科研，还曾向慈善机构捐赠1.38亿元用于支持教育等公益项目。 陈岩也分析说，DeepSeek开源，一方面是出于技术理想，希望推动技术更快发展，让更多人参与到技术发展中，集合众人的智慧和力量，加速技术的创新和进步；另一方面或许有其商业考量。面对忧虑，陈岩认为，不必过于焦虑：“Linux系统证明，开源生态反而能增强话语权。” 当下，DeepSeek仍有诸多不容忽视的挑战。目前，DeepSeek的多模态能力较弱，图像、视频处理尚依赖其他模型，而Meta的Llama、谷歌的Gemini也正加速生态布局，成为其强劲的对手。“它能写诗，但看不懂画。”在陈岩看来，DeepSeek的落地仍存在鸿沟。数据显示，约60%尝鲜用户仅将其用于娱乐，真正嵌入工作流的不足15%。有团队测试发现，DeepSeek对包含图文混排的电商详情页解析错误率达43%，而谷歌Gemini仅为12%。更棘手的是，DeepSeek视频处理目前依赖于第三方模型，导致医疗影像分析等场景成本翻倍。“就像造了辆跑车，轮胎却要问别家借。” 如何从“玩具”变“工具”，是DeepSeek必须跨越的门槛。 2024世界人工智能大会 资料图 涟漪 激活青年创新的勇气和热情 与美国以OpenAI为首的“模型闭源+高算力”的巨头模式不同，中国AI公司正探索独特路径。DeepSeek母公司“幻方”背靠量化投资资金与技术积累，走“模型开源+低成本”路线；阿里、腾讯、百度等则通过云平台集成模型，降低中小企业使用门槛，赋能垂直应用。“我们不需要完全复制硅谷，而是要解决产业中的真问题。”林圆圆说。 DeepSeek或许正成为草根创业者、普通用户“技术平权”的突破点。“创新者首先要有勇气和热情，相信自己能够赢。其次，创新过程中，要有不怕输的精神，同时不计功利得失。DeepSeek团队的年轻人们经历了一次次尝试，而每一次尝试探索之前他们并没有考虑会有多少得失、回报。这才是真正的科学态度。最后，任何一项科学实验都要有那么一点运气，但运气也是实力的一部分。偶然中蕴含着必然，这是事物发展的客观规律。最终，DeepSeek找到了算法。”马剑鹏说，其实，今年诺贝尔奖的两位谷歌公司得主，当年也是走了同样一条道路，创造出AlphaFold，使人工智能发展走上快车道。 不少人担忧，AI的进步，正给人类的生存带来危机。马剑鹏给公众的忠告意味深长：“别只顾找‘锤子’，先看清‘钉子’在哪里。”当AI能自动整理知识库、分析健康数据时，人类的核心竞争力正转向“提出正确问题的能力”。这场变革中，最大的赢家或许是那些既懂技术逻辑，又深谙人性需求的“跨界者”。陈岩同样认为，与其惧怕，不如拥抱。“AI时代，建立个人知识库变得尤为重要。以我自身经历为例，过去，我只是简单地将好的内容资料收藏在微信收藏夹里，利用率很低。而现在，知识工作者可以借助AI强大的检索和归纳能力管理这些信息，十倍百倍千倍地扩大自己的记忆和知识储备。” DeepSeek风暴引发的涟漪远未消散。它证明了中国团队能用算法突破算力桎梏，但也显露了应用落地与生态建设的短板。“成本大幅降低，是AI发展的重大利好。”马剑鹏预测，DeepSeek的成功，是站在前人的基础之上，因此，也许很快，美国硅谷的创新者们在此基础上，又创造出更优化的大模型，而后，中国或其他国家再开发出进一步完善的AI结构。 “后浪推前浪、一浪比一浪高，是人类科技不断向前的趋势。同时，依靠90后、00后的活力，民营企业的灵活机制，中国AI前景未来值得期待。” 举报/反馈"
    },
    {
      "doc_id": 49739,
      "title": "DeepSeek现象背后:算法弈局与巨头焦虑",
      "time": "2024-02-03T00:00:00+00:00",
      "content": "21世纪经济报道记者孔海丽 北京报道 从2024年12月发布V3大模型，到最近推出R1模型和多模态模型Janus-Pro，DeepSeek持续出圈，形成了全球AI界乃至整个科技圈的“DeepSeek现象”。 多次采访马斯克等AI企业家的知名播客主持人莱克斯·弗里德曼（Lex Fridman），用了一个词叫做“DeepSeek 时刻”来描述，“我认为 5年后它仍将作为科技史上的关键事件被人们铭记。” DeepSeek出圈的原因之一是，它采用“更聪明”的算法，把AI训练成本砍掉近60%，却实现甚至超越了同类模型的性能。简单来说，同样的产品，别人花100块训练一个AI模型，它只要40元。这种“省钱打法”直接戳中了行业的痛点——过去拼的是谁能买更多高价芯片，现在比的是谁能把芯片用得更好。 DeepSeek不仅提供了新的AI技术路线，更重要的是，它在硅谷和华尔街联合主导的全球AI叙事铁墙上撕开了一道口子。 但我们在自豪和兴奋之余，还是要保持清醒的头脑。且不说，在资金、技术、人才等方面，以DeepSeek为代表的新创AI企业，尚无法向OpenAI、Anthropic 这些巨头发起全面挑战，单单就V3、R1而言，其算法优化也有代价：处理复杂场景时，它的表现明显不如烧钱堆出来的大模型。就像用精简版PS软件修图——日常够用，专业场景会露怯。何况，短时间内我们还不足以撼动英伟达巨头们的硬件江湖。 摆脱硬件依赖尚不现实 在“DeepSeek现象”推动下，未来的算力图景，并非单一曲线绘就。 一方面，像DeepSeek这样的产品，更高流量、更低开发和消费成本，可能带来AI应用的突然爆发，这是所有从业人员梦寐以求的场景。 另一方面，当训练成本下降刺激更多公司入场，消费者应用呈指数级增加，催生AI生态链全面繁荣，芯片需求将迎来超乎预期的增长。 硬币两面，恰好构成了算力命题的悖论。 业内人士援引腾讯之前发布的白皮书，AI Agent应用要实现跳跃式增长乃至爆发，必须闯过三关：场景渗透率大于15%、任务完成度大于80%、用户信任度大于60%。 仅以信任度为例，此前Gartner的一项抽样调查显示，64%的人表示，不希望在客户服务中使用人工智能。 目前AI Agent应用的技术能力仅满足简单场景，如客服、日程管理等。而复杂决策如医疗咨询、法律建议等，仍存在难以填补的缺陷。AI最大的应用场景是教育、医疗、金融等，但是，误诊率5%的AI医生看病，依然很难被接受。就好比，无人驾驶比人类更安全，但无人驾驶每出现一次事故都会被凝视被放大。人类对AI的信任，只是处于初始水平，此外还面临着各国隐私保护法规、用户习惯、能源约束、技术路线分歧、多智能体协作、伦理困境等方面的挑战。 业内此前预计，要到2026年前后，才将出现AI信任度的分水岭（大于60%）。“DeepSeek现象”会不会加快这个时间表的到来？现在没有人能够断定。 有人说，2025年将是AI Agent应用元年。而DeepSeek通过异构计算架构、CPU+FPGA+ASIC混合部署和动态负载均衡算法等创新，将单位算力产出提升2倍多，这是否意味着它探索的技术方向将打破算力垄断，导致算力过剩？ 这关系到算力现状。其特点是严重不均衡。一是地区不均衡。北美尤其是美国占据了全球算力规模最大份额，其次是中国，但高性能算力基本集中在北美。 二是供应不均衡。GPU厂商主要是英伟达，2025年其GPU销量预计可达700万块，CPU厂商主要是英特尔、AMD；BSIC芯片的主要厂商是博通和Marvell，合计占有超60%的份额；云计算方面，谷歌、微软、亚马逊占据全球65%的市场份额。这就是大家所说的算力垄断。 三是企业不均衡。高端芯片方面，微软、Meta、谷歌、亚马逊、xAI几大巨头目前囤积的算力总共约合355万块等效H100，这还不包括AI新贵OpenAI在内。其他经济体企业能拿到的高端芯片量，无法与之相比。 算力供需还存在结构性错配的问题。从纵向看，随着多模态应用的普及，推理侧的算力需求增速已经超过训练侧，但算力还主要布局于训练侧，调整需要一点时间；从横向看，大量算力被消耗在数据清洗和模型调试等非核心环节。 以大模型算力为例。2024年下半年以来，大模型算力已经从训练向推理转移，其中占据推理算力市场最大份额的，仍然是英伟达。 《中国算力发展报告（2024）》援引援引IDC报告，截至2023年四季度，英伟达GPU全球市场份额达95.9%，英特尔和AMD在CPU市场合计占比89.2%。英伟达通过在CUDA和GPU两端同时发力，构筑了软硬协同的护城河。有人说DeepSeek通过架构革新，绕开了CUDA，冲破了它的护城河，这其实是误读。多位专家研读DeepSeek公开（开源））论文后表示，V3、R1的底层架构仍然是基于CUDA生态建构。 在这种市场格局下，其他区域及其厂商要发起挑战，试图打破巨头垄断，摆脱以英伟达为代表的算力依赖，更多是乐观主义的展望式预期。除非量子芯片实现规模化商用，但那是5年甚至10年以后的事。 至于算力过剩，短期内不存在，整体上仍然是供大于求。《中国算力发展报告（2024）》援引中国信通院数据，截至2023年底，全球算力规模同比增长40%，但以CPU为代表但芯片年性能提升不足15%，无法满足视频、图片等非结构化数据的处理需求。赛迪智库2024年初测算，2023年中国智能算力需求达123.6EFLOPS，但智能算力供给规模仅为57.9EFLOPS，严重供不应求。“DeepSeek现象”目前看来是增加了而不是减少了硬件需求。比如，32G的英伟达RTX50系显卡，近半个月涨势凶猛，最高已经炒到了6万元以上。其中部分原因在于，部分消费者购入RTX50显卡去做DeepSeek V3、R1本地化部署。 AI巨头为何焦虑 既然DeepSeek尚未突破硬件限制，所做的也是巨人肩上的创新，但为什么还是引起美国AI巨头的焦虑甚至恐慌？ 从表层看，美国AI巨头嗅到了危机，不是因为技术被超越，而是实现目标的技术路径变了，新创企业有了更多选择。就像燃油车时代比拼的是发动机，电动车时代比拼的是电池管理技术。DeepSeek证明了硅谷堆硬件堆数据的路线不是唯一选择，高效用好现有资源同样能打。 DeepSeek省钱省力的R1模型发布时，刚好是OpenAI、软银、英伟达等科技巨头宣布5000亿美元算力基建——星际之门计划的时间段，放在这个背景下对比来看，美国AI巨头的刺痛感就更强烈了。 一位资深AI观察人士告诉21世纪经济报道记者，DeepSeek发起的这场“效率革命”，是AI发展从技术理想主义转向工程实用主义的标志性事件。它证明了，在现有硬件和物理约束条件下，通过计算拓扑结构优化获得的边际收益，远高于单纯增加芯片数量的线性增长。 这解释了为何美国AI巨头会产生战略焦虑的深层因素——当工程创新能力开始在AI竞争中脱颖而出，硅谷长期主导的技术先发优势就面临重估，而且它也将带来AI叙事的重估，背后是资本和资本市场的重估。 宏观趋势研究学者、经济学家David Woo近日接受访谈时表示，过去两年，人们一直在谈论美国经济的“例外主义”，而AI是推动这一论断形成的重要因素。美股市值占全球资本市场的份额达63%，其中ChatGPT出现后的两年，就增加了10个百分点，而七大科技巨头又占美股市值的25%。这些巨头正是依靠AI技术的强大优势巩固了它们的地位，从而间接巩固了美国资本市场的优势地位。 因此，AI与美国科技巨头、资本市场其实是捆绑在一起的，也正是硅谷和华尔街联合主导了全球AI叙事。 如今，来自东方的神秘力量DeepSeek向这套AI叙事发起了冲锋。全球科技和资本领域持续10多天的热烈反应，可以从侧面解释科技巨头的焦虑和资本市场为何如此紧张。截至2月3日美股盘前，英伟达股价自1月24日以来已跌去20%。当然，这不排除是投资者市场（避险）情绪的短期波动。 前述资深AI分析人士认为，DeepSeek创造的历史性价值有两点：一是力行开源，本质上是人类资源、科技创新的共享表达；二是提供了碓砌算力和数据之外的新的技术路径。记者这几天的采访发现，DeepSeek以上两点价值，基本已成为业内的共识。 在现实层面，DeepSeek也揭示了一个残酷的真相：当创新进入深水区，工程能力比学术突破更重要，成本控制比参数竞赛更致命，社会接受度比算法精度更关键。 如果跳开地缘政治谁赢谁输的问题，仅仅着眼于行业本身，商业本质在于，赚钱的公司才能活下去。当资本泡沫退去，或许我们会发现，技术强大固然重要，但应用和生存才是企业当下的现实，也是所有AI新创企业的必答题。 从 “谁能烧钱造最大模型”，过渡到“谁能用最少钱办最多事” ；美国企业依然掌握着最先进的芯片，但中国企业找到了更省钱的玩法——这才是DeepSeek重新书写的AI叙事。 毕竟，不是所有新创企业都像OpenAI、xAI动不动就能融资到60亿美元。正是在这个意义上，DeepSeek的技术路线，受到全球大批AI企业的效仿，其开源策略受到全球研究机构的称赞，其价格策略引发全球消费者的热捧。 高效率低成本的技术创新，加上全球关注的巨大流量，让DeepSeek赢得了宝贵的时间窗口。这是堆积大量美元都难以买到的，也是OpenAI、Anthropic等AI新创企业羡慕甚至嫉妒的。 （作者：孔海丽 编辑：骆一帆） 举报/反馈"
    },
    {
      "doc_id": 49741,
      "title": "马斯克拟推儿童版AI应用;中国模型霸榜前三丨新鲜早科技",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "21世纪经济报道新质生产力研究院综合报道 早上好，新的一天又开始了。在过去的24小时内，科技行业发生了哪些有意思的事情？来跟21tech一起看看吧。 【巨头风向标】 马斯克宣布将推出儿童版AI应用“Baby Grok” 7月20日，马斯克宣布，其人工智能公司xAI将开发一款专为儿童设计的应用“Baby Grok”，该应用将提供“友好型内容”。此外，Grok平台已推出“虚拟伙伴”功能，首批虚拟形象包括动漫角色Ani和卡通熊猫Rudy，并计划推出命名为瓦伦丁的“男性伙伴”。 黄仁勋力赞DeepSeek对中国创新能力充满信心 美国英伟达公司创始人兼首席执行官黄仁勋在接受央视《面对面》栏目采访时表示，AI是一个极其复杂的系统，中国的创新能力很惊人。这正是为什么你不得不佩服DeepSeek这家公司的惊人创新能力，他们研发的R1模型是真正的创新，它重新设计了AI模型的很多运行方式，让它们能充分发挥H20架构的优势，这种做法非常有创意。我对中国的创新能力充满乐观和信心，不管手头有什么资源他们都能适应。H20虽然不是英伟达最顶尖的产品，但能力依然非常出色，正是这种架构定义，甚至可以说创造了现在的AI革命，所以即便放到今天它依然相当出色。（央视新闻） 优必选科技拿下人形机器人企业最大采购订单 7月20日，据中国招标投标公共服务平台7月18日发布的《机器人设备采购项目中标公示》显示，优必选科技中标觅亿(上海)汽车科技有限公司9051.15万元人民币的机器人设备采购项目。这笔订单成为目前全球人形机器人企业中标金额最大的采购订单。据悉，优必选在7月17日发布了全球首个会自主换电的人形机器人Walker S2，并计划今年交付500台工业人形机器人投入到智能制造产业，此前还面向科研教育领域收获了百台天工行者机器人订单。 英伟达GPU被曝严重漏洞 7月20日消息，白帽黑客发现英伟达GPU存在严重漏洞，可通过“GPUHammer”攻击方式，让GPU上运行的大模型准确率从80%暴跌至0.02%。这种攻击并非代码篡改，而是通过反复“敲击”显存引发比特翻转的“物理攻击”。目前，研究人员已在英伟达RTX A6000上成功测试，并警告可能导致自动驾驶误识别或医疗AI误诊。英伟达建议用户开启系统级纠错码（ECC）作为防御措施，但此举会导致GPU性能下降约3%-12%。 中国模型霸榜前三 据全球大模型竞技场LMArena消息，开源模型与闭源模型的竞争进一步升级。在全球开源模型排行榜中，Kimi K2、DeepSeek R1、Qwen3等3个来自中国的开源模型排名前三，领先于谷歌Gemma3和Meta旗下Llama4，Kimi K2成为全球最强开源模型。该榜单由数千位开发者通过动态盲测进行投票。英伟达CEO黄仁勋近期也多次在北京表示，DeepSeek、Qwen和Kimi是全球最领先的开源模型。 OpenAI模型IMO夺金引数学界热议 7月20日，OpenAI宣布其推理模型在国际数学奥林匹克（IMO）竞赛中取得了金牌水平的表现，成功解决了六道题中的五道，获得35分（满分42分）。此消息引发AI社区振奋，但著名数学家陶哲轩对此表示谨慎，指出AI模型在竞赛中的表现可能因测试条件、资源辅助及结果汇报方式等因素而显著不同，呼吁在缺乏受控测试方法论的情况下，警惕将AI模型与人类表现进行“同类比较”。 微软达成超10亿美元合作 7月20日，微软与Vaulted Deep达成一项重要合作协议，计划在未来12年内处理490万吨来自粪便、污水和农业副产品的有机废物，并将其注入地下深处。这项价值超过17亿美元的交易旨在通过避免废物分解释放温室气体，帮助微软抵消数据中心产生的碳排放。 华为鸿蒙HarmonyOS 5.1系统将陆续升级 华为宣布，鸿蒙HarmonyOS 5.1将于7月开启升级，HUAWEI Mate 70系列、HUAWEI Mate 60系列机型预计2025年7月底之前陆续升级。 贾跃亭新车被指抄袭长城汽车，官网删除“高山9”描述 近日，由贾跃亭创立的法拉第未来在美国举行新车发布会，旗下第二品牌Faraday X的首款MPV车型Super One正式亮相。这款车型定位中大型MPV，提供纯电和增程两种动力类型，预计定价可能会在8万美元内（约合人民币58万元内）。据悉，整场发布会直播进行了约1个小时，临近结束大屏幕上的实时数据显示，FX Super One一小时内下定量为10034台。不过，新车发布后，有不少网友质疑FX Super One的外观设计抄袭了长城汽车旗下高端品牌魏牌的MPV车型“高山”，甚至有网友发现在Super One的介绍页面出现了“高山9”字样，FX对此并未做出回应。目前，FF官网已删除“高山9”字样。 【上市资本流】 瀚博半导体启动上市辅导 7月20日，中国证监会官网显示，瀚博半导体（上海）股份有限公司已正式启动上市辅导，由中信证券担任辅导机构。辅导备案报告披露，钱军（JUN QIAN）和张磊（LEI ZHANG）通过直接及间接持股，并结合17家员工持股平台，合计控制公司42.1465%的表决权，二人已签署一致行动协议并分别担任公司董事长和董事，被认定为公司的共同实际控制人。公司目前不存在直接持股30%以上的单独股东主体，也无控股股东。 醇氢科技完成超2亿美元第三轮融资 7月20日，醇氢科技宣布完成第三轮融资，由杭州高新金投领投，湘潭电化产投、南浔产业基金等数家战略合作伙伴跟投。本轮融资金额超2亿美元，融资资金主要用于醇氢产品技术研发及醇氢生态体系建设。醇氢科技将进一步推动液态阳光醇氢电动技术在商用领域的高质量发展，为国家能源变革提供更经济、更便捷、更可持续的液态能源技术路线。 【最芯见闻】 Linux用户空间模拟器felix86更新 RISC-V处理器可运行《巫师3》等3A游戏：7月20日，Linux用户空间模拟器felix86发布最新版本，使得RISC-V处理器能够运行《巫师2》、《巫师3》和《孤岛危机》等多款AAA级游戏。尽管实现了突破，但目前仍面临性能瓶颈和RISC-V处理器核心数量有限的挑战，影响实际可玩性。 【潮新品】 折叠屏iPhone定价或超15000元，或成苹果最贵手机 博主定焦数码爆料，苹果折叠屏iPhone采用三星提供的OLED面板，折痕做到了行业最佳，电池容量预计在5000-5500mAh之间，定价可能不止15000元。此前UBS发布了一份分析报告，报告中称折叠屏iPhone的物料成本(BOM)预计为759美元，定价预计在2000-2400美元之间，但苹果的成本控制能力可使其定价处于1800美元-2000美元的较低区间。按照1800美元来算，这个价格折合人民币约为12920元，由此猜测，国行版定价可能会突破15000元，成为史上最贵iPhone。 特斯拉首家超级充电餐厅今日起试营业 7月20日，特斯拉位于洛杉矶圣莫尼卡大道的首家“超级充电餐厅(Supercharger Diner)”正式开启试营业。该餐厅由特斯拉CEO埃隆・马斯克于2018年构想，旨在打造一家具有20世纪50年代风格的汽车餐厅，融合了复古元素，包括机器人服务员、大尺寸电影屏幕，以及一份灵感来源于过去几十年经典美食的菜单。 华为Pura 80标准版手机7月23日开启预售 7月20日，华为常务董事余承东透露，华为Pura 80标准版手机将于7月23日开启预售。该机搭载麒麟9010S处理器，配备6.6英寸LTPO OLED直屏，支持可变光圈四摄、5600mAh电池、66W快充、IP68/IP69防尘防水、卫星通信和星闪技术。 小米骨传导耳机2参数公布 7月20日，小米骨传导耳机2在京东上架，定价699元，次日10点首销。该耳机采用开放式设计，支持IP68防水，内置32GB存储，核心亮点是内置游泳算法和多项传感器，可监测游泳配速、距离等关键数据。 更多内容请下载21财经APP 举报/反馈"
    },
    {
      "doc_id": 49742,
      "title": "DeepSeek新模型霸榜,代码能力与OpenAI o1相当且确认开源,网友...",
      "time": "2024-01-20T00:00:00+00:00",
      "content": "原创 关注前沿科技 量子位 梦晨 西风 发自 凹非寺 量子位 | 公众号 QbitAI DeepSeek版o1，有消息了。 还未正式发布，已在代码基准测试LiveCodeBench霸榜前三，表现与OpenAI o1的中档推理设置相当。 注意了，这不是在DeepSeek官方App已经能试玩的DeepSeek-R1-Lite-Preview（轻量预览版）。 而是摘掉了轻量版的帽子，称为DeepSeek-R1-Preview（预览版），意味着替换了规模更大的基础模型。 LiveCodeBench团队透露，他们正在与DeepSeek合作评估新模型的能力，在合作过程中，DeepSeek团队还帮他们找出并解决了评分系统的一些bug。 与此同时，他们还晒出了目前仅有的一张DeepSeek-R1-Preview的思考过程。 鉴于DeepSeek此前已宣布R1模型将开源，有网友表示，与OpenAI o1编程能力相当的开源模型即将发布，2025年的编程就只剩下按Tab键了。 DeepSeek推理大模型满血版 两个月前，DeepSeek在官网上线DeepSeek-R1-Lite-Preview时曾透露： DeepSeek-R1-Lite-Preview使用强化学习训练，推理含大量反思和验证，遵循新的Scaling Laws—— 推理越长，表现越强。 在AIME测试基准中，随着推理长度的增加，DeepSeek-R1-Lite-Preview表现出稳定的得分提升。 DeepSeek-R1-Lite推理的特点在网友们的后续测试中也得到了验证： 在某些情况下，模型似乎能够在生成推理步骤时自我纠正，表现出类似原生“自我反思”的能力。不过，没有训练数据、模型架构和技术报告/论文的细节，很难确认这一点。 期待未来的开源模型和API！ 摘掉Lite的帽子，变成DeepSeek-R1-Preview，意味着换了更大的基础模型。 之前Lite版就在难度较高数学和代码任务上超越o1-preview，大幅领先GPT-4o。 这次在LiveCodeBench上，这次的DeepSeek-R1-Preview的表现又与OpenAI o1-Medium相当，网友们更加期待开源模型和API了。 LiveCodeBench由UC伯克利、MIT和康奈尔大学团队推出，旨在对大模型的代码能力进行全面且无污染的评估。 具体避免测试数据泄露的方法，是随着时间的推移不断从人类的编程竞赛平台收集新的题目。 除了代码生成，还会评估模型在代码自修复、执行和测试输出预测等方面的能力。 这样实时更新、确保公平性和可靠性的测试方法，获得了开发者社区的认可。 还有程序猿喊话Cursor直接把R1-Preview集成到Agent mode里： One More Thing 赶在春节前，许多还在做训练的国产大模型团队，都把自家模型更新了一遍： …… OpenAI似乎要趁这边放假开始搞事情了（狗头），奥特曼发帖透露： o3-mini完成外部合作测试，已确定最终版，将在几周内推出，会同时上线API和ChatGPT。 在后续对话中，奥特曼还确认了未来模型更多基本情况： o3-mini的速度会非常快 o3-mini大多数情况下不如o1-pro o3 pro收费从$200/月起步 OpenAI正在关注如何让AI一次性输出更多内容 2025年计划把GPT系列和o系列合并 参考链接： [1]https://x.com/StringChaos/status/1880317308515897761 [2]https://x.com/deepseek_ai/status/1859200149844803724 [3]https://x.com/sama/status/1880356297985638649 — 完 —"
    },
    {
      "doc_id": 49743,
      "title": "DeepSeek新模型霸榜,写代码与o1相当,网友:今年编程只剩Tab键",
      "time": "2024-01-19T00:00:00+00:00",
      "content": "梦晨 西风 发自 凹非寺量子位 | 公众号 QbitAI DeepSeek版o1，有消息了。 还未正式发布，已在代码基准测试LiveCodeBench霸榜前三，表现与OpenAI o1的中档推理设置相当。 注意了，这不是在DeepSeek官方App已经能试玩的DeepSeek-R1-Lite-Preview（轻量预览版）。 而是摘掉了轻量版的帽子，称为DeepSeek-R1-Preview（预览版），意味着替换了规模更大的基础模型。 LiveCodeBench团队透露，他们正在与DeepSeek合作评估新模型的能力，在合作过程中，DeepSeek团队还帮他们找出并解决了评分系统的一些bug。 与此同时，他们还晒出了目前仅有的一张DeepSeek-R1-Preview的思考过程。 鉴于DeepSeek此前已宣布R1模型将开源，有网友表示，与OpenAI o1编程能力相当的开源模型即将发布，2025年的编程就只剩下按Tab键了。 DeepSeek推理大模型满血版 两个月前，DeepSeek在官网上线DeepSeek-R1-Lite-Preview时曾透露： DeepSeek-R1-Lite-Preview使用强化学习训练，推理含大量反思和验证，遵循新的Scaling Laws—— 推理越长，表现越强。 在AIME测试基准中，随着推理长度的增加，DeepSeek-R1-Lite-Preview表现出稳定的得分提升。 DeepSeek-R1-Lite推理的特点在网友们的后续测试中也得到了验证： 在某些情况下，模型似乎能够在生成推理步骤时自我纠正，表现出类似原生“自我反思”的能力。不过，没有训练数据、模型架构和技术报告/论文的细节，很难确认这一点。期待未来的开源模型和API！ 摘掉Lite的帽子，变成DeepSeek-R1-Preview，意味着换了更大的基础模型。 之前Lite版就在难度较高数学和代码任务上超越o1-preview，大幅领先GPT-4o。 这次在LiveCodeBench上，这次的DeepSeek-R1-Preview的表现又与OpenAI o1-Medium相当，网友们更加期待开源模型和API了。 LiveCodeBench由UC伯克利、MIT和康奈尔大学团队推出，旨在对大模型的代码能力进行全面且无污染的评估。 具体避免测试数据泄露的方法，是随着时间的推移不断从人类的编程竞赛平台收集新的题目。 除了代码生成，还会评估模型在代码自修复、执行和测试输出预测等方面的能力。 这样实时更新、确保公平性和可靠性的测试方法，获得了开发者社区的认可。 还有程序猿喊话Cursor直接把R1-Preview集成到Agent mode里： One More Thing 赶在春节前，许多还在做训练的国产大模型团队，都把自家模型更新了一遍： MiniMax开源4M超长上下文新模型！性能比肩DeepSeek-v3、GPT-4o 全球首次！国产AI开源端侧GPT-4o海外爆火，8B参数iPad就能跑 国内数学最强！实测讯飞版o1：上能打奥赛卷高考，下能辅导寒假作业 阿里开源首个视觉推理模型，击败GPT-4o，网页一度404 …… OpenAI似乎要趁这边放假开始搞事情了（狗头），奥特曼发帖透露： o3-mini完成外部合作测试，已确定最终版，将在几周内推出，会同时上线API和ChatGPT。 在后续对话中，奥特曼还确认了未来模型更多基本情况： o3-mini的速度会非常快 o3-mini大多数情况下不如o1-pro o3 pro收费从$200/月起步 OpenAI正在关注如何让AI一次性输出更多内容 2025年计划把GPT系列和o系列合并 参考链接： [1]https://x.com/StringChaos/status/1880317308515897761 [2]https://x.com/deepseek_ai/status/1859200149844803724 [3]https://x.com/sama/status/1880356297985638649 举报/反馈"
    },
    {
      "doc_id": 49744,
      "title": "再见ChatGPT!Deepseek爆火海外 霸榜美区App Store下载榜",
      "time": "2024-01-27T00:00:00+00:00",
      "content": "财联社1月27日讯（编辑 刘蕊）1月20日，国产大模型公司杭州深度求索正式发布DeepSeek R1模型。这一模型展示了在数学、编程和推理等关键领域的表现甚至能媲美OpenAI的最强推理模型o1，但其API调用成本却低了90%-95%。 仅仅一周时间，这一最新模型的优越表现和超低成本就让整个硅谷都慌了神，轻而易举地轰动了海内外AI圈。 随着DeepSeek热度不断攀升，1月26日，DeepSeek应用一度因用户流量暴增，出现服务器短暂繁忙甚至“崩溃”的情况。1月27日，DeepSeek应用登顶苹果中国地区和美国地区应用商店免费APP下载排行榜，在美区下载榜上超越了ChatGPT。 苹果美区应用商店免费APP下载排行榜 中信证券研报指出，DeepSeek模型相比GPT4模型更小的参数量也意味着更低的推理成本，推理成本的降低，将是AI应用普及的前奏。预计模型性价比持续提升下，国内AI应用依托丰富生态和成熟流量加速各领域落地。其中，Agent模式有望以更长的任务流程、更好的场景理解、更高的自主能力，成为所有互联网用户的数字助手，在企业管理、教育、办公、金融等领域展现应用价值。 DeepSeek获海外科技大佬超高评价 DeepSeek之所以爆火，一方面是由于它以更低的训练成本取得与OpenAI o1相当的性能，可谓十足的“物美价廉”；另一方面，它作为一款开源模型，采用MIT许可协议，支持免费商用、任意修改和衍生开发等。所以也难怪众多科技家大佬都对DeepSeek予以了超高评价。 DeepSeek-V3在仅使用2048块H800 GPU的情况下，完成了6710亿参数模型的训练，训练成本仅为557.6万美元，远低于其他顶级模型的训练成本（例如GPT-4的10亿美元）。因此，一些人认为，DeepSeek可能会颠覆英伟达在AI硬件领域的主导地位。 上周三，微软首席执行官萨蒂亚·纳德拉（Satya Nadella）在达沃斯世界经济论坛上表示：“DeepSeek 的新模型非常令人印象深刻，他们不仅有效地开发出一种开源模型，实现了推理时间计算，而且计算效率极高…我们应该非常认真地对待中国的发展。” Meta首席AI科学家、图灵奖得主Yann LeCun表示，DeepSeek的成功，并不应该被看作中国的人工智能“超越了美国”，而应看作“开源模型正在超越专有模型”。 LeCun写道：“DeepSeek 受益于开放研究和开源…他们提出了新的想法，并在其他人的工作基础上构建了这些想法。因为他们的工作是公开的和开源的，所以每个人都可以从中受益。” 英国《金融时报》指出，DeepSeek 的成功颠覆了“AI研发必须依赖巨额投入”的传统认知，证明精准的技术路线同样可以取得优异的研究成果。更重要的是，DeepSeek 团队对技术创新的开放和分享，让这家公司成为了挑战了OpenAI、Google和Meta等老牌公司主导地位的异常强劲的竞争对手。 目前，在国外大模型排名榜Chatbot Arena上，DeepSeek-R1的基准测试排名已经升至全类别大模型第三，与OpenAI的ChatGPT-4o最新版并列，并在风格控制类模型（StyleCtrl）分类中与OpenAI的o1模型并列第一。 引发科技圈人士热议 事实上，除了科技大佬和媒体，DeepSeek也已经在海外热爱科技的大众人群中掀起热潮。 在社交平台X上，DeepSeek已经成为热门话题。一位科技爱好者在X发布一篇贴文名为“再见ChatGPT！”的贴文，直言DeepSeek最新模型才发布五天，世界已经被其潜力所震惊。这篇贴文获得了超过8000个转发和超5万点赞。 另一位科技圈人士用电影《钢铁侠》的片段制作了meme动图，嘲讽“硅谷就是个骗局”，因为DeepSeek的开发成本相比于众多美国AI巨头可谓微不足道，如同是在山洞里面用一堆破铜烂铁造出来的钢铁侠。 还有人在这张meme图中反派角色头上PS了META和扎克伯格的头像，暗讽DeepSeek的出现把META和扎克伯格打的措手不及。 事实上，相比于OPENAI的ChatGPT，META旗下的开源AI模型Llama系列的确是DeepSeek最直接的竞争对手。 据悉，随着DeepSeek爆火，Meta生成AI小组和基础设施团队的经理和工程师已开设了四个作战室来学习DeepSeek的工作原理：其中两个动员起来的小组正在试图了解幻方如何降低训练和运行DeepSeek的成本；第三个Meta研究小组正在试图弄清楚幻方可能使用哪些数据来训练其模型；第四作战室正在考虑基于DeepSeek模型属性重构Meta模型的新技术。 （财联社 刘蕊） 举报/反馈"
    },
    {
      "doc_id": 49745,
      "title": "DeepSeek 霸榜 App Store,中国 AI 引发美国科技圈地震的一周",
      "time": "2024-01-26T00:00:00+00:00",
      "content": "来源：市场资讯 来源：APPSO 过去一周，来自中国的 DeepSeek R1 模型搅动整个海外 AI 圈。 一方面，它以较低的训练成本实现了媲美 OpenAI o1 性能的效果，诠释了中国在工程能力和规模创新上的优势；另一方面，它也秉持开源精神，热衷分享技术细节。 最近，来自加州伯克利大学在读博士 Jiayi Pan 的研究团队更是成功地以极低的成本（低于 30 美元）复现了 DeepSeek R1-Zero 的关键技术——‘顿悟时刻’。 所以也难怪 Meta CEO 扎克伯格、图灵奖得主 Yann LeCun 以及 Deepmind CEO Demis Hassabis 等人都对 DeepSeek 给予了高度评价。 随着 DeepSeek R1 的热度不断攀升，今天下午，DeepSeek App 因用户访问量激增而短暂出现服务器繁忙的状况，甚至一度‘崩了’。 在海外，OpenAI CEO Sam Altman 刚刚也试图剧透 o3-mini 使用额度，来抢回国际媒体的头版头条——ChatGPT Plus 会员每天可查询 100 次。 然而，鲜为人知的是，在 DeepSeek 声名鹊起之前，其母公司幻方量化其实是国内量化私募领域的头部企业之一。 DeepSeek 模型震撼硅谷，含金量还在上升 2024 年 12 月 26 日，DeepSeek 正式发布了 DeepSeek-V3 大模型。 这款模型在多项基准测试表现优异，超越业内主流顶尖模型，特别是在知识问答、长文本处理、代码生成和数学能力等方面。例如，在 MMLU、GPQA 等知识类任务中，DeepSeek-V3 的表现接近国际顶尖模型 Claude-3.5-Sonnet。 在数学能力方面，更是在 AIME 2024 和 CNMO 2024 等测试中创造了新的记录，超越所有已知的开源和闭源模型。同时，其生成速度较上代提升了 200%，达到 60 TPS，大幅改善了用户体验。 根据独立评测网站 Artificial Analysis 的分析，DeepSeek-V3 在多项关键指标上超越了其他开源模型，并在性能上与世界顶尖的闭源模型 GPT-4o 和 Claude-3.5-Sonnet 不分伯仲。 DeepSeek-V3 的核心技术优势包括： 1． 混合专家（MoE）架构：DeepSeek-V3 拥有 6710 亿参数，但在实际运行中，每个输入仅激活 370 亿参数，这种选择性激活的方式大大降低了计算成本，同时保持了高性能。 2． 多头潜在注意力（MLA）：该架构在 DeepSeek-V2 中已经得到验证，能够实现高效的训练和推理。 3． 无辅助损失的负载平衡策略：这一策略旨在最小化因负载平衡对模型性能产生的负面影响。 4． 多 tokens 预测训练目标：该策略提升了模型的整体性能。 5． 高效的训练框架：采用 HAI-LLM 框架，支持 16-way Pipeline Parallelism（PP）、64-way Expert Parallelism（EP）和 ZeRO-1 Data Parallelism（DP），并通过多种优化手段降低了训练成本。 更重要的是，DeepSeek-V3 的训练成本仅为 558 万美元，远低于如训练成本高达 7800 万美元的 GPT-4。并且，其 API 服务价格也延续了过往亲民的打法。 输入 tokens 每百万仅需 0.5元（缓存命中）或 2 元（缓存未命中），输出 tokens 每百万仅需 8 元。 《金融时报》将其描述为‘震惊国际科技界的黑马’，认为其性能已与资金雄厚的 OpenAI 等美国竞争对手模型相媲美。Maginative 创始人 Chris McKay 更进一步指出，DeepSeek-V3 的成功或将重新定义 AI 模型开发的既定方法。 换句话说，DeepSeek-V3 的成功也被视为对美国算力出口限制的直接回应，这种外部压力反而刺激了中国的创新。 DeepSeek 创始人梁文锋，低调的浙大天才 DeepSeek 的崛起让硅谷寝食难安，这个搅动全球 AI 行业模型的背后创始人梁文锋则完美诠释了中国传统意义上天才的成长轨迹——少年功成，历久弥新。 一个好的 AI 公司领导者，需要既懂技术又懂商业，既要有远见又要务实，既要有创新勇气又要有工程纪律。这种复合型人才本身就是稀缺资源。 17 岁考入浙江大学信息与电子工程学专业，30 岁创办幻方量化（Hquant），开始带领团队探索全自动量化交易。梁文锋的故事印证了天才总会在正确的时间做对的事。 2010 年：随着沪深 300 股指期货推出，量化投资迎来发展机遇，幻方团队乘势而上，自营资金迅速增长。 2015 年：梁文锋与校友共同创立幻方量化，次年推出首个 AI 模型，上线深度学习生成的交易仓位。 2017 年：幻方量化宣称实现投资策略全面 AI 化。 2018 年：确立 AI 为公司主要发展方向。 2019 年：资金管理规模突破百亿元，成为国内量化私募‘四巨头’一。 2021 年：幻方量化成为国内首家突破千亿规模的量化私募大厂。 你不能只在成功的时候才想起这家公司在过去几年坐冷板凳的日子。不过，就像量化交易公司转型 AI，看似意外，实则顺理成章 —— 因为它们都是数据驱动的技术密集型行业。 黄仁勋只想卖游戏显卡，赚我们这些臭打游戏的三瓜两枣，却没想到成了全球最大的 AI 军火库，幻方踏进 AI 领域也是何其相似。这种演进比当下许多行业生搬硬套 AI 大模型更有生命力。 幻方量化在量化投资过程中积累了大量数据处理和算法优化经验，同时拥有大量 A100 芯片，为 AI 模型训练提供了强大硬件支持。从 2017 年开始，幻方量化大规模布局 AI 算力，搭建‘萤火一号’‘萤火二号’等高性能计算集群，为 AI 模型训练提供强大算力支持。 2023 年，幻方量化正式成立 DeepSeek，专注于 AI 大模型研发。DeepSeek 继承了幻方量化在技术、人才和资源方面的积累，迅速在 AI 领域崭露头角。 在接受《暗涌》的深度访谈中，DeepSeek 创始人梁文锋同样展现出独特的战略视野。 不同于大多数选择复制 Llama 架构的中国公司，DeepSeek 直接从模型结构入手，只为瞄准 AGI 的宏伟目标。 梁文锋毫不讳言当前的差距当前中国 AI 与国际顶尖水平存在显著差距，在模型结构、训练动力学和数据效率上的综合差距导致需要投入 4 倍的算力才能达到同等效果。 这种直面挑战的态度源于梁文锋在幻方多年的经验积累。 他强调，开源不仅是技术分享，更是一种文化表达，真正的护城河在于团队的持续创新能力。DeepSeek 独特的组织文化鼓励自下而上的创新，淡化层级，重视人才的热情和创造力。 团队主要由顶尖高校的年轻人组成，采用自然分工模式，让员工自主探索和协作。在招聘时更看重员工的热爱和好奇心，而非传统意义上的经验和背景。 对于行业前景，梁文锋认为 AI 正处于技术创新的爆发期，而非应用爆发期。他强调，中国需要更多原创技术创新，不能永远处于模仿阶段，需要有人站到技术前沿。 即使 OpenAI 等公司目前处于领先地位，但创新的机会仍然存在。 卷翻硅谷，Deepseek 让海外 AI 圈坐立不安 尽管业界对 DeepSeek 的评价不尽相同，但我们还是搜集了一些业内人士的评价。 英伟达 GEAR Lab 项目负责人 Jim Fan 对 DeepSeek-R1 给予了高度评价。 他指出这代表着非美国公司正在践行 OpenAI 最初的开放使命，通过公开原始算法和学习曲线等方式实现影响力，顺便还内涵了一波 OpenAI。 DeepSeek-R1 不仅开源了一系列模型，还披露了所有训练秘密。它们可能是首个展示 RL 飞轮重大且持续增长的开源项目。 影响力既可以通过‘ASI 内部实现’或‘草莓计划’等传说般的项目实现，也可以简单地通过公开原始算法和 matplotlib 学习曲线来达成。 华尔街顶级风投 A16Z 创始人 Marc Andreesen 则认为 DeepSeek R1 是他所见过的最令人惊奇和令人印象深刻的突破之一，作为开源，这是给世界的一份意义深远的礼物。 腾讯前高级研究员、北京大学人工智能方向博士后卢菁从技术积累的角度进行分析。他指出 DeepSeek 并非突然爆火，它承接了上一代模型版本中的很多创新，相关模型架构、算法创新经过迭代验证，震动行业也有其必然性。 图灵奖得主、Meta 首席 AI 科学家 Yann LeCun 则提出了一个新的视角： ‘给那些看到 DeepSeek 的表现后，觉得“中国在 AI 方面正在超越美国”的人，你们的解读是错的。正确的解读应该是，开源模型正在超越专有模型’。’ Deepmind CEO Demis Hassabis 的评价则透露出一丝忧虑： 它（DeepSeek）取得的成就令人印象深刻，我认为我们需要考虑如何保持西方前沿模型的领先地位，我认为西方仍然领先，但可以肯定的是，中国具有极强的工程和规模化能力。 微软 CEO Satya Nadella 在瑞士达沃斯世界经济论坛上表示，DeepSeek 切实有效地开发出了一款开源模型，不仅在推理计算方面表现出色，而且超级计算效率极高。 他强调，微软必须以最高度的重视来应对中国的这些突破性进展。 Meta CEO 扎克伯格评价则更加深入，他认为 DeepSeek 展现出的技术实力和性能令人印象深刻，并指出中美之间的 AI 差距已经微乎其微，中国的全力冲刺使得这场竞争愈发激烈。 来自竞争对手的反应或许是对 DeepSeek 最好的认可。据 Meta 员工在匿名职场社区 TeamBlind 上的爆料，DeepSeek-V3 和 R1 的出现让 Meta 的生成式 AI 团队陷入了恐慌。 Meta 的工程师们正在争分夺秒地分析 DeepSeek 的技术，试图从中复制任何可能的技术。 原因在于 DeepSeek-V3 的训练成本仅为 558 万美元，这个数字甚至不及 Meta 某些高管的年薪。如此悬殊的投入产出比，让 Meta 管理层在解释其庞大的 AI 研发预算时倍感压力。 国际主流媒体对 DeepSeek 的崛起也给予了高度关注。 《金融时报》指出，DeepSeek 的成功颠覆了‘AI 研发必须依赖巨额投入’的传统认知，证明精准的技术路线同样能实现卓越的研究成果。更重要的是，DeepSeek 团队对技术创新的无私分享，让这家更注重研究价值的公司成为了一个格外强劲的竞争对手。 《经济学人》表示，认为中国 AI 技术在成本效益方面的快速突破，已经开始动摇美国的技术优势，这可能会影响美国未来十年的生产力提升和经济增长潜力。 《纽约时报》则从另一个角度切入，DeepSeek-V3 在性能上与美国公司的高端聊天机器人相当，但成本大大降低。 这表明即使在芯片出口管制的情况下，中国公司也能通过创新和高效利用资源来竞争。并且，美国政府的芯片限制政策可能适得其反，反而推动了中国在开源 AI 技术领域的创新突破。 DeepSeek‘报错家门’，自称是 GPT-4 在一片赞誉声中，DeepSeek 也面临着一些争议。 不少外界人士认为 DeepSeek可能在训练过程中使用了 ChatGPT 等模型的输出数据作为训练材料，通过模型蒸馏技术，这些数据中的‘知识’被迁移到 DeepSeek 自己的模型中。 这种做法在 AI 领域并非罕见，但质疑者关注的是 DeepSeek 是否在未充分披露的情况下使用了 OpenAI 模型的输出数据。这似乎在 DeepSeek-V3 的自我认知上也有所体现。 早前就有用户发现，当询问模型的身份时，它会将自己误认为是 GPT-4。 高质量数据一直是 AI 发展的重要因素，就连 OpenAI 也难以避免数据获取的争议，其从互联网大规模爬取数据的做法同样因此吃了许多版权官司，截至目前，OpenAI 与纽约时报的一审裁决尚未靴子落地，又再添新案。 所以 DeepSeek 也因此遭到了 Sam Altman 和 John Schulman 的公开内涵。 ‘复制你知道行得通的东西是（相对）容易的。当你不知道它是否行得通时，做一些新的、有风险的、困难的事情是非常困难的。’ 不过，DeepSeek 团队在 R1 的技术报告中明确表示未使用 OpenAI 模型的输出数据，并表示通过强化学习和独特的训练策略实现了高性能。 例如，采用了多阶段训练方式，包括基础模型训练、强化学习（RL）训练、微调等，这种多阶段循环训练方式有助于模型在不同阶段吸收不同的知识和能力。 省钱也是技术活，DeepSeek 背后技术的可取之道 DeepSeek-R1 技术报告里提到一个值得关注的发现，那就是 R1 zero 训练过程里出现的‘aha moment（顿悟时刻）’。 在模型的中期训练阶段，DeepSeek-R1-Zero 开始主动重新评估初始解题思路，并分配更多时间优化策略（如多次尝试不同解法）。 换句话说，通过 RL 框架，AI 可能自发形成类人推理能力，甚至超越预设规则的限制。并且这也将有望为开发更自主、自适应的 AI 模型提供方向，比如在复杂决策（医疗诊断、算法设计）中动态调整策略。 与此同时，许多业内人士正试图深入解析 DeepSeek 的技术报告。OpenAI 前联创 Andrej Karpathy 则在 DeepSeek V3 发布后曾表示： DeepSeek（这家中国的 AI 公司）今天让人感到轻松，它公开发布了一个前沿级的语言模型（LLM），并且在极低的预算下完成了训练（2048个GPU，持续 2 个月，花费 600 万美元）。 作为参考，这种能力通常需要 16K 个 GPU 的集群来支持，而现在这些先进的系统大多都使用大约 100K 个 GPU。例如，Llama 3（405B参数）使用了 3080 万个 GPU 小时，而 DeepSeek-V3 似乎是一个更强大的模型，仅用了 280 万个 GPU 小时（约为 Llama 3 的 1/11 计算量）。 如果这个模型在实际测试中也表现出色（例如，LLM 竞技场排名正在进行，我的快速测试表现不错），那么这将是一个在资源受限的情况下，展现出研究和工程能力的非常令人印象深刻的成果。 那么，这是不是意味着我们不再需要大型 GPU 集群来训练前沿 LLM 了？并非如此，但它表明，你必须确保自己使用的资源不浪费，这个案例展示了数据和算法优化仍然能带来很大进展。此外，这份技术报告也非常精彩和详细，值得一读。 面对 DeepSeek V3 被质疑使用 ChatGPT 数据的争议，Karpathy 则表示，大语言模型本质上并不具备人类式的自我意识． 模型是否能正确回答自己身份，完全取决于开发团队是否专门构建了自我认知训练集，如果没有特意训练，模型会基于训练数据中最接近的信息作答。 此外，模型将自己识别为 ChatGPT 并非问题所在，考虑到ChatGPT相关数据在互联网上的普遍性，这种回答实际上反映了一种自然的知识涌现现象。 Jim Fan 在阅读 DeepSeek-R1 的技术报告后则指出： 这篇论文的最重要观点是：完全由强化学习驱动，完全没有任何监督学习（SFT）的参与，这种方法类似于AlphaZero——通过‘冷启动（Cold Start）’从零开始掌握围棋、将棋和国际象棋，而不需要模仿人类棋手的下法。 使用基于硬编码规则计算的真实奖励，而不是那些容易被强化学习‘破解’的学习型奖励模型。 模型的思考时间随着训练进程的推进稳步增加，这不是预先编程的，而是一种自发的特性。 出现了自我反思和探索行为的现象。 使用 GRPO 代替 PPO：GRPO 去除了 PPO 中的评论员网络，转而使用多个样本的平均奖励。这是一种简单的方法，可以减少内存使用。 值得注意的是，GRPO 是由 DeepSeek 团队在 2024 年 2 月发明的，真的是一个非常强大的团队。 同一天 Kimi 也发布了类似的研究成果时，Jim Fan 发现两家公司的研究殊途同归： 都放弃了 MCTS 等复杂树搜索方法，转向更简单的线性化思维轨迹，采用传统的自回归预测方式 都避免使用需要额外模型副本的价值函数，降低了计算资源需求，提高了训练效率 都摒弃密集的奖励建模，尽可能依靠真实结果作为指导，确保了训练的稳定性 但两者也存在显著差异： DeepSeek 采用 AlphaZero 式的纯 RL 冷启动方法，Kimi k1.5 选择 AlphaGo-Master 式的预热策略，使用轻量级 SFT DeepSeek 以 MIT 协议开源，Kimi 则在多模态基准测试中表现出色，论文系统设计细节上更为丰富，涵盖 RL 基础设施、混合集群、代码沙箱、并行策略 不过，在这个快速迭代的 AI 市场中，领先优势往往稍纵即逝。其他模型公司必将迅速汲取 DeepSeek 的经验并加以改进，或许很快就能迎头赶上。 大模型价格战的发起者 很多人都知道 DeepSeek 有一个名为‘AI 届拼多多’的称号，却并不知道这背后的含义其实源于去年打响的大模型价格战。 2024 年 5 月 6 日，DeepSeek 发布了 DeepSeek-V2 开源 MoE 模型，通过如 MLA（多头潜在注意力机制）和 MoE（混合专家模型）等创新架构，实现了性能与成本的双重突破。 推理成本被降至每百万 token 仅 1 元人民币，约为当时 Llama3 70B 的七分之一，GPT-4 Turbo 的七十分之一。这种技术突破使得 DeepSeek 能够在不贴钱的情况下，提供极具性价比的服务，同时也给其他厂商带来了巨大的竞争压力。 DeepSeek-V2 的发布引发了连锁反应，字节跳动、百度、阿里、腾讯、智谱 AI 纷纷跟进，大幅下调其大模型产品的价格。这场价格战的影响力甚至跨越太平洋，引起了硅谷的高度关注。 DeepSeek 也因此被冠以‘AI 届的拼多多’之称。 面对外界的质疑，DeepSeek 创始人梁文锋在接受暗涌的采访时回应称： ‘抢用户并不是我们的主要目的。我们降价一方面是因为我们在探索下一代模型的结构中，成本先降下来了； 另一方面，我们也觉得无论是 API 还是 AI，都应该是普惠的、人人可以用得起的东西。’ 事实上，这场价格战的意义远超竞争本身，更低的准入门槛让更多企业和开发者得以接触和应用前沿 AI，同时也倒逼整个行业重新思考定价策略，正是在这个时期，DeepSeek 开始进入公众视野，崭露头角。 千金买马骨，雷军挖角 AI 天才少女 几周前，DeepSeek 还出现了一个引人注目的人事变动。 据第一财经报道，雷军花千万年薪以千万年薪成功挖角了罗福莉，并委以小米 AI 实验室大模型团队负责人重任。 罗福莉于 2022 年加入幻方量化旗下的 DeepSeek，在 DeepSeek-V2 和最新的 R1 等重要技术报告中都能看到她的身影。 再后来，一度专注于 B 端的 DeepSeek 也开始布局 C 端，推出移动应用。截至发稿前，DeepSeek 的移动应用在苹果 App Store 免费版应用最高排到第二，展现出强劲的竞争力。 一连串的小高潮让 DeepSeek 声名鹊起，但同时也在叠加着更高的高潮，1 月 20 日晚，拥有 660B 参数的超大规模模型 DeepSeek R1 正式发布。 这款模型在数学任务上表现出色，如在 AIME 2024 上获得 79.8% 的 pass@1 得分，略超 OpenAI-o1；在 MATH-500 上得分高达97.3%，与 OpenAI-o1 相当。 编程任务方面，如 Codeforces 上获得 2029 Elo 评级，超越 96.3%的人类参与者。在 MMLU、MMLU-Pro 和 GPQA Diamond 等知识基准测试中，DeepSeek R1 得分分别为 90.8%、84.0% 和 71.5%，虽略低于 OpenAI-o1，但优于其他闭源模型。 在最新公布的大模型竞技场 LM Arena 的综合榜单中，DeepSeek R1 排名第三，与 o1 并列。 在‘Hard Prompts’（高难度提示词）、‘Coding’（代码能力）和‘Math’（数学能力）等领域，DeepSeek R1 位列第一。 在‘Style Control’（风格控制）方面，DeepSeek R1 与 o1 并列第一。 在‘Hard Prompt with Style Control’（高难度提示词与风格控制结合）的测试中，DeepSeek R1 也与 o1 并列第一。 在开源策略上，R1 采用 MIT License，给予用户最大程度的使用自由，支持模型蒸馏，可将推理能力蒸馏到更小的模型，如 32B 和 70B 模型在多项能力上实现了对标 o1-mini 的效果，开源力度甚至超越了此前一直被诟病的 Meta。 DeepSeek R1 的横空出世，让国内用户首次能够免费使用到媲美 o1 级别的模型，打破了长期存在的信息壁垒。其在小红书等社交平台掀起的讨论热潮，堪比发布之初的 GPT-4 。 走出海去，去内卷 回望 DeepSeek 的发展轨迹，其成功密码清晰可见，实力是基础，但品牌认知才是护城河。 在与《晚点 LatePost》的对话中，MiniMax CEO 闫俊杰深入分享了他对 AI 行业的思考和公司战略的转变。他强调了两个关键转折点：一是认识到技术品牌的重要性，二是理解开源策略的价值。 闫俊杰认为在 AI 领域，技术进化速度比当前成就更重要，而开源可以通过社区反馈加速这一进程；其次，强大的技术品牌对吸引人才、获取资源至关重要。 以 OpenAI 为例，尽管后期遭遇管理层动荡，但其早期树立的创新形象和开源精神已为其积攒了第一波好印象。即便 Claude 后续在技术上已势均力敌，逐步蚕食 OpenAI 的 B 端用户，但凭借着用户的路径依赖，OpenAI 依然在 C 端用户上遥遥领先。 在 AI 领域，真正的竞争舞台永远在全球，走出海去，去内卷，去宣传也是一条不折不扣的好路。 这股出海浪潮早已在业内激起涟漪，更早时候的 Qwen、面壁智能、以及最近 DeepSeek R1、kimi v1.5、豆包 v1.5 Pro 都早已在海外闹起了不小的动静。 2025 年虽被冠上了智能体元年，AI 眼镜元年等诸多标签，但今年将是中国 AI 企业拥抱全球市场的重要元年，走出去将成为绕不开的关键词。 并且，开源策略也是一步好棋，吸引了大量技术博主和开发者自发成为 DeepSeek 的‘自来水’。 科技向善，不该只是口号，从‘AI for All’的口号到真正的技术普惠，DeepSeek 走出了一条比 OpenAI 更纯粹的道路。 如果说 OpenAI 让我们看到了 AI 的力量，那么 DeepSeek 则让我们相信： 这股力量终将惠及每个人。 举报/反馈"
    },
    {
      "doc_id": 49746,
      "title": "霸榜刷屏 “掀翻”美股 引爆AI圈的东方“黑马”DeepSeek啥来头?",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "当地时间1月27日，美国三大股指开盘即暴跌，英伟达、微软、谷歌母公司Alphabet、Meta等美国主要科技股均遭遇股市地震。其中英伟达跌近17%，单日市值蒸发约6000亿美元，创美股最高纪录。这一切，要从成立了仅一年多的中国人工智能初创公司深度求索（DeepSeek）说起。“掀翻”美股、登顶免费应用下载榜首，DeepSeek何以让硅谷和华尔街巨头“睡不着觉”？ 01 屠榜刷屏 “掀翻”美股 1月27日，DeepSeek AI智能助手同时冲上中美苹果免费应用排行榜第一，在美区下载榜上力压ChatGPT，实现中国大模型历史性一刻。而由于下载量陡增，DeepSeek服务器几度被挤崩。 一夜之间，DeepSeek在各大社媒的屠版也引发了从华尔街到硅谷的恐慌，并霸榜各大美媒头条。 《华尔街日报》：硅谷对中国制造的人工智能模型赞不绝口 雅虎财经：DeepSeek让华尔街对人工智能投资热潮感到紧张 CNBC：人工智能股票在DeepSeek的刺激下大幅抛售 《纽约时报》：DeepSeek是如何颠覆人工智能的 《时代杂志》：DeepSeek引发股市混乱 DeepSeek“现象级”的崛起，“掀翻”了美国科技股。因受到DeepSeek冲击，美国股市27日开盘暴跌，美国芯片巨头英伟达（NVIDIA）当日股价暴跌约17%，博通公司股价下跌17%，超威半导体公司（AMD）股价下跌6%，微软股价下跌2%。此外，人工智能领域的衍生品，如电力供应商也受到重创。美国联合能源公司股价下跌21%，Vistra的股价下跌29%。 01:15 02 神秘东方力量 “AI界的拼多多” DeepSeek啥来头？ 成立于2023年7月的DeepSeek并不是一夜爆红“惊艳”所有人，从DeepSeek-V2开始，这家公司已经被硅谷视为一股东方的神秘力量。近期它再度成为热议核心，主要在于它相继发布的DeepSeek-V3和R1两款大模型产品。2024年年末，DeepSeek-V3大模型一经发布，就迅速成为全球人工智能领域的焦点，刷屏科技圈。V3以极低的训练成本实现了与GPT-4o和Claude Sonnet 3.5等顶尖模型相媲美的性能，DeepSeek就此令整个业界惊叹不已。 今年1月20日，最新开源模型DeepSeek R1的发布又在全球范围内引发持续轰动。该模型的研发仅耗时不到两个月。它具有所有熟悉的功能，对标OpenAI o1模型，但运行成本仅为OpenAI、谷歌或Meta的流行人工智能模型的极小部分。该公司表示，其基础模型的计算能力仅花费了不到600万美元，而美国公司在人工智能技术上花费了数亿或数十亿美元。这意味着DeepSeek实现了高性能与低成本的平衡。 而国内大模型行业第一场真正意义上的“降价潮”，也是由这家公司掀起的“价格战”引起。 DeepSeek因此有“价格屠夫”之称，也有人称之为“AI界的拼多多”。 03 DeepSeek何以搅动科技巨头？ 近年来，包括微软、谷歌、Meta、亚马逊和特斯拉在内的科技巨头一直在增加与人工智能相关的投资。这些公司预计将于2025年在人工智能领域总共投资约2000亿美元，其中大部分投资用于数据中心的建设。 在人工智能方面的持续投入也在不断推动这些巨头企业的估值。但DeepSeek正在以低成本的方式颠覆目前人工智能市场的格局，这引发了资本市场的恐慌，也意味着未来人工智能科技公司的估值可能迎来重构。 值得关注的是，DeepSeek的模型是使用易于访问的开源技术构建的。这引发了市场对美国人工智能技术领先中国多年观点的质疑。还有分析指出，DeepSeek恰恰是美国对华进行芯片出口限制之下所激发出的创新。 04 DeepSeek的含金量还在上升 特朗普：给美国产业敲响警钟 当地时间1月23日，刚上任不久的美国总统特朗普就签署了一项与人工智能相关的行政命令，旨在“让美国成为AI世界之都”。该命令为人工智能行动计划设定了180天的期限，以制定一项政策“以维持和增强美国在全球人工智能领域的主导地位”。 00:28 当地时间1月27日晚，特朗普在佛罗里达州迈阿密发表讲话时，对DeepSeek搅动纳斯达克一事表示，DeepSeek的出现“给美国相关产业敲响了警钟”，美国“需要集中精力赢得竞争”。特朗普同时表示，他认为，DeepSeek的模型高效且经济，其出现是一种积极的发展。 27日，英伟达针对DeepSeek的最新进展发表声明称，DeepSeek在人工智能领域取得了卓越进展，是“测试时间缩放”的绝佳范例。 DeepSeek创始人此前接受采访时曾表示，“创新首先需要自信”。他相信中国AI不会“永远跟随”，希望DeepSeek以创新贡献者的身份加入新的技术浪潮之中。 监制丨陆毅 制片人丨赵新宇 主编丨崔翀 编辑丨谢淳 ©2025中央广播电视总台版权所有。未经许可，请勿转载使用。 举报/反馈"
    },
    {
      "doc_id": 49749,
      "title": "港媒:中国企业开源浪潮重塑全球AI版图",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "参考消息网7月21日报道据香港《南华早报》网站7月19日报道，2024年7月9日或许会被称为中国人工智能（AI）界的“羞辱日”。从当天起，美国初创企业、全球人工智能模型开发领军企业开放人工智能研究中心(OpenAI)禁止中国开发者使用其模型。 与之形成鲜明对比的是，大部分国家的开发者均可正常访问，这无声地传达了该公司的立场：其宝贵的模型必须提防中国使用。 如今风向已变。2024年12月，深度求索推出面向所有人免费的DeepSeek-V3大语言模型；2025年1月，深度求索又发布推理模型DeepSeek-R1，能力媲美OpenAI的o1模型。中国企业掀起的这场开源浪潮，已在硅谷和华尔街掀起冲击波。 这一趋势不仅在中国催生了一波人工智能应用大爆发，也重塑了全球人工智能版图，并赢得世界各地开发者的拥护。中国开源模型为美国科技巨头所力推的封闭系统，提供了切实可行的替代方案。 报道称，开源人工智能模型的源代码和模型权重对所有人公开，可自由使用、修改和分发，倡导一种协作式开发模式。 以往，类似Linux的开源计算机操作系统未能取代微软Windows等专有系统，但分析师指出，这一次，中国免费开放的人工智能模型正对美国同类产品构成重大挑战。 英伟达公司创始人兼首席执行官黄仁勋称赞中国在开源人工智能方面的成就，表示将继续深化与中国企业的合作。 黄仁勋说中国公司开发的大语言模型是“世界级”的，对全球人工智能进步至关重要。 这几天在北京举行的中国国际供应链促进博览会上，他表示，中国的开源人工智能发展已成为“全球进步的催化剂”，让每个国家和行业都有机会加入人工智能变革。 报道称，与中国企业快速推出开源模型形成鲜明对比的是，OpenAI创始人兼首席执行官萨姆·奥尔特曼近日宣布，原定数日内发布的开源大模型将推迟上线，理由是出于安全考量，还需进一步测试。 科技行业投资人凯文·徐(音)指出，对深度求索等中国初创公司而言，采用开源策略是追赶的有效手段，因为这让它们能够借力更广泛的开发者社区。 自2022年底OpenAI推出聊天生成预训练转换器(ChatGPT)以来，中国开源人工智能开发者的模型开发取得显著进展。凯文·徐说：“现在大多数中国开源人工智能模型已处于或接近前沿水平……最新一波开放权重模型的发布，显示出中国在开源采用与贡献上的日益成熟。” 报道称，中国模型的先进能力已获得用户广泛认可。 截至7月中旬，深度求索在全球人工智能模型市场平台“开放路由器”上的份额达到24%，成为第二大受欢迎的模型开发商，仅次于占据37%份额的谷歌。 与此同时，世界最大开源人工智能社区抱抱脸公司网站的数据显示，阿里巴巴的千问模型家族已成为全球最大的开源人工智能生态系统，衍生模型数量超过10万个，超越元宇宙平台公司的模型社区。 中国科学院下属的多模态人工智能系统全国重点实验室研究员郑晓龙指出，中国庞大的开源生态系统应用场景遍及智能制造、数字政务等各个领域。 郑晓龙认为，技术演进与产业需求汇聚，在中国形成了独特的发展模式——应用需求驱动创新，开源生态又反哺产业成长。 他表示，中国的开源发展体现了“技术平权”的趋势，正在挑战闭源模型的地位。（编译/郭骏） 举报/反馈"
    },
    {
      "doc_id": 49750,
      "title": "全球媒体聚焦丨美媒:中国是如何斥巨资打造人工智能大国的",
      "time": "2025-07-20T00:00:00+00:00",
      "content": "最近，美国《纽约时报》的一篇文章称，去年底，全球开发先进人工智能的竞争发生了重大转变。像DeepSeek和阿里巴巴这样的中国公司已经推出了自己的开源人工智能系统，其性能跻身世界前列。与此同时，在人脑科技竞争的技术方面，中国也正在迅速缩小与美国的差距。而这并非偶然。 《纽约时报》截图 文章指出，过去十年里，中国致力于将自己打造成人工智能大国，这与中国在电动汽车和太阳能行业占据主导地位时所采用的策略如出一辙。中国还推动本国企业在高科技行业加强制造能力，此前这些行业依赖进口。这一举措已助力中国成为全球三分之一制成品的生产国，并成为电动汽车、电池以及太阳能电池板生产的领军者。中国还将这种做法应用到发展先进AI系统的组成部分上，涵盖计算能力、训练有素的工程师以及数据资源。 文章进一步分析称，在美国，谷歌和Meta等公司已在数据中心建设上投入了数十亿美元。但中国在人工智能基础设施和硬件的融资方面发挥了重要作用，涉及数据中心、大容量服务器和半导体。为了集中国内的工程人才，中国还投资建设了一个实验室网络，为了把国内的工程学人才集中起来，中国政府还投资建设了一个实验室网络，国内最先进的人工智能研究大多在此进行，而且通常是与阿里巴巴和字节跳动等大型科技企业合作。中国还引导银行和地方政府协同，催生出数百家初创企业。地方政府推动建立初创企业孵化器，不同城区还竞相提供激励措施吸引初创企业落户。 《纽约时报》截图 文章表示，中国企业正转向开源人工智能系统，视其为追赶硅谷竞争对手的最快途径。过去一年，阿里巴巴发布了几款热门的开源系统。字节跳动去年在数据中心和其他人工智能基础设施上投入了110亿美元，还公布了其部分技术构建的细节。本月，华为也发布了一款开源系统。就连此前盛赞封闭式人工智能产品“盈利潜力”的中国互联网公司最近也发布了部分系统的开源版本。尽管OpenAI和谷歌对其封闭式人工智能系统的访问收取额外费用，但中国公开大模型的做法让世界各地的工程师更容易在其系统上进行开发。 尽管有观点认为，像DeepSeek这样的中国人工智能公司可能会将美国竞争对手挡在全球市场之外，从而让它们有机会为新技术的使用方式制定标准。不过，中国的开源做法也许对全球更多工程师更有吸引力。毕竟开源是技术软实力的来源，“它相当于技术界的巨无霸”。 编译丨魏宇晨 签审丨魏 郁 邹浩宇 举报/反馈"
    },
    {
      "doc_id": 49751,
      "title": "从DeepSeek突破看我国人工智能自主创新与技术应用",
      "time": "2024-05-29T00:00:00+00:00",
      "content": "转自：前线理论圈 DeepSeek（深度求索）作为我国人工智能领域的新兴力量，凭借其开源、低成本和高性能的AI模型这一突破性成果，颠覆了“高算力、高成本”是AI模型开发必要条件的传统认知，从而霸榜各大媒体头条，为全球所关注。 DeepSeek是我国在全球人工智能领域实现的历史性新突破，也为全球舆论场提供了应用新场景新技术。在复杂的国际环境里，我们要遵循新质生产力发展规律，面向世界科技前沿，围绕战略制高点，不断突破核心技术难题，深化自主创新，加强信息基础设施建设，把握互联网发展主动权、AI发展主导权和国际传播话语权。 DeepSeek重塑全球AI发展新格局 2025年1月，杭州深度求索人工智能基础技术研究有限公司发布DeepSeek-R1模型，并同步开源模型权重。DeepSeek-R1性能类比OpenAI 01正式版，推理成本却更低。一个星期内，DeepSeek应用在1月27日登顶苹果美国地区应用商店免费App下载排行榜。 DeepSeek-R1模型是AI领域极为出色的“中国智慧”和“中国方案”，赋能重塑全球AI大模型的发展新格局。DeepSeek-R1的开源、低成本和高性能，引发全球科技界广泛关注，其推理效率与美国顶尖模型相当，硅谷称之为“中国的ChatGPT时刻”。国际社会普遍认为，DeepSeek以算法优化和异构计算架构，打破了AI领域“堆算力”的传统路径，展示了我国在工程实用上的重大突破。 DeepSeek优势在于以算法优化突破大模型算力竞赛困境，其作为极致优化的AI大模型和智能媒介技术，有望打通低成本与高性能间价值实现的“最后一公里”。DeepSeek开放的技术生态使得全球研发力量能更快共享资源，这种合作模式正在改变美国长期以来构建的封闭体系，也在一定程度上消解了美国在AI领域的话语霸权和技术优势。 海外主流媒体指出，DeepSeek-R1模型在性能上与美国领先模型相当，但训练成本远低于美国公司的巨额投入，形成了巨大发展优势。法国AI公司Mistral AI认为R1模型证明了小型语言模型的可行性，并为欧洲企业在与美国科技巨头竞争中提供了启发。微软CEO萨提亚·纳德拉认为，DeepSeek有“真创新”，并指出AI成本下降是趋势，该观点得到不少科技界人士的认同，认为DeepSeek技术创新让AI行业距离实际产业应用又近了一步。不少发展中国家主流舆论表示，DeepSeek的成功经验，使他们看到了在AI领域追赶发达国家的希望。 全球人工智能发展面临的风险挑战 人工智能作为21世纪最具革命性的技术之一，正在深刻改变全球经济、社会和生活方式的方方面面。然而，其在被广泛应用的同时，也面临诸多亟待解决的问题。 如何有效保护数据隐私，已成为全球AI发展面临的挑战。隐私保护不仅是西方社会关注的热点议题，更逐渐演变为全球AI治理领域的话语权博弈焦点。虽然诸多AI企业明确声明会严格遵循相关法律法规，全力保障用户数据隐私安全，但在当前国际数据安全形势错综复杂、保护标准与监管机制差异显著的大背景下，仍存在数据泄露与滥用的风险。 以DeepSeek为代表的AI企业不断涌现，为全球AI发展注入活力，但算力瓶颈仍待突破。训练大规模AI模型需要消耗海量能源，若算力问题得不到解决，不仅限制模型性能提升，也会增加AI发展成本，阻碍技术普及。 算法偏见可能导致不公平决策。比如，在就业、金融等领域应用时，由于语料库和训练数据存在偏差，其算法可能产生偏见，从而作出不公平乃至错误的决策。全球AI发展普遍存在此类问题，亟须制定统一伦理准则和监管机制，明确责任界定，从源头上保证数据公正，避免算法偏见。 我国人工智能发展的升维路径 2016年4月19日，习近平总书记在网络安全和信息化座谈会上强调：“目前，大国网络安全博弈，不单是技术博弈，还是理念博弈、话语权博弈。”如今，AI大模型的发展是大国网络安全博弈的聚焦点，要建设好发展好“大国网络安全博弈”的国之重器，切实维护国家主权、安全和发展利益。 加强技术博弈。一是以增强原创能力为重点，以关键核心技术为主攻方向，夯实我国AI发展基础。DeepSeek的实践让全球AI叙事从单纯的“硬件竞赛”转向“算法优化”，人们逐渐意识到算法创新对于推动AI发展的重要性。在此趋势下，亟须提升我国AI在复杂场景的应用能力和创新水平，以适应不断变化发展的市场需求和技术发展趋势。在理论方面，加强基础理论研究，特别是关键共性技术、前沿引领技术等创新，持续提升原始创新能力。在技术层面，加快发展智能芯片与硬件、物联网与边缘计算、生成式人工智能等关键核心技术，鼓励原创算法创新，确保我国占领关键核心技术制高点。 二是升华国内AI应用场景和重视海外市场拓展。近期，DeepSeek模型在超算互联网平台的规模化落地，获得丰富的异构算力资源，或将改变国内AI行业依赖海外闭源模型的现状。未来，我国人工智能大模型发展需主动拥抱全球AI开源发展态势，激发原创活力与应用动力，加强不同模型技术间的交互学习与协同创新；以“中国AI方案”助力海外市场，推动全球AI全产业链协同发展。 三是完善AI法治与伦理体系，为AI健康发展筑牢规范基石。数据是AI发展的基础，低质量数据会影响AI模型准确性和可靠性，导致数据隐私和安全问题突出。需建立完善数据质量管理体系，规范数据采集、标注和使用流程；加强数据隐私保护技术研发，在保障数据安全前提下，实现数据价值的最大化利用。 深化理念博弈。网络空间是人类共同的活动空间，网络空间前途命运应由世界各国共同掌握。习近平主席在第二届世界互联网大会上提出了全球互联网发展治理的“四项原则”“五点主张”，特别是我们倡导尊重网络主权、构建网络空间命运共同体，赢得了世界上绝大多数国家的赞同。 “四项原则”，即尊重网络主权、维护和平安全、促进开放合作、构建良好秩序。“五点主张”，即加快全球网络基础设施建设，促进互联互通；打造网上文化交流共享平台，促进交流互鉴；推动网络经济创新发展，促进共同繁荣；保障网络安全，促进有序发展；构建互联网治理体系，促进公平正义。 ✦ 一是以开源模式打破西方“价值普遍性”的话语垄断。从知识与信息平权角度来看，技术自主创新与开源共享模式意味着知识和技术不再被少数巨头垄断，全球开发者都能平等获取技术底层资源，拥有参与AI技术创新的机会，促进知识在全球范围内的流动与共享。同时，要强化对媒介物质性的认知，构建符合全球发展需求、更具责任意识的传播伦理体系，从而推动技术发展与价值引导的良性互动。 二是DeepSeek以其独特的技术路径极大地激发了民族自豪感，对此，既要充分肯定DeepSeek在技术创新上的重大突破，展示中国科技企业在全球竞争中的实力，激发国人对本土科技发展的信心，又要严守理性与客观，坚持平衡民族自豪感与技术客观性，对打破西方“小院高墙”“脱钩断链”政策充满信心。 提升话语权博弈。人工智能传播的发展对国际传播提出了更高要求。一方面，DeepSeek在西方软件排行榜快速登顶，印证了国内外用户对先进技术的普遍偏好，支持和鼓励中国AI技术的发展，这是提升我国国际传播影响力的重要机遇。另一方面，国内人工智能内容生成受西方媒体和语料库的影响，在概率算法中难以成为AI最终生成内容的选择，这就导致最终生成内容要么无法呈现，要么受到西方意识形态的制约。 对此，一是要提高算力，强化传播技术。加强精准传播能力，利用算法推荐和数据分析，实现文化内容的精准推送和个性化定制，更加生动立体地展现丰富多彩的中国形象。二是要把握人工智能时代为国际传播创造的广阔机遇，继续加大政策支持力度，激发人工智能企业的创造力，打造数字化、网络化、智能化的文化传播平台，拓展多样化的文化传播渠道，搭建起人文交流、民心相通的桥梁。 作者：王凤翔，中国社会科学院新闻与传播研究所大数据舆情研究室主任，中国社会科学院创新工程首席专家；张洁，中国社会科学院大学硕士研究生 文章来源：《前线》杂志2025年第5期 图片来源：视觉中国 责任编辑：申洁 网络编辑：张家伟 举报/反馈"
    },
    {
      "doc_id": 49752,
      "title": "DeepSeek埋头“小更新”,又打了模圈一个措手不及",
      "time": "2024-05-31T00:00:00+00:00",
      "content": "作者｜参商 编辑｜星奈 媒体｜AI大模型工场 29号，深度求索赶在端午假期到来前正式完成了DeepSeek R1模型的小版本升级，消息一出模圈哗然。自从2月份红遍国内外后DeepSeek一直是以模型供应商的身份活跃在大模型圈的“幕后”版块，鲜少有在一线露面的机会，更多的是各家采购商只言片语的提及，没想到再听见发声，已是憋出来个升级的时候： 现在DeepSeek R1已经升级为最新的DeepSeek-R1-0528，用户可通过官方网站、APP 或小程序进入对话界面后，开启“深度思考”功能即可体验最新版本。API 也已同步更新，调用方式不变。 01 超强能力者再创国产模型评分新高 作为一个深度思考模型，本次升级自然是绕不开深度思考能力的强化。具体而言，DeepSeek-R1-0528仍然使用的是去年12月发布的DeepSeek V3 Base模型作为基座模型进行训练，但在后训练过程中投入了更多算力，以此达到了显著提升模型思维深度与推理能力的效果。 根据官方披露，更新后的R1在数学、编程与通用逻辑等多个基准测评中取得了当前国内所有模型中首屈一指的优异成绩，并且在整体表现上已接近其他国际顶尖模型，如 o3 与 Gemini-2.5-Pro： 可以看到相较于旧版本R1，新版R1在复杂推理任务中的表现有非常显著的提升，真正追平国际顶尖水平。具体在 AIME 2025测试中，新版模型准确率由旧版的 70% 提升至 87.5%。根据官方解释，这是得益于模型在推理过程中的思维深度增强：在 AIME 2025 测试集上，旧版模型平均每题使用 12K tokens，而新版模型平均每题使用 23K tokens，表明其在解题过程中进行了更为详尽和深入的思考。 同时，深度求索还基于DeepSeek-R1-0528的思维链，后训练了Qwen3-8B Base，得到了 DeepSeek-R1-0528-Qwen3-8B。而该8B模型在数学测试 AIME 2024 中仅次于DeepSeek-R1-0528，超越 Qwen3-8B（+10.0%），与 Qwen3-235B 相当。再次证明了全新R1的强劲能力。 02 实测：肉眼可见的生成内容提升 至于具体体验如何，我们一起来看看快速上手测试的结果。下图是我让全新DeepSeek R1进行自我介绍的聊天过程： 可以看到现在的R1相比先前版本有了更流畅更清晰的回答过程，不论是思考链还是正式生成内容，甚至有非常贴心的对比和总结，都用了一些特殊符号标注出来。 这些充分的交互功能在过去的R1版本是所不曾体现，当时大家还在调侃DeepSeek过于活人感，有一股机器人魔性的疯癫美，但现在看来，全新R1的工具化进程明显，更有个人通用助手的味道，这在当下强调agent通用处理能力的形势下具有一定意义。 当然除了针对深度思考生成结果本身提升来说，这次也同步升级了许多其他的特点，比如针对翻译内容的优化： 可以看见翻译得非常准确，而且非常有人味，当我们要求翻译Love loves to love love ，遵循信达雅时： R1能够自动匹配到林语堂先生的语录，并且能够帮我们去对比与直译的差别，可谓是文科强者，这在先前版本的R1那个理工脑子是不存在的。 同样的全新R1编程能力也不俗，像这里我们要求其为我们生成一个网页： prompt：你能为我创建一个基于情绪的食谱生成器吗？它应该询问用户的情绪，然后根据他们拥有的食材推荐食谱。它应该有明亮自然的主题，搭配纤细且美观的字体，并且应该是动画的和互动的。不要使用紫色暗色调主题，主题就由你的创造力来决定。 可以看到质量尚可，当然R1并不是编程agent，生成的内容无法自带后端，但是这个前端编程能力已经在所实际体验过的深度思考agent里属于头部水平了。 同时，在旧版R1的基础上，更新后的 R1 模型针对议论文、小说、散文等文体进行了进一步优化，能够输出篇幅更长、结构内容更完整的长篇作品，同时呈现出更加贴近人类偏好的写作风格，像这里我要求R1以端午和六一为背景写一篇抒情散文诗，首先散文诗这个格式的文章本来就不多见，其次我还特别要求以近代著名文学家端木蕻良的文风来创作： 上下滑动查看完整内容 可以看见生成内容文学气质直接拉爆了，标题这个“端午与六一的断章”就起得非常有意境，并且内容辞藻在保证华丽的基础上，多多添了白描的手法，保证了整体内容散形不散的文种特点。 除了这些比较明显的更新外，新版 DeepSeek R1 针对“幻觉”问题进行了优化。与旧版相比，更新后的模型在改写润色、总结摘要、阅读理解等场景中，幻觉率降低了 45～50% 左右，能够有效地提供更为准确、可靠的结果。同时DeepSeek-R1-0528 支持工具调用（不支持在 thinking 中进行工具调用）。虽然目前水平与 o3-High 以及 Claude 4 Sonnet 仍有差距，但Tau-Bench 测评成绩为 airline 53.5% / retail 63.9%，已经做到了OpenAI o1-high 相当。 03 DeepSeek给模圈一个措手不及，模圈给DeepSeek一个强制爱 DeepSeek这一次的更新，API 已同步更新，接口与调用方式保持不变。新版 R1 API 仍支持查看模型思考过程，同时还增加了 Function Calling 和 JsonOutput 的支持。同时对新版 R1 API 中 max_tokens 参数的含义做了调整：现在 max_tokens用于限制模型单次输出的总长度（包括思考过程），默认为 32K，最大为 64K。如果用户对更长的上下文长度有需求，可以通过其他第三方平台调用上下文长度为 128K 的开源版本 R1-0528 模型。 和之前的操作一样，这次的模型也同步开源。DeepSeek-R1-0528 与之前的 DeepSeek-R1 使用同样的 base 模型，仅改进了后训练方法。私有化部署时只需要更新 checkpoint 和 tokenizer_config.json（tool calls 相关变动）。模型参数为 685B（其中 14B 为 MTP 层），开源版本上下文长度为 128K（网页端、App 和 API 提供 64K 上下文）。与旧版本的 DeepSeek-R1 保持一致，此次我们的开源仓库（包括模型权重）仍然统一采用 MIT License，并允许用户利用模型输出、通过模型蒸馏等方式训练其他模型。 就在DeepSeek发布全新R1的第二天，火山引擎和腾讯就前后脚更新了最新版： 很明显各大厂商并没有被这场突袭搞蒙圈，反倒是给了DeepSeek一个强制爱，可见现阶段各家大厂对于行业最新的前沿技术跟进非常用心。DeepSeek-R1-0528的思维链对于学术界推理模型的研究和工业界针对小模型的开发都将具有重要意义。现阶段已经进入大模型存续阶段，谁有丝毫懈怠就会被落下身位。半年已过，DeepSeek全新R1也正式拉开了下半年的模圈大战，期待未来行业的发展，特别是以后R2的来袭。"
    },
    {
      "doc_id": 49753,
      "title": "外媒:中国AI模型震惊硅谷",
      "time": "2024-01-26T00:00:00+00:00",
      "content": "英国《金融时报》1月25日文章，原题：中国小型人工智能初创公司深度求索如何震惊硅谷。 本周，中国一家人工智能（AI）实验室发布尖端模型的“技术配方”，此举不仅震惊世界，也使其低调的负责人变成无视美国阻止中国高科技雄心企图的民族英雄。 1月20日，由对冲基金经理梁文锋创立的公司深度求索正式发布R1模型，并在一篇论文中详细解释了如何利用有限的自筹预算来构建一个大语言模型，该模型可在没有人工监督的情况下自动学习和自我改善。 包括OpenAI和谷歌DeepMind在内的美企率先开发出推理模型，这是一个相对较新的人工智能研究领域，旨在尝试使模型具有与人类相匹配的认知能力。上月，OpenAI发布o1模型的完整版本，但对创建模型的方法保密。 深度求索R1模型的发布在硅谷引发一场激烈辩论，主题是包括Meta和Anthropic在内资源更雄厚的美国人工智能企业能否守住技术优势。与此同时，梁文锋也成为提升中国国内民族自豪感的焦点人物。本周，在中国总理召开的一次座谈会中，梁文锋是唯一的人工智能企业负责人。 2023年梁文锋创建深度求索公司。“他建立一个出色的基础设施团队，他们真正了解芯片的工作原理。”另一家大语言模型公司的创始人说。 在华盛顿禁止英伟达向中国出口功能最强大的芯片后，中国本土人工智能企业被迫寻找创新方法，以最大限度地利用现有芯片的计算能力，而梁的团队已经知道如何解决这一问题。“深度求索公司的工程师知道如何释放这些图形处理器（GPU）的潜力，即使它们不是最先进的。”一名人工智能研究人员说。 业内人士表示，深度求索对研究的专注使之成为一个可畏的竞争对手，因为该公司愿意分享取得的突破，而非为获取商业利益保护它们。深度求索没有从外部基金筹集资金，也没有采取重大举措将其模型货币化。北京的一名人工智能行业投资者说：“深度求索的运作方式就像早期的DeepMind，它专注于研究和工程。” 深度求索仅用2048颗英伟达H800 GPU和560万美元，就训练出6710亿参数的开源大模型，这只是OpenAI和谷歌训练同等类型模型花费的一小部分。加州大学伯克利分校人工智能政策研究员里特维克·古普塔表示，深度求索最近发布的模型表明，“没有阻碍人们获取人工智能能力的壕沟”。他说：“训练模型第一人必须花费大量资源才能实现目的，但跟进者可用更少的费用且以更快的速度实现目的。” 古普塔还表示，中国拥有比美国大得多的系统工程师人才库，他们知道如何最好地利用计算资源，以更便宜的方式训练和运行模型。 美国的竞争对手也没有停滞不前。它们正在构建由英伟达新一代Blackwell芯片组成的超大型“集群”，从而创造出强大的计算能力，有可能再次拉开与中国竞争对手的性能差距。（作者埃莉诺·奥尔科特等） 美国“商业内幕”网站1月25日文章，原题：当来自中国的人工智能竞争令硅谷感到恐慌，扎克伯格表示Meta将投资600多亿美元扎克伯格24日在社交媒体上表示，2025年将是“人工智能的决定性一年”。他透露：“我们计划今年对该领域增加600亿至650亿美元投资，同时大幅扩大人工智能研发团队。” 就在扎克伯格宣布这一消息之际，硅谷正在审视与中国企业深度求索有关的新闻，在第三方开展的基准测试中，该公司开发的开源人工智能模型的表现超过Meta、OpenAI和Anthropic等美企的模型。人工智能和中国成为本周在瑞士达沃斯举行的世界经济论坛2025年年会的主要话题。“我们应该非常、非常认真地对待来自中国的发展态势。”微软（OpenAI最大投资方）的首席执行官纳德拉如是说。（作者凯蒂·贝尔维奇，王会聪译） 举报/反馈"
    },
    {
      "doc_id": 49754,
      "title": "外媒:中国AI模型震惊硅谷",
      "time": "2024-01-26T00:00:00+00:00",
      "content": "英国《金融时报》1月25日文章，原题：中国小型人工智能初创公司深度求索如何震惊硅谷本周，中国一家人工智能（AI）实验室发布尖端模型的“技术配方”，此举不仅震惊世界，也使其低调的负责人变成无视美国阻止中国高科技雄心企图的民族英雄。 1月20日，由对冲基金经理梁文锋创立的公司深度求索正式发布R1模型，并在一篇论文中详细解释了如何利用有限的自筹预算来构建一个大语言模型，该模型可在没有人工监督的情况下自动学习和自我改善。 包括OpenAI和谷歌DeepMind在内的美企率先开发出推理模型，这是一个相对较新的人工智能研究领域，旨在尝试使模型具有与人类相匹配的认知能力。上月，OpenAI发布o1模型的完整版本，但对创建模型的方法保密。 深度求索R1模型的发布在硅谷引发一场激烈辩论，主题是包括Meta和Anthropic在内资源更雄厚的美国人工智能企业能否守住技术优势。与此同时，梁文锋也成为提升中国国内民族自豪感的焦点人物。本周，在中国总理召开的一次座谈会中，梁文锋是唯一的人工智能企业负责人。 2023年梁文锋创建深度求索公司。“他建立一个出色的基础设施团队，他们真正了解芯片的工作原理。”另一家大语言模型公司的创始人说。 在华盛顿禁止英伟达向中国出口功能最强大的芯片后，中国本土人工智能企业被迫寻找创新方法，以最大限度地利用现有芯片的计算能力，而梁的团队已经知道如何解决这一问题。“深度求索公司的工程师知道如何释放这些图形处理器（GPU）的潜力，即使它们不是最先进的。”一名人工智能研究人员说。 业内人士表示，深度求索对研究的专注使之成为一个可畏的竞争对手，因为该公司愿意分享取得的突破，而非为获取商业利益保护它们。深度求索没有从外部基金筹集资金，也没有采取重大举措将其模型货币化。北京的一名人工智能行业投资者说：“深度求索的运作方式就像早期的DeepMind，它专注于研究和工程。” 深度求索仅用2048颗英伟达H800 GPU和560万美元，就训练出6710亿参数的开源大模型，这只是OpenAI和谷歌训练同等类型模型花费的一小部分。加州大学伯克利分校人工智能政策研究员里特维克·古普塔表示，深度求索最近发布的模型表明，“没有阻碍人们获取人工智能能力的壕沟”。他说：“训练模型第一人必须花费大量资源才能实现目的，但跟进者可用更少的费用且以更快的速度实现目的。” 古普塔还表示，中国拥有比美国大得多的系统工程师人才库，他们知道如何最好地利用计算资源，以更便宜的方式训练和运行模型。 美国的竞争对手也没有停滞不前。它们正在构建由英伟达新一代Blackwell芯片组成的超大型“集群”，从而创造出强大的计算能力，有可能再次拉开与中国竞争对手的性能差距。（作者埃莉诺·奥尔科特等） 美国“商业内幕”网站1月25日文章，原题：当来自中国的人工智能竞争令硅谷感到恐慌，扎克伯格表示Meta将投资600多亿美元扎克伯格24日在社交媒体上表示，2025年将是“人工智能的决定性一年”。他透露：“我们计划今年对该领域增加600亿至650亿美元投资，同时大幅扩大人工智能研发团队。” 就在扎克伯格宣布这一消息之际，硅谷正在审视与中国企业深度求索有关的新闻，在第三方开展的基准测试中，该公司开发的开源人工智能模型的表现超过Meta、OpenAI和Anthropic等美企的模型。人工智能和中国成为本周在瑞士达沃斯举行的世界经济论坛2025年年会的主要话题。“我们应该非常、非常认真地对待来自中国的发展态势。”微软（OpenAI最大投资方）的首席执行官纳德拉如是说。（作者凯蒂·贝尔维奇，王会聪译） 举报/反馈"
    },
    {
      "doc_id": 49756,
      "title": "DeepSeek爆火,中国人工智能要“井喷”如何闯关?",
      "time": "2024-02-21T00:00:00+00:00",
      "content": "“中国距离追上ChatGPT还有多远？” 过去几年里，这是几乎每个中国大模型从业者们都被反复拷问的话题。 2025年初，这个问题被重新解构。 “来自东方的神秘力量”搅动全球科技圈，一度带崩芯片股，也引领了持续一个月的“DeepSeek热”。从巴黎到迪拜，近期所有国际性AI大会都在讨论它，尽管它并未参加。 风投机构a16z创始人安德森将DeepSeek R1描述为“人工智能的斯普特尼克时刻”，斯普特尼克是苏联在1957年先于美国发射的人造卫星。 ScaleAI创始人亚历山大·王的观点更激进：过去十年来，美国可能一直在AI竞赛中领先于中国，但DeepSeek的AI大模型发布可能会“改变一切”。 压力之下，海外AI巨头近期动作频频，谷歌端出了热乎的新产品Gemini2.0系列，xAI发布了马斯克口中“地球上最聪明的人工智能”Grok 3，为坐稳大模型王座，OpenAI也变得焦虑，CEO在线投票征集开源方案。 以DeepSeek为代表的中国模型看起来追上甚至部分超越了一向领先的海外模型。QuestMobile数据显示，DeepSeek日活跃用户已在2月1日突破3000万大关，成为史上最快达到这一里程碑的应用。随后，全球最大的代码托管平台GitHub显示，DeepSeek的Star量（星标）超过了OpenAI。 全球在人工智能领域长期角力进入新阶段，全球的大模型实力差距到了重估的时候。 通往罗马的路不只有一条 自2022年底ChatGPT发布以来，中国AI的主流叙事一直是“追赶”。过去一两年，当被问及我们离OpenAI有多远时，有从业者给出的答案还是代差两三年。2025年，这个问题的答案会更乐观。 “通往罗马的路并不是只有一条，可能有很多风景更优美的路径。”枫清科技创始人兼 CEO 高雪峰对第一财经记者表示， DeepSeek-R1 将很多方面的研究创新性地组合在一起，并真正实验，达成了现在的效果，的确是一件值得让全球关注的创新性研究成果。 复旦大学计算机科学技术学院教授邱锡鹏则用“令人震惊”形容R1系列中的R1-Zero，以往大模型团队复刻GPT-o1时会遇到如何拿到训练数据的重要问题，而R1-zero证明了纯RL就能增强模型推理能力。“这让人产生非常大的遐想，打开了思路：未来是不是有很大的机会能通过大规模RL在推理路线上超越o1？”邱锡鹏说。 CIC灼识咨询执行董事董晓雅在接受记者采访时认为，DeepSeek的爆火意味着中国的AI已大幅拉近了与美国技术的差距。“DeepSeek证明中国能够在既有的技术框架下，通过局部创新与大规模系统级工程优化，实现对国际领先水平的追赶甚至超越。” 而从AI从业者的感知来看，今年年初曾前往硅谷的光轮智能创始人谢晨对第一财经记者说，他发现硅谷在AI领域的认知其实和国内顶尖创业者的认知并没有太大差异，且形成了相当程度的共识。例如，“预训练不行了，要转向后训练”、“RLHF很关键”、“具身智能前景广阔”等，其实这些在国内早已有深入讨论，硅谷正在“祛魅”。 不只是DeepSeek，复旦大学计算机科学技术学院教授、上海市数据科学重点实验室主任肖仰华对第一财经记者表示，单纯从国内外模型的效果上来看，我们的差距已经比较微弱。无论是黑马大模型Deepseek还是大厂派的通义千问系列，从模型效果上看，都已经非常接近海外顶尖模型。 如果看向模型榜单，中国AI势力不容小觑。全球知名AI模型评测平台Chatbot Arena（大模型竞技场）公布的最新一期榜单显示，Top11名单中（包含部分并列的模型，总数不止11个），国内4家大模型厂商共有6款产品上榜，包括排在第5位的推理模型DeepSeek-R1，第8位的通义千问Qwen2.5-Max，并列第10位的DeepSeek-V3、Qwen-Plus-0125和智谱AI的GLM-4-Plus-0111，阶跃星辰的Step-2-16K-Exp排在11位。 大模型竞技场是业界公认的榜单之一，采用匿名方式将大模型两两组队，交给用户进行盲测（提出任何相同问题），根据真实对话体验对模型能力进行投票。这份榜单部分可以代表中国大模型在全球市场的竞争力。 分领域来看，在基座大模型领域，通义千问旗舰版模型Qwen2.5-Max模型挤进了基座模型TOP5，排在前面的是xAI最新发布的Grok-3，谷歌旗舰模型Gemini 2.0 Pro、OpenAI最新的GPT-4o模型，以及谷歌通用模型Gemini 2.0 Flash。DeepSeek-V3作为基座模型排在第6位。 在推理模型领域，DeepSeek的R1已经挤进全球开闭源推理模型TOP3，在榜单中仅次于谷歌的推理模型Gemini 2.0 Flash Thinking，超过OpenAI的o1。 除了榜单外，从在专利、顶会论文等维度来看，中国在大模型赛道上也展现出强大的竞争实力。 根据去年7月发布的《2023全球人工智能创新指数报告》显示，在主要国家人工智能顶级论文数量和主要国家人工智能专利授权数量上，中国远高于美国。 其中，顶会顶刊论文中国作者数量从2018年的328人增长到2022年的1674人，与美国的差距正逐渐缩小。在主要国家人工智能顶级论文数量占比上，中国占比36.7%，美国占比22.6%。 专利领域同样竞争激烈。上述报告称，在主要国家人工智能专利授权数量占比上，中国占比34.7%，美国占比32%。 近日记者从知识产权信息服务商智慧芽获得的数据显示，2020年至2024年期间，美国在人工智能领域累计申请8.4万余件专利，其中2.4万余件已获授权；同期中国在人工智能领域累计申请77.6万余件专利，其中29.9万余件已获授权，分别是美国的9.23倍和12.45倍。 这些领域，中国AI仍需追赶 DeepSeek的横空出世，让全球看到了中国AI技术的潜力，但这场爆火背后，业界仍需直面与美国AI产业的差距。这既体现在AI企业数量、技术、算法等显性维度，也体现在创新土壤与生态体系的深层结构之中。 根据《全球数字经济白皮书（2024年）》，截至2024年一季度，全球AI企业中美国占34%，而中国仅占15%。尽管中国AI企业数量不少，但与美国相比仍有较大差距。 上述报告还显示，截至去年7月，全球人工智能大模型有1328个（包含同一企业、同一模型的不同参数版本），美国大模型数量位居全球第一，占44%，位居第二的中国大模型数量占比为36%。 而在AI独角兽规模中，在2023年到2024年第一季度，全球AI独角兽已有234家，新增数量为37家，占新增独角兽总量的40%，其中，美国AI独角兽120家，中国AI独角兽71家。 AI目前仍是高度依赖资金投入的烧钱行业，在投融资方面，中美存在不小差距。 过去一年里，全球AI领域投资呈现爆发式增长，CB Insights报告显示，去年全球 AI 领域融资总额达1004亿美元，同比增长79.61%，占全球融资总额的69%。其中，美国依然是AI投资的主要力量，AI初创企业融资额约占全球70%，以伊隆·马斯克的xAI、OpenAI和Anthropic等为代表的美国AI公司获得了数十亿美元的巨额投资。中国在2024年的AI初创企业融资额仅占全球融资额的7%，远远低于美国。 一位聚焦中美市场的AI创业者告诉第一财经记者，目前美国一级市场仍是繁荣的状态，一方面表现在VC基金绝对数量多，另一方面表现在创投生态完善。从pre-seed一直到A轮甚至B轮，美国VC们形成了一条“流水线”似的投资孵化链条，为早期创业公司保驾护航，提供了更多的确定性。 另一位AI创业者对记者举例，自己在硅谷观察到，一些AI初创团队的创始人来自斯坦福、MIT 等名校，通常三五人组成小团队、开发一款产品，并构建一个宏大故事，美国投资人态度宽容，即使团队商业路径还未想清楚，也能拿到 50～80 万美元的种子轮融资，而在国内同阶段可能很难达到这种规模。此后在天使轮阶段，即便商业化尚未完善，也能拿到 500～800 万美元的投资。 在此前为数不多对外发声中，DeepSeek创始人梁文锋提到，他的团队不会过早设计基于模型的应用，而会专注在大模型上，目标是做研究、做探索。此前DeepSeek也在找不同出资方谈，但接触下来感觉很多VC对做研究有顾虑，VC有退出的需求，希望尽快做出产品商业化，而按照DeepSeek优先做研究的思路，很难从VC获得融资。 清华大学长聘副教授、面壁智能首席科学家刘知远也以DeepSeek为例，称这是一个非常技术理想主义、以AGI（通用人工智能）为梦想组建的团队，拥有一个由技术长期主义推出来的结构。“中国已经到了这样一个阶段，需要有更多像DeepSeek这样的团队，但是又不像DeepSeek这么有钱，能不能让他们踏踏实实地做一些创新？这非常值得我们思考。” “我们需要更多的DeepSeek” DeepSeek的爆火并非终点，而是中国AI从单点突破迈向“系统能力构建”的起点。 大模型生态社区OpenCSG（开放传神）创始人陈冉对记者提到建设生态的迫切性，有了模型，需要建生态。“单点有了，但没有面，没有网状生态。” 高雪峰同样认为，在基础算法研究的沉淀上，在大生态圈的建设方面，以及在硬件基础设施的创新与追赶方面，我们都需要继续付出更多的努力。 他表示，DeepSeek将普惠 AI 的基准水平拉齐到了最前沿的水准。当全球越来越多用户， AI 技术生态就会明显倾向国内优秀开源模型，“可以明显看到，普惠 AI 的风已经在中国吹响，各个城市的大中小型企业都在寻求用 DeepSeek的开源技术来实现自身的智能化场景，这会对模型甚至硬件的发展带来不可估量的正向影响。” 高雪峰认为，当国内真正涌现出非常多具备行业特定推理能力的优秀模型与行业知识体系时，我们会真正具备与任何领先的 AI 技术竞争的实力，因为国内在数据整合，知识整合的方面有先天优势。 “雪球就这么滚起来了”。盘古智库学术委员、FutureLabs未来实验室首席专家胡延平对第一财经记者提到，DeepSeek引爆市场带来巨大的信心提振，有助于接下来形成良性的开源生态循环， 而接下来一个重要的方向是国产算力要能够跟上，形成生态软硬件协同。 此外，从技术创新的角度看，肖仰华认为，关键不在于我们是否属于第一阵营，而在于是否是第一。 “想要与海外顶尖模型竞争，在效果上接近的同时，能否做到成本更低、服务更优、响应更快、场景适配更好也很重要。”肖仰华对记者表示，在达到当前性能接近的成果之后，国内模型已具备与头部模型竞争的可能性，但还要看很多其他因素。 “AGI容易形成类似于差之毫厘、失之千里的效应，即使在某个领域以微弱优势领先，但AI是一种基础能力，在千行百业无处不在的应用中，会放大这一微弱的领先优势。”因此，国内模型并不能满足于现阶段的成果。 他同时也认为，AI是全方位的，“例如在具身智能、在千行百业的应用，我们的亮点仍然不多，但是美国已经取得了很多世界级的成果。”他补充道，“我们还需要更多的Deepseek。” “此前，国内外大模型公司都在追随OpenAI，DeepSeek-R1追上o1后，国内面临的下一个问题变成了，下一步需要自己走一条全新的路或找到全新的创新点。这是未来看中美差距的关键点。”张俊林说。 开创性的突破也需要容忍失败的勇气。张俊林提到，国内存在做原始创新的可能性，前提是有这种企业文化：不着急赚钱，在宽松环境下做各种尝试。目前看，国内只有DeepSeek有这种环境，但如果其他企业能复刻这种环境，将推动国内大模型团队创新甚至反超OpenAI。 肖仰华认为，市场投入结构和效率或许需要改变。 他对记者提到，中国在AI方面的资源、资本投入并不少，但主要是自上而下的规划和创新，作为辅助的是民营企业和民间投入的科技创新。 “此次Deepseek的成功，让我们意识到，来自民营小微企业等市场主体自发地创新难能可贵，可能是整个国家科研科技创新体系中非常宝贵的一分子。” 肖仰华说，优化投入效率和投入结构很重要。初创企业、小微企业和民营企业是具有创新活力的，是他们的好奇心和创造力成就了这次突破，全社会需要“呵护”这种创新。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 49757,
      "title": "DeepSeek是中国对全球AI发展格局的重塑",
      "time": "2024-02-19T00:00:00+00:00",
      "content": "2025年1月20日，中国人工智能企业深度求索（DeepSeek）发布的开源模型DeepSeek—R1，犹如一颗投入平静湖面的巨石，在国际上激起千层浪，它颠覆了国际社会对AI研发“高投入、长周期”的固有认知，打破了美国对AI话语权的垄断，更被西方媒体称为“人工智能的斯普特尼克时刻”。 DepSeek是世界AI的“斯普特尼克时刻” 自2022年美国ChatGPT问世并在全球引起广泛关注以来，AI大模型服务逐渐形成了“堆算力”的思维定式：想要用上更优性能的产品必须支付更高昂的费用，以覆盖整个模型训练过程中更高算力成本的支出。因此，当中国DeepSeek以1/18的训练成本、1/10的团队规模、不分伯仲的模型性能出现在世人面前时，在全球掀起了一场AI风暴，其震撼力不亚于两年前的ChatGPT，上至硅谷、科研院校，下至社交媒体、普通用户，全在谈论DeepSeek带来的震撼。同时，也令华尔街股票市场对斥巨资构建人工智能大语言模型的合理性和前景产生质疑，部分投资者开始抛售权重科技股。当天，美国股市大幅下跌。其中，市值排名第一的英伟达公司股价暴跌16.97%，市值蒸发近6000亿美元，创下美国上市公司单日市值损失的纪录。 “DeepSeek冲击波”还在不断扩散。最新突破在于其新一代大语言模型V3，该模型在多项评测中表现优于主流开源模型，并且具有成本优势。DeepSeek的R1模型在技术上实现了重要突破，通过纯深度学习方法使AI自发涌现出推理能力，在数学、代码、自然语言推理等任务上的性能比肩OpenAI的o1模型正式版。美国《商业内幕》网站2月2日报道称，DeepSeek这家创新实力超群的中国人工智能初创企业正在展现赶超美国顶级人工智能实验室的能力。美国科技投资家、亿万富翁马克·安德雷森将其形容为人工智能的“斯普特尼克时刻”。 中国AI开发给全球AI带来新的活力和机遇 2024年底，DeepSeek发布了新一代大语言模型V3并宣布开源。这一举措让它在AI领域崭露头角。紧接着，在世界经济论坛2025年年会开幕当天，DeepSeek又发布了最新开源模型R1，再次引发全球人工智能领域的关注热潮。DeepSeek-R1和DeepSeek-V3在数学、代码、自然语言推理等任务上的性能表现卓越，接近OpenAI的GPT-01正式版。然而，其训练成本却远低于美国开放人工智能研究中心、谷歌、“元”公司等美国科技巨头在人工智能技术上的投入。据悉，R1模型训练成本仅为560万美元，而目前顶尖模型的训练成本往往高达数亿美元乃至数十亿美元。 不仅是DeepSeek在世界AI市场具有影响力，中国各大头部企业也在自主推进AI开发。近期，阿里巴巴旗下的阿里云发布通义千问旗舰版模型Qwen2.5-Max，其性能超过DeepSeek-V3。腾讯、字节跳动、百度、华为等公司也在加紧提高AI性能。国家互联网信息办公室近期发布的信息显示，截至2024年12月31日，共有302款生成式人工智能服务在国家网信办完成备案。从大型企业到初创公司，各企业通过应用程序等，在生活中的方方面面对AI加以有效利用。DeepSeek的成功标志着中国在国家层面推进的AI战略正结出果实。除了这些主流云平台外，360数字安全、云轴科技ZStack、移动云、中国联通等也纷纷宣布上线DeepSeek大模型。此外，DeepSeek的出现为全球AI领域带来了新的活力和机遇，DeepSeek的移动应用已经超越ChatGPT，登顶苹果手机应用商店美国区免费应用榜单。其日活用户数量在上线仅仅20天就突破了2000万大关，日活增长速度超过了当初爆火的ChatGPT。亚马逊、微软等多家海外科技巨头对DeepSeek表现出开放态度，陆续宣布接入DeepSeek模型，充分显示了DeepSeek在技术层面的卓越表现得到广泛认可。这一系列成绩都充分证明了DeepSeek在国际市场上的受欢迎程度和强大影响力。 中国是全球AI治理的积极倡导者和践行者 DeepSeek以开源思维挑战传统AI行业的一些传统路径，展现中国人工智能技术的巨大潜力，其使用的算力能够远低于全球平均水平，还可以免费使用，而且是开源的。低成本与开放性的强强联合有助于普及AI技术，为全球开发者提供了一个低成本、高效的人工智能开发平台，促进了全球人工智能技术的共享与发展。国际学术期刊英国《自然》杂志网站发文称，中国推出的实惠、开放的人工智能模型DeepSeek-R1让科学家们兴奋不已。文章表示，该模型被视为是比OpenAI的o1模型更加经济实惠且开放的竞争对手。多家海外媒体发文高度评价DeepSeek-R1模型性能，并对中国国产AI大模型坚持开源的开放共享精神表示赞赏，称其“为全球科研工作者们提供了前所未有的机遇”。DeepSeek-R1的崛起不仅是中国创新的里程碑，更是一面摆在美方垄断霸权面前的“照妖镜”。当美国仍在执着于技术遏制时，中国已用行动证明，开放创新的浪潮无法阻挡，合作才是穿越技术铁幕的唯一出路。 人工智能已成为世界新一轮科技革命和产业变革的重要驱动力量。刚刚闭幕的巴黎人工智能（AI）行动峰会落下帷幕，巴黎峰会最重要的成果之一是法国、中国、印度等61国联合发布了《关于发展包容、可持续的人工智能造福人类与地球的声明》，推动了全球范围内对AI治理的合作共识，凸显了加强AI生态系统多样性的重要性，提出了AI可及性、开放性、透明度、可持续发展等优先事项，尤其是缩小数字鸿沟、提升发展中国家AI能力建设的目标，具有重要意义。中国在全球AI治理上持续推动多边合作，以高度负责的态度参与人工智能全球治理，于2023年提出《全球人工智能治理倡议》，强调人工智能治理需要全面平衡，并倡导创造开放、包容、无障碍和非歧视的发展环境，确保所有国家都能从人工智能的进步中获益。中国还承诺于2025年底前重点面向发展中国家举办10期人工智能领域的研修研讨项目，成立了对应国际上的“AI安全研究所（AISI）”的“中国人工智能发展与安全研究中心”，将在上海召开2025世界人工智能大会，包括9月在上海国家会展中心举办第25届中国国际工业博览会，届时将汇集人工智能开发人员、研究人员和从业者，共同探讨技术进步、实际应用和人工智能治理。中国愿在人工智能领域与各国共推发展、共护安全、共享成果，共同构建人类命运共同体。 来源：中国日报网 举报/反馈"
    },
    {
      "doc_id": 49759,
      "title": "特朗普的第一周;中国大模型震惊硅谷;加州新火情致数万民众撤离...",
      "time": "2024-01-25T00:00:00+00:00",
      "content": "◆ 本周，特朗普正式宣誓就任美国总统。上台后，他迅速签署了一系列行政命令，涉及科技、关税、经济、移民、外交等多个领域，同时还废除了前任拜登政府的近80项政策。特朗普在继承其上一任期核心议题的同时，也在策略上做出了一些新的调整。与其首届任期相比，“特朗普2.0”有何不同？金融市场作何反应？《每日经济新闻》记者连线国际关系学院美国问题专家孙冰岩解读。 ◆ 中国大模型震惊硅谷；加州新火情致数万民众撤离；OpenAI创始成员之一Andrej Karpathy给智能体泼冷水；特斯拉、微软、Meta和阿斯麦财报下周来袭。更多内容，尽在《一周国际财经》。 特朗普的第一周：“退群”，“围追堵截”非法移民 喊话美联储降息，拟投5000亿美元“星际之门” 当地时间1月20日中午，美国首都华盛顿大雪纷飞，在国会大厦圆形大厅，特朗普宣誓就职，正式出任美国第47任总统，时隔4年后开启第二个任期。 重返白宫第一周，特朗普密集签署一系列行政命令，承诺迅速变革一切。从科技、关税到经济、内政，再到外交，特朗普在继承其上一任期核心议题的同时，也在策略上做出了一些新的调整。 “特朗普2.0”与其首届任期相比有何不同？国际关系学院美国问题专家孙冰岩对《每日经济新闻》记者指出，“特朗普2.0”相比八年前有“3个不变”和“4大变化”。 特朗普就职后的第一周，金融市场如预期般充满刺激，但市场反应却出乎意料。本周，标普500指数虽然上涨1.7%，创下自1985年里根就职以来最佳开局，但表现不及日本和德国等市场。美元也大幅走弱。 科技：5000亿美元打开“星际之门” 从出席特朗普就职典礼的宾客名单就可以看出本届政府对科技界的重视。全美三大超级富豪——埃隆·马斯克、马克·扎克伯格与杰夫·贝索斯全部受邀，且都在会场的前排就座。 1月21日，上任第二天，特朗普在白宫宣布，日本软银集团、OpenAI和甲骨文公司将联手打造“星际之门”项目，计划在美国建设数据中心。特朗普强调，这是“史上最大”的AI基础设施投资项目。该项目的初始投资为1000亿美元，并计划在未来4年内扩展至5000亿美元。 1月23日，特朗普签署了一项与人工智能（AI）相关的行政命令，旨在“让美国成为AI世界之都”。该命令为AI行动计划设定了180天的期限，以制定一项政策“以维持和增强美国在全球AI领域的主导地位，从而促进人类繁荣、经济竞争力和国家安全”。此前，特朗普还撤销了拜登2023年签署的行政命令，该命令旨在降低AI对消费者、劳工和国家安全构成的风险。 此外，关于TikTok的未来，特朗普要求TikTok“不卖就禁用”法律在未来75天内暂不执行。在75天宽限期内，美国司法部不得依据“不卖就禁用”法律采取任何执法行动，也不得处罚任何不遵守该法律的实体。但特朗普也表示，若想取消禁令，美国“应该有权获得一半股份”。特朗普这一要求再次凸显了“强买强卖”“不给就抢”的美国式谈判策略。 关税：不在美生产就缴巨额关税 据央视新闻报道，1月23日，特朗普在世界经济论坛2025年年会上发表视频讲话时称，如果不在美国生产产品，就将面临“数千亿美元甚至数万亿美元”关税。 同时，特朗普批评欧盟关税太高，监管限制性太强，与美国贸易逆差太大。他表示将对此采取措施，因为这“对美国非常非常不公平”。对此，当地时间1月22日，欧盟经济专员瓦尔迪斯·东布罗夫斯基斯（Valdis Dombrovskis）在达沃斯论坛上表示，如果特朗普对欧洲征收关税，欧洲将以相应的方式回应。 上任首日，特朗普还宣称，可能从2月1日起对所有从墨西哥和加拿大进口的商品征收25%的关税。加拿大总理特鲁多回应称，如有必要，加拿大将采取报复性关税，他支持一比一对等关税原则。日前，加拿大拟定反制清单，准备对价值1500亿加元（约合1050亿美元）的美国产品加征关税，约占加拿大进口美国商品总值的近三分之一。 1月21日，特朗普声称，美国政府正在讨论从2月1日起对从中国进口的商品加征10%的关税。1月22日，我国外交部发言人毛宁主持例行记者会上重申，我们始终认为贸易战、关税战没有赢家，中方始终坚定维护国家利益。 经济：宣布进入“国家能源紧急状态”，要求立即降息 国内经济方面，特朗普对前任政府政策进行了180度的改变。 特朗普宣布美国进入“国家能源紧急状态”，加大传统能源开采，结束拜登政府“绿色新政”，撤销电动车优惠政策以“拯救美国传统汽车工业”。 在具体能源政策上，特朗普提出了一系列新措施，包括简化审批流程、限制风电场发展，并废除拜登政府时期的“气候极端主义”政策。 针对电动汽车，特朗普的新令将停止把从50亿美元基金中分配未使用的政府资金用于车辆充电站建设，要求终止各州到2035年采用零排放汽车规则的豁免。特朗普还表示，其政府将考虑取消电动汽车税收抵免。 1月23日，特朗普还对美联储发起猛烈抨击。据参考消息，特朗普当天在达沃斯论坛发表视频讲话时称：“随着油价下跌，我将要求立即降息。同样地，全球的利率都应该降下来。” 他重申，美联储官员们听他的是很正常的事，因为“我比他们更懂利率”。 移民：废除出生公民权、“围追堵截”非法移民 在宣誓就职首日，特朗普就签署了多份涉及移民政策的行政令来打击非法移民。 其中一项就是废除非法移民或合法临时居留者在美出生子女的“出生公民权”。“出生公民权”政策在美国已有100多年历史，保证在美国出生的所有人都享有公民身份，无论其父母身份如何。美国宪法第十四条修正案中对“出生公民权”作出了规定。 1月23日，华盛顿州美国地区法官约翰·考夫诺尔以“公然违宪”为由，发布临时限制令叫停总统的行政令。此禁令有效期为14天。 1月22日，美国代理国防部长罗伯特·塞勒塞斯就响应特朗普关于保卫美国边境的行政命令所采取的行动发表声明。首先，国防部将开始增强其在西南边境的兵力，增加约1500名地面人员、直升机及相关机组人员和情报分析员，以支持加强的侦查和监控工作。其次，国防部将提供军用空运以支持国土安全部的驱逐航班，驱逐被美国海关和边境保护局拘留的5000多名非法移民。此外，国防部将开始协助建造临时和永久性的物理屏障，以增加安全保障，遏制非法越境和非法贩运。 1月24日，美国白宫新闻发言人卡罗琳·莱维特称，美国已经开始使用军用飞机驱逐移民。 此外，特朗普已签署行政命令，要求撤销拜登政府时期曾颁布的有关“保障美国女性获得生殖保健和其他保健服务”的行政令。 孙冰岩对每经记者表示，特朗普这一任期内的移民政策与其说是“调整”，不如用“剧变”来形容。美国的非法移民主要聚焦在建筑行业，然后是零售业和餐饮业。如果大规模动用军队驱逐，服务业会率先受到冲击，房地产价格也可能会有一些上涨。 外交：施压、对话、“退群” 在俄乌冲突问题上，特朗普一边寻求对话，一边又在施压。1月22日，特朗普在社交媒体上发文称，如果俄罗斯拒绝与乌克兰就结束俄乌冲突谈判达成和平协议，美国将对俄罗斯征收高额关税并实施制裁。然而，特朗普23日表示，希望尽快与俄罗斯总统普京举行会晤，讨论解决乌克兰冲突问题。24日，普京表示，俄方已作好就乌克兰问题进行谈判的准备，他愿意与特朗普就“任何双方感兴趣的领域”进行对话。 此外，特朗普在1月20日签署行政令，将“墨西哥湾”更名为“美国湾”。特朗普在这项行政令中说，在美国发展壮大的过程中，墨西哥湾一直是其“不可或缺的财富”，至今仍是“美国不可去除的一部分”。 特朗普就任首日，美国接连“退群”，宣布将退出世界卫生组织和应对气候变化的《巴黎协定》。特朗普表示，《巴黎协定》“不公平”“一边倒”，“美国不会破坏自己的工业”，自诩“美国在推进经济和环保目标放标的成功记录应成为其他国家的榜样”。美国公共事务研究中心一项民意调查显示，半数美国人“强烈”或在“一定程度上”反对美国退出《巴黎协定》。 专家解读：特朗普2.0的“3个不变”与“4大变化” 在孙冰岩看来，“特朗普2.0”相比八年前有“3个不变”和“4大变化”。 特朗普在第二任期的不变在于： 首先，保守主义加民粹主义的执政议程没有变，核心议程仍是移民、税改和去管制化； 其次，兑现竞选承诺、说到做到的形象没有变； 第三，迅速扭转上一任政府政策的风格没有变。 关于“4大变化”，孙冰岩认为，首先，现在特朗普的执政阻力远远小于首个任期。新华社也分析称，经历2024年大选，特朗普成功组建了一个由科技大亨和民粹主义者组成的“让美国再次伟大”联盟，把共和党改造成“特朗普党”。 其次，特朗普更会扩张总统权力，更会挑战宪法，挑战最高院，挑战国会的制约，挑战媒体的制约。 第三，“特朗普2.0时代”的参众两院比较听从指挥。孙冰岩说：“特朗普如果要在国会立法推行一些政策，会比2017年顺利很多。特朗普现在和两院关系非常好，两院都非常听从指挥。” 最后，“反对”声音也更加微弱。目前美国主流媒体的环境也不一样了，对特朗普的态度可能更偏向于客观中立。据新华社报道，2017年1月特朗普首次就职时，近60万抗议者涌入华盛顿特区。今年特朗普宣誓就职时，反特朗普的抗议活动“规模显著缩小”。 新华社分析称，特朗普现在被认为是上世纪80年代里根以来权力最大的美国总统，美国的政治钟摆向右剧烈摆动。与八年前特朗普开启首个任期时相比，当今世界更加不稳定。特朗普在就职演讲中宣称：“美国的黄金时代现在开始了”。但世界看到的，却是一个贫富分化加剧、社会不信任加深、社会失序加重的美国。 金融市场怎么反应？ 特朗普就职后的第一周，金融市场如预期般充满刺激，但市场反应却出乎意料。 本周，标普500指数虽然上涨超1.7%，创下自1985年里根就职以来最佳开局，但表现不及日本股市的3.9%、德国股市的2.4%和墨西哥股市的约5%。 美国国债市场相对平静，10年期国债收益率与一周前基本持平，变动幅度为去年9月以来最小。 美元则大幅走弱，彭博美元现货指数周跌幅达1.6%，创下14个月以来最大单周跌幅。新兴市场货币普遍上涨，哥伦比亚比索、匈牙利福林和波兰兹罗提兑美元均上涨超过3%。在非美资产中，受益于“星际之门”项目所带动的市场乐观情绪，日本半导体股和欧洲电气股表现尤为突出。 中国大模型全球“刷屏”，震惊硅谷 近日，中国AI初创公司深度求索（DeepSeek）引发硅谷的震惊。 深度求索于去年12月底推出了一款免费的开源大模型DeepSeek-V3。该模型仅耗时两个月、花费不到557万美元便搭建完成。 在一系列第三方基准测试中，从复杂问题解决到数学和编程等方面，DeepSeek-V3在准确性上超越了Meta的Llama 3.1、OpenAI的GPT-4o以及 Anthropic的Claude Sonnet 3.5。 1月20日，深度求索又推出推理模型DeepSeek-R1，在许多第三方测试中，该模型同样超越了OpenAI最新的o1模型。 据外媒报道，中国大模型取得的新进展，为硅谷敲响了警钟，人们开始担忧，美国在AI领域的全球领先优势是否正在缩小，大型科技公司也开始质疑，在打造AI模型和数据中心上巨额投入是否值得。 “看到深度求索的新模型，我深感震撼。他们不仅成功打造出一款开源模型，实现了推理时的高效计算，而且超级计算效率极高，” 微软首席执行官萨提亚・纳德拉周三在瑞士达沃斯世界经济论坛上表示，“我们必须极其严肃地对待中国在这方面的发展。” “需求是发明之母，”Perplexity首席执行官阿拉温德・斯里尼瓦斯说，“因为（在外部限制条件下）他们不得不寻找变通方法，结果反而打造出了效率更高的产品。” 被誉为“AI教父”的杰弗里·辛顿指出，尽管中国尚未完全赶上西方，但已经非常接近。他认为，尽管美国试图通过限制（如英伟达芯片）来减缓中国的发展，但这只会促使中国加速发展自己的技术，“他们可能会落后几年，但最终会赶上”。 旧火未灭新火又来，加州数万民众被迫撤离 1月7日起，加州洛杉矶县接连爆发山火，就在“帕利塞德”与“伊顿”山火尚未被扑灭之时，洛杉矶北部1月22日又发生名为“休斯”的山火，火势向社区快速蔓延。据加州林业和消防局消息，起火点为卡斯泰克湖附近。山火在季节性强风“圣安娜风”推动下迅速蔓延。 央视新闻 据美联社报道，不到一天，“休斯”过火面积就达到41平方公里。23日下午晚些时候，灭火工作取得进展，大约四分之一火势得到控制。 洛杉矶县警察局23日说，卡斯泰克地区仍有近5.4万人接到疏散警告。 与此同时，加州南部其他地区同样出现新火灾。当地时间23日，文图拉县发生名为“拉古纳”的新山火，山火在加州州立大学海峡群岛分校校园西面出现并迅速蔓延，该校随即发布了紧急疏散的通知。文图拉县消防部门表示，消防人员正在地面和空中作业，试图扑灭山火。 Andrej Karpathy泼冷水：智能体爆发还需十年 1月24日，OpenAI创始成员之一Andrej Karpathy在社交平台上发表了对OpenAI最新的发布的智能体“Operator”的看法。他将OpenAI的Operator等项目比作数字世界的“人形机器人”，并预言未来十年将是智能体蓬勃发展的时代。 Andrej表示，社交媒体上许多人预测2025年将是“智能体元年”，但Andrej认为，2025~2035年才是真正的“智能体十年”。他强调，要让智能体真正发挥作用，还需要在各个方面进行大量的努力。但他坚信，智能体“应该”能够成功。 Andrej还描绘了智能体未来的发展蓝图。他提到，如今，Operator已经能够帮助用户在DoorDash上订餐或查询酒店信息，尽管有时效果“可能”还不够理想。然而，在不久的将来，用户将能够构建由多个Operator组成的“组织”，用于执行更长期的、用户自定义的任务，例如运营一家完整的公司。那时，人类将扮演类似首席执行官 (CEO) 的角色，同时监控十几个智能体，偶尔深入“一线”解决问题。这样的未来“将会非常有趣”。 “国会山股神”出手，这只AI医疗股周涨45% “国会山股神”、前美国众议院议长佩洛西的炒股实力惊人。 根据最新披露的国会议员交易记录，佩洛西于1月14日购买了50份2026年1月到期的Tempus AI看涨期权，行权价为20美元。在佩洛西交易当天，Tempus AI股价收于每股32美元以下，而截至周五收盘，股价已升至每股51.4美元，涨幅超61%。本周涨幅为45.61%，年初至今则上涨了52.25%。 自2024年6月IPO以来，Tempus AI的股价一直处于波动状态。去年11月份，该股盘中一度涨至近每股80美元，此后大幅下跌，市值缩水一半以上。 除佩洛西外，知名投资者“木头姐”Cathie Wood也早已对Tempus AI表现出浓厚兴趣，并在去年10月该公司财报发布前买入了3万股，此后还一直不断买入。 Tempus AI成立于2015年，是一家专注于科技驱动医疗发展的公司，尤其在癌症治疗和个性化医疗科技领域有显著的影响力。公司的技术平台结合了生成式AI、机器学习、基因组学、生物信息学以及临床数据分析，用以推动精准医学领域的发展。通过将基因组数据与临床数据结合，并利用AI和大数据分析，Tempus AI可提供个性化的治疗方案。 当地时间周二（1月21日），Tempus AI推出一款AI驱动的个人健康助手应用——olivia，旨在通过将用户的健康数据集中在一个平台上，然后利用AI技术来增强患者的健康管理能力。 据介绍，olivia可以与苹果手表和谷歌健身应用 Google Fit集成，追踪用户的日常健康状况，总结临床历史，并转录医生的预约记录。Tempus AI首席执行官Eric Lefkofsky强调，olivia不仅仅是信息的组织者，更是患者健康管理的“主动伙伴”。 自2022年以来，AI基础设施建设的核心公司一直是AI热潮的主要受益者。高盛去年11月预测，AI革命将在今年进入“第三阶段”，届时更多类型的公司将看到AI对其营收和利润的实质性贡献。随着像olivia这样的AI助手的推出，预计Tempus AI将受益匪浅。 生成式AI与医疗/医药/制药领域的深度融合，已经推动多项细分领域研发取得积极进展，特别是在药物发现、基因编辑、疾病诊断、患者监护和医疗影像分析等方面，预计2025年可能将涌现出一大批与”AI+医疗”相关的极具商业前景的突破式研究成果。 2024年第三季度，Tempus AI营收同比增长33%至1.809亿美元，净亏损7580万美元。本月中旬公布的初步业绩显示，公司2024年第四季度营收同比增长约35%至2亿美元。2024年全年的营收约为6.93亿美元，同比增长约30%，调整后的EBITDA（息税折旧摊销前利润）同比持续改善。 公开资料显示，截至2024年第三季度末，Tempus AI的前十大机构投资者包括软银、普徕仕、方舟投资和谷歌母公司Alphabet。 中国资产逆势大涨！黄金逼近历史新高 周五收盘，美股三大指数集体收跌，纳指跌0.5%，本周累涨1.65%；标普500指数跌0.29%，本周累涨1.74%；道指跌0.32%，本周累涨2.15%。 中国资产逆势大涨，纳斯达克中国金龙指数周五收涨3.72%，创一个多月来最大单日涨幅，本周累涨2.81%。富时中国3倍做多ETF收涨7.35%，本周累涨8.88%，延续上周反弹18.39%的表现。 人民币汇率持续走强，离岸人民币对美元汇率一度涨超500点、涨破7.24，创近两个月新高，最终收涨435个基点，报7.2443，本周累计涨967个基点。 随着美元回落，现货黄金周五一度站上2780美元关口，徘徊在去年10月创下的历史高位附近，本周上涨近3%。外汇资讯网站FXStreet分析师表示，一旦超过2790美元，金价就会再创新高，2800美元可能是其达到3000美元目标价前的下一个阻力位。 免责声明：本文内容与数据仅供参考，不构成投资建议，使用前请核实。据此操作，风险自担。 记者|宋欣悦 兰素英 郑雨航 蔡鼎 编辑|何小桃 兰素英 杜波 校对|程鹏 ｜每日经济新闻 nbdnews 原创文章｜ 未经许可禁止转载、摘编、复制及镜像等使用 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 49760,
      "title": "德媒:中国人工智能大模型捷报频传",
      "time": "2025-07-23T00:00:00+00:00",
      "content": "参考消息网7月23日报道 据德国《法兰克福汇报》网站7月21日报道，当中国初创公司深度求索（DeepSeek）在2024年12月凭借其人工智能模型震惊世界时，有人将其称为人工智能领域的“斯普特尼克时刻”。这类比了1957年苏联通过发射首颗人造卫星“斯普特尼克1号”，向美国人表明美国在太空探索领域已经落后。突然间，一家资源远不及硅谷巨头的公司也能角逐最佳人工智能模型了，而且还是一家中国公司：美国在人工智能领域的霸主地位受到了挑战。 现在，中国人准备再次出击。这次，大家最好记住一个名字：Kimi K2。这是月之暗面科技有限公司的全新人工智能模型。开发人员称，在标准化编程任务中，Kimi的表现几乎与美国Anthropic公司的“克劳德4-十四行诗”模型相当，并且明显优于开放人工智能研究中心（OpenAI）的GPT-4.1——这是聊天生成预训练转换器（ChatGPT）默认使用的模型。Kimi K2在数学推理方面也表现出色。 报道称，艾伦人工智能研究所的人工智能研究员内森·兰伯特在社交平台“蓝天”上写道，Kimi是新的“世界最佳开源模型”。 与DeepSeek和元宇宙平台公司的Llama大型语言模型一样，人们可以免费下载并进一步开发该模型。Kimi K2还可通过API接口访问——价格远低于竞争对手。投资人兼技术专家阿齐姆·爱资哈尔在其撰写的新闻稿中说，如果说DeepSeek是“斯普特尼克时刻”，那我们现在迎来的便是“东方1号时刻”——1961年，作为第一个进入太空的人，尤里·加加林乘坐的是“东方1号”飞船。那一刻，人们意识到，“斯普特尼克”的诞生对苏联人来说并非偶然，也不会是昙花一现——苏联人不仅能与美国人并驾齐驱，而且还能把美国人甩在身后。 据报道，月之暗面科技有限公司成立于2023年，该公司是中国新兴人工智能领军企业之一。中国有一批有着大好发展前景的人工智能初创公司。 月之暗面科技有限公司创始人杨植麟出生于1992年，是中国人工智能领域的希望之星。据香港《南华早报》报道，在宾夕法尼亚州卡内基-梅隆大学攻读计算机专业博士学位期间，杨植麟曾为脸书网站和谷歌的人工智能部门工作。 报道称，杨植麟在23岁时创立了他的第一家公司。如今，他正在大型语言模型领域引发轰动。OpenAI本应在上周发布自己的开放权重模型，但最终却推迟了发布。与此同时，月之暗面科技有限公司于7月11日推出了Kimi K2。（编译/宋羽豪） 6月20日，参观者在北京中关村展示中心“人工智能+”展示区域参观。（新华社） 举报/反馈"
    },
    {
      "doc_id": 49771,
      "title": "比C罗还贵 95后华人AI天才被扎克伯格1亿挖走 华人撑起AI全球半壁...",
      "time": "2025-07-17T00:00:00+00:00",
      "content": "来源：IT时报 作者／ IT时报记者 孙妍 编辑／ 郝俊慧 孙妍 一觉醒来，整个硅谷圈的顶尖AI人才都被扎克伯格挖空了，被“偷家”的OpenAI奥特曼和苹果库克都如坐针毡。 据不完全统计，近期Meta从OpenAI至少挖走了14名核心研究人员，其中8名是华人，签约奖金达1亿美元。随后，Meta又以超2亿美元（折合人民币约14.36亿元）的薪酬包，把苹果核心AI高管Ruoming Pang（庞若鸣）挖走，这9名华人人才都将归入由扎克伯格领衔的“超级智能梦之队”。 OpenAI坐不住了。“有人闯进我们家偷东西。”OpenAI首席研究官Mark Chen如此形容挖角行为，但也不得不应对。于是，OpenAI从Meta、特斯拉、xAI连抢四名大将。 苹果并没有跟进，因为2亿美元远超苹果高管的薪酬水平，其中，库克2024年公开薪酬为7460万美元。苹果的危机感达到了顶峰，苹果服务主管Eddy Cue发起内部警告：“如果不能迅速适应AI时代，苹果有可能成为下一个黑莓或诺基亚。” 在这场迄今为止最激烈的“抢人”大战背后，华人AI人才的崛起成为新焦点。 英伟达CEO黄仁勋说：“全球50%的AI研究人员是中国人，你无法阻止他们推进AI发展。” 这句话的含金量正一次次被验证。 人才收购成大厂“招安”新模式 这场人才大战中，一位95后正搅动美国AI圈。Meta以1亿美元从OpenAI挖来了余家辉，要知道，皇家马德里曾花费8000万美元从曼联手里挖来了C罗（克里斯蒂亚诺·罗纳尔多）。AI圈已经超越了足球圈的天价“转会费”。 不过，这已不足为奇，一场又一场浩浩荡荡的“人才收购”戏码连番登场。 Meta砸143亿美元（折合人民币约1026.68亿元）收购汪滔（Alexandr Wang）创办的Scale AI 49%无投票权股份，背后的真实目的是让汪滔打包嫡系部队加入Meta超级智能团队。这被认为是最令人震撼的“人才收购案”。 这位28岁华裔天才，重演了辍学创业成功的故事，现被任命为Meta首席AI官，图灵奖获得者、Meta首席AI科学家杨立昆或向他汇报。 19岁时，汪滔创立了Scale AI，这家公司的核心业务是为微软、OpenAI等大模型厂商提供数据标注解决方案，去年营收已达8.7亿美元（折合人民币约62.52亿元），预计今年营收将飙升至20亿美元（折合人民币约143.72亿元）以上。按Scale AI营收规模来看，Meta的这笔人才收购案并不亏，将在短短几年内收回成本。 不只是Meta花1027亿元“招安”创业公司，谷歌等美国大厂也激进地收购人才。 距离谷歌以24亿美元收购AI编码初创公司Windsurf核心人员仅仅过去两天，当地时间7月14日，另一家AI编程初创公司Cognition宣布收购Windsurf剩余的团队和技术资产。 谷歌没有全盘收购Windsurf，而是将其首席执行官Varun Mohan、联合创始人Douglas Chen部分关键研究人员收入麾下，并获取技术许可，这一方式被称为“反向收购”（reverse acqui - hire），这种挖角模式是AI时代的新产物，为的是避免大规模收购导致的监管障碍，又能以天价快速招募AI人才。 “大厂就是为了挖千分之一、万分之一的顶尖AI人才，其他业务连人都不要。”在PPIO CEO姚欣看来，人才并购动辄花费十几亿、几十亿美元，给AI大牛开出几千万美元的年薪不足为奇。 跟互联网时代类似，赢者通吃仍是AI时代的一条铁律。放眼望去，在搜索引擎市场只看到了谷歌，云计算市场只看到了亚马逊等少数几家头部厂商。扎克伯格掀起人才大战，正是因为今天的Meta已经没有退路。 在Llama 4遭遇滑铁卢后，“在硅谷看来，目前占据大模型前三宝座的是OpenAI、谷歌和Anthropic。Meta这波重金挖人，可以看出小扎的处境已经很难了，只有拥有最顶尖的人才团队，他才能扳回几城。”姚欣认为。 华人撑起全球AI“半边天” 12年前，姚欣也是大厂收购的亲历者，他创立的互联网视频平台PPTV被苏宁云商和弘毅投资以4.2亿美元控股。 此后，他从创业者变身投资者，在创投圈的几年，他深谙人才的重要性，甚至常常在美国顶尖高校门口蹲守人才，先下手为强。 他回忆，2023年，生成式人工智能刚冒头时，华人AI人才就已经非常抢手，挖人的难度越来越大，“华人的数理基础好，愿意‘卷’且成效明显，能如此拼搏的只有华人。” 在马斯克发布号称“地表最强大模型”Grok 4时，大众关注焦点集中在几张照片上，一张照片曝光了Grok 4幕后团队，该团队七成以上都是亚洲面孔；另一张照片是在Grok 4发布前夕，马斯克带头睡在办公室，常常凌晨2点开会，于是xAI办公室里搭满了帐篷。 “数学学得好，走遍天下都不怕，中国人更不怕。”80后华人工程师安超（化名）在硅谷工作近18年，他也认为，中国人能在美国AI圈脱颖而出，主要是因为中国人数理基础强，而数学是AI大模型或其他理论研究的基础。 根据MacroPolo发布的《全球人工智能人才追踪调查报告2.0》，2019年到2022年间，来自中国的顶尖AI研究人员占比从29%提升到了47%。 “美国现在最贵的是中国AI人才。”一位曾在美国亚马逊工作多年的华人工程师姚华（化名）说道，Meta掀起的AI人才大战推高了硅谷整体的AI人才薪酬水平，AI顶尖人才的年薪甚至超过了一些初创公司的A轮融资金额。 顶尖AI人才开始分化 去年7月，中国AI创业圈被一众学霸包围，呈现出“北有清华系，南有交大帮”的格局，据不完全统计，拥有清华背景的AI公司创始人已多达40位。如果说，清华系撑起了中国AI创业圈的半壁江山，那么一年后，华人撑起了全球AI“半边天”。 Meta从OpenAI挖来的华人AI人才，清一色出自中国顶尖高校，本科毕业于清华、交大、北大、中科大等。 而且，多位美国AI圈华人大牛“师出同门”。苹果AI大牛庞若鸣加入Meta超级智能部门后，将与前OpenAI感知团队负责人余家辉搭档，两人都出自吴永辉门下，而吴永辉正是前Google Fellow、现任字节跳动Seed模型负责人。 2018年从硅谷回国，又从投资者转变为创业者，创立了“算力界滴滴”PPIO的姚欣，每年都会定期往返硅谷和上海两地，花大量时间接触顶尖AI人才，了解美国最新的AI趋势与技术。 最近，他明显感受到了中美AI创业圈的氛围变化：中国公司靠人海战术和拼搏精神，美国公司靠人才质量和钻研精神；中国硬件实力强，具身智能成为炙手可热的新星，美国软件实力强，AI Agent（智能体）是最火的趋势，很多美国公司开始用AI Agent来替代人类员工，编程、销售、运营等岗位替代率甚至高达70%。不少垂直领域的AI Agent企业开始赚钱，编程、医疗、法律等垂直行业的Agent开发公司模式经过市场验证，年化收入已经超过1亿美元。 “在美国，苹果等大厂快招不到顶尖AI人才了。”一位硅谷猎头提到，对顶尖AI人才来说，与其去一家层级多、效率低、创新难的传统大厂，不如自己创业。 排版／ 季嘉颖 图片／ Meta xAI 网络 来源／《IT时报》公众号vittimes 举报/反馈"
    },
    {
      "doc_id": 49772,
      "title": "开价1亿美元,硅谷巨头疯抢中国AI科学家",
      "time": "2024-07-07T00:00:00+00:00",
      "content": "在AI人才争夺战中，扎克伯格近期展开的系列操作堪称教科书级案例。 继以148亿美元重金将95后华裔天才亚历山大王（Alexandr Wang）创办的Scale AI 纳入麾下后，这位Meta掌门人迅速启动战略升级——两周内突然宣布成立“Meta超级智能实验室”（MSL），整合旗下FAIR研究团队与Llama模型开发组等核心AI资源，并直接委派Wang全权执掌实验室。 而这个豪华实验室的核心人才，都是扎克伯格从OpenAI挖过来的。 据知情人士透露，Meta通过闪电战式招募从OpenAI连夜签下8名顶尖华人AI学者，且均为多模态模型、语音交互、强化学习等战略领域的技术骨干，传闻有1亿美元报酬（现金+股票），但并未。 扎克伯格亲自推行“CEO直聘”模式：其不仅亲自梳理全球顶尖AI研究员名单，更在加州帕洛阿尔托和太浩湖的私人住所与候选人直接会面，甚至为关键人才开辟免面试的“绿色通道”。 这种打破常规的决策机制大幅压缩了招聘流程——从首次接触到正式签约，部分核心成员的入职周期被压缩至72小时。 值得注意的是，这场由扎克伯格亲自操盘的人才争夺战，已引发行业连锁反应：谷歌、英伟达等科技巨头正以惊人投入加入战局，而全球AI竞争的核心焦点，正逐渐聚焦于华人AI技术人才群体。 全球疯抢中国AI顶尖人才 此次扎克伯格的“挖角”行动引人注目——从OpenAI挖走的华人学者，均来自清华大学、北京大学等国内顶尖高校，且具备OpenAI、Google等科技巨头的核心算法经验——有人主导过ChatGPT研发，有人负责自动驾驶感知系统，堪称AI行业的“梦之队”。 具体来看，被挖角的学者背景极具代表性： 毕树超（Shuchao Bi）：浙江大学本科、加州大学伯克利分校博士，曾任Google工程总监及YouTube Shorts联合创始人，在OpenAI担任多模态后训练负责人。 赵盛佳（Shengjia Zhao）：清华大学本科、斯坦福大学计算机科学博士，2022年加入OpenAI担任研究科学家，主导大语言模型训练优化，是o1-mini与o3-mini模型的关键贡献者。这两款模型虽体量小，但推理速度极快，去年秋季o1-mini在数学任务上的表现甚至超过更大规模的o1-preview模型。 任泓宇（Hongyu Ren）：北京大学本科、斯坦福大学博士，作为o3-mini和o1-mini的创建者，以及GPT-4o mini负责人和GPT-4o核心贡献者，他在OpenAI后训练团队主导语言模型训练优化。2018年，他曾与赵盛佳共同发表关于生成式AI模型偏见的研究论文，提出深度生成模型泛化能力的新分析框架。 于佳慧（Jiahui Yu）：中国科学技术大学少年班本科、伊利诺伊大学香槟分校博士，加入OpenAI前曾在百度、英伟达、Google DeepMind任职，2022—2023年担任Gemini多模态项目视觉联合负责人。2023年10月加入OpenAI后，他领导感知团队主导o3、o4-mini及GPT-4.1、GPT-4o等项目，专注AI环境信息收集与理解。 此外，还有HuiWen Chang, Ji Lin以及Pei Sun三位中国人。 不过，针对网传1亿美元年薪挖角三人的说法，CTO Andrew Bosworth后续在线辟谣，他表示，所谓高额待遇仅适用于极少数高级岗位。“我非常清楚他为什么这么说：因为我们确实成功吸引了一些OpenAI的人才，而他对此显然并不高兴。” Levels.fyi数据显示，Meta常规E7-E9级工程师年薪在150万-500万美元区间，但为挖角可能支付1.5倍溢价。独立分析师估算，被挖的OpenAI研究员实际薪酬包约在500万-1000万美元/年，就算没有1亿美元，但相比OpenAI现有薪酬仍是质的飞跃。 目前，AI技术已然步入“后摩尔定律”时代。在这一阶段，单纯依靠增加参数规模所带来的边际效益不断递减，创新愈发依赖于算法的突破以及工程的优化。 这场技术范式的转变，成为全球科技巨头展开激烈人才争夺战的深层次驱动力。企业间的“军备竞赛”态势愈演愈烈，进一步推高了顶尖人才的身价。而在这场人才竞争中，华人科学家已然成为核心力量。 传统上，印度裔在硅谷的优势主要集中在项目管理和商业落地环节。然而，在AI时代的技术逻辑下，这一格局被彻底颠覆。面对Transformer架构这类复杂的数学难题，10个普通程序员的作用也抵不上1个顶尖科学家。 正如英伟达CEO黄仁勋所说：“全球50%的人工智能研究人员都来自中国；美国每个AI实验室都活跃着华人研究者身影，无一例外。” 从近期科技巨头的一系列动作中，便能真切感受到这场人才战争的激烈程度。 马斯克在OpenAI陷入人才危机时高调宣布，将在本月发布Grok 4，并透露将构建专门编程模型。其xAI创始团队中，华人占比达三分之一。 全球AI芯片领域的“一哥”英伟达，其创始人黄仁勋最近也亲自下场抢人，悄悄招揽了两位华人AI大神。 其中一位是Banghua Zhu，他2018年本科毕业于清华大学，获得电气与电子工程学士学位，2024年在加州大学伯克利分校电子工程与计算机科学系获得博士学位，师从Jiantao Jiao教授和Michael I. Jordan教授。2023年，他与Jiantao Jiao联合创立Nexusflow AI，致力于为企业级应用场景提供可靠的AI智能体解决方案。加入英伟达后，他将在Star Nemotron团队担任首席研究科学家，专注于企业级AI Agent的应用研究，他还是大模型竞技场LMArena的创始作者之一。 另一位重量级学者Jiantao Jiao也在同一时间官宣加盟英伟达。 他本科毕业于清华电子系，2018年取得斯坦福大学博士学位，现为加州大学伯克利分校电子工程与计算机科学系及统计系助理教授，研究领域横跨基础模型、生成式AI、机器学习、强化学习与博弈论、多模态应用等前沿方向。 谷歌也没闲着，前段时间把无人AI模型的基石Riston NE的发明者、华人AI顶尖科学家何恺明请出山，兼职加入谷歌DeepMind的团队。何恺明2024年加入麻省理工学院（MIT），2025年6月，年纪轻轻的他便获得了MIT的终身教职（副教授），成绩斐然。 数据揭示了更为惊人的现实。《2023年人工智能指数报告》显示，全球顶尖AI研究者中47%来自中国，美国顶级AI人才中华人更是高达75%。 “中国本科 + 美国博士”的培养模式，已经成为硅谷AI精英的标配路径。根据全球AI人才追踪报告2.0显示，2022年在全球前20%的顶尖AI人才中，原籍国为中国的人才占比高达38%，超过美国本土的37%。 正如黄仁勋所言：“中国用全世界20%的人口培养出了全世界50%的AI人才。”中式基础教育的优势在此显露无遗——尽管曾被批评为“应试教育”，但强大的数学、理科基础培养了大量具备创新潜力的人才基础。当然，这也是有代价的，筛选出优质人才也代表了有大批被迫卷入筛选的学生。 但一个严峻的现实不容忽视。麦肯锡预测，到2030年，中国AI人才缺口将达400万，低门槛岗位趋于饱和，高端岗位却严重短缺。另外，自特朗普政府以来，美国对华AI打压始终围绕人才展开，从限制英伟达对华供应AI芯片，到禁止提供芯片设计软件，核心目标均为遏制中国AI发展。 更令人警觉的是，顶尖人才持续流向海外——每年最顶尖的毕业生中，依然会有一部分最优秀的学生选择去美国继续进修。 这其中有很多原因，美国良好的研究环境，研究资金和研究自由，会吸引很多全球优秀的人才去进修，锻炼。我们不用责怪个人选择，而是应该反思国内高校的研究体系如何才能留住大量顶级的人才。 因为最顶级的人才作用，可能抵100个甚至1000个普通人才，特别在基础科研领域。当然，也有很多优秀的毕业生在中国的顶尖企业里继续研究，未来谁会发展得更好也还不好说。 此外，面对这一局面，国内企业正在奋起破局：腾讯、阿里、百度在2025年春招期间，算法工程师岗位招聘量同比增长46.8%，平均月薪达2.35万元人民币，深度学习岗位更高达2.4万元。 就连宇树科技这样的初创公司也为AI算法岗开出7万元/月的高薪，广东神舞科技提供“两室一厅免费住房+40万-70万年薪”的优厚条件。 此外，腾讯还举办“AI算法大赛”，奖金池达5000万元人民币，试图通过竞赛挖掘全球顶尖人才。 但与Meta、谷歌等巨头相比，差距依然明显。无论是顶尖科学家的薪酬、科研环境，还是国际影响力，国内企业仍需长期积累。 马斯克曾说：“这是我看到过最疯狂的技术人才争夺战。”在这场没有硝烟却异常激烈的全球AI人才争夺战中，中国科学家凭借扎实的专业素养和创新能力，成为各方竞相疯抢的“香饽饽”。 但如何留住并充分发挥这些顶尖人才的作用，构建起具有国际竞争力的人才生态，让中国在全球AI赛道上持续领跑，依旧是摆在我们面前亟待解决的关键课题。 一场以高薪为“饵”的精彩博弈 对于Meta的挖角行为，OpenAI首席研究官Mark Chen马克·陈将此比喻为“有人闯进我们的家偷东西”，其愤懑之情溢于言表。 随即，（Mark Chen）向全体员工发送了一封措辞强硬的备忘录：“我们比以往任何时候都更主动，正在调整薪酬，并在寻找创新方式来认可和奖励顶尖人才。” 除了承诺调整薪酬体系外，OpenAI宣布6月30日至7月6日期间员工需居家办公，管理层则加班加点应对这场人才危机。尽管名义上是为缓解员工每周80小时超负荷工作的压力，但知情人士透露，管理层的真实目的是防止离职传言在办公室蔓延，造成更大范围的人心动荡。 这场突如其来的挖角危机，直接导火索是2025年初Meta自研大模型Llama 4表现不及预期。扎克伯格曾放话：“我要在2027年前，让Meta的AI超越Google和OpenAI，成为世界第一。” 但Llama 4 项目受挫令扎克伯格“非常沮丧”。这位CEO随即改变策略——与其押注单一模型，不如通过吸纳顶尖人才实现多点突破。 为此，Meta在AI领域的投入堪称“砸钱换时间”。除每年数百亿美元的芯片、数据中心和算法研发支出外，此次更以巨资招揽AI领域最具潜力的华人天才。 但薪酬诱惑只是表象，更深层次的吸引力在于科研自主权与资源保障。一位接近OpenAI的知情人士透露，公司内部常因算力分配爆发激烈争吵，“重要项目尚需排队等待，边缘研究更难获得支持”。 反观Meta，扎克伯格宣布“未来几年将在AI上投入数千亿美元”，并承诺为MSL团队提供“无限制的先进算力资源”——这对饱受GPU短缺困扰的OpenAI研究员堪称致命诱惑。 这场人才集体流失的背后，其实也是OpenAI长期积累的深层隐患。 2024年启动的重组计划将核心业务转由营利性公司经营，非营利董事会仅保留少数股份，彻底倒向商业化。以CEO山姆·奥尔特曼为首的商业化派主张加快产品迭代与盈利步伐，要求“每隔几个月就要有重磅产品发布”，导致研究人员疲于应付短期目标。 曾主导ChatGPT开发的约翰·舒尔曼（John Schulman）离职时坦言，他希望“重返实际技术工作”，这句委婉的批评直指OpenAI日益严重的官僚化倾向。 约翰·舒尔曼 薪酬体系的不合理，也进一步加剧了人才流失。尽管OpenAI估值高达1500亿美元，但其独特的“利润封顶”结构限制了员工回报——最初承诺投资者收益不超过投入的100倍，后改为每年增长20%。 如今，当Meta用真金白银挖走技术骨干，OpenAI才如梦初醒。核心骨干的集体出走，不仅延缓了OpenAI o系列轻量模型的迭代速度，更可能中断其多模态技术的连续性发展。 对于Meta而言，这种“新人笑旧人哭”的局面也并非全然乐观。通过引入OpenAI系人才，Meta希望弥补自身在生成式AI应用层的短板；而Scale AI的数据标注能力与王氏领导的算法团队结合，可能孕育出不同于GPT的技术路径。 但这种“杂交优势”是否真能超越OpenAI尚待观察，且已在Meta内部引发不满——老员工抱怨公司用2-3倍薪资招揽外部“超级巨星”，变相贬低现有团队价值。 扎克伯格豪掷重金收购的Alexander Wang 回到最开始说的被扎克伯格视为“同辈创业者中最杰出”的亚历山大·王，他到底是谁？ 扎克伯格对他评价极高：“我认为他是同辈创业者中最杰出的一位，他对超级智能的历史性意义有着清晰的认识。并且作为联合创始人兼CEO，他将Scale AI打造成了一家高速发展的公司，几乎参与了行业内所有领先模型的开发工作。” 亚历山大·王 亚历山大·王确实有着与年龄不相符的履历：1997年出生的他，父母均为物理学家，自幼展现出数学与计算机领域的惊人天赋。2013年入选美国数学奥林匹克集训队，2014年进入美国物理奥林匹克国家队，2012—2013年连续两年成为美国计算机奥林匹克竞赛（USACO）决赛选手，青少年时期便在Quora担任软件程序员。 尽管短暂就读于MIT并在高频交易公司Hudson River Trading担任算法开发员，但他最终选择在2016年辍学创立Scale AI。这家专注于AI数据标注与模型评估服务的公司，短短数年便成长为硅谷最具影响力的AI企业之一，也让亚历山大·王一跃成为亿万富豪，业内称他为「下一个马斯克」。 2025 年 1 月 22 日，他在《华盛顿邮报》（The Washington Post）自费购买整版广告，以公开信形式向时任美国总统特朗普喊话，标题为： “亲爱的特朗普总统，美国必须赢得 AI 战争。” （原文：\"Dear President Trump, America Must Win the AI War.\"） 虽然他的“战争叙事”遭到很多人反对，譬如，在 2025 年卡塔尔网络峰会上，现场观众对其“AI 战争论”进行投票，支持者不足 10 人，反对者占压倒性多数。 但因为言论获特朗普政府重视，他受邀参与白宫会议，并与国防部签订军事 AI 项目 Thunderforge（开发战场决策 AI 系统）。 可以说，他才是中国真正要担心的AI阴谋家。 参考资料： 1、《1人开价1亿美元，硅谷巨头疯抢中国留学生》华商韬略毕亚军 2、《突发！小扎“突袭”OpenAI核心，四名顶尖华人被挖走》AI寒武纪 3、《硅谷华人AI大牛被疯狂挖角！小扎打包带走4名OpenAI研究员》智东西 转自：首席商业评论 举报/反馈"
    },
    {
      "doc_id": 49773,
      "title": "DeepSeek新模型“火”到海外,Meta首席AI科学家称“开源在超越闭源...",
      "time": "2024-01-26T00:00:00+00:00",
      "content": "DeepSeek上周发布开源的DeepSeek-R1，并称该模型性能对标OpenAI o1正式版之后，海外AI业界对该模型的讨论还在持续。 热议的焦点在于，当开源模型能力赶上最新的闭源模型，可能改变大模型的竞争格局。 据DeepSeek介绍，DeepSeek-R1在Codeforces、GPQA Diamond、MATH-500、MMLU、SWE-bench Verified等测试中，得分与o1正式版接近，部分测试中得分还超过o1正式版。该模型在后训练阶段大规模使用了强化学习技术，在只有极少标注数据的情况下提升了模型推理能力。 AI业界人士已经在讨论开源的影响。Meta首席AI科学家Yann Lecun表示，DeepSeek-R1面世与其说意味着中国公司在AI领域正在超越美国公司，不如说意味着开源大模型正在超越闭源。“DeepSeek会从开放研究和开源中获利，可能会类似Meta的PyTorch和Llama。他们提出新想法，并在别人的工作基础上实现。因为他们的工作是公开和开源的，每个人都能从中获利，这就是开放研究和开源的力量。”Yann Lecun表示。 “我们生活在这样一个时代，一家非美国公司正在让OpenAI的初衷得以延续，即做真正开放、为所有人赋能的前沿研究。”英伟达高级研究科学家Jim Fan表示，DeepSeek-R1可能是第一个展示了RL（强化学习）飞轮可发挥作用且能带来持续增长的OSS（开源软件）项目。加利福尼亚大学伯克利分校教授Alex Dimakis则称，DeepSeek似乎是奔赴OpenAI最初使命的“最佳人选”，其他公司需要迎头赶上。 硅谷风投A16Z创始人Marc Andreessen也发表评论称，DeepSeek-R1是他见过的最令人惊叹且令人印象深刻的一个突破，作为开源的模型，它的面世给世界带来了一份礼物。 对比也走开源路线的Meta，新浪微博新技术研发负责人张俊林表示，DeepSeek和阿里在开源方面已经领先Meta，国内的开源风气越来越好，这是被DeepSeek和阿里带动起来的。得益于DeepSeek开源出的众多R1版本模型，业界可以低成本快速复制出逻辑推理能力更强大的模型。 用户可以在自己的服务器上或使用云算力部署开源模型，并用自己的数据微调大模型，使用开源模型在数据安全方面可能优于调用闭源大模型的API接口，且用户不需要向大模型厂商支付API调用费用。在开源大模型能力超过或比肩闭源大模型能力时，开源对闭源将造成冲击。 DeepSeep-R1推出前，开源领域的标杆是Meta的Llama系列模型，MiniMax副总裁刘华就坦言此前接受第一财经记者采访时，比开源模型更好是一个最基本的门槛，如果基础模型做不到这一点就可以转而做AI应用了。在国内做商业化一个最基本的前提就是比Meta的Llama模型更好，“否则别人可以用Llama，为什么花钱用你的模型？这很现实。” DeepSeek是幻方量化旗下的AI公司，创立于2023年，幻方量化创始人梁文峰在量化投资和高性能计算领域有深厚背景。该公司走开源、性价比路线，也被冠以“AI界拼多多”的名号。去年5月，DeepSeek发布DeepSeek-V2，价格是GPT-4-Turbo的近百分之一，打响了大模型价格战的先声。此次发布的DeepSeek-R1也提供了API调用方式，API输入（缓存命中）、输出定价分别为每百万tokens1云、6元，低于o1的55元、438元。去年12月，DeepSeek还发布了大模型DeepSeek-V3，因该模型“2048个GPU、2个月、近600万美元”的极低训练预算受到关注。 不过，从最新消息看，DeepSeek的产品更新并未改变海外巨头向大模型投入巨额资金、大举建设算力基础设施的做法。近日OpenAI、甲骨文和软银宣布将成立一家合资企业“星际之门计划”，计划未来四年投资高达5000亿美元用于建设AI相关基础设施，该计划得到了刚上任的美国总统特朗普的力挺。 当地时间1月24日，Meta CEO扎克伯格则表示，为了实现公司在AI领域的目标，公司正在建设一个2吉瓦以上的数据中心，占地面积“能够覆盖纽约曼哈顿的很大一部分”，公司预期到今年年底拥有130万块GPU，今年的资本支出将达到600亿~650亿美元的规模。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 49778,
      "title": "算力焦虑背后的认知博弈",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "2012年，谷歌的一个研究小组公开了一个叫做“谷歌猫”的研究项目。 他们将16000个计算机处理器连接起来，建造了一个超大规模的机器学习神经网络，让它在海量图片中自主学习，最终成功识别出了“猫”。 “谷歌猫”项目，揭示了人工智能时代的临近。这个时代，也火了一家企业——英伟达。 人工智能的发展，简单来说，需要三个元素： 算法、算力和数据。 芯片的性能影响着算力，而英伟达，在AI芯片市场的占有率高达70%以上。 正是这种“天下英雄尽入彀中”的局面，让英伟达的股价一路飙涨。 2012年至今，英伟达的市值上涨500多倍，一度成为全世界第一家市值突破4万亿美元的公司。 7月15日，英伟达公司创始人兼首席执行官黄仁勋到访中国并表示，将开始向中国市场销售H20芯片。 据报道，H20的推理能力仅为H100的20%，是阉割版。 用这样的芯片去发展人工智能，是否意味着“起步即落后”？ “算力焦虑”，再次被推至台前。 算力比算法和数据都重要吗 ？ 简单逻辑看复杂世界 YU YUAN TAN TIAN 这是英伟达的股价走势图。可以看到，在今年1月，英伟达股价大幅下跌。下跌的直接诱因，是DeepSeek的出现。 DeepSeek用更小的算力、更高的效率，带来了更优的表现，一时间，“AI大模型是否不再需要那么多算力”成为焦点话题，这也导致英伟达一天之内股价暴跌近17%，创下了美股的跌幅纪录。 在这其中，很少有人探究一个问题，这种“唯算力论”的认知，是如何形成的？ 我们刚才提到，决定人工智能发展的要素有三个，为何算力这么吸引眼球？ 谭主拉出了美国媒体关于中美人工智能报道的曲线，从2020年5月（当月，GPT-3推出，通用大模型引发很大讨论）至今，并从中提取出其中对“算力”“算法”“数据”的关注度。 可以看到，在2022年8月前，这三个词的讨论基本处于同一水平线。但在2022年8月后，“算力”直接断层领先，成为关注度最高的词。 那个月，美国政府的一纸禁令，限制英伟达向中国出口高性能芯片。它们可用于加速AI、资料分析和高效能运算作业。 美国政府希望通过控制算力来扼住中国人工智能发展的“咽喉”。 算力焦虑是如何形成的 ？ 简单逻辑看复杂世界 YU YUAN TAN TIAN 谭主发现，这项禁令的背后有一个关键人物——赛义夫·汗。 赛义夫·汗曾任职于白宫国家安全委员会（NSC），负责科技相关事务。他此前在智库就职的研究方向，正是半导体供应链以及美国半导体政策。 从2019年起，他的观点开始成型：最先进的AI芯片是训练最先进算法的基石，控制了最先进芯片的产业链供应链，就能固化领先优势。 这种观点，成为了催生拜登政府《芯片与科学法案》以及对华限制措施的一环。 赛义夫·汗的观点为什么能获得美国政府的高度认可？这正是来自于其他相关研究报告带来的隐忧。 它们分析了中国发展人工智能的优势，包括研发投入、人才培养、产业优势等等，最后得出结论，中国将在10年内，取代美国在人工智能领域的领导地位。 在这种背景下，赛义夫·汗的观点无异于提供了一剂“解药”：它不仅“缓解”了美国对被超越的焦虑，更重要的是，它为全世界制造了一种新的焦虑——算力焦虑。 想要发展人工智能，就需要最先进的人工智能芯片，而这一芯片，牢牢掌握在美国企业手中。换句话说，其他国家的人工智能发展程度，取决于拥有多少英伟达的GPU。 在这个过程中，英伟达和美国的资本市场，也在为这个叙事“添砖加瓦”： AI正在高速与世界上的各个行业深入融合，真正的AI时代很快就要到来。 这种描绘方式并不新鲜，正如有评论形容，“第四次工业革命”已经来了8次——元宇宙、Sora、室温超导等都曾被认为是“第四次工业革命”。 我们当然不否认下一个时代会是人工智能的时代，但真的有那么快吗？ 在部分机构的报告中，英伟达的GPU仿佛是通往人工智能时代的门票，算力的缺口每天都在扩大，随之带来的，就是对英伟达GPU的需求，而英伟达的股价，也在不断涨高。 “唯算力论”能否扼住中国人工智能发展的“咽喉” ？ 简单逻辑看复杂世界 YU YUAN TAN TIAN 凡事物极必反，不同的看法正在涌现。 麻省理工一位研究人工智能的教授指出，今天的资本市场对AI的追捧已经显得有些过热。 他还专门做了一张《AI炒作周期图》，梳理了AI技术在几十年间反复经历失望与再起的循环。 从上世纪的神经网络，到AlphaGo的震撼，再到如今的ChatGPT，每一次高峰都伴随着巨大的期望，但最后，很多预期的承诺都无疾而终。 而这一次的“唯算力论”，也迎来了冷思考——就是前文中提到的，DeepSeek的出现。 在2020年至2023年的大部分时间里，美国媒体和研究机构眼中的中国，是一个努力在人工智能领域追赶的“后来者”。 但2023年底，报道的口风开始发生变化。 这些研究机构总结称，美国的算力限制在客观上形成了一种“倒逼机制”，由于无法直接获取顶级的算力，中国的研究机构将更多的资源和精力投入到算法创新上，目标是用更少的算力实现同等甚至更高的性能。这是美国所始料未及的。 正如上图所展现的，人工智能的叙事，发生了改变。 这些美国媒体和研究机构对人工智能领导力的定义，从“算力”，变成了“算力”“算法”以及技术扩散（将AI技术广泛应用于整个经济的能力）。 正是因为这样的现实情况，美国政府也在调整其相关政策。 允许英伟达向中国出口H20，就是迹象之一。 一位关注美国人工智能政策的专家告诉谭主，H20芯片的性能参数经过精确设计，其虽然沿用了先进的架构和封装技术，但在决定AI训练与推理效率的核心计算性能上受到了严格限制。 美国政府在这个时候放行H20，也许是担心，自己的封锁政策可能催生出一个独立且强大的竞争对手，因此，美国政府需要推出一款性能经过精确计算的受限产品，用以延缓中国自主技术生态的成长速度。 这样的方式，能奏效吗？ 有一个角度，可以思考这个问题。 要争先，更要争源源不断 简单逻辑看复杂世界 YU YUAN TAN TIAN 谭主把中美各自关于人工智能发展的报道，输入到了大模型，大模型总结出了两种“发展哲学”： 美国人工智能的发展，基本是“闭源”的。美国公司通过保密其模型架构、训练数据和权重，来保护其巨大的研发投入和知识产权。这种模式的盈利来源很稳定。 而中国人工智能的发展是“开源”的，中国企业提供免费的大模型，吸引更多企业在其生态系统上进行二次开发和创新。 到目前为止，我们还很难下结论，这两种模式，谁就一定会更成功。 但谭主从中国的方式中，看到了更多的可能性。 再过几天，2025世界人工智能大会将会在中国举行。谭主统计了大会公开的人工智能应用的案例集发现： 人工智能应用的行业，涉及教育、文化、气象、农业、矿业开采、药物研发、医疗诊断等等； 与中国合作的国家，有泰国、加拿大、越南、缅甸、沙特、希腊、葡萄牙等国家。 这些应用，有些在今天看来或许还很初级，可能只是庞大生产流程中的一个微小环节。 但历史的有趣之处恰恰在于此。 1894年，法国举办了世界上第一场赛车比赛。出人意料的是，第一个到达的，是一辆蒸汽拖拉机。 然而后来的故事，所有人都已知道。 一场技术革命的最终走向，往往不由最初拥有最快速度的人或事物决定，而由那个率先构建起最庞大、最繁荣应用生态的体系来定义。 只要开始了，就拥有无限可能。 来源：玉渊潭天 举报/反馈"
    },
    {
      "doc_id": 49781,
      "title": "DeepSeek R1小步快跑,中国AI迎来高光时刻",
      "time": "2024-05-30T00:00:00+00:00",
      "content": "一次看似不起眼的小版本更新，却让国产大模型在编程和设计领域逼近全球顶尖水准——小步快跑的迭代哲学正在重塑AI竞争规则。 2025年1月，DeepSeek R1的横空出世触发了全球AI格局的重新洗牌。这个由中国团队开发的模型以仅600万美元的训练成本，实现了与OpenAI投入5亿美元打造的o1模型相匹敌的性能。 更令人惊讶的是，在随后几个月里，DeepSeek没有如预期般推出革命性的R2版本，而是通过一系列小版本迭代持续进化。 今年5月28日上线的R1-0528版本，再次以一次“小升级”震动技术圈。新版本在编程能力上实现突破，能一次性生成728行代码构建出带粒子效果的3D动画应用，其效果已与Anthropic的Claude 4并驾齐驱。 小步迭代的得与失：优化幻觉与有限的能力拓展 在R1-0528版本中，DeepSeek团队重点优化了模型的核心痛点——幻觉问题。通过增强自我验证机制，模型在数学推理和事实性回答中的准确率明显提升。 一组对比测试显示，在Extended NYT Connections基准测试中，新版本的得分从原始R1的38.6跃升至49.8，涨幅近30%。 这种进步源于DeepSeek创新的GRPO算法（组相对策略优化）。与传统PPO算法不同，GRPO通过组内样本对比动态调整策略，省去了独立价值网络，使内存占用降低40%，训练效率提升2.3倍。 然而细察之下，此次升级并未带来颠覆性能力突破。模型在多语言支持、多模态理解等关键领域进展有限。当用户用德语提问时，模型仍需将其翻译成中英文处理，导致响应速度下降。 在复杂函数调用和角色扮演等场景，表现仍不及行业顶尖水平。业界期待的真正革新——如跨模态理解和复杂工具使用——仍需等待R2的到来。 思维深度：是进化还是过剩？ 最显著的变化发生在模型的思考方式上。R1-0528采用了更长的思维链，在解决复杂问题时展现出类似人类的逐步推理能力。 当被要求“估算π/7”时，模型耗时148秒生成包含大量中间步骤的解答。其推理过程详细展示了对泰勒级数展开、数值逼近等方法的考量，远超简单问题所需。 这种深度思考模式是双刃剑： 优势：在编程任务中，长思维链使模型能自我纠错。测试显示，面对Zig语言开发任务时，模型能在出错后快速调整方案。 代价：响应时间显著延长。普通用户面对“思考中”提示等待十余秒已成常态，在实时交互场景中体验不佳。 技术爱好者赞赏这种透明化的推理过程，认为它增强结果的可信度。但普通用户更关注效率——当Claude能在3秒内给出正确答案时，过长的思考链是否真正创造用户价值值得商榷。 中长篇写作：结构化的胜利 在内容创作领域，R1-0528展现出质的飞跃。与早期版本相比，其中长篇输出实现了三重进化： 结构更严谨：回答采用“问题解析→分步推导→结论验证”的标准流程，逻辑清晰度显著提升。信息更丰富：在历史类问题中，模型能补充文化背景和争议观点，而不局限于简单事实。表达更规范：通过RL训练中的格式奖励机制，模型输出中的中英文混杂问题基本解决。 速度之困：深度思考的代价 性能提升的最大代价是响应速度。多个实测场景暴露了这一瓶颈： ●解答高考数学压轴题耗时83秒 ●应对AIME竞赛真题需213秒 ●处理少样本提示（Few-Shot Prompt）比非推理模型慢7倍 速度瓶颈部分源于工程选择。为保持低成本优势，DeepSeek坚持使用MoE架构（专家混合模型），每次推理仅激活370亿参数（总量6710亿）。 这种“省电模式”限制了并行计算效率。 在API服务场景，速度问题被性价比缓解：新版本保持输入0.55美元/百万token、输出2.19美元/百万token的定价，仅为OpenAI o1价格的3.7%。但当企业需要实时交互时，这一短板依然明显。 小步快跑：AI产品迭代新范式 DeepSeek此次采用的策略，标志AI产品开发模式的转变。与追求颠覆性突破的“大版本”思维不同，小步快跑模式展现出独特优势： 风险可控：每次迭代聚焦特定能力提升（如本次的编程与设计），避免全面重构风险。用户导向：快速响应社区反馈，如针对开发者需求强化three.js框架支持。生态友好：MIT开源许可使企业可即时集成新版本，蒸馏模型让普通显卡也能运行70B参数模型。 这种模式有效破解“杰文斯悖论”：当技术进步降低算力成本时，反而激发更大需求。R1-0528上线后，其API调用量激增导致服务短暂中断，正是这一现象的生动体现。 小版本迭代的累积效应不可小觑。经过数次更新，R1的编程能力已从年初的Codeforces 1890 ELO提升至2029，超越96%人类选手。 前端设计质量更达到专业设计师才能分辨差异的水准。 业界目光已投向DeepSeek R2。当小步迭代已能在编程和设计领域比肩Claude 4，真正的下一代架构革新或将重新定义国产AI的天花板。"
    },
    {
      "doc_id": 49783,
      "title": "外媒:“人工智能的未来属于中国”",
      "time": "2025-07-16T00:00:00+00:00",
      "content": "从深度求索（DeepSeek）R1模型到人形机器人足球赛，中国人工智能产业发展的脚步稳扎稳打，吸引全球瞩目。近期，多家海外主流媒体围绕中国人工智能技术研发应用相关进展发布报道，有外媒称，中国正以一次次突破不断刷新世界对AI的想象，在全球人工智能版图上刻下辉煌印记。卡塔尔半岛电视台报道截图卡塔尔半岛电视台报道表示，人工智能的未来是开源的，而且是属于中国的。中国强大的开源人工智能模型DeepSeek-R1模型的发布，给全球科技行业带来巨大震动，挑战了美国在人工智能领域的主导地位，打破了硅谷封闭的商业模式，更改变了全球人工智能地缘格局。这种开源模式已成为中国提供的战略性解决方案，具有高度灵活、全球协作、成本较低的优势。中国的人工智能产业还具备速度与规模优势，中国企业通过大量投放具有成本优势和优越性能的模型提高竞争力。未来人工智能主导权或将属于那些能够实现普遍可触达性和持续创新的玩家，而中国在美国技术封锁下坚持自主发展芯片产业，并凭借开放且去中心化的研发模式重塑全球人工智能格局。美国彭博新闻社文章截图美国彭博新闻社的一篇文章从人才培养与吸引力角度分析中国人工智能产业发展潜力。文章指出，全球人工智能竞赛的关键驱动力是一场对中国技术人才的激烈争夺，在全球顶尖人工智能研究人员中，有约一半来自中国，仅有18%来自美国。哈佛大学和斯坦福大学的研究人员都表示，中国在“人工智能人才资源原生力量”方面处于主导地位，推动了中国本土研究的可持续发展，以深度求索为例，其团队中有一半成员从未离开过中国接受教育或从事工作。文章称，与此同时，中国对顶级人工智能研究人员的吸引力在迅速上升，而美国的吸引力正在下降，两地差距迅速缩小。中国政府还通过政策资助大学人工智能实验室与研究，孕育了大量能够在民营人工智能企业实现突破的人才，打造出一个独立自主、无需“挖墙角”的创新生态系统。美国福克斯新闻报道截图美国福克斯新闻网还关注到近日举办的一场“充满未来感”中国首届由人工智能驱动的人形机器人足球赛。报道指出，这场赛事标志着中国在人工智能现实应用中的一个重要里程碑，完全实现了“零人类干预”。尽管这些机器人的步伐还稍显笨拙，但整场比赛过程中，机器人能够自主运行，独立行动，并通过人工智能和传感器作出实时决策，让世界得以管窥人工智能和机器人技术的发展方向，也预示着智能机器在人类未来日常生活中可能扮演的角色。（胡晓薇） 【责任编辑：赵超】"
    },
    {
      "doc_id": 49785,
      "title": "DeepSeek-R1挑战美AI霸权,科技行业“规模迷思”暴露无遗",
      "time": "2024-02-11T00:00:00+00:00",
      "content": "1月20日，一个名为DeepSeek的公司发布了其最新的人工智能模型——DeepSeek-R1，这一事件迅速在科技界引发了轩然大波，导致全球芯片巨头英伟达（Nvidia Corp.）的股价大幅下跌。这一突如其来的变故，不仅让投资者们措手不及，更引发了业界对于中美在人工智能领域争夺霸主地位的担忧，有人甚至将其比作是新的“人造卫星时刻”。 所谓“人造卫星时刻”，通常指的是某个国家或地区在科技领域取得重大突破，从而在该领域确立领先地位的关键时刻。而DeepSeek-R1的发布，似乎正预示着中国在人工智能领域正加速追赶，甚至有可能在某些方面超越美国。 美国的人工智能行业，一直以来都是全球科技创新的领头羊。高盛（Goldman Sachs）曾估计，“未来几年，大型科技公司、企业和公用事业公司将在资本支出上花费约1万亿美元来支持人工智能。”这样的投资规模，无疑显示了美国对于人工智能领域的重视和信心。然而，随着DeepSeek-R1的发布，美国人工智能行业的一些潜在问题也逐渐浮出水面。 长期以来，美国科技公司在人工智能领域的投资和发展方向，一直备受争议。许多观察人士指出，美国的人工智能行业似乎陷入了一种“群体思维”，几乎所有的领先公司都在遵循相同的剧本。他们痴迷于规模，认为为模型提供更多的数据和计算能力是释放更大功能的关键。这种对“缩放定律”的盲目崇拜，导致美国科技公司几乎完全专注于扩散模型和旨在执行人类（或类人）任务的聊天机器人。 然而，DeepSeek-R1的发布，却打破了这种“群体思维”。DeepSeek的方法虽然与美国公司的大致相同，但它似乎更多地依赖于强化学习、专家混合方法（使用许多更小、更有效的模型）、蒸馏和精炼的思维链推理。据报道，这一策略使得DeepSeek能够以很小的成本生产出具有竞争力的模型，这无疑是对美国人工智能行业的一种巨大挑战。 DeepSeek-R1的发布，不仅让英伟达等芯片公司的股价大幅下跌，更引发了业界对于美国人工智能行业投资方向的深刻反思。一些批评者指出，美国科技公司过于追求规模和速度，而忽视了对于技术深度和广度的探索。他们过于依赖某些尚未被证实的理论，而忽视了对于其他可能更有前途的方法的研究。 此外，美国领先科技公司是否错过了将它们的模型推向更“亲人类”方向的机会，也成为了业界关注的焦点。随着人工智能技术的不断发展，人们对于其伦理和道德问题的关注也日益增加。然而，美国科技公司在追求技术突破的同时，似乎忽视了对于这些问题的思考和探索。相比之下，DeepSeek等公司在开发人工智能模型时，更加注重其对于人类社会的实际价值和意义，这也使得它们的模型更加符合人类的需求和期望。 当然，对于DeepSeek-R1的发布和其对美国人工智能行业的影响，也存在着一些争议和质疑。有人认为，DeepSeek可能并没有完全透露其模型的所有细节和技术原理，因此其所谓的“竞争力”可能存在一定的夸大成分。然而，无论如何，DeepSeek-R1的发布都已经对美国人工智能行业产生了巨大的冲击和挑战。 这一事件也再次提醒我们，科技创新并不是一蹴而就的，而是需要不断的探索和实践。美国人工智能行业虽然拥有强大的实力和优势，但也需要时刻保持警惕和开放的心态，勇于尝试新的方法和思路。只有这样，才能在激烈的全球科技竞争中保持领先地位。 同时，对于中国政府和企业来说，DeepSeek-R1的发布也是一个重要的启示。它表明，中国在人工智能领域已经具备了与世界领先国家竞争的实力和潜力。只要继续加大投入和研发力度，不断优化和创新技术方法和思路，中国完全有可能在人工智能领域取得更大的突破和成就。 总之，DeepSeek-R1的发布不仅是一次技术上的突破和创新，更是一次对于全球人工智能行业格局和发展方向的深刻影响和挑战。它让我们看到了科技创新的无限可能和希望，也让我们更加期待未来人工智能领域的发展和变革。而对于美国人工智能行业来说，这一事件无疑是一个警钟和提醒，让它们更加珍惜和把握每一次科技创新的机会和机遇。 本文源自：金融界 作者：青枫 举报/反馈"
    },
    {
      "doc_id": 49786,
      "title": "AI人才争夺“中场激战”:国内企业缺口约500万,海外巨头上亿美元...",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "站在聚光灯下的AI（人工智能）行业正在面临激烈洗牌。 “目前AI核心技术岗位，大厂招聘实习薪资就达到5000元/天，以一个月计算收入超过10万元。”某行业猎头向记者透露。 伴随AI掀起的浪潮愈发汹涌，对于人才争夺的中场也未停歇。“去年AI人才供需比为：一个岗位对应一个人；而在今年上半年，供需比上升为4个人抢3个岗位。”脉脉创始人兼CEO林凡告诉记者，今年上半年，AI领域人才投递量大幅提升30%，AI人才在全国的缺口约500万，其中技术人才尤为紧缺。 DeepSeek横空出世搅动AI行业后，曾经一度占尽风光的“AI六小龙”：智谱、MiniMax（稀宇科技）、月之暗面、阶跃星辰等正面临更严峻的竞争格局，背后的人才争夺成为关键。 如火如荼的AI人才战已经从国内蔓延到了美国硅谷，其中华人更是科技公司关注的焦点，最近刚造访中国的英伟达CEO黄仁勋更是坦言：“全球50%的AI研究人员是中国人，你无法阻止他们推进AI发展。” 互联网大厂强势抢人 人们颇为向往的依旧是AI领域的高薪神话。 从薪资上来看，AI行业已经出现了明显的分水岭，技术岗位是高薪集中区。林凡向记者介绍，以校招数据来看，目前AI行业收入比重最高的依然是2万以下月薪，占比为32.45%，5万及以上月薪的岗位仅占比为18.17%，超过55%收入在3万元以下。 根据猎聘数据显示，50万以上招聘年薪在AI技术职位中超30%，而在整体职位中不足10%。 “All in AI”无疑是上半年科技公司的主旋律，和以往科技人才纷纷从大厂流向创业公司不同，今年以来，互联网大厂对AI的打法日渐强势，以字节跳动、腾讯为例，近两年持续保持AI人才净流入状态。 据脉脉披露数据显示，40%的AI“六小龙”员工正在“看机会”，明显高于互联网行业的平均水平（占比15%）。而据第三方统计，去年以来，至少22名高管从“六小龙”中离职。仅今年上半年就有12位，这些顶尖技术人才有些回流大厂，也有些选择自己创业。林凡认为，这一现象背后是基座模型竞争格局的基本确立，部分AI人才开始从基座模型公司流出。 在这场人才争夺战中，字节跳动是国内大厂中“挖人”最强势的一家，数据显示，在今年上半年的人才流入流出比为1.71，保持较高的人才流入。更有传言称，字节跳动曾以八位数年薪挖角某大厂头部技术负责人。 澎湃新闻记者了解到，尽管已经卸任CEO一职，但字节跳动创始人张一鸣非常关注AI业务，将其工作重心转到大模型和AI战略和研究。他经常往返北京和新加坡，多次在内部强调追求“通用人工智能”的目标，对实现通用人工智能（AGI）极其专注。 “大厂有稳定的资源、清晰的业务场景和成熟的商业化路径，尤其是对核心AI人才来说，大厂提供了更强的职业发展确定性。”业内人士向记者介绍，对于最顶尖的人才，头部大厂是不惜一切代价的，大模型公司的天花板取决于技术领袖，以字节跳动为例，招聘年薪达到3000-4000万元也并不意外。 大厂可以给到的是天花板级别的薪资，而对于创业公司而言，更多是股权和分红的激励，“一些创业公司可能会给到估值1%的股权，价值或高达千万美元。”林凡表示，很多AI创业公司高管和HR在脉脉亲自下场招人，智谱、MiniMax的HR更是分钟级的活跃在脉脉。 此外，多行业正在大规模吸纳AI人才，包括新能源汽车、智驾、机器人、电商、互联网、游戏、新生活服务行业，还有新能源车企（如比亚迪、理想汽车、小鹏汽车）、智驾企业（如地平线、轻舟智航）、电商平台（如淘宝、拼多多）等，近两年AI人才持续净流入，已经找到明确的AI落地场景。 AI公司集体冲刺IPO 对于大模型从业者来说，DeepSeek就是那条在年初搅动行业的“鲶鱼”。 “去年以来大模型行业曾经引发激烈的烧钱投流大战，但是随着DeepSeek爆红，大家逐渐趋于冷静。”上海某大模型企业内部人士向记者透露，“DeepSeek使得原本略显小众的大模型正式破圈，很多不了解AI行业的用户，通过DeepSeek更深入了解到AI市场。” 从卷投流到卷技术，洗牌完成后，迈向成熟期的AI公司逐渐茁壮。 以上海AI独角兽MiniMax（稀宇科技）为例，2024年3月，MiniMax获6亿美元A轮融资，投后估值25亿美元，由阿里巴巴领投，此前融资的投资方包括腾讯、明势资本、米哈游等。据悉，去年年底MiniMax曾完成一轮估值30亿美元的融资。 今年6月，据知情人士向记者确认，MiniMax正在初步筹备赴港上市。 此前MiniMax发起为期一周的“技术发布周”，发布首个开源大规模混合架构的推理模型MiniMax-M1，被视为正式对标DeepSeek R1。数据显示，在进行8万Token的深度推理时，M1所需的算力仅为DeepSeek R1约30%；生成10万token时，推理算力只需要DeepSeek R1的25%。 另一AI“六小龙”智谱也率先启动IPO流程。 4月15日中国证监会官网显示，北京智谱华章科技股份有限公司（下称“智谱”）已在北京证监局办理上市辅导备案，成为第一家正式启动IPO流程的大模型创业公司，7月2日，智谱宣布获得上海国资达到10亿元的战略投资——投资方包括浦东创投集团和张江集团，并于近期完成首笔交割。 AI人才争夺成全球趋势 作为全球科技界坐标，围绕AI人才的争夺，已经在美国硅谷如火如荼，尤其是华人成为了各家科技公司争夺焦点。 “中国不是众多市场中的一个，而是一个独一无二的市场。这个市场的活力、创新能力、发展势头，以及产业的发展速度，都是绝无仅有的。”7月21日，在接受央视新闻采访时，英伟达CEO黄仁勋表示。 近日，本科毕业于清华大学的AI科学家朱邦华（Banghua Zhu）和焦剑涛（Jiantao Jiao）分别宣布加入英伟达。 朱邦华本科毕业于清华大学，随后在加州大学伯克利分校的电气工程与计算机科学系获博士学位。焦剑涛本科同样毕业于清华大学，是2011年清华大学特等奖学金获得者。从清华大学毕业后，他又拿下斯坦福大学电子工程系博士学位，主要研究方向为信息论。 另一家科技公司Meta则从人工智能巨头OpenAI挖走超过14名核心研究人员，其中8名是华人，奖金达1亿美元。随后，Meta被曝又以上亿美元的薪资引入苹果AI高管Ruoming Pang（庞若鸣），这9名华人科学家都将加入扎克伯格亲自带领的“超级智能梦之队”。 6月25日，特斯拉CEO埃隆·马斯克在他的社交媒体平台X上宣布，特斯拉正式推出Robotaxi，并称这一刻是“十年艰苦工作的顶点”。在马斯克秀出的技术团队照片中，C位掌镜的是来自中国的年轻人段鹏飞，也是特斯拉Autopilot关键技术负责人，本科毕业于武汉理工大学光电信息科学与工程专业，后于俄亥俄大学获电子工程硕博学位。 段鹏飞在特斯拉AI团队的职位是首席软件工程师，领导Autopilot的Fleet Learning团队。Fleet Learning是特斯拉自动驾驶技术中重要的一环，旨在利用量产车，在“车队”成员中共享经验和数据，即通过协同学习实现知识共享和模型优化。 段鹏飞与特斯拉自动驾驶团队 “中国拥有最庞大的AI工程师队伍和最多的AI论文数量。”长期押注AI的昆仑万维CEO方汉向澎湃新闻记者坦言，在AI领域，中国和美国的优势相比其他国家是巨大的，50%的AI顶尖人才是华人，无疑说明中国在AI领域的创新优势和活力，未来的发展潜力令人瞩目。 “伴随行业整合加剧，中国的大模型产业正逐渐从‘烧钱狂飙’的狂热转化为价值主导的冷静思考，技术创新、商业落地与资本市场之间的互动也无疑将更加深入。”方汉向记者坦言，任何创业大潮，都有一个规律，叫做“抢椅子游戏”，随着椅子的数量逐渐减少，这场关乎未来的人工智能革命无疑即将迈上新的台阶。 澎湃新闻记者 范佳来 实习生 刘天颖 (本文来自澎湃新闻，更多原创资讯请下载“澎湃新闻”APP) 举报/反馈"
    },
    {
      "doc_id": 49788,
      "title": "DeepSeek流量暴跌?AI大模型全球霸主离奇遇冷,外媒曝出真相",
      "time": "2024-07-04T00:00:00+00:00",
      "content": "编辑：Aeneas 好困 【新智元导读】曾以低价高性能震撼市场的DeepSeek，为何在自家平台遇冷，市场份额下滑？背后隐藏的「Token经济学」和这场精心策划的战略转移，正悄然改变着AI的价值链与分发模式。 最近，全世界的大厂都在蠢蠢欲动了！ GPT-5、Grok 4，甚至Claude，都已经纷纷有了消息，一场恶战仿佛就在眼前！ DeepSeek这边，似乎也有新动静了。 就在昨天，一个疑似DeepSeek的新模型现身LM Arena。 也有人猜测，这个模型更可能是DeepSeek V4，而DeepSeek R2会稍后发布。 套路很可能和之前是一样的，先在第一个月发布V3，然后在下个月发布R1。 所以，曾经轰动全球AI圈的中国大模型DeepSeek R1，如今怎样了？ 到今天为止，DeepSeek R1已经发布超过150天了。 当时一经问世，它就以OpenAI同等级的推理能力和低90%的价格而迅速出圈，甚至一度撼动了西方的资本市场。 可是如今，它在用户留存和官网流量上却双双遇冷，市场份额持续下滑。 DeepSeek就这样昙花一现，红极一时后迅速衰落了？ 其实不然，在这背后，其实隐藏着另一条增长曲线—— 在第三方平台上，R1已经成爆炸性增长，这背后，正是折射出AI模型分发与价值链的悄然变革。 SemiAnalysis今天发布的这篇文章，挖出了不少一手的内幕信息。 DeepSeek，盛极而衰？ DeepSeek发布后，消费者应用的流量一度激增，市场份额也随之急剧上升。 为此，SemiAnalysis做出了下面这份统计曲线。 当然，他们也承认，由于中国的用户活动数据难以追踪，且西方实验室在中国无法运营，下面这些数据实际上低估了DeepSeek的总覆盖范围。 不过即便如此，曾经它爆炸性的增长势头也未能跟上其他AI应用的步伐，可以确定，DeepSeek的市场份额此后已然下滑。 而在网络浏览器流量方面，它的数据就更为惨淡了：绝对流量一直在下降，但其他顶尖模型的用户数却噌噌飞涨，十分可观。 不过，虽然DeepSeek自家托管模型的用户增长乏力，但在第三方平台那里，就完全是冰火两重天了。 可以看到，R1和V3模型的总使用量一直在持续快速增长，自R1首次发布以来，已经增长将近20倍！ 如果进一步深挖数据，就会发现：只看由DeepSeek自己托管的那部分Token流量，那它在总Token中的份额的确是逐月下降的。 那么，问题来了：为何在DeepSeek模型本身越来越受欢迎、官方价格非常低廉的情况下，用户反而从DeepSeek自家的网页应用和API流失，转向了其他开源提供商呢？ SemiAnalysis点出了问题关键—— 答案就在于「Token经济学」，以及在平衡模型服务的各项KPI时所做的无数权衡。 这些权衡意味着，每个Token的价格并非一个孤立的数字，而是模型提供商根据其硬件和模型配置，在对各项KPI进行决策后得出的最终结果。 Token经济学基础 我们都知道，Token是构成AI模型的基本单元。AI模型通过读取以Token为单位的互联网信息进行学习，并以文本、音频、图像或行为指令等Token形式生成输出。 所谓Token，就是像「fan」、「tas」、「tic」这样的小文本片段。LLM在处理文本时，并非针对完整的单词或字母，而是对这些片段进行计数和处理。 这些Token，便是老黄口中数据中心「AI工厂」的输入和输出。 如同实体工厂一样，AI工厂也遵循一个「P x Q」（价格 x 数量）的公式来盈利：其中，P代表每个 Token的价格，Q代表输入和输出Token的总量。 但与普通工厂不同，Token的价格是一个可变参数，模型服务商可以根据其他属性来设定这个价格。 以下，就是几个关键的性能指标（KPI）。 延迟（Latency）或首个Token输出时间（Time-to-First-Token） 指模型生成第一个Token所需的时长。这也可以理解为模型完成「预填充」阶段（即将输入提示词编码到KVCache中）并开始在「解码」阶段生成第一个Token所需的时间。 吞吐量（Throughput）或交互速度（Interactivity） 指生成每个Token的速度，通常以「每个用户每秒可生成的Token数量」来衡量。 当然，有些服务商也会使用其倒数——即生成每个输出Token的平均间隔时间（Time Per Output Token, TPOT）。 人类的阅读速度约为每秒3-5个单词，而大部分模型服务商设定的输出速度约为每秒20-60个Token。 上下文窗口（Context Window） 指在模型「遗忘」对话的早期部分、并清除旧的Token之前，其「短期记忆」中能够容纳的Token数量。 不同的应用场景需要大小各异的上下文窗口。 例如，分析大型文档和代码库时，就需要更大的上下文窗口，以确保模型能够对海量数据进行连贯的推理。 对于任何一个给定的模型，你都可以通过调控这三大KPI，设定出几乎任何价位的单位Token价格。 因此，单纯基于「每百万Token的价格」（$/Mtok）来讨论优劣，并没有什么意义，因为这种方式忽略了具体工作负载的性质，以及用户对Token的实际需求。 DeepSeek的策略权衡 所以，DeepSeek在R1模型服务上采用了何种Token经济学策略，以至于市场份额会不断流失？ 通过对比延迟与价格的关系图，可以看到，在同等延迟水平上，DeepSeek的自有服务已不再是价格最低的选择。 事实上，DeepSeek之所以能提供如此低廉的价格，一个重要原因在于，用户等待数秒后，才能收到模型返回的第一个Token。 相比之下，其他服务商的延迟会短得多，价格却几乎没有差别。 也就是说，Token消费者只需花费2-4美元，就能从Parasail或Friendli这类服务商那里，获得近乎零延迟的体验。 同样，微软Azure的服务价格虽比DeepSeek高2.5倍，但延迟却减少了整整25秒。 这样看来，DeepSeek现在面临的处境就尤为严峻了。 原因在于，现在几乎所有托管R1 0528模型的实例都实现了低于5秒的延迟。 沿用同一图表，但这次我们将上下文窗口的大小用气泡面积来表示。 从中可以看到，DeepSeek为了用有限的推理算力资源来提供低价模型，所做的另一项权衡。 他们采用的64K上下文窗口，几乎是主流模型服务商中最小的之一。 较小的上下文窗口限制了编程等场景的发挥，因为这类任务需要模型能够连贯地记忆代码库中的大量Token，才能进行有效推理。 从图表中可见，若花费同样的价格，用户可以从Lambda和Nebius等服务商那里获得超过2.5倍的上下文窗口大小。 如果深入硬件层面，在AMD和英伟达芯片上对DeepSeek V3模型的基准测试，就可以看清服务商是如何确定其「每百万Token价格」（$/Mtok）的—— 模型服务商会通过在单个GPU或GPU集群上同时处理更多用户的请求（即「批处理」），来降低单位Token的总成本。 这种做法的直接后果，就是终端用户需要承受更高的延迟和更慢的吞吐量，从而导致用户体验急剧下降。 之所以DeepSeek完全不关心用户的体验到底如何，实际上是一种主动作出的战略选择。 毕竟，从终端用户身上赚钱，或是通过聊天应用和API来消耗大量Token，并不是他们的兴趣所在。 这家公司的唯一焦点就是实现AGI！ 而通过采用极高批处理方式，DeepSeek可以最大限度地减少用于模型推理和对外服务的计算资源消耗，从而将尽可能多的算力保留在公司内部，从而用于研发。 另外还有一点：出口管制也限制了中国AI生态系统在模型服务方面的能力。 因此，对DeepSeek而言，开源就是最合乎逻辑的选择：将宝贵的计算资源留作内部使用，同时让其他云服务商去托管其模型，以此赢得全球市场的认知度和用户基础。 不过，SemiAnalysis也承认，这却并没有削弱中国公司训练模型的能力——无论是腾讯、阿里、百度，还是小红书最近发布的新模型，都证明了这一点。 Anthropic也一样？ 和DeepSeek一样，Anthropic的算力也是同样受限的。 可以看到，它产品研发的重心显然放在了编程上，而且已经在Cursor等应用中大放异彩。 Cursor的用户使用情况，就是评判模型优劣的终极试金石，因为它直接反映了用户最关心的两个问题——成本与体验。 而如今，Anthropic的模型已雄踞榜首超过一年——在瞬息万变的AI行业里，这个时长仿佛已经如十年。 而在Cursor上大获成功后，Anthropic立马顺势推出了Claude Code，一款集成在终端里的编程工具。 它的用户量一路飙升，将OpenAI的Codex模型远远甩在身后。 为了对达Claude Code，谷歌也紧急发布了Gemini CLI。 它与Claude Code功能相似，但因为背靠谷歌TPU，却有非凡的算力优势——用户能免费使用的额度，几乎无上限。 不过，尽管Claude Code的性能和设计都十分出色，价格却不菲。 Anthropic在编程上的成功，反而给公司带来了巨大压力——他们在算力上已经捉襟见肘。 这一点，在Claude 4 Sonnet的API输出速度上就已经体现得淋漓尽致。自发布以来，它的生成速度已下降了40%，略高于每秒45个Token。 背后的原因，也和DeepSeek如出一辙——为了在有限的算力下处理所有涌入的请求，他们不得不提高批处理的速率。 此外，编程类的使用场景往往涉及更长的对话和更多的Token数量，这就进一步加剧了算力的紧张状况。 无论是何种原因，像o3和Gemini 2.5 Pro这类对标模型的运行速度要快得多，这也反映出OpenAI和谷歌所拥有的算力规模要庞大得多。 现在，Anthropic正集中精力获取更多算力，已经和亚马逊达成了协议。它将获得超过五十万枚Trainium芯片，用于模型训练和推理。 另外，Claude 4模型并非在AWS Trainium上预训练的，而是在GPU和TPU上训练。 速度劣势可由效率弥补 Claude 的生成速度虽然暴露了其算力上的局限，但总体而言，Anthropic的用户体验（UX）要优于 DeepSeek。 首先，其速度虽然偏低，但仍快于DeepSeek的每秒25个Token。 其次，Anthropic的模型回答同一个问题所需的Token数量远少于其他模型。 这意味着，尽管生成速度不占优，用户实际感受到的端到端响应时间反而显著缩短了。 值得一提的是，在所有领先的推理模型中，Claude的总输出Token量是最低的。 相比之下，Gemini 2.5 Pro和DeepSeek R1 0528等模型的输出内容，「啰嗦」程度都是Claude的三倍以上。 Token经济学的这一方面揭示出，服务商正在从多个维度上改进模型，其目标不再仅仅是提升智能水平，而是致力于提高「每单位Token所承载的智能」。 随着Cursor、Windsurf、Replit、Perplexity等一大批「GPT套壳」应用（或称由AI Token驱动的应用）迅速流行并获得主流市场的认可。 我们看到，越来越多的公司开始效仿Anthropic的模式，专注于将Token作为一种服务来销售，而不是像ChatGPT那样以月度订阅的方式打包。 参考资料： https://semianalysis.com/2025/07/03/deepseek-debrief-128-days-later/ 举报/反馈"
    },
    {
      "doc_id": 49789,
      "title": "Kimi和DeepSeek又又又撞车?",
      "time": "2024-06-04T00:00:00+00:00",
      "content": "摘要： 据凤凰网科技了解，今年杨植麟的关注重心早已发生改变。2月底，Kimi内部在重点推进模型表现的提升，“杨植麟亲自带队”。近期，Kimi则专注垂直领域，核心都是提升模型能力上限。 几个大模型初创企业里，Kimi当下最为安静。 “（Kimi）最核心的任务就是提升留存，或者把留存作为一个重要的衡量指标” 去年11月，在Kimi上线一周年之际，创始人兼CEO杨植麟曾在一场小型沟通会中亮相并提出了这一观点。 “有一轮大厂的钱进来后，投资人确实会要求看数据，杨植麟作为创始人肯定要在这方面用心”，接近Kimi的人士告诉凤凰网科技，根据披露，那时Kimi的月活用户突破了3600万，跻身国内AI原生应用TOP3的席位。 据凤凰网科技了解，今年杨植麟的关注重心早已发生改变。 2月底，Kimi内部专注模型能力的提升，最直观的体现就是榜单，“杨植麟亲自带队”，接近Kimi的人士表示。参与打榜的模型为K1.6，其结果显示，在全球动态基准测试平台 LiveCodeBench，K1.6超过了 GPT o3mini、o1 等模型，在代码生成测试中实现登顶。不过，K1.6和坊间传闻的K2至今没有发布。 与打榜同期进行的，是招聘法律相关的数据专家。5月，Kimi被传进军医疗赛道，实际上同样是招聘医疗领域的相关数据专家，目标是为了提升医疗内容的信息检索质量。 近日，Kimi又悄悄上线了学术搜索。 “很明显，Kimi在加强垂直领域的能力”，另一行业人士对凤凰网科技表示。 “Kimi作为闭源模型，想要去证明自己的能力，打榜是一个很重要的途径，这也是为什么之前杨植麟会带队上场”，多位行业人士对凤凰网科技表示，“早就听说Kimi回归基模了”。而入局垂类赛道，同样不失为一种提升模型能力，减少幻觉的有效手段之一。 在新的对垒格局下，Kimi仍在努力留在牌桌上。 再度撞车DeepSeek 颇为巧合的是，DeepSeek5月在招聘的新数据百晓生，便是以医学方向为主。 所谓百晓生，主要做的是文本语料标注工作，并与AI工程师进行合作提升大模型的能力和反馈质量。 通过加强专业内容的索引，可以有效的减少模型的幻觉率。有行业人士对凤凰网科技表示，“大量专业用户，在财经、医疗、法律、代码等领域对模型的专业和可靠存在需求”。 更早之前，DeepSeek与Kimi都瞄准了法律赛道。 今年2月，Kimi开放了AI数据专家法律方向的招聘，职位要求应聘者具备2年以上法律相关垂类场景工作的经验，有对相关垂类场景较好的专业功底和知识储备，并能理解在法律相关垂类场景中用户的诉求。 据前述行业人士分享，Kimi在2024年曾有相当长的时间保持Web端用户量的第一，拥有大量专业用户，也在外界心中形成了AI可以被当作生产力工具的认知。 昆仑万维CEO方汉在发布新agent产品时也曾对凤凰网科技表示，AI在生产力场景下有着广阔的商业化前景。但现阶段，很多模型在垂类领域的表现只能打60到70分，可用性还不够强。 这也恰恰是当前基座大模型企业发展垂直领域的难点，“想把垂直领域做好了，还是非常考验模型能力的。同时还得做好专业数据的深度挖掘，这是Kimi当前面临的考验”，前述行业人士对凤凰网科技表示。 同样是在4月，Kimi宣布与财新传媒正式达成内容合作。在Kimi提问财经相关内容时，Kimi将结合财新传媒旗下报道内容，通过模型生成答案，意图是提高真实性，降低幻觉。 目标依旧是AGI 今年以来，国内月活Top3的AI原生应用座次，从豆包、Kimi和文心一言，摇身一变成了DeepSeek、豆包和腾讯元宝。Kimi落到了第四的位置。 与此同时，Kimi暂停了此前的投流营销策略。有接近Kimi的人士对凤凰网科技表示，“Kimi今年更关注自然增长和用户留存”，另有多位博主表示，春节后就没再接到过Kimi的需求。 该行业人士认为，不同时期会有不同市场形势，“DeepSeek的出圈，包括Kimi去年凭借200万字长文本的出圈，都说明了创新的重要性”。这在今天的市场上，也成为了一个新共识。 阶跃星辰CEO姜大昕在不久前的一场小范围沟通会中表达，“DeepSeek给我们的经验就是，投流的逻辑实际上（对AI的c端产品来说）是不成立的”。 “根据我对Kimi的了解，他们一直是把探索AGI、提升模型能力作为目标的”，前述行业人士对凤凰网科技表示，发力垂类赛道不等于放弃对基座模型的预训练，“相反需要在基建上做得更扎实，才能支撑起垂类赛道的专业和领先”。 尽管AI六小虎的概念人们开始提得越来越少了，但其中还是有不少小规模公司仍在追求模型能力的上限。 杨植麟在去年底的沟通中提过一个观点，其认为“AI的发展就像荡秋千，我们会在两种状态之间来回切换：有时候，算法、数据都很ready了，但是算力不够，我们要做的就是加算力；但今天我们发现，不断扩大算力规模已经不一定能直接解决问题了，所以这时就需要通过改变算法，来突破这个瓶颈。” 当前，各个公司从不同路线入手，以期达到模型更高的可用性。 就在端午节前夕，DeepSeek更新了R1模型的小版本升级，并透露该版本模型是基于去年12月发布的V3 Base模型作为基座模型，但在后训练中投入了更多算力，显著提升了模型的思维深度和推理能力。特别是在编程等基准测试中，评分表现已与o3、Gemini-2.5-Pro相当。 DeepSeek官方还着重强调了幻觉改善，称“与旧版相比，更新后的模型在改写润色、总结摘要、阅读理解等场景中，幻觉率降低了 45～50% 左右，能够有效地提供更为准确、可靠的结果”。 阿里云创始人王坚也在不久前的采访中对凤凰网科技表示，当下是基础模型能力最强的时期，鼓励更多开发者去做潜在颠覆式应用的开发。 不过，王坚也坦言，个人并不认可“通用人工智能（AGI）”这一新概念，认为AI的核心价值应回归技术本身。“如果一定要谈未来，AI的发展阶段和能力边界将远超今天人类的想象，至于是否会被定义为AGI，答案或许并不重要。”他强调，技术的颠覆性突破往往诞生于“未被预设的领域”，而当前大模型展现出的能力已让许多传统认知被重新定义。 王坚还以OpenAI的发展历程为例：“ChatGPT的诞生并非一蹴而就，而是建立在GPT-3.5、GPT-4等多次迭代的基础上。关键在于，开发者能否跳出传统思维，主动探索模型潜藏的能力。”他特别表示，如今AI基础模型的成熟度已远超OpenAI初创时期，且技术门槛的降低让更多企业站上同一起跑线。“今天具备这样模型能力的有很多家公司，那在杭州就有DeepSeek，也有千问。（所以）先不要担心大模型能做什么，不能做什么，我觉得这是唯一我们往前走（通往AGI）的方法”。 值得一提的是，最新消息称，两名 OpenAI 公司代表在墨西哥举办的 AI Summit 峰会上透露，公司正在开发下一代基础模型 GPT-5，并计划通过该模型与竞争对手展开更激烈角逐。他们还明确表示，GPT-5即将面世，另有消息称或许是7月。 如若GPT-5如期面世，AI行业或将再度迎来飞跃性时刻。 本文源自：凤凰网科技 举报/反馈"
    },
    {
      "doc_id": 49790,
      "title": "「产业互联网周报」阿里通义千问与DeepSeek开源两款新模型;谷歌...",
      "time": "2024-03-31T00:00:00+00:00",
      "content": "【产业互联网周报是由钛媒体TMTpost发布的特色产品，将整合本周最重要的企业级服务、云计算、大数据领域的前沿趋势、重磅政策及行研报告。】 国内资讯 宝马官宣与阿里达成AI合作 宝马集团宣布与阿里巴巴集团在中国达成AI领域战略合作，双方在AI大语言模型和智能语音交互等前沿领域开展联合研发，提供最贴近中国用户需求的前瞻性解决方案。阿里通义大模型将应用于中国市场的宝马新世代系列车型。 腾讯混元T1正式版上线元宝 腾讯混元宣布，深度思考模型“混元T1”正式版携手DeepSeek V3最新版已上线元宝。 浙江省政府与阿里巴巴集团蚂蚁集团签署战略合作协议 浙江省政府与阿里巴巴集团、蚂蚁集团签署战略合作协议。省长刘捷分别与阿里巴巴集团董事会主席蔡崇信、蚂蚁集团董事长井贤栋见证签约。根据协议，省政府与阿里巴巴集团、蚂蚁集团将紧紧围绕“以高质量发展为首要任务、以缩小‘三大差距’为主攻方向、以改革创新为根本动力、以满足人民美好生活需要为根本目的”，进一步整合资源、紧密协同，推动平台经济健康发展，在人工智能等领域展开合作，更好服务中国式现代化省域实践，共同推动国家重大战略落地实施。 华弘数科发布新款全液冷智算一体机 3月27日，华弘数科发布AI新物种：全液冷智算一体机。据了解，此次发布的新品为承影系列，定位为千亿级模型微调训练与高密度计算平台，主要应用场景为深度学习与人工智能、医疗与生物信息科研、图形渲染与虚拟现实、具身机器人智造等。支持高达96核处理器，8根DDR5 ECC内存插槽，支持2TB内存；GPU方面，支持7张GPU计算卡（液冷散热），显存可达560G。该一体机采用整机CNC精雕一体成型制造工艺辅以纳米级抛光技术，呈现全镜面视觉美学，自研全液冷散热技术，在压缩体积的同时，提升散热效率并降低运行噪音。 快手：AI大模型预计可把客户短视频营销素材制作成本降低60—70% 在快手2024年第四季度及全年业绩电话会上，快手科技创始人兼首席执行官程一笑称，2024年第四季度，快手平台上的AIGC营销素材和虚拟数字人直播解决方案的日均消耗超过3000万元。程一笑表示，根据快手内部测算，AI大模型预计可以把客户的短视频营销素材制作成本降低60—70%甚至更高。目前快手正致力于逐步把磁力引擎全面升级下一代的AI智能商业引擎。 快手程一笑：可灵AI已与小米、亚马逊云科技等数千家企业合作 在快手2024Q4及全年业绩电话会上，快手科技创始人兼首席执行官程一笑透露，自商业化以来截至2025年2月底，可灵AI的累计营业收入超1亿元。除了C端用户订阅，可灵AI也面向B端商家提供API接入等服务。目前，可灵AI已与包括小米、亚马逊云科技、Freepik、蓝色光标等在内的数千家国内外企业客户建立了合作关系。 中欧国际工商学院正将人工智能模块融入课程体系 中欧国际工商学院近日举办以“‘AI+商业’进化论”为主题的行业峰会，并发布人工智能与商业创新白皮书。中欧国际工商学院院长、管理学教授汪泓指出，“技术突破正加速教育体系、科研范式及产业生态的深度变革。人工智能已成为国家战略性新兴产业的核心引擎。针对AI技术对高等教育的冲击，中欧正将人工智能模块深度融入课程体系，打造‘商业智慧+AI技术’的复合培养模式。交叉学科与AI融合已成趋势，当企业家同时掌握专业知识和AI技术时，商科教育需要重新定义人才培养标准。” 中国电信：今年算力资本开支初步计划同比增长22%，将根据需求灵活调整不设限 通过中国电信2024年度业绩说明会获悉，公司2025年计划资本开支836亿元，预计同比下滑10.6%。其中，产业数字化方面占比预计提升至38%，算力方面资本开支预计同比增长22%。公司董事长兼首席执行官柯瑞文表示，“算力方面，我们初步安排是百分之二十几的增长，但不设限。将根据客户需求、市场发展的一些情况灵活调用（投资额）。” 中国电信：2024年面向AI适度超前布局云网基础设施，智能算力资源达35EFLOPS 中国电信发布2024年度业绩，面向AI适度超前布局云网基础设施。建成京津冀、长三角两个全液冷万卡池，在粤苏浙蒙贵等地区部署千卡池，智能算力资源达到35EFLOPS。推动数据中心全面向AIDC升级，依托重点区域大型园区、省市机房和边缘局站，满足训练和推理、中心和边缘、云侧和端侧等各类智算部署需求。建设高通量、低时延的智算互联网，规模部署G.654E新型光纤，建设400Gbps全光传输网络，八大枢纽间平均时延下降7%，新型城域网覆盖超200个边缘算力池，实现毫秒级入算。千兆光网10G PON端口达929万个，城镇住宅覆盖率超95%，试点部署50G PON网络。 微软-张江人工智能与物联网实验室或已关闭 位于上海张江的，号称微软全球最大的人工智能和物联网实验室据传已经关闭。多位接近微软的业内人表示，该实验室最初由张江和微软共同出资建立，不久前合同临近到期时，微软方面表示不愿再投入资金，直至近期，有传言称双方合作已经终止，该实验室已经关闭。 中信集团在港成立人工智能科技创新中心、人工智能数智创新联合实验室 3月27日，中信集团在港揭牌成立中信香港人工智能科技创新中心，并与香港理工大学签署框架协议，宣布共同成立人工智能数智创新联合实验室。此外，中信银行、中信重工、中信泰富特钢、中信国际电讯分别与香港理工大学签署了意向合作协议，明确了实验室成立后双方在工业智能、具身智能、金融科技等领域的首批联合攻关课题。 豆包测试新版深度思考功能，支持边想边搜 AI助手豆包近日测试新版“深度思考”功能。该功能将推理过程的思维链与搜索深度结合，支持“边想边搜”。用户下载最新版豆包App，开启深度思考模式后，豆包在思考过程中可以基于推理多次调用工具、搜索信息，提供更全面，更丰富、准确性更高的结果。 蚂蚁集团战略调整：减持传统投资，加码AI布局 蚂蚁集团近期减持奥比中光和永安行，累计获得超7.75亿元投资回报，引发市场关注。此次减持是基于战略方向的调整，蚂蚁将资金转向人工智能等前沿科技领域，支持新一代科技创新。蚂蚁的投资策略仍以公司战略为导向，重点关注AI大模型、AI算力、具身智能等方向，已投资多家相关企业。蚂蚁强调，持有期较长，注重生态协同，通过投资推动技术创新，为社会创造更多价值。 启明创投邝子平：中国人工智能投资远未过热 在3月23日至24日中国发展高层论坛2025年年会上，与会代表围绕人工智能发展与安全、全球共享共治等话题展开深入探讨。邝子平提出，人工智能将为人类带来巨大福祉，成为未来10年最重要的投资机会之一。他强调了以下四个观点：一是人工智能的国际化，强调人工智能解决的问题具有普遍性，其带来的好处应由全人类共享；二是中国人工智能市场潜力巨大，虽然中国人工智能投资规模远小于美国，但中国市场前景广阔，投资并未过热；三是人工智能投资的国际化，中国应吸引全球资金投资于人工智能领域，投资市场的变化将促使全球投资人越来越关注中国市场；四是人工智能国际治理，人工智能的国际治理前提是国际化，包括人员、技术、投资和产品服务的交流。 阿里通义千问与DeepSeek开源两款新模型 阿里通义千问与DeepSeek均于昨日低调开源了两款新模型。阿里发布了更适合本地部署的高性能“多模态模型”Qwen2.5-VL-32B，DeepSeek则将此前热门的“基座模型”V3更新到0324版本，并官宣在魔搭社区上架开源。截至目前，魔搭社区模型总数已超4万个，已成为中国最大的AI开源社区。 阿里开源首个全模态大模型Qwen2.5-Omni，7B尺寸远超Gemini-1.5-Pro等同类模型 3月27日凌晨，阿里巴巴发布并开源首个端到端全模态大模型通义千问Qwen2.5-Omni-7B，可同时处理文本、图像、音频和视频等多种输入，并实时生成文本与自然语音合成输出。在权威的多模态融合任务OmniBench等测评中，Qwen2.5-Omni刷新业界纪录，全维度远超Google的Gemini-1.5-Pro等同类模型。Qwen2.5-Omni以接近人类的多感官方式立体认知世界并与之实时交互，还能通过音视频识别情绪，在复杂任务中进行更智能、更自然的反馈与决策。现在，开发者和企业可免费下载商用Qwen2.5-Omni，手机等终端智能硬件也可轻松部署运行。 百度网盘和文库联合推出首个一站式视频AI笔记 华为近日举行的新品发布会上，余承东现场介绍鸿蒙版百度网盘及其推出的视频AI笔记。据悉，该功能由百度网盘和文库联合推出，是业内首个一站式视频AI笔记，打通学习资料从存储、总结、创作、编辑到消费的闭环。用户在百度网盘PC端、网页端、APP端观看学习视频时，点击“笔记”侧边栏即可体验。 海外消息 安卓停止开源？谷歌：简化开发不是闭源，将继续发布源代码 据安卓领域专家Mishaal Rahman在垂类网站Android Authority发布的文章，谷歌证实，下周起谷歌将开始完全在内部分支机构闭门开发安卓操作系统，此举是为了简化安卓操作系统的开发。但谷歌也明确强调，安卓不会成为闭源系统。该公司将继续发布新安卓版本的源代码，并对外开放。 (澎湃新闻) 新加坡GTS与马来西亚电信运营商CelcomDigi签订3年独家合同 总部位于新加坡的电信企业集团Globe Teleservices Pte. Ltd. （GTS）宣布，已获得一份为期3年的独家合同，为马来西亚最大的移动网络运营商CelcomDigi部署其先进的A2P短信防火墙解决方案。 OpenAI：对话补全API遭遇高错误率，正努力实施缓解措施 OpenAI发布事故报告称，确认用户在使用对话补全（Chat Completions）API时遭遇高错误率，目前正在努力实施缓解措施。此外，Sora图像生成问题已解决，目前正在进行监控。 DigiCore房地产信托入股日本一数据中心 DigiCore房地产信托宣布，收购日本大阪第二座永久产权、已完全建成并投入运营的数据中心20%股权。这一资产从三菱商事手中收购，交易价格为130亿日元。 谷歌发布旗舰推理模型，单次可处理百万token 美国时间周二，谷歌发布Gemini 2.5系列人工智能推理模型。该系列模型在回答问题前会“思考”片刻。作为这一系列模型的首发产品，Gemini 2.5 Pro Experimental已经率先亮相。这款多模态推理人工智能模型被谷歌称为“目前最智能的模型”，支持高达100万token的超大上下文窗口，单次可以处理约75万英文单词，远超《指环王》三部曲的总字数。谷歌透露，未来Gemini 2.5 Pro将支持200万token的双倍输入长度。这一模型将于周二登陆谷歌开发者平台Google AI Studio，同时向每月支付20美元订阅“Gemini Advanced”的用户开放。谷歌表示，未来所有新推出的人工智能模型都将集成推理能力。 高通向全球监管机构发起对Arm的反垄断行动 据媒体报道，高通(QCOM.O)对Arm(ARM.O)发起了一场全球反垄断行动，这两家长期合作的伙伴正在计算机半导体市场争夺优势。据知情人士透露，在非公开会议和提交给三大洲监管机构的机密文件中，高通称其最大供应商Arm存在反竞争行为。知情人士表示，高通向欧盟委员会、美国联邦贸易委员会和韩国公平贸易委员会提出的申诉称，在运营开放网络20多年后，Arm限制了对其技术的获取，损害了竞争。高通认为，Arm通过开放授权模式，让人们对其技术产生了严重依赖，同时也促成了蓬勃发展的芯片产业。高通正向全球竞争监管机构反映，Arm目前正在限制准入，以推动自身的芯片制造业务并提高利润，从而威胁到这一充满活力的市场。 特朗普政府将多家中国科技公司列入“实体清单” 美国商务部工业与安全局美国当地时间周二在联邦公报上刊发两份文件，将50余个中国科技企业和机构纳入所谓的“实体清单”，预期将于3月28日生效。在其中的一份文件中，美国商务部将一系列与中国AI大模型开发、服务器以及超级计算机产业相关的12家公司列入“实体清单”，包括北京智源人工智能研究院、宁畅信息产业、中科可控旗下的服务器品牌Suma，以及浪潮信息在中国内地以及港台地区的多家子公司。在另一份文件中，还有42家中国公司，19家巴基斯坦公司，以及伊朗、南非、阿联酋的多家公司被纳入“实体清单”。其中美国商务部以“支持中国量子技术发展”为借口，对赛澔仪器、安徽科华贸易、重庆西南集成电路设计有限责任公司等一系列公司展开无理制裁。另外还有数十家中国公司，被美方以“涉军”为由，列入出口关注清单。 OpenAI推出GPT-4o图像生成功能 OpenAI宣布推出4o图像生成功能，“将迄今最先进的图像生成器集成至GPT-4o”。即日起，所有Plus、Pro、Team及免费用户将陆续在ChatGPT和Sora中体验该功能，企业版与教育版即将接入，Sora平台同步启用。开发者即将通过API调用GPT-4o图像生成功能，接口权限将于未来数周内开放。据介绍，GPT-4o图像生成功能可精准文本渲染、严格遵循指令提示、深度调用4o知识库及对话上下文——包括对上传图像进行二次创作或将其转化为视觉灵感。 消息称苹果正在订购英伟达GB300 NVL72系统，订单价值约10亿美元 Loop Capital分析师Ananda Baruah在当地时间周一的一份报告中表示，苹果正在订购英伟达GB300 NVL72系统，订单价值约10亿美元，这相当于大约250台服务器，每台售价370万至400万美元。“苹果正式加入AI大型服务器集群竞赛”，公司正在与戴尔和超微计算机合作开发大型服务器集群，以支持生成式人工智能应用。 美国科技企业高管和外国领导人据悉敦促特朗普重新考虑AI芯片限制 媒体报道称，美国科技企业高管和外国领导人敦促特朗普重新考虑对AI芯片的限制。据悉，英伟达和甲骨文正在推动全面废除AI扩散规则，阿联酋、以色列、印度是要求放宽规则的国家之一。公司需在5月15日前遵守全球AI限制。 OpenAI智能体支持MCP，已开源 3月27日凌晨2点，OpenAI对AgentSDK进行了重大更新支持MCP服务，可以统一接口标准解锁无限工具。现在Agent可以快速集成网络搜索、专业分析、本地查询、网络追踪等各式各样的工具，这对于开发超复杂自动化智能体来说帮助巨大。例如，在开发一个需要同时进行文件处理、数据查询和网络信息收集的智能体时，开发者可以通过MCP服务器分别集成文件系统工具、数据库查询工具和网络爬虫工具，更高效地完成复杂任务。 融资并购 超融合数据库企业「九有数据库」完成A轮融资 专注于高性能、多模态国产超融合数据库产品和解决方案研发的创企「九有数据库」宣布完成A轮融资，由深圳天使母基金和龙华资本的共同子基金深圳市大米成长天使投资合伙企业（大米创投）领投。此轮融资将用于进一步加大技术研发投入，拓展市场版图。 具身智能初创公司它石智航完成1.2亿美元天使轮融资，蓝驰创投、启明创投领投 具身智能初创公司它石智航（TARS）宣布完成天使轮1.2亿美元融资。本轮融资由蓝驰创投、启明创投共同领投，线性资本、恒旭资本、洪泰基金、联想创投、襄禾资本、高瓴创投跟投。它石智航创下中国具身智能行业天使轮最大融资额纪录。本轮融资将主要用于公司的产品和技术研发、模型训练、场景拓展等方向。 具身智能公司“原力灵机”完成2亿元天使轮融资 原力灵机（重庆）智能科技有限公司近日完成2亿元天使轮融资，投资人包含君联资本、九坤创投、启明创投。原力灵机研发团队兼具顶尖学术背景以及超过10年的AI原生产品落地经验，是行业内为数不多的兼具大模型技术与机器人场景的具身智能公司。据透露，原力灵机核心创始团队源于旷视科技，成员包括范浩强、周而进和汪天才。值得关注的是，原力灵机团队在端到端具身算法方面进展迅速，旷视在物流机器人行业又有多年的积淀与场景优势，相信原力灵机会快速推进具身智能技术在实际工业环境中的应用和落地。 苏州吴中机器人产业投资合伙企业成立，出资额10亿元 天眼查App显示，苏州吴中机器人产业投资合伙企业（有限合伙）近日成立，执行事务合伙人为苏州市吴中金控股权投资管理有限公司，出资额10亿人民币，经营范围为股权投资、创业投资、以自有资金从事投资活动。合伙人信息显示，该企业由苏州太湖科技发展投资有限公司、苏州吴中国太发展有限公司、苏州吴中经开产业基金有限公司、江苏吴中高新创业投资有限公司等共同出资。 OpenAI接近敲定由软银牵头的400亿美元融资 据知情人士透露，OpenAI即将完成由软银集团领投的400亿美元融资，包括Magnetar Capital、Coatue Management、Founders Fund和Altimeter Capital Management在内的投资者正在参与谈判。这笔交易将使该公司估值达到3000亿美元。据多位知情人士透露，总部位于伊利诺伊州埃文斯顿的对冲基金Magnetar Capital可能会贡献高达10亿美元的资金。 英伟达计划收购阿里云前副总裁贾扬清的创企Lepton AI 据报道，英伟达计划以数亿美元收购阿里云前副总裁贾扬清的创企Lepton AI。Lepton成立于2023年，是被称为“Caffe之父”的AI领域大牛贾扬清在离开阿里之后创办的，其主要业务是出租英伟达GPU服务器，开发软件帮助创企在云中构建和管理自己的应用。该公司于2023年5月完成了1100万美元（折合人民币约7900万元）天使轮融资。据猜测，英伟达收购Lepton意在进军云和企业软件市场，与AWS和谷歌等主要云服务商竞争。 政策&趋势 工信部：1-2月 中国电信业务收入累计完成2950亿元 工信部公布2025年前2个月通信业经济运行情况。前2个月，电信业务收入保持正增长，5G、千兆光网等网络建设和应用不断推进，连接用户规模稳步扩大，移动互联网接入流量较快增长。前2个月，电信业务收入累计完成2950亿元，同比增长0.9%。按照上年不变价计算的电信业务总量同比增长7.6%。截至2月末，三家基础电信企业的固定互联网宽带接入用户总数达6.75亿户，比上年末净增493.6万户。 湖北省发布科技型企业知识价值信用贷款政策 湖北省科技型企业知识价值信用贷款政策发布会昨日在武汉举行，会上发布《湖北省科技型企业知识价值信用贷款实施办法（试行）》。《办法》针对科技型企业轻资产债权融资难题，充分开发知识价值的信用空间，围绕企业科技创新要素生成知识价值评价模型，对全省28.5万家科技型企业进行评价，评价结果按5个等次推送各银行机构，银行机构运用评价结果相应为科技型企业提供“全线上、纯信用、优利率”、期限不超过3年、单笔金额不超过1000万元的授信支持。在健全风险分担机制，运用财政资金设立风险补偿资金池的同时，建立以合理不良贷款率为触发条件的熔断机制，解决银行机构后顾之忧。 国资委：持续壮大发展人工智能的长期资本、战略资本、耐心资本 在国务院国资委召开的中央企业“人工智能+”媒体通气会上，国务院国资委规划发展局相关负责人表示，将积极引导中央企业加大资金投入，坚持产投结合、以投促产，持续壮大发展人工智能的长期资本、战略资本、耐心资本，优化人才引育，建立更加符合行业特点规律的人才评价体系，发挥需求规模大、产业配套全、应用场景多的优势，聚焦关键领域，加快掌握“根技术”，积极参与开放生态建设，推动产生更多“从0到1”的原始创新，深化与各方协同合作，为加快推动中国人工智能产业高质量发展作出更大贡献。 国资委：中央企业人工智能产业发展将进一步提速加力 在国务院国资委召开的中央企业“人工智能+”媒体通气会上，国务院国资委规划发展局相关负责人表示，目前，中央企业人工智能产业发展将进一步提速加力。该负责人表示，国务院国资委持续深化中央企业AI+专项行动，指导央企紧盯发展态势、服务国家战略，全力当好国家智算基础设施的重要供给者、人工智能赋能千行百业的重要破题者、产业体系化布局的重要组织者，着力提升中央企业在人工智能领域全方位的能力，在应用、算力、数据、模型等人工智能产业重点领域取得积极成效。 李开复称DeepSeek将中美AI差距缩小至3个月 据新加坡《联合早报》网站3月25日报道，中国初创企业零一万物首席执行官李开复说，在人工智能（AI）发展方面，中国已将与美国在某些领域的差距缩小至仅3个月，因为中国初创企业深度求索（DeepSeek）等公司已经研究出如何更有效地使用芯片和应用算法。 谷歌高管：量子计算离实际应用可能剩五年 谷歌量子AI硬件部门负责人Julian Kelly日前表示，量子计算机可能能够实现前所未有的技术突破，包括进行尖端物理学的研究，并生成新型数据。他表示：“我们认为大约五年后，量子计算机会迎来一次真正的突破，能够解决只有量子计算机才能解决的实际问题。” 三大运营商AI投资提速且设立特别预算或不设上限 中国移动、中国电信和中国联通已披露2024年业绩，均计划大手笔分红回报股东。三大运营商的资本开支计划合计达2898亿元，尽管总体投资规模有所下调，但算力、AI成为运营商适当超前布局发力的重点，甚至还设立了特别预算或者“不设上限”。中国移动计划2025年投1512亿元，聚焦5G和智算基础设施，预计智算规模达34EFLOPS。中国联通和中国电信也分别调整投资，提升AI和算力的投资比例。AI应用成为三大运营商的共同关注点，中国移动推出多款AI产品并布局云智算，中国联通和中国电信则加速智算服务和AI终端产品的发展，以推动业务转型升级。 机构：中国大陆云基础设施服务支出将在2025年增长15% Canalys的最新数据显示，2024年第四季度，中国大陆的云基础设施服务支出达到111亿美元，同比增长14%。2024年全年，云服务总支出从2023年的353亿美元增长至400亿美元，年增幅为13%。AI模型的快速应用超出预期，带动了对云服务需求的显著增长。得益于其卓越的性能和成本效益，DeepSeek在全球市场迅速崛起，进一步激发了中国大陆企业客户加快AI应用探索和部署的热情。Canalys预测，2025年中国大陆云基础设施服务市场的增长将进一步加快，预计增速将达15%。 重庆：加快研发智能车载操作系统，强化车路云网图协同等智能驾驶技术攻关 《重庆市人工智能赋能制造业高质量发展行动方案（2025—2027年）（征求意见稿）》公开征求意见。其中提到，组织实施人工智能“模动山城”计划，加快研发迭代垂直行业大模型，做精细分场景专用模型，鼓励基于DeepSeek等前沿开源模型开展蒸馏、量化，发展轻量、高效、易部署的中小型模型。鼓励企业开展智能体（Agent）研发，推进产品与服务标准化、模块化发展；加快研发具有自主知识产权的智能车载操作系统、工控操作系统等智能操作系统；依托国家智能网联汽车“车路云一体化”应用试点城市建设，强化车路云网图协同、多传感器融合感知、高动态智能执行等智能驾驶技术攻关。持续研发具身智能多模态“大脑”和运动控制“小脑”，推动机器人双臂协同、手眼协同、脑身协同、力控制技术等关键技术攻关。 今年以来中国已新增智慧医疗相关企业超过3万余家 天眼查专业版数据显示，截至目前中国现存在业、存续状态的智慧医疗相关企业超76.4万家。其中，2025年截至目前新增注册相关企业约3万余家，从企业注册数量趋势来看，近五年间，智慧医疗相关企业的注册数量呈现出逐年增长的态势，并在2024年达到顶峰，为15万余家。从区域分布来看，广东省、上海省、江苏省智慧医疗相关企业数量位居前列，三个省市数量总和超过25.5万余家，占企业总数的33.4%。排在其后的是山东省和北京市。此外，通过天眼查天眼风险和深度风险来看，涉及司法案件的智慧医疗相关企业约占总数的2.7%。 AI驱动卖方研究转型，私域数字资产价值凸显 人工智能（AI）助推投研提效，驱动转型的不只是券商分析师，也包括研究所本身。在这场效率革命中，从人力、组织、科技投入等各方面，券商研究所都需要在变化中寻求未来的方向。近日，有大型券商研究所从业人士表示，“AI平权加速推动卖方研究转向深度”，也有人士直言，“卖方研究行业可能会迎来大浪淘沙的洗牌”。还有人提出，“私域数字资产会是研究所未来差异化服务的基石”。总体而言，在公募佣金新规的大背景下，AI为券商研究所带来了更多构建差异化发展路径的可能性，同时也驱动券商研究所更加重视具有价值的研究工作。 福建发布全国首个公共数据运营服务定价收费标准 据福建省发展和改革委员会官网27日消息，近日，福建省公共数据资源开发服务平台发布了《福建省公共数据运营服务收费标准（试行）》，弥补了全国公共数据运营服务定价收费的空白，在全国率先建立公共数据授权运营价格形成机制，破局打通公共数据资源市场化配置利用最后一公里。下一步，福建省将重点推动公共数据应用赋能，充分发挥公共数据资源在推动产业升级、优化公共服务、提升治理能力等方面的重要作用,加快公共数据应用场景建设，推动公共数据赋能产业发展示范场景培育，形成一批经济社会效益突出、产业带动效应强的应用,充分释放公共数据资源价值。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 49791,
      "title": "DeepSeek再更新!",
      "time": "2024-03-27T00:00:00+00:00",
      "content": "近日 DeepSeek低调上线了 新版V3模型DeepSeek-V3-0324 官方表示 如非复杂推理任务 建议使用新版V3模型 享受速度更加流畅 效果全面提升的对话体验 值得一提的是 业内的早期测试证实 该模型可以直接在消费级硬件上运行 2025年2月17日，用户在DeepSeek手机客户端上提问。 图源：新华社 初代DeepSeek-V3 发布于2024年12月26日 这款模型自上线后 便以高性价比火速“出圈” 根据官方技术论文披露 DeepSeek-V3模型的总训练成本 为557.6万美元 而GPT-4o等模型的训练成本 约为1亿美元 公开报道显示 此次新版V3模型 参数量为6850亿 借鉴了DeepSeek-R1模型 训练过程中所使用的强化学习技术 大幅提高了在推理类任务上的表现水平 在代码、数学、推理等 多个方面的能力 新版V3模型得到显著提升 其中代码能力追平 美国Anthropic公司的模型Claude 3.7 动图展示了一个由模型生成的演示多个小球在指定空间范围内运动的p5.js程序，包含若干可以调整重力、摩擦力等参数的滑动按钮，并以赛博朋克风格的HTML呈现。 图源：DeepSeek 《联合早报》报道称 让更多科技博主关注的是 V3-0324模型 可直接在消费级硬件上运行 不需要动辄千瓦级别功耗的数据中心 在社交平台X上 苹果机器学习工程师 Awni Hannun称 其已在512GB M3 Ultra的 Mac Studio上成功部署了 DeepSeek-V3-0324 并且实现了超过20 token/s的速度 2025年2月24日，湖北省襄阳市老年大学授课教师在电脑课上为学员讲解如何使用DeepSeek人工智能应用。 图源：新华社 Awni Hannun表示 这打破了业界 关于人工智能模型能力 与本地化运行或冲突的早前共识 也意味着数据中心 并不是大模型的必要搭配 中文IT技术社区CSDN 一篇文章认为 虽然说 售价74249元起的Mac Studio 并非普通大众级设备 但这一突破意味着 过去依赖多张 Nvidia GPU 高功耗数据中心运行的大模型 如今可以在功耗不到200瓦的 设备上运行 挑战了AI行业 对基础设施需求的传统认知 《联合早报》在文章中认为 这也意味着V3-0324模型的 部署和运营门槛已大大降低 新版V3模型回复亚太峰会相关情况。 即将于4月14日至15日 在香港召开的 世界互联网大会亚太峰会 特别设置了“人工智能大模型”分论坛 围绕人工智能大模型的 通用与专用化发展等议题 邀请企业高管和专家学者 汇聚一堂，贡献创见 共议人工智能大模型 高水平开发与应用的 新理念、新策略 本次亚太峰会 还将面向公众开放部分门票 如有意报名 可通过大会官网在线购票 cn.wicinternet.org ↓↓↓ 持电子门票 即可参加亚太峰会 世界互联网大会期待在香港 与你共话智能未来！ 撰文：李飞、张祖有 排版：李汶键 统筹：李政葳 参考丨环球时报、每日经济新闻、澎湃新闻、观察者网、CSDN、DeepSeek公众号 光明网出品 来源：世界互联网大会 举报/反馈"
    },
    {
      "doc_id": 49792,
      "title": "别让DeepSeek成了造谣者的“白手套”",
      "time": "2024-03-03T00:00:00+00:00",
      "content": "来源：一点财经 今年2月，一位普通股民在雪球论坛看到一张AI问答截图：“某公司已投资AI巨头DeepSeek，股价即将暴涨！” 对于在股市中摸爬滚打、渴望抓住每一个投资机会的股民来说，这无疑是一条极具诱惑的消息。他坚信截图中的内容，并且兴奋地跟风买入，结果次日发现该公司辟谣，股价反而下跌，自己遭受沉重一击。 这样的事情并非个例，从“某公司投资DeepSeek”到“凉山山体滑坡”，AI生成的虚假信息正以病毒式速度扩散，这背后存在一条由黑灰产操控的“AI谣言流水线”。 在股市里，有一种造谣者被称为“黑嘴”。他们发布虚假信息，引诱投资者上钩，通过养粉荐股后的反向操作收割机构或个人。 现在不少领域的“黑嘴”，就将DeepSeek、豆包等AI工具当做“白手套”。他们利用AI技术的短板，制造谣言并将其包装成“权威答案”，再通过算法反哺形成闭环，最终收割流量与利益。 第一批用DeepSeek掘金的人，已经在这上面栽了跟头。 AI沦为造谣者的“嘴替” 很多虚假信息的背后，是造谣者在有组织、有计划地进行AI造谣。 此前在DeepSeek、豆包、文心一言、Kimi等AI工具的问答中，慈星股份、华胜天成、并行科技、诚迈科技等多家公司都被描述为“DeepSeek的投资者”，但事实上这些公司都没有参与投资。 为什么会出现与事实背离的情况？这跟数据投喂有直接关系。 隐藏在网络背后的造谣者，会利用AI批量生产谣言，比如“慈星股份投资了DeepSeek”等等，堪称流水线上的“谎言印刷机”。而且造谣者的“效率”非常高，有人一天就能制造几千篇虚假文章，甚至还出现了一天生成19万篇虚假文章的造假软件。 然后，造谣者会操控成百上千个水军账号，在多个线上平台高频传播这些造谣信息。他们的最终目的，是让AI援引大量的虚假信息，充当自己的嘴替。 所以，很多人就会看到AI工具援引虚假信源，给出了错误答案。本来有些人对谣言是将信将疑，但看到AI给出的答案后坚信不疑，此时就落入了造谣者制造的圈套，从而栽了跟头。有人就因为看到AI回答中有“某某投资品有潜力”等信息，误以为发现了财富密码，结果被割了韭菜。 最可怕的是，造谣者还会将AI给出的回答，再以截图形式继续传播扩散，以诱导欺骗更多人。所以这些AI谣言并非单次传播，而是“谣言—AI回答—更多谣言”的循环。这种自我强化的闭环，让谣言像癌细胞般无限增殖。 据南都大数据研究院不完全统计，2024年搜索热度较高的50个国内AI风险相关舆情案例中，超1/5与AI造谣有关，68%的网民曾因AI生成的“专家解读”“权威数据”而误信谣言。 一名受访者苦笑：“以前不信小道消息，现在连AI都撒谎，我们还能信谁？” AI谣言带来的破坏力是巨大的，且不限于资本市场。 前不久，“广州法院对某汽车品牌L3级自动驾驶追尾事故作出首例判决”的谣言全网传播，就对该品牌的声誉和销售造成打击，损害企业利益。 在发生公共安全事故时，有人故意制造AI谣言扰乱视听。这不仅会干扰救援节奏，还容易引发民众恐慌。当造谣者通过收割流量，社会付出的代价其实是信任的崩塌与秩序的混乱。 AI谣言带来的危害还是全球性的，世界经济论坛发布的《2025年全球风险报告》显示，“错误和虚假信息”是2025年全球面临的五大风险之一，AI的滥用是这种风险的重要推手。 那么，AI究竟是如何沦为造谣者的“嘴替”呢？ AI如何沦为造谣者的“嘴替”？ 虽然AI现在火的发紫，更新换代也非常快，但是仍然存在不少短板。 其中，较为突出的问题就是语料污染与AI幻觉。 AI大模型的训练依赖海量数据，但数据的真实性却无人担保。中国信通院曾做过实验，当在特定论坛连续发布百余条虚假信息后，主流AI大模型对对标问题的回答置信度，就会从百分之十几快速飙升。 前不久，纽约大学的研究团队发表了一项研究，揭示了大语言模型（LLM）在数据训练中的脆弱性。他们发现，即使是极少量的虚假信息，只需占训练数据的0.001%，就能导致整个模型出现重大错误，而这个过程的成本极其低廉，仅花费了5美元。 这就像在水库中注入几滴毒药，就能让水库里的每一滴水都带着谎言的味道，信息体系都会被破坏，堪称污染AI的“精神投毒”。 这其实暴露了AI的致命缺陷：它很难区分“热门帖子”和“真实信息”，只认数据权重。它像一面诚实的镜子，但映射的可能是被篡改的世界。 有的AI为了完成逻辑自洽，甚至还会胡编乱造。 某AI工具就根据“80后死亡率5.2%”的虚假语料，输出“每20个80后就有1人死亡”的结论。这种“一本正经地胡说八道”，源于AI大语言模型在编造它认为真实存在甚至看起来合理的信息。它追求的是逻辑自洽，而非事实正确，这也被称为“AI幻觉”。 看来在“开局一张图，剩下全靠编”这件事上，AI比人类还擅长。 技术是否有罪本身是个有争议的话题，但人性的贪婪一定是AI谣言的罪魁祸首。 传统造谣需要雇佣写手，而AI将成本压缩至近乎为零且效率极高，利益极为丰厚。2024年南昌警方查处某MCN机构，其负责人王某某通过AI工具每日生成虚假文章4000-7000篇，内容涵盖“某公司暴雷”“某地灾情”等，最高峰的时候每天能生成4000-7000篇，每天收入超1万元。 某黑产从业者声称：“用AI造谣就像开印钞机，团队3个人一个月能赚50万。”更讽刺的是，他们甚至开发了“谣言KPI系统”：每篇假新闻根据传播量奖励造谣者，形成“多劳多得”的激励机制。 在利益的趋势和AI的加持下，造谣似乎从“作坊式的小打小闹”进化成“工业化生产”。 尽管《互联网信息服务深度合成管理规定》要求标注AI内容，但一些AI工具和平台在这方面仍有所欠缺。有些造谣团伙发布AI生成的虚假信息时，某平台仅弹出“请遵守法律法规”的提示，点击“确认”后仍可正常发布。 当越来越多的人，被卷入这场AI造谣形成的虚假信息漩涡，单纯谴责技术已无济于事。唯有技术防御、平台责任与法律制裁三管齐下，才能斩断这条“谎言流水线”。 真相与谣言，如何对决？ 首先，数据源引用和AI检测是必须要重视的。 要减小谣言发生的概率，AI工具就要严格检测数据的来源和真实性。据悉，豆包的数据源主要依赖自有业务数据，占比50%-60%；外采数据占比为15%-20%。由于质量不确定性，豆包在投喂合成数据时较为审慎。 另外，豆包也公开强调“不使用任何其他模型数据”，这也是确保数据来源的独立性、可靠性、可控性。 用“魔法打败魔法”，即用AI检测AI生成的内容，也不失为一种有效的控制谣言的办法。 国内外已有多个团队，正在投入开发AI生成内容检测技术。比如，腾讯混元安全团队朱雀实验室研发了一款AI生成图片检测系统，通过AI模型来捕捉真实图片与AI生图之间的各类差异，最终测试检出率达95%以上。 国外的Meta创建了一个系统，可以在AI生成的音频片段中嵌入名为“水印”的隐藏信号，有助于在网络上检测AI生成的内容。 未来，DeepSeek、豆包、文心一言、Kimi等AI工具，还是要通过AI技术比如自然语言处理（NLP）技术，分析数据的语义、逻辑结构，识别文本中的矛盾、不合理表述，尽量避免数据投喂中涌入虚假信息。 其次，内容平台作为信息传播的重要渠道，要担负起“信息守门人”的责任。 抖音、微博、快手、小红书等平台，已经开始强制添加“本内容由AI生成”的水印，转发时保留标识。今日头条在谣言治理上，着重建设了三个方面的能力，包括谣言库、权威信源库以及专业审核团队。 另外，咱们用户自己也要学会辨别虚假信息，加强防范意识。 对于AI给出的回答，我们不要全盘接收，而是要追问具体细节，让AI的回答更具可信度，从而判断回答是否存在幻觉‌，比如当AI声称“某股票将暴涨”时，要进一步追问“数据来源有哪些”。 另外，交叉验证信息也是一个有效的方法，也就是要通过多种渠道验证答案的准确性。此前有“某地地震预警”的AI谣言引发恐慌，但有网民通过对比气象局、地震台官网数据，迅速识破虚假信息。‌ 最后，相关法律也要跟上。 《生成式人工智能服务管理暂行办法》已经要求数据来源合法化，并且明确了“不得生成虚假有害信息”的红线，但是当前法律法规对“AI投喂”的问题仍然存在空白，需要进一步优化。具体而言，法律需要在“投喂者如何打造语料”“语料的真实性”“投喂的目的”等环节上，进行相关管制。 结语 对于大众而言，AI应是“真相守护者”，而非“谎言扩音器”。当技术沦为贪婪的帮凶，我们需要的不仅是更聪明的AI，而是更清醒的人性。 从语料净化，到平台和法律的同步整治，这场“AI打假”必须要打赢。AI工具、内容平台与监管者要合力构建“共治防火墙”，让谣言困在笼子里。 这样一来，AI才能真正成为照亮真相的火炬，而非造谣者的“白手套”。 举报/反馈"
    },
    {
      "doc_id": 49795,
      "title": "R2模型呼之欲出!“卷王”DeepSeek继续给巨头上压力",
      "time": "2024-02-28T00:00:00+00:00",
      "content": "DeepSeek-R1的热度尚未消散，DeepSeek-R2就要来了？ 日前报道称，三位知情人士透露，原计划今年5月发布的DeepSeek-R2模型，正在加速开发，或将提前发布，新模型有望可以生成更好的代码，并且使用英语之外的语言进行推理。对此，DeepSeek母公司幻方量化回应称，以官方消息为准。 考虑到DeepSeek成立于2023年7月17日，至今不满两年时间，已开发出了涵盖编程、数学推理、大语言、多模态、对话等不同场景的多个模型。今年5月前推出R2模型，属于DeepSeek大模型的正常更新频率。从R1模型到R2模型，DeepSeek正在改变AI行业。 巨头惊慌失措，R1模型创下奇迹 2023年3月OpenAI发布GPT-4后，整个AI行业不但没有因这款大模型的到来更加活跃，反而显得有些沉寂。哪怕后续OpenAI接连推出了GPT-4o、o1、Sora等大模型，其他企业也纷纷推出了各种大语言、视频生成、多模态模型，却未能再现GPT-3到GPT-4的突破性进展。 直到DeepSeek-R1的到来，仿佛为AI行业注入了活力，让各行各业都积极拥抱AI和R1模型。R1模型的能力得到证实后，国内手机、电视、PC等行业大量企业纷纷为旗下的产品接入了R1模型。 （图源：DeepSeek） 以手机行业为例，华为、荣耀、OPPO、vivo率先官宣，为智能助手接入R1模型，小米略作犹豫后也选择跟进，为超级小爱接入了R1模型。日前著名数码博主@i冰宇宙爆料称，三星也在积极推进为国行版机型接入R1模型的工作。 不仅如此，腾讯、百度、360等互联网企业，虽已组建AI团队，开发出了自己的大模型，但依然选择为旗下的AI工具接入R1模型。可见，就连其他AI企业，也承认了R1模型在某些领域领先自己。 更关键的是，R1模型诞生之前AI工具虽以免费使用为主，可不乏收费服务的平台，例如ChatGPT和文心一言。OpenAI为了实现盈利，甚至放弃了开源模式，从OpenAI变成「CloseAI」，百度更是闭源方案的拥趸。 然而在R1模型的冲击下，这两家企业也改变了原有路线。百度宣布文心一言将从4月1日起免费为用户提供服务，并于6月30日正式开源。OpenAI则承诺，免费版ChatGPT在标准模式下可无限制使用GPT-5，其CEO山姆·奥特曼还在X平台表示，将打造开源项目，并向网友们征集意见，究竟打造仍需在GPU上运行的o3-mini模型，还是能力强大的端侧模型。 （图源：豆包AI生成） DeepSeek还通过R1模型证明了通过知识蒸馏、混合并行策略、动态稀疏训练、即时编译、层次化稀疏注意力等技术，大幅压缩AI大模型训练成本的可能性。过去AI企业训练大模型，不但需要用到规模庞大的算力集群，还需要大量数据，OpenAI甚至招聘人员编写数据供大模型训练所用。马斯克旗下的xAI为训练Grok 3模型，不惜搭建了一个具有10万张GPU的全球最大算力集群。 长此以往，AI未必不会变成互联网巨头比拼财力的游戏，最终因数据量的不足进展缓慢。DeepSeek之所以能够给AI行业带来巨大的冲击，能力强、训练成本低、开源三大因素缺一不可。尤其是采用指令集框架PTX和CUDA、ROCm、OpenCL等底层指令都封装为统一接口的特性，让其不再依赖NVIDIA GPU，能够更加自由的部署在各种设备上。 在R1撬动了AI行业的地基后，DeepSeek并未止步不前，如今R2模型即将到来，或将接力R1模型，进一步改变AI行业。 延续低成本、高性能传统，R2模型拉满期待值 R1模型逻辑推理能力不输字节跳动、阿里巴巴、月之暗面等企业花高成本训练出的大模型，对标行业领导者OpenAI开发的o1模型。但OpenAI不只有o1模型，ChatGPT专业版会员已能够使用更强的o1 Pro和o3模型。在R1模型追上o1模型后，R2模型自然要向o3模型发起挑战。 在动态稀疏架构、量化知识蒸馏、混合专家（MoE）架构与多头潜在注意力（MLA）等技术的加持下，DeepSeek训练R2模型的成本有望进一步降低。开发训练数据与模型参数的共适应系统，则可动态调整数据与模型参数的协同关系，提升机器学习系统的效率、泛化性和适应性。 最近几天DeepSeek每天都会公开一批开源代码库，其公布的DeepGEMM采用FP8通用矩阵乘法，支持稠密和MoE模型，仅300行代码即可实现超越专家优化的内核，能够降低AI大模型的推理成本，该技术自然也要被用于R2模型。 （图源：豆包AI生成） R1模型的论文中提到，RL（强化学习）数据的增加，不仅可以提升AI大模型面对复杂任务时的推理能力，还会自发地出现一些复杂行为能力，比如反思和探索不同方法。现阶段R1模型所拥有的RL数据较少，未来版本将会大幅增加。 综合来看，R2模型与R1模型相同，基于V3底座，对标OpenAI o3模型，以常规升级为主。在更多RL数据的支持下，R2模型有望提高推理能力和响应速度，并依靠「反思」能力，生成更准确的推理结果。 未来将诞生的V4，对标OpenAI计划在今年中期发布的GPT-4.5。基于V4底座+RL开发的R3模型，竞争对手则是OpenAI下一代模型GPT-5。 除了成本和能力方面的提升，R2模型要将把开源理念推向新高度。从o1模型开始，OpenAI强化了闭源理念，不但大模型不再开放，就连思维链也被取消，甚至警告用户使用提示词诱导模型输出完整思维链会被限制账号，GPT-4.5将成为OpenAI最后一个独立发布的基座模型。GPT-5将进入混合模型时代，让AI大模型彻底变成「黑盒」模式。 （图源：豆包AI生成） DeepSeek坚持开源理念，允许其他企业或个人部署、使用、修改、分发R2模型，持续推动AI行业的发展。360 CEO周鸿祎曾表示，没有开源就没有 Linux、没有互联网，甚至包括我们自己借助了开源技术才能发展至今。闭源固然有机会获取更多营收，但开源才能加快行业向前迈进。 从GPT-4发布以来，AI大模型虽不断进步，却不再有划时代的改变。R1模型依靠低成本、高性能的特性，一定程度改变了AI行业。R2难以复刻R1的盛况，但推理能力方面会有大幅提升，给予其他AI企业更大压力。 DeepSeek成「卷王」，友商被卷到头疼？ DeepSeek-V1和R1模型发布时间间隔仅13个月，R1模型和R2模型之间间隔可能仅有三四个月，堪称「终极卷王」。百度、腾讯、360等企业可以像之前接入R1模型一样，再次接入R2模型，但头部互联网企业需要打造出自己的AI大模型，而不是指望着DeepSeek的开源模型去升级AI工具的能力。 就小雷的体验而言，绝大多数国产AI大模型在深度思考方面表现不如R1模型，仅有少数能够在部分场景下与R1模型平分秋色。将要到来的R2模型，给了AI企业更多压力，他们需要在R2模型上线前，强化自己大模型的能力，避免被DeepSeek甩在身后。 借助DeepSeek开源模型提高AI工具的能力只是权宜之计，百度、腾讯、360从未放弃AI大模型的开发工作，例如百度的文心4.5已在路上。 （图源：豆包AI生成） 作为用户，我们自然更倾向于AI工具能够同时接入多个模型，方便自己选择最好用的模型。尤其是头部AI企业，拥有更庞大的算力规模，接入R1模型后执行推理任务时响应更流畅，体验优于DeepSeek官网或App。 DeepSeek不仅仅带来了能力出众的R1模型，所采用的多种低成本方案，还给其他AI企业指明了方向，通过知识蒸馏和混合精度等技术，任何AI公司都可以实现低成本训练大模型，至于大模型的能力如何，则要看研发人员的实力。 以开源为基调的DeepSeek将在AI行业起到鲶鱼效应，督促每一家AI企业加快新模型的研发工作，并不断探索新方向。"
    },
    {
      "doc_id": 49799,
      "title": "DeepSeek进军文生图领域:发布多模态模型JanusPro",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "来源：观察者网 【#DeepSeek进军文生图领域#：发布多模态模型#JanusPro#】北京时间1月28日凌晨，近期爆红的国产大模型DeepSeek在GitHub平台发布了Janus-Pro多模态大模型，进军文生图领域。 DeepSeek方面表示，该款大模型是2024年11月13日发布的JanusFlow大模型的高级版本。相比前一代模型，Janus-Pro优化了训练策略、扩展了训练数据，模型也更大。通过这些改进，Janus-Pro 在多模态理解和文本到图像的指令跟踪功能方面都取得了重大进步，同时还增强了文本到图像生成的稳定性。 根据DeepSeek发布的测试结果，Janus-Pro在 GenEval 和 DPG-Bench 基准测试中击败了 Stable Diffusion 和 OpenAI 的 DALL-E 3。目前，Janus系列的4款模型已经开源。（新京报） 举报/反馈"
    },
    {
      "doc_id": 49800,
      "title": "进军文生图,DeepSeek发布多模态模型Janus-Pro",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "北京时间1月28日凌晨，近期爆红的国产大模型DeepSeek在GitHub平台发布了Janus-Pro多模态大模型，进军文生图领域。 DeepSeek方面表示，该款大模型是2024年11月13日发布的JanusFlow大模型的高级版本。相比前一代模型，Janus-Pro优化了训练策略、扩展了训练数据，模型也更大。通过这些改进，Janus-Pro 在多模态理解和文本到图像的指令跟踪功能方面都取得了重大进步，同时还增强了文本到图像生成的稳定性。 根据DeepSeek发布的测试结果，Janus-Pro在 GenEval 和 DPG-Bench 基准测试中击败了 Stable Diffusion 和 OpenAI 的 DALL-E 3。目前，Janus系列的4款模型已经开源。 （来源：新京报） 更多精彩资讯请在应用市场下载“极目新闻”客户端，未经授权请勿转载，欢迎提供新闻线索，一经采纳即付报酬。 举报/反馈"
    },
    {
      "doc_id": 49801,
      "title": "DeepSeek重塑AI行业格局:技术突破、产业变革与未来图景",
      "time": "2024-03-04T00:00:00+00:00",
      "content": "2025年，随着DeepSeek大模型的全面落地，人工智能行业迎来结构性变革。作为基于Transformer架构的突破性技术，DeepSeek凭借其注意力机制与动态数学建模能力，不仅在算法效率、应用场景拓展上实现跃升，更推动AI技术从“工具辅助”向“认知协同”的范式转变。本文从行业现状重构、技术价值释放、未来挑战与机遇三大维度展开分析，探讨其引发的连锁反应与长期影响。 一、行业现状重构：DeepSeek驱动的技术革命 1.算法效率的颠覆性突破 DeepSeek通过“自我对抗式强化学习”重构算法研发路径。其摒弃传统依赖海量标注数据的训练模式，转而采用“辩论式训练”机制，使模型在推理过程中自主发现最优路径。例如，在数学任务中，DeepSeek对微积分问题的解题准确率高达98.7%，解题路径生成效率较传统模型提升300%。这种技术突破使得AI研发成本降低60%以上，推动中小型企业加速入局AI赛道。 2. 行业应用边界的极速扩张 DeepSeek的多模态能力推动AI渗透至传统技术禁区。在医疗领域，其通过动态数学建模分析数十万份癌症病例，成功识别出7种罕见基因突变模式，为个性化治疗方案设计提供新方向。法律行业则借助其自然语言处理能力，将合同审查时间从平均8小时压缩至20分钟，错误率从12%降至1.5%。这种跨领域渗透使AI应用场景覆盖率从2023年的38%跃升至2025年的72%。 3.技术扩散引发的市场格局重塑 DeepSeek的开源特性导致行业竞争焦点转移。头部企业如特斯拉虽持续优化人形机器人灵巧手技术（如22自由度机械手研发），但中小团队通过DeepSeek快速实现场景化创新。例如，武汉大学团队基于DeepSeek开发的“天问”机器人，其灵巧手成本控制在100美元以内，性能却达到工业级三爪卡盘的85%，正在咖啡零售、商超理货等场景快速商业化。这种“技术民主化”趋势正在瓦解传统巨头的垄断格局。 二、技术价值释放：DeepSeek的核心作用 1. 认知外骨骼：人类能力增强范式 DeepSeek构建了“人机协同认知网络”。在战略决策领域，其通过多路径推理构建概率化方程，将企业市场预测误差率从传统模型的15%压缩至3.8%。某跨国集团使用DeepSeek分析全球23国消费数据后，成功预判东南亚新兴市场增长拐点，较行业平均提前9个月完成产能布局。这种能力增强使人类决策者可将70%的精力转向创造性工作。 2. 产业自动化进程的催化剂 DeepSeek推动自动化向“认知密集型”领域渗透。客服行业中，其通过语义理解与情感分析技术，将复杂问题解决率从45%提升至82%，同时减少人工客服需求40%。在数据录入领域，DeepSeek的图像识别与OCR技术使医疗票据处理效率提升15倍，错误率低于0.01%，直接导致初级数据处理岗位需求下降62%。这种自动化升级每年为全球企业节约运营成本超1.2万亿美元。 3. 技术伦理治理的新挑战 DeepSeek的“黑箱化”特性引发治理难题。尽管无锡市政务系统通过“双结果显示”机制提升透明度，但模型决策逻辑的不可解释性仍导致30%用户对AI建议持怀疑态度。在医疗诊断场景中，DeepSeek虽能识别罕见病症，但其建议采纳率仅为68%，主要源于医生对AI推理过程的不信任。这要求建立新型人机信任机制与技术问责框架。 三、未来展望：挑战与机遇并存的进化路径 1. 算法革命的下一站：量子化推理架构 DeepSeek研发团队正探索量子计算与动态数学建模的融合。通过将复杂问题分解为量子比特态空间，模型推理速度有望再提升1000倍。在药物研发领域，这种架构可使分子模拟效率提升至传统方法的10^6倍，或将新药研发周期从12年缩短至3年以内。但量子化架构对算力的需求将激增，可能引发新一轮基础设施竞赛。 2. 人机共生生态的构建路径 未来需建立“能力互补型”协作框架。DeepSeek的“认知外骨骼”定位将更加清晰：在数据处理、模式识别等确定性领域承担主要任务，而人类聚焦价值判断与伦理决策。例如，法律系统中AI负责法条检索与案例匹配，法官则专注意见裁量与情理平衡。这种分工可使司法效率提升50%，同时降低判决争议率12%。 3. 技术普惠与风险防控的平衡术 DeepSeek的扩散需建立“梯度赋能”机制。通过区域性算力共享平台（如西部数据中心），欠发达地区可获取相当于一线城市60%的模型性能，成本仅为自建算力的30%。同时，需构建“AI防火墙”系统：对核心基础设施采用物理隔离，对民用场景实施联邦学习，确保技术红利共享与数据安全的动态平衡。 DeepSeek的问世标志着AI发展进入“质变临界点”。其带来的不仅是算法效率的量级提升，更是人类认知范式与产业形态的深层重构。然而，技术黑箱化、伦理失范风险、区域发展失衡等问题，仍需通过制度创新与技术治理协同破解。未来十年，AI行业将呈现“双螺旋进化”特征：一方面持续突破算力与算法极限，另一方面加速构建人机共生新文明。唯有在效率追求与人文关怀间找到平衡点，方能真正释放DeepSeek的变革潜力，引领智能时代走向可持续未来。"
    },
    {
      "doc_id": 49802,
      "title": "豆包还能“反超”吗?",
      "time": "2024-03-02T00:00:00+00:00",
      "content": "撰文 | 程书书 编辑 | 李信马 题图 | 豆包AI DeepSeek的火爆有目共睹，自春节假期期间在社交媒体上引发广泛讨论，当下正以迅猛之势向各个行业渗透。随着“XXX接入DeepSeek”的消息如雪花般飞来，接入DeepSeek似乎成为当下拥抱AI的“先进”标志。 随着腾讯、百度、阿里、字节等大模型第一梯队的大厂们都相继宣布接入DeepSeek，“AI六小虎”中的阶跃星辰和MiniMax等也都做出了同样的选择。 但有意思的是，腾讯、百度、阿里、字节等接入DeepSeek的程度不同。 对比来看，腾讯、百度接入DeepSeek最“深”。除了业务侧产品（像腾讯的微信、腾讯文档、QQ浏览器，百度的百度搜索、百度智能云旗下应用产品等），自研的AI助手腾讯元宝、文小言（原文心一言）也都接入了DeepSeek-R1。 阿里则是业务侧产品接入了DeepSeek，像钉钉支持用户使用DeepSeek 系列模型创建钉钉AI助理、定制智能多维表格，阿里云百炼平台上线全尺寸DeepSeek模型，以及1688宣布将基于DeepSeek开发生意大模型，但给自研的大模型产品通义千问还是留有一部分独立空间。 而字节对于DeepSeek的接入相对最“浅”，仅有火山引擎及其旗下产品和飞书官宣上线了DeepSeek系列模型。但一般来说，云平台通常会提供多种大模型供用户选择和使用，以满足不同的应用需求。火山引擎旗下的大模型服务平台火山方舟在此前，也上架了除自家豆包外的其他大模型，像智谱AI的GLM 模型、月之暗面的Moonshot等。至于飞书，准确来说，是飞书的多维表格中接入了 DeepSeek R1。 接入的最“浅”，是否意味着字节最为“自信”？认为其自研模型能达到或是赶超DeepSeek的水平？ 2 月 13 日，字节举办了新一期的 All Hands 全员会上，关于DeepSeek的现象级热度，字节 CEO 梁汝波反思的同时，强调了2025年的重点目标：追求 “智能” 上限，关注关键技术，字节的应对策略透露出战略级的调整。 前几天又有消息称，前谷歌大牛吴永辉加入字节跳动担任大模型团队Seed基础研究负责人，进一步释放其坚持自研大模型的信号，未来，字节AI能否又后来居上呢？ 01. 迟到的入场与资本驱动的反超 字节有这样的发展思路其实并不令人意外。毕竟，其旗下的豆包大模型在过去一年里已经上演了一场“后来者居上”的逆袭剧情。 时间回溯到2022年11月，ChatGPT发布后在全球掀起了一场AI浪潮，国产大模型也随之迎来了爆发期。2023年，众多大厂和创新型企业纷纷亮出自研大模型产品，比如百度的文心、阿里的通义千问1.0、腾讯的混元、360的智脑、华为的盘古、科大讯飞的星火、商汤的日日新、百川大模型，以及智谱AI的GLM等，一时间群雄逐鹿，好不热闹。 然而，直到2023年1月，字节的大模型研发团队才正式成立。 反应过来的字节，在7个月后，推出自研的“云雀”大模型（后更名为“豆包”），同时还推出了一款多模态大模型——BuboGPT。在之后的大模型“价格战”中，更是打出响亮的一枪。 进入2024年，为了在大模型追逐战里抢占先机，字节一方面四处挖人：先后挖来了零一万物原预训练负责人黄文灏、Google 原 VideoPoet 项目负责人蒋路等。10 月份，还被曝出以八位数年薪的豪爽手笔挖走了阿里通义千问技术负责人周畅。 另一方面，字节倾注全系流量推广豆包APP。2024年3月18日，抖音巨量广告发布公告，限制AIGC软件投流，从4月2日到年末，非字节系产品无人能使用抖音、头条的巨大流量池。而根据AppGrowing的数据显示，豆包智能助手在去年4月、5月的投放金额接近1800万元，到6月上旬，这一数字飙升至1.24亿元。在字节这种不计成本的投入下，成功让豆包成了月活7000万的国内头部AI APP。 如果以往的经验，这一赛道上，同行想要追赶上豆包恐怕是难上加难。 据浙商证券研报显示，字节在 AI 领域的投入堪称大手笔，2024 年的资本开支高达 800 亿元，这一数字接近百度、阿里、腾讯三家总和（约 1000 亿元），研发投入显著领先于同行竞争对手。有媒体报道称，字节计划在2025年投入超1500亿元用于资本支出。 另一方面，字节跳动早些年在移动互联网时代积累下的成功 To C 经验，如今也转化为了其独特的差异化优势。相较于竞争对手，字节拥有更为丰沛海量的流量资源，能够为落地应用的快速起量提供强有力的支撑保障。 据不完全统计，字节在2024年发布了接近20款AI应用，基本覆盖了图像、语音、音乐、视频、3D等主流模态和场景。这种“饱和式”打法，让字节成为AI领域“军火库”最齐全的科技公司之一。 02. DeepSeek重新定义游戏规则 然而，DeepSeek的出现，却改变了行业以往的规则。 首先，C端发生了肉眼可见的变化，随着DeepSeek接连发布V3模型和R1模型后，豆包在过去一年建立的DAU优势，瞬间被瓦解。据QuestMobile数据显示，DeepSeek在1月28日的日活跃用户数就首次超越豆包，2月1日突破3000万大关。且快速增长的用户日活还没“花钱”。用影视圈的说法是，全是“自来水”。 让DeepSeek从豆包、Kimi等AI智能助手App中脱颖而出的，除了其对指令的理解以及答案的更为准确外，还有它出色的思维链（Long-CoT）能力。 不同于以往的AI大多只给结果，DeepSeek模型能够展示思考过程，包括问题复述、回顾反思、知识调用（结论的来源和引用的网站等关键信息）与公式化等环节等。透明的思考路径既为用户提供了深入了解模型推理细节的机会，也能够增强用户对 AI 系统的信任。 而自1月份开始，阿里、科大讯飞、百川智能、月之暗面等AI企业，也开始密集为旗下模型升级了深度思考能力。 当然，除了思维链模型，DeepSeek身上还有开源模式和低算力需求的优势。前者降低了进军AI领域的技术门槛，后者在保持高准确性的同时显著降低了内存占用和计算开销。这也使得DeepSeek在to B端更有性价比。 DeepSeek技术上突破所带来的优势，打破了此前国内市场的竞争格局与规则，科技大厂们似乎又回到同一起跑线。 面对新的游戏规则，相比百度、阿里、腾讯果断接入DeepSeek的态度，字节的选择确实更难。也选择深度拥抱DeepSeek，那么此前建立的优势可能会功亏一篑；如若不，就意味着要和DeepSeek“硬刚”。 字节当下所展现出的态度，似乎更像是选择 “硬碰硬” 式的应对。在其全员会的前两天，豆包大模型团队还提出了全新的稀疏模型架构UltraMem，推理速度较MoE架构提升2~6倍，推理成本最高可降低83%，看起来颇有剑指 DeepSeek 核心优势的意图。 长远来看，字节未必没有胜算，上文的竞争规律在新一轮的赛程中同样适用。在技术侧的迭代和升级速度上“持久战”，以及做好大模型技术与各类应用、场景的深度融合工作。 字节过去一年在应用端已经打下一定基础，在技术侧方面，当下 “智能上限” 更高的 DeepSeek，同样得直面技术迭代挑战。 不过就当下情况来看，字节似乎处于比较被动的境地。通过接入DeepSeek，腾讯已经在C端用户的争夺上展现出了赶超势头。从2月22日开始，腾讯旗下的AI应用“腾讯元宝”，就超越了豆包，跃居中国区苹果应用商店免费APP下载排行榜第二位，并一直维持至今。 阿里也在DeepSeek带来的新局面下，开始加大AI技术方面的投入。阿里集团CEO吴泳铭在2月20日晚财报电话会上称：“未来三年在云和AI的基础设施投入预计将超越过去十年的总和。” 扩大到全球范围，在DeepSeek的刺激下，更多科技公司开始提速。如果不能尽快推出新的可以媲美DeepSeek的自研推理大模型，字节接下来或许将会更加的被动。 本文源自：DoNews 举报/反馈"
    },
    {
      "doc_id": 49803,
      "title": "DeepSeek,开始搅动医疗业了",
      "time": "2024-02-28T00:00:00+00:00",
      "content": "来源：21世纪经济报道 作 者丨唐唯珂 编 辑丨张伟贤 图 源丨AI 今年以来，\"AI+医疗\"的浪潮奔涌。不过，人工智能医疗绝非新鲜事，其在过往发展中始终在技术理想主义与商业现实主义间寻找平衡点。 商业化落地的艰难、数据标准化采集难，漫长的产品研发周期以及巨大的投入，一直是行业痛点，资本也早已经历狂欢到泡沫、死亡到信仰的跌宕起伏。2025年开年，以DeepSeek为代表的通用人工智能技术在逻辑推理领域的惊艳表现，再次搅动AI+医疗。 CIC灼识咨询董事总经理刘立鹤对21世纪经济报道记者表示， “Deepseek的颠覆性不在于单一技术指标超越GPT-4，而在于将大模型从技术能力展示推向行业工作流重构，例如在金融、医疗领域的深入应用。” 智药局发布的数据显示，根据不完全统计，目前全国已有超过30家药企、医院、IVD公司、互联网医疗、智慧医疗、中医医疗等方面机构宣布，正将DeepSeek技术深度嵌入药物研发、临床决策、慢病管理等多个核心场景。 这股在应用端落地的热情也迅速蔓延到了资本市场。今年以来，医疗AI概念股在美股、港股和A股市场均表现强劲、反复活跃，海内外多家相关企业的股价大幅上涨。智慧医疗板块也走出一波上涨行情，AI+辅助诊断、AI+数据服务领域等个股表现亮眼。一个月时间，不少公司股价接近翻倍。 在技术突破、资本加码、政策支持以及需求刚性等多重因素的共同驱动下，目前有观点认为，医疗行业中长期增长逻辑已然清晰。国信证券发布研报称，AI在医药板块的落地或将是2025年全年的投资机会。 但狂欢的背后亦有隐忧。部分涉及相关概念的上市公司的业绩表现实际并不乐观。同时，股东和高管的减持也引发市场关注。此前即有行业人士对21世纪经济报道记者指出，医疗AI概念的想象空间很大，但如果只是单纯接入DeepSeek、与实际业务没太多关联的，多数仍是炒概念。此外，当下数据壁垒仍横亘如天堑，是模型训练亟待突破的瓶颈。 DeepSeek激起的层层涟漪正不断向外扩散，医疗AI的价值也在迎来重估。 重塑底层逻辑 DeepSeek的一个重要影响是给大模型在应用端蓬勃发展提供了空间，尤其是医疗行业。 一方面是DeepSeek低成本高效能，极大地赋能了医疗AI的开发。 在“AI届的拼多多”DeepSeek出现之前，大模型的开发和应用面临高昂的成本和技术门槛。传统的大模型需要大量的算力支持，尤其是在训练和推理阶段，这使得许多企业望而却步。 国泰君安证券研报指出，DeepSeek采用 MoE（混合专家模型）和 MLA（多层次注意力）两大创新架构，通过算法优化显著降低了大模型的训练和推理成本，极大地降低了对硬件算力的需求，颠覆了过去“算力军备竞赛”的发展路径。 其中，对下游企业最重要的影响是推理成本的降低。推理成本是指使用已经训练好的大模型在实际使用中，进行预测或生成响应时所消耗的成本，如计算资源和时间成本。它就像是购买了一件大功率的商品，在使用过程中需要不停地花钱。推理成本的降低使得下游用户通过API接口使用大模型时需要支付的费用，即API调用成本大幅缩减，降幅超90%。这种“平民化”技术路径使医疗企业，不论规模大小，均能以极低成本接入比肩OpenAI的大模型能力。 另一方面是DeepSeek诚意满满的开源策略，有助于构建一个开放、协作、可持续的医疗AI创新生态。 早期性能优越的大模型多为闭源，企业需依赖API调用，无法定制优化，导致医疗场景的细粒度需求（如专科病历生成、罕见病分析）难以满足。兼具性能和经济性的开源大模型DeepSeek出现后，医疗健康公司能够结合医疗专业数据，针对复杂性的垂直场景进行二次开发，从而推动AI技术在医疗行业的商业化落地。毫无疑问，DeepSeek将加速医疗行业的智能化转型。 刘立鹤告诉21世纪经济报道记者：“由于Deepseek采用了开源模型，可以更好地吸引开发者，同时通过私有化部署的高级功能（如行业专属微调工具）盈利，形成生态闭环。” 而医疗行业具备自身独特性，对数据隐私和安全的要求极高，传统不开源模型存在数据外训和云端接入风险，难以满足医疗行业的合规要求。DeepSeek通过开源和支持本地化部署的方式，医疗数据无需上传至云端，全程在医院或企业内部封闭训练。 “之前医疗行业一般都是用第三方的大语言模型来投喂自己的数据，这次是直接自己上手操作，自主性和便利性都大大加强了。”一位医疗行业资深从业者说。 回归长期价值锚点 医疗AI长期发展的核心价值在于通过技术突破与模式创新，实现普惠、精准、可持续的医疗服务升级。 许多医疗AI企业的技术人员都表示，DeepSeek作为基座模型，其医疗垂类模型的建构仍需本地化部署，但经过“微调”后，其在推理和决策场景下的出色表现，的确能为自家产品在处理复杂医疗数据或支持精准决策等方面提供更强大的支持。 随着人口老龄化和慢性病高发，医疗资源的紧缺问题日益突出。而医疗AI可以突破时空限制与人力瓶颈，将优质医疗能力转化为可标准化复制的数字服务。例如在基层或偏远地区，AI大模型作为医生的智能助手，能够整合患者的症状、病史、检查结果等多方面数据，利用优质医疗资源训练出的推理能力进行综合分析，辅助基层医生决策。 不止是常见病，DeepSeek等大模型也走进了三甲医院的重症监护室、急诊科、儿科等。近日，深圳大学附属华南医院、昆山市第一人民医院、陆军军医大学第二附属医院等纷纷宣布已经部署DeepSeek模型；接入DeepSeek-R1(671B)后的医学模型Med-Go也已在上海东方医院等临床机构应用，并在ICU环境下验证了能力。 AI与诊断以外的医疗流程深度融合重点在，用好DeepSeek等AI工具有助于提高医疗质量和患者体验，优化医疗资源的运营分配。刘立鹤对21世纪经济报道记者表示，“AI技术可以应用于药物开发、药品生产流程管理、辅助诊断、慢病管理等医疗领域，包括研发、生产、销售、诊断、治疗、康复的全流程，极大地提升流程效率。” 中信建投证券医药行业首席分析师贺菊颖也表示，AI医疗在提升医疗器械功能、检查检验结果解读、辅助临床医生决策、健康管理等多个领域的应用价值较大，是医疗企业和医院必须重视的创新方向和竞争趋势。 AI在医疗领域的另一个重要突破方向是预测性AI，即利用数据来评估患者未来发生疾病或临床事件的风险，而不仅仅是识别当前疾病。Apple Heart Study 的共同首席研究员、斯坦福大学医学教授明图·图拉基亚博士（Dr. Mintu Turakhia）认为，未来，人工智能的重点将从诊断疾病转向预测健康风险，从而推动主动性和预防性医疗的发展。 有行业内人士推测，未来，预测性AI在临床应用中可能有一个方向是，通过AI+可穿戴设备，监测生命体征数据，建立长期健康模型，在临床事件发生前就识别健康风险，进而提前采取预防措施，降低急诊和住院率。据悉，在AI帮助下，阿尔茨海默病的五年预测准确率已达80%以上。 医疗AI要想重塑医疗研究、诊疗和健康管理的全链条，数据是重中之重。 财通证券报告称，自从DeepSeek大模型开源后，AI或已进入平权时代。这个时代，大部分AI医疗最有价值的不是算力、甚至不是算法，而是可靠的、高质量的数据。在医疗行业，这些数据不仅可以优化现有的诊断与治疗流程，还能为未来的创新提供必要的支撑。 在当前的数据应用中，医疗企业绕不开的难点还是围绕合规性、标准化和数据质量等展开。尽管国内已有数据交易所，但尚未形成规范的医疗数据交易市场。许多企业开始尝试数据交易，并在政策指导下挂牌数据资产，但效果和获取程度尚不明确。有专家指出，国内医疗信息数据高度分散在不同机构，而且不同医疗机构的信息系统、格式标准各不相同，导致数据难以互联互通。 想要将这些分散的数据整合到大型综合数据库，技术难度大且涉及多方利益协调，困难重重。此外，如何在保障不侵犯患者隐私的前提下安全使用数据，也是实际运作中会遇到的挑战。 此外，提高医疗数据质量需要设定评判标准，确保数据的准确性、完整性和时效性并根据不同机构的需求定制化处理，这是未来所有的从业企业都将面临的挑战。 细分赛道成色几何？ 在本轮行情中，互联网医疗的巨头们涨幅凶猛。 “相较于传统药企，互联网医疗企业可以更快速的享受到DeepSeek出现而带来的红利，例如国内全病程管理平台微脉，其管理智能应用CareAI已经全面接入DeepSeek V3和R1模型能力，实现DeepSeek强大的逻辑推理能力与CareAI的智能体深度集成。”刘立鹤对21世纪经济报道记者说。 2月3日，英伟达欧洲、中东和非洲地区医疗保健与生命科学主管Eva-Maria Hempe发表文章，指出2025年AI将在三个领域对医疗产生变革性影响：改善患者医疗过程的智能代理；能够执行复杂手术任务的机器人；加速药物研发的生成式AI工具。 “AI+医疗的想象力广阔，但是AI+检测诊断最成熟，应用逻辑相对更清晰。”华南某医疗器械公司负责人对21世纪经济报道记者表示。 四川一家三级甲等医院的影像科主任公开发文称：“AI技术能够在短时间内阅读成千上万张影像资料，并能识别出其中的细微差异，这是仅凭手工和肉眼无法比拟的。” 人称“女版巴菲特”的凯西·伍德在近期发布的《Big Ideas 2025》报告中预测，AI将使DNA等生物信息的读取和写入成本分别降低99%和99.9%，使癌症筛查的效率提高20倍，并且将市场规模扩大10倍。 此外，AI制药也是被许多知名投资人寄予厚望的细分应用赛道。 《Big Ideas 2025》报告认为，AI驱动的新药研发可将周期从13年缩短至8年；AI将使药物开发成本降低4倍，并将研发投入的回报提高5倍；AI药物的商业价值将比标准药物高20倍，比同类最佳的精准药物高2.4倍。 山东大学淄博生物医药研究院在官方微信公众号中表示，DeepSeek不仅仅是一个工具，它代表了医药行业从“试错法”向“预测科学”的转变。通过深度学习模型，DeepSeek能模拟药物与生物分子的相互作用，预测药物的活性、毒性和代谢途径。这种预测能力不仅提高了研发的成功率，还为药物的个性化治疗提供了可能。 尽管如此，多位行业人士也对21世纪经济报道记者直言，AI药物研发是难啃的骨头，暂时难以取得突破性进展。随着算法迭代和数据积累，AI可能将临床成功率从10%提升至20%~30%，但仍需与传统方法深度融合。AI是工具，而非“颠覆者”，药物开发的核心仍是生物学洞察与临床验证。本轮AI浪潮中，两家AI制药龙头Recursion和Schrodinger股价表现滞后，可见主流资金的顾虑。 复星医药相关人士在接受媒体采访时表示，现在AI比较成熟的是语言模型，是在既定框架下，按照人为规定规则进行演算、知识抓取等。但制药是对未知世界的探索。目前的AI还无法自主思考，很难在这种探索性的新药研发中发挥关键作用。 此外，英矽智能CEO任峰也曾表示，临床试验是AI制药的真正考验。“当药物研发步入临床试验阶段，还未有证据表明AI可以完全地赋能临床研究、缩短临床试验的时间。我认为目前AI还不能有效解决这一阶段的问题。” 总之，医疗AI的落地，离不开具体的场景。2024年11月，国家卫健委等三部门曾发布《卫生健康行业人工智能应用场景参考指引》，从“人工智能+医疗服务管理”、“人工智能+基层公共卫生服务”、“人工智能+健康产业发展”和“人工智能+医学教学科研”四大领域，给出了84个应用场景。随着DeepSeek将AI在应用端蓬勃发展开辟了空间，医疗产业大模型的商业化想象空间也在被进一步打开。2月26日，深圳医保也公布与腾讯合作，全面启用DeepSeek大模型与腾讯混元双AI引擎。 医疗是个庞大的赛道，环节众多。中信证券指出，可以围绕两条主线挖掘AI+医疗受益标的。一是从技术壁垒角度，挖掘具备模型能力、稀缺数据竞争壁垒的企业。二是从商业化落地角度，挖掘B端客户基础扎实，在电子病历临床决策、电子病历、语音识别等领域和场景有成熟产品的企业。 华南一位一级行业投资人向21世纪经济报道记者表示，早期很多投资人对医疗AI并不看好，原因就在于缺乏清晰的盈利模式，很多产品烧了几亿元，数据做得很漂亮，但也只能从科研上赚点碎银，投资回报完全不成正比。还有应用停留在浅层次的问诊业务，无法打通数据和智能化程度的深入变革，缺乏真正的变革性企业和领域的突破。市场目前都认为2025年或将是医疗AI商业化落地的爆发年，对行业来说，价值重塑的节点已经到来。 （实习生孙伟对本文亦有贡献） 举报/反馈"
    },
    {
      "doc_id": 49806,
      "title": "开年大吉,DeepSeek崛起,打破技术追随走向创新引领",
      "time": "2024-02-26T00:00:00+00:00",
      "content": "文｜极光月狐数据研究院 DeepSeek成为了春节期间最炙热的话题之一，成为了继ChatGPT后又一现象级大模型。DeepSeek的出现对国内科技创新起到了振兴的作用，击碎了“AIGC初创企业难超车”的论调，也是以算法突破“算力霸权”的一重大胜利。DeepSeek之所以能够突出重围进入大众视线，主要在于其创新能力。 一、创新引领DeepSeek发展之路，单项能力赶超ChatGPT DeepSeek的发展之路始于“百模大战”，彼时我国10亿参数规模以上的大模型已发布79个（科技部-《中国人工智能大模型地图研究报告》），正在寻找落地的应用场景，由此可见，DeepSeek起步较晚。2024年年初，DeepSeek发布第一版大模型即为百亿级参数大模型，5个月后，发布DeepSeek-V2，逐渐崭露头角：DeepSeek-V2提出了DeepSeekMoE的新型MoE架构，实现了更高的计算效率和更低的计算成本，提出的MLA架构创新将显存占用降至传统MHA架构的5%-13%。2024年年底，DeepSeek发布了千亿级的DeepSeek-V3，其中引入了FP8混合精度训练框架和MTP机制，显著减少计算资源的消耗的同时提升计算效率。2025年开年发布的DeepSeek-R1-zero及DeepSeek-R1使用了监督微调和强化学习的迭代训练方式和GRPO群体相对策略优化算法，降低了内存使用和计算开销，同时获得了强大的推理能力。 从测评结果上看，DeepSeek-R1大模型在多家国内外权威测评机构的综合榜单中名列前茅，仅次于OpenAI、谷歌等拥有极强计算能力的AI巨头。在ChatbotArenaLeaderboard上和中文大模型测评机构SuperClue的综合榜单上位列第四，在OpenCompass的学术榜单中位列第一。只看单一能力，在ChatbotArenaLeaderboard的测评结果中，DeepSeek的数学、指令遵循、多轮对话能力进入前五；在SuperClue的测评结果中，DeepSeek针对中小学数学竞赛的能力登顶，在链式推理能力也较为突出，但与ChatGPT仍有距离。 目前，DeepSeek主要用于C端体验，在B端生态上的合作还在起步中，但实力和名气再加上开源的DeepSeek并不缺少合作伙伴。目前，国内外华为云、百度智能云、阿里云、腾讯云、360数字安全、亚马逊AWS、微软Azure、英伟达等多个平台接入DeepSeek大模型供用户实时调用；吉利、极氪、岚图、智己等多个品牌的智能座舱已与DeepSeek大模型完成深度融合；北京银行联合华为率先引入部署DeepSeek系列大模型，探索DeepSeek大模型在金融领域的应用；极光GPTBots.ai作为领先的企业级AI智能体构建平台，正式推出基于DeepSeek集成的增强型私有化部署解决方案等。各行各业都在积极探索DeepSeek的深入融入带来的应用创新。同时，基于开源的大模型，高校、研究院等也在开发各个版本的DeepSeek模型，以提高其多模态交互等能力，如北大联合港科大团队基于自研全模态框架推出多模态版DeepSeek-R1：Align-DS-V等。 二、DeepSeek用户数增长迅猛，“男性”、“年轻化”、“中高消费人群”成为其用户标签 国内用户对DeepSeek的热情高涨。从极光月狐研究院的数据来看，截止至2025年2月7日，DeepSeek的安装量已超2亿；从发布到现在已半月有余，渗透率和DAU涨势惊人。从渗透率来看，DeepSeek从0.1%的渗透率到超越kimi成为行业第二仅用了10天时间，截止至2025年2月7日渗透率已超过16%，或有超越豆包成为行业首位之势；从DAU来看，DeepSeek为增长陷入瓶颈的行业带来活力，开工日（2月5日）达到了发布以来的峰值，实现了2467万的日活。 2025年1月，从新增用户特征数据上看，相较于头部生成式AI应用较为均衡的男女比例，DeepSeek目前68%的用户为男性；从用户年龄结构来看，DeepSeek较为年轻化，46岁及以上的中老年用户还未大规模进场。从用户分布及消费水平上看，一线城市和新一线城市成为DeepSeek的主战场，超过40%的用户集中于此，＞85%的用户处于中高消费水平。 同时间，从运营数据上看，DeepSeek与豆包、Kimi的用户重合度较高，超过77%，豆包与Kimi也成为DeepSeek的主要来源与去向。DeepSeek的C端用户消费能力较高，利于其后期实现会员付费等模式；但与友商的用户重合度高，暂未形成独有的大规模用户群体。DeepSeek在磨练性能，努力成为重合用户第一选择的同时，也应在其定位上与豆包、Kimi有所区隔。这需要利用其技术创新的优势深挖应用场景。 三、DeepSeek结合“占卜”、“数学”等应用场景大出圈 目前C端用户挖掘出的DeepSeek的应用场景主要集中于占卜、数学推理、写作与陪伴等。在占卜场景中，DeepSeek生成内容准确度、完整度均超越友商应用。在数学问题中，与友商应用相比DeepSeek针对代数、逻辑等题型较有优势，准确度较高、但思考过程冗余多导致时间过长，同时泛化能力有待提高，针对带图的几何题答题效果较差；对比垂类应用如作业帮等，通用大模型应用在解题思路精准度、答案准确度上明显较差。在写作场景中，DeepSeek相对友商应用情感充沛，颇有哲思。 AI占卜 DeepSeek在小红书、抖音等平台大热，其中最突出的落地应用场景当属占卜算命。区别于“准了”、“预见塔塔”等塔罗、星盘付费占卜模式，DeepSeek主打“适合中国人体质”的“八字测算”。相比于豆包、Kimi等头部生成式AI应用，DeepSeek在八字排盘、格局分析、大运与流年方面都具有更详细的输出，在其思维链中也会显示如需更详细的信息需要提供哪些线索，在用户补充线索后能针对前序内容进行补充。但占卜应用难以验证其科学性及准确性，目前多以娱乐性为主。 AI数学 正如上文中部分机构对于DeepSeek能力的拆分测评中显示，DeepSeek在数学解答能力上较为突出。与豆包、Kimi等通用生成式AI应用的结果相比，其准确性更高，且展示出了明显的思维链路；但与作业帮等垂类应用相比，思考时间过长，过程存在冗余。 AI写作与陪伴 DeepSeek的中文写作能力相对其他生成式AI应用较强，经常针对问题给予哲学性较强或具有诗意的回答，提供情绪价值。同时，可根据用户的要求进行不同风格的文本输出，如模仿知乎、贴吧等平台，模仿鲁迅、张爱玲等作家的文笔等。但使用评价褒贬不一，且存在用户审美疲劳的情况。 其他 DeepSeek在办公过程中需要的框架性的内容生成等具有创新性，相较于目前较为同质化的内容，DeepSeek从行文风格上具有特殊性，同时因其思维链的存在能够展示各部分内容生成时使用的方法论。但在内容的充实性和规范化上仍与豆包等应用相差较远。 DeepSeek以其实力一跃成为全国甚至全球最受瞩目的大模型，正在诉说着“创新才能重塑A行业竞争版图、跻身前列”的逆袭故事。大模型仍处于高速迭代期，持续地“打碎重铸”才是守住行业地位，推动社会科技变革的关键所在。只有不断打破旧有的框架，才能在新的技术浪潮中占据主动，引领行业的发展方向。DeepSeek的成功案例与卓越的创新竞赛将带领中国企业从技术追随走向自主创新之路。 举报/反馈"
    },
    {
      "doc_id": 49807,
      "title": "DeepSeek文生图来了部分性能测试不输OpenAI",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "经济观察网 记者 钱玉娟 北京时间1月28日凌晨，农历新年前夕，中国人工智能（AI）初创公司DeepSeek在GitHub（面向开源及私有软件项目的托管平台）以及Hugging Face（AI社区）上发布了多模态大模型Janus-Pro，进军文生图领域。 DeepSeek介绍，Janus-Pro大模型是2024年11月发布的JanusFlow大模型的升级，分为7B（70亿）和1.5B（15亿）两个参数量版本，且均开源。 AI社区开发者的评论显示，DeepSeek的Janus-Pro模型具备在消费级电脑终端上本地运行的潜力。 Janus-Pro在多模态理解和文本到图像的指令跟踪功能上实现重大进步，其文本到图像生成的稳定性明显提升。 DeepSeek发布的测试结果显示，Janus-Pro的70亿参数版模型在一些基准测试中击败了美国AI独角兽OpenAI的多模态大模型DALL-E3。 尽管Janus-Pro的模型尺寸有限，但从技术报告看，DeepSeek团队添加了7200万张高质量合成图像，模型在预训练阶段的真实数据与合成数据的比例达到了1：1，这使模型的图像视觉生成能力更稳定。 另外，Janus-Pro还通过将视觉编码分离为“理解”和“生成”两条路径，既缓解了视觉编码器在理解和生成中的角色冲突，还提升了模型框架的灵活性。 该模型还在多模态理解的训练数据上增加了大约9000万个样本，令其在文生图的同时，也能识别图像及其中的文字、知识等。 就在北京时间1月27日，由DeepSeek开发的App也超越了OpenAI的ChatGPT，成为苹果应用商店下载量最大的免费App。 几乎在同一天，包括英伟达、博通公司、超威半导体公司以及微软等在内的美国科技板块公司股价大幅下跌，华尔街均评估是受中国企业DeepSeek的技术突破影响。 在DeepSeek发布文生图多模态大模型前一晚，达闼机器人创始人黄晓庆接受经济观察网采访时称，其团队已基于DeepSeek的V3及R1大模型，将对话功能应用于旗下的机器人开发创新中，目前正在规划基于DeepSeek的多模态大模型进行二次训练。 黄晓庆认为：“DeepSeek开源、开放的模式，有利于第三方进行二次训练，加入多模态和机器人控制模型。”DeepSeek的MoE专家模型的融合架构不仅适合模型应用下游厂商的分布式训练场景，对像达闼机器人这样的厂商来说，跨应用场景的各种形态的机器人开发，也可以与DeepSeek的多模态大模型进行融合。 举报/反馈"
    },
    {
      "doc_id": 49808,
      "title": "AI新纪元:砥砺开疆・智火燎原|中信建投500页深度研报",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "来源：中信建投证券研究 文｜黄文涛 阎贵成 程似骐 崔世峰 贺菊颖 黎韬扬 刘双锋 刘永旭 庞佳军 陶亦然 王在存 许琳 许光坦 杨艾莉 叶乐 应瑛 于芳博 袁清慧 赵然 朱玥 500页重磅深度，全面拆解AI模型、应用与算力，勾勒AI新纪元产业图谱。 《AI新纪元：砥砺开疆・智火燎原》40万字深度解析，以全球化视野系统解码全球人工智能产业最新发展脉络。内容贯穿AI垂直产业链核心环节，从底层算力基础设施到中层大模型技术迭代，再到终端应用场景落地，实现软硬件研究全链路贯通。立足全球最新AI大模型演进趋势，精准构建覆盖全产业链的“AI+产业”投资图谱，全方位挖掘横跨软硬领域的人工智能产业投资机遇。登录“中信建投研究机构服务平台”小程序可查看下载全文。 自ChatGPT发布后，大模型向更强、更高效、更可靠方向发展，呈现推理模型深化、智能体模型爆发的格局。美国在探索更强大模型上保持全球领先，中国企业则在算力受限下实现高效性全球领先。2025年是应用加速落地之年，OpenAI已达百亿美金ARR，Claude月收入环比增速超20%。受互联网大厂推动AI与业务结合、Agent推出、主权AI需求及多模态渗透等因素影响，AI算力消耗从训练转向推理，带来显著增量，国内算力自主可控趋势凸显。B端应用渗透率慢于C端，落地顺序由容错率与复杂度决定，从高容错、单一任务场景到低容错、高复杂度场景尚需时间。但本轮AI渗透较互联网时代大幅提速，B端落地进程或超预期。 大模型继续向更强大、更高效及更可靠的方向发展。人工智能发展历经三个主要阶段，从符号智能、专用智能迈向通用智能，2017年之后正处于通用智能阶段。在这个阶段中，以Transformer架构为基础，训练数据从有标注变为通用无标注数据，学习方法从过去的有监督学习变成无监督学习，能力从专用任务扩展到通用任务，并在算力的加持下，参数量和数据量都急剧变大，因而有了今天的大模型。值得关注的是，随着模型规模、数据量的持续突破与学习范式的迭代，大模型逐渐展现出显著的“涌现能力”——即当模型达到一定复杂度后，自发产生超越其设计目标或训练数据覆盖范围的新能力。这种来源于模型对海量数据中潜在规律的深度捕捉与跨领域关联能力，正是通用智能阶段大模型从“量变积累”迈向“质变突破”的核心标志，也为其在更复杂、更开放的现实场景中实现自主决策与创新应用奠定了基础。2025年模型继续向着更强大、更高效、更可靠的方向去发展，其中，更强大体现为Scaling Law跨域延伸、推理能力自主进化、多模态深度融合、Agent与群体智能、实时数据验证以及合成数据助力，尤其是强化学习在其中起到了至关重要的作用；更高效依托MOE架构优化、FP8等低精度应用、Mamba等新型架构探索及计算效率提升；更可靠则通过Scaling Law降幻觉、实时事实验证、思维链等实现，部分方法兼具多重作用。 时至今日，美国依然在探索更强大模型上具备全球领先性。目前呈现推理模型深化、智能体模型爆发格局。OpenAI o3领跑全球，但近期受到Claude4、Gemini2.5 pro升级版的挑战，大模型竞争格局逐渐从OpenAI一家独大转变为北美大厂竞相霸榜。 而中国企业在算力受限的情况下，在更高效上做到了全球领先。从地理分布上看，全球已经形成人工智能的“两极格局”，且未来这一格局仍将长期保持。至2024年，中美两国自研大模型数量占全球80%以上，中国大模型数量已经接近100款。 根据斯坦福以人为本人工智能研究所（Human-CenteredArtificialIntelligence,HAI，领导者为李飞飞）发布《2025年人工智能指数报告》，2024年结束后，中美顶级AI模型的能力（多项基准测试得分加权平均）差距已由前一年的20%缩小至0.3%。中国视角来看，DeepSeek-R1迈出了中国AI全面追赶美国的关键一步。DeepSeek-R1通过架构创新、软件优化及前沿方法，在推理能力上逼近国际顶尖水平，且训练成本大幅降低。其开源策略为本土AI发展提供了技术参考，缩小了与美国的技术差距，如今豆包Seed1.6、阿里通义千问、KimiK2等国产模型呈现百花齐放局面，并且开源的KimiK2再次体现国产模型更高效的特点。从大模型的技术本质与人才储备来看，中国的大模型企业的能力并不落后，2025年是世界认知中国人工智能潜力的第一年，未来有望走出国门、走向世界。 进入2025年，大模型的应用落地进程呈现显著加速态势。我们总结了目前海外典型大模型ARR（年化收入，亿美元）情况，OpenAI已实现百亿美金ARR，月度CAGR仍然保持10%的环比增速，Claude4凭借代码优势，ARR半年时间从10亿美金奔向30亿美金，月度CAGR超过20%的环比增速，海外大模型开始加速实现商业化落地。然而，这只是刚开始，结合Pew Research的样本调查，截至1Q25，34%的美国成年人已经采用ChatGPT，大约相当于美国PC互联网2003-04年的渗透率水平。考虑到ChatGPT是22年底推出，意味着ChatGPT用两年零一个季度的渗透率大致对应PC互联网10年的渗透进度。 AI大模型对产业的渗透速度超过此前互联网革命，并且其展现出来的商业化潜力和付费意愿也超过传统应用。从Sensor Tower统计的应用内购收入来看，AI应用占据整体应用(剔除游戏)比例约1.73%。而如果从AI应用的下载量来看，2024年AI应用下载量达14亿次，占据全球所有应用下载量约1.0%，付费比例超过了下载比例。从24年中预训练进度放缓，到25年初大模型与实际业务第一阶段协同落地，这一阶段的进展体现了大模型技术在原有业务上实现了效率层面的大幅度跃升，从而形成了商业逻辑的闭环，之后大模型将快速的向其他行业渗透，其渗透节奏有快有慢，总体体现从易到难，从虚拟到现实，从科技到传统，从研发到生产的主要渗透趋势，从行业特有的限制角度看，生产环境与法规限制较少到的产业会快于限制较多的产业。 作为AI应用的重要载体和下一代人工智能的具体形态，AI Agent将成为2025年AI发展的重要方向。年初国内Manus发布引起广泛关注，国内大厂纷纷打出各有特色的Agent战略。北美市场各类Agent同样层出不穷：OpenAI连发两款研究型Agent、Claude 4代码能力突出、Google Deep Research深度嵌套Google Scholar生态，AI Agent正进入技术突破与商业化加速阶段。Agent的出现将快速把大模型能力从“做题”延伸到“工作”中，简而言之，大模型开始从“小镇做题家”变成“都市白领多面手”。生物群落带来生物群体智能涌现，多智能体集群也将带来AI群体智能涌现，进一步提升大模型性能，目前GitHub上已有不少明星项目，预计未来两到三年内该技术将逐步成熟。目前看，Agent的发展比较依赖于数据和生态，具备数据优势、生态体系构建的企业未来将更具发展潜力。 多模态商业化进展快，国产AI视频与海外模型各有千秋。多模态模型历经任务导向、视觉 - 语言预训练、多模态大模型三阶段，当前以 “语言为统一交互工具” 实现跨模态对齐与零样本应用。原生多模态模型（如 GPT-4o、Gemini）解决输入延迟问题，基于 Transformer 的扩散模型提升文生视频质量。应用上，C 端聚焦社交娱乐（如快手可灵的视频特效），B 端侧重营销素材与商品图创作（如美图设计室），专业领域（如影视制作）通过 AI 降本增效显著。据不完全统计，25年上半年有全球有超30款多模态模型更新或发布，其中超75%为国产模型。国产模型尺寸上均支持多种规格；时长上国产可灵达 2 分钟，部分推理更快；效果上国产多次登顶全球榜单；使用门槛上，国产多端可用、价格更低。中国的互联网企业在多媒体领域具有全球影响力，游戏、电影、短剧、短视频等领域将是目前多模态落地的第一阶段，随后在自动化装备、机器人、自动驾驶等产业也将快速渗透。 随着各方面应用的加速，AI算力消耗开始从训练走向推理，同时主权AI加大投入，带来显著的算力增量。探究背后增量需求主要来自四方面： 一是各家互联网大厂纷纷加速AI与原有业务结合，如谷歌搜索在今年5月21日正式迎来 AI 模式，并逐步在美国市场推出，考虑到谷歌搜索全球范围内年搜索量为5万亿次+，假设单次回答平均为2000token，则该功能都将带来日均27万亿token消耗（超过其Gemini模型目前日均16万亿token消耗），类似案例如抖音搜索、微博AI智搜，搜索功能开始从普通服务器迁移到AI服务器并重塑所有搜索体验，类似的视频编辑、剪辑功能也被AI重塑； 二是Agent和深度思考推理的结合，通过两者结合，Agent执行任务准确率大幅提高，Agent执行一次任务平均消耗token达到10万的量级，大幅超过AI搜索单次问答token消耗，并且能延伸到更多开放式场景，同时多Agent协作的群体智能也已开始逐步商用化，过去复杂、多步骤的任务可通过Agent实现，Agent的普及将带来推理算力需求的大幅增长； 三是多模态，随着多模态生成的图片及视频质量今年均显著提升，今年AI营销内容占比提升十分明显，根据《2025中国广告主营销趋势调查报告》显示“超过50%的广告主，已经在生成创意内容时使用AIGC，并且AI营销内容占比超过10%”，而一分钟视频的生成token消耗基本在10万token至百万token量级，目前多模态模型开始步入快速商业化阶段，如快手可灵四五月连续两月付费金额超过1亿，多模态的加速渗透带来明显的算力需求提升。 四是主权AI，科研和军事领域是关键，随之扩展到其他各行业的效率提升，典型代表为美国重点推进其“星际之门”计划。与之而来的是各国政府也纷纷开启主权AI的投资计划，尤其是以欧洲、中东、日本等国为代表，投资体量超过3000亿美金。 算力方面从投资角度来看，一是随着推理占比的提升，云计算厂商投入产出比逐渐清晰，并且超卖率有望继续提升，从而带动利润率提升；二是围绕机柜增量变化及新技术投资，25年下半年核心是英伟达NVL72机柜上量，其中液冷散热、铜连接、电源变化最大：三是围绕估值性价比、景气度投资，重视PCB、光模块等供应链。 1）散热方面：散热方面将是AI算力领域未来几年核心技术升级方向之一，英伟达单卡功耗从700瓦到1200、1400瓦，未来有望迭代至2000瓦+，并且大机柜、超节点的出现，热源的叠加使得散热难度进一步提升，因此散热成为了接下来持续迭代升级的方向。其次，目前供应商以台系、美系厂为主，如Coolermaster、AVC、BOYD及台达等，中国大陆供应商比例较低，随着液冷散热从研发走向大规模量产，中国大陆公司扩产能力更具优势，我们认为液冷散热领域一系列部件会有更多中国大陆供应商进入到全球供应体系。 2）铜链接：铜线在短距数据传输的成熟度更高且448G等新技术路线逐步面世，今年扩产最快的公司将充分享受从Blackwell到Rubin所带来的高速连接需求增长。 3）电源领域：高功率带动单W价值提升。PSU是服务器电源进行AC-DC转换的核心，随着单体功率密度的提升，单W价格也在提升，呈现量价齐升局面。新一代GB300等GPU方案中，BBU、CBU逐步成为标配，能够解决负载波动率大的供电稳定、电压稳定问题。目前5.5 KW电源已进入量产阶段，后续伴随2026 下半年800 V HVDC 数据中心电力基础设施及 1 MW IT 机架逐步落地，电源将持续升级。随着功率密度要求的提升，UPS目前正在由600kW级向MW级迈进，以应对越来越大的功率密度需求，未来AIDC有望全面切换到HVDC为代表的全直流供电方案，电压等级也提升至800V。巴拿马电源等集成化、模块化产品逐步成为大厂青睐的主流，更先进的固态变压器（SST）也已开始研发和测试。 4）PCB：亚马逊、META、谷歌等自研芯片设计能力弱于英伟达，因此对PCB等材料要求更高，价值量更有弹性。随着短距离数据传输要求不断提高，PCB持续升级，并带动产业链上游升级，覆铜板从M6/M7升级到M8/M9。伴随国内PCB公司在全球份额持续提升，并带动上游产业链国产化，从覆铜板出发，并带动上游高端树脂、玻纤布、铜箔等国内份额进一步提升。 5）光模块：除了GPU等算力硬件需求强劲，也催生了网络端更大带宽需求。优秀的网络性能可以提升计算效率，显著提升算力水平。相较于传统的云计算网络，AI训练组网由叶脊架构向胖树架构转变，交换机和光模块数量大幅提升，且随着通信数据量的增加，对光模块的速率要求也更高。800G光模块2023年开始放量，2024-2026年都保持高速增长；1.6T光模块2025年开始出货，2026年有望放量，整个光模块产业链迎来量价齐升的景气周期。从竞争格局看，国内光模块巨头经历了一轮又一轮的竞争，与北美的云厂商深度绑定，占据了全球光模块市场的主要份额。从未来技术趋势演进看，我们建议关注硅光与CPO（共封装光学）。 6）先进封装、HBM：为了解决先进制程成本快速提升和“内存墙”等问题，Chiplet设计+异构先进封装成为性能与成本平衡的最佳方案，台积电开发的CoWoS封装技术可以实现计算核心与HBM通过2.5D封装互连，因此英伟达A100、H100等AI芯片纷纷采用台积电CoWos封装，并分别配备40GB HBM2E、80GB的HBM3内存。全球晶圆代工龙头台积电打造全球2.5D/3D先进封装工艺标杆，未来几年封装市场增长主要受益于先进封装的扩产。先进封装市场的快速增长，有望成为国内晶圆代工厂商与封测厂商的新一轮成长驱动力。 7）国内算力链：一方面来自于美国BIS政策的持续收紧，中期维度看，国产芯片占比提升是必然趋势。考虑到国产芯片逐渐进入量产交付阶段，预期市场集中度将看到显著提升。另一方面随着国内算力消耗快速增长（典型如字节跳动，每三个月token消耗接近翻一倍，5月底为16.4万亿token），我们预计国内各家大型云厂商在日均token消耗达到30万亿token时会感受到算力紧张，在达到60万亿token时会开始出现一定算力缺口。我们认为国内增速斜率更陡峭，国产芯片今年将迎来发展大年。 C端应用：从移动互联网迈向 AI 定义的新时代，AI 原生应用成为主角。其与传统应用大不相同，以 AI 为架构核心，软件开发范式历经从代码、权重到提示词的转变。在应用层，它降低构建应用门槛，改变交互形式，能完成复杂任务决策执行，还简化了 UI，让 LUI 走向前台。从渗透率看，当前 AI 应用普及程度相当于美国 PC 互联网 2003-04 年水平，且增速迅猛；从类型看，内容创作工具商业化进度领先，通用助手、垂直领域智能体等多类应用并存。海外 AI应用数量自 2023 年 1 月起每月新增超 1000 款，2024 年超 4000 款，AI应用开始迅速普及。 B端应用：企业端 AI 应用渗透率方面，美国企业采用 AI 技术比例为 9.2%，低于 C端，其中大型企业采用率最高。容错率与复杂度决定B端各场景AI应用落地顺序。其模型推理能力决定复杂任务场景突破速度，模型幻觉率决定容错率场景突破进度。从高容错、单一任务的AI+搜索/AI+编程场景到低容错、高复杂度的具身智能/AI+制药场景，AI应用尚需一定时间周期。但道阻且长，行则将至，本轮AI渗透相较于互联网时代的大幅提速预示着B端应用落地进程或将远超预期。分场景来看： 1）教育领域：因其场景清晰性、数据丰富性和需求刚性，成为AI技术落地的黄金赛道。AI+教育软件以人工智能技术为驱动，通过算法分析学情数据、动态定制学习路径，实现教学流程智能化重构。 2）医疗/制药领域：AI制药领域正经历着快速的迭代和变革，算法的更新迭代和算力的支持为AI在制药领域的应用打下了良好的基础。目前AI算法在临床前药物发现阶段已经有着深入且深刻的应用，海外头部临床CRO公司在临床试验中已经布局AI多年，完全由AI研发的新药有望在1-2年内成功上市。AI有望重塑药物发现的模式，并且为制药行业带来潜移默化且持续地降本增效，驱动AI制药管线和市场的快速增长。同时AI医疗在提升医疗器械功能、检查检验结果解读、辅助临床医生决策、健康管理等多个领域的应用价值较大，是医疗企业和医院必须重视的创新方向和竞争趋势。企业有望借助AI进一步提高产品竞争力和客户粘性，巩固行业地位和竞争优势。 3）工业领域：现代工业作为规模化制造体系，其标准化流程与确定性物理规则恰是AI模型的最佳训练场。AI+工业正沿两条主线突进：在增量市场，新能源汽车、光伏等新兴制造领域从零构建AI原生工厂，将视觉质检、预测性维护等模块嵌入产线设计底层，如智能制造服务商为车厂搭建的全链条数字孪生系统；在存量改造中，传统重工业通过渐进式部署解决关键瓶颈，例如钢铁企业用参数优化模型降低能耗，化工企业利用DCS等智能控制提高流程工业生产效率。当AI将分散的专家经验凝练为可复用的工业智能，传统制造的效率边界正被重新定义。 4）军事领域：AI正加速落地，广泛用于无人作战系统与战场决策支持。AI 正在重塑现代战争体系，从辅助工具跃升为智能战场的核心中枢。美军通过构建以“数据获取—智能平台—作战应用”为主干的三层级作战架构，实现从感知到打击的闭环式智能决策； 系统性赋能无人系统、网络攻防、战场感知、战争推演与后勤保障等五大作战核心领域。 SpaceX、 Palantir、Anduril 等新型防务企业成为关键推动力量，形成“算法主导”的新军工联盟。在此背景下，未来军事竞争重点关注低轨卫星（通导遥一体化）、 AI 平台与边缘智能、智能无人系统三大方向的融合突破，构建体系化、可实战部署的智能作战能力。 机器人：目前机器人大模型训练方式已经开始向端到端大模型+世界模型（物理规则建模）发展，同时模态能力也越来越丰富，从VLM过渡到VLA，典型的是Gemini Robotics（2025.3）已实现视觉-语言-动作（VLA）三模态深度融合，推动机器人从感知理解走向高频执行。目前具身智能大模型仍有数据集不够、思考跟不上运动、缺乏生态等主要痛点，但随着合成数据使用、模型持续迭代，未来将有效解决上述问题。 随着大模型快速迭代，供应链快速降本，两大因素加速以人形机器人为代表的具身智能商业化落地。自Tesla于2021年宣布推出人形机器人“擎天柱”，到现在Tesla即将推出第三代人形机器人、Figure推出搭载了Helix模型的新款、1X推出人工智能算法优化的NEO GAMMA等，国内的宇树、智元、优必选等步态、动作优化，我们看到模型迭代、训练算法优化、供应链快速降本，正在加速以人形机器人为代表的具身智能商业化落地，目前多家人形机器人产品已经在下游工业客户展开实训，预计未来人形机器人市场规模将远超汽车、3C行业，带动包括丝杠、减速器、传感器、电机等相关产业链的旺盛需求。 智驾：特斯拉FSD Beta V12.3为第一个使用端到端神经网络的FSD版本，端到端大模型相比过去的算法有四个重要特点及优势： 1）数据驱动：过去是靠写规则去定义自动驾驶，现在是由数据驱动，每看100-150万个视频片段，效果会有明显提升； 2）上限高：大模型的涌现能力目前看在自动驾驶中也有体现，意味着把参数量做大，能解决过去自动驾驶过程中一些难解决的驾驶行为； 3）计算效率提升：端到端模型将传统数十个独立模块集成至单一网络，消除信息传递延迟，因此推理时延缩短至毫秒级，进一步推动城市NOA等高阶功能落地提供技术基础； 4）驾驶体验逼近人类：过去规则定义下的自动驾驶很生硬，目前体验更加类似于人类驾驶的感受，从而降低了接管次数。目前，VLA（视觉 - 语言 - 动作模型）作为端到端架构的重要发展方向，通过融合视觉、语言等多模态数据构建 “多模态世界模型”，已经开始加速在车厂应用。除了模型变化，2025 年成上车元年，元戎启行、理想等国内外车企加速布局低速场景试点。车企推动 “智驾平权”，比亚迪等将高阶智驾下沉至 10 万级，带动城市 NOA 渗透率提升。 端侧：端侧硬件的多元化高度契合人工智能技术的交互需求，其声学、视觉、执行单元、光学、显示屏幕等组件，可以组合出丰富多彩的硬件产品。当前端侧的能力足以支撑不同场景下交互与传输工作，对模型的承载上还无法承载千亿参数规模的大模型，因此模型分级分工是当前端侧AI的阶段性特色。 不同场景下的端侧硬件展现出不同的技术需求，如AI眼镜追求轻薄且高续航，AI手机追求隐私与高效，AI电脑追求效率与便携，等等。未来端侧仍然是各场景下大模型渗透的核心载体，其技术路线呈现容量更大、电量更足、模型更强、声光屏交互更便捷的发展趋势，对高端cis摄像头与显示技术、消费电子级固态电池技术、高端存储封装技术、端侧高算力技术、超低功耗芯片设计技术、超低功耗声学技术等提出了多样的技术需求。 北美经济衰退预期逐步增强，国际地缘变局冲击全球供应链韧性，企业海外拓展承压；芯片结构性短缺可能制约产能释放与交付节奏；行业竞争加剧触发价格战隐忧，中低端产品毛利率可能跌破盈亏平衡点；原材料成本高企叠加汇率宽幅波动持续侵蚀外向型企业利润空间；技术端则面临大模型迭代周期拉长的风险），影响AI产业化进程；汽车智能化渗透率及工业AI质检等场景落地进度不及预期，或将延缓第二增长曲线兑现。 黄文涛：经济学博士，纽约州立大学访问学者。现任中信建投证券首席经济学家、研究发展部联席负责人、中信建投机构委、投委会委员，董事总经理。兼任南开大学硕士导师、中信改革发展研究基金会咨询委员、中国首席经济学家论坛理事、中国证券业协会首席经济学家委员会委员等职务。多次参与国务院部委等机构形势分析研讨及课题研究。多年荣获新财富、水晶球、金牛奖、保险资管协会等最佳分析师，2016年新财富最佳分析师评比荣获固定收益第一名。2024年荣获服务高质量发展最佳首席经济学家。 阎贵成：中信建投证券通信行业首席分析师，北京大学学士、硕士，近8年中国移动工作经验，9年多证券行业研究工作经验。目前专注于人工智能、云计算、物联网、卫星互联网、5G/6G、光通信等领域研究，曾多次获得证券行业各大评选的通信行业第一名，如新财富、水晶球、金麒麟、上证报、Wind等。 程似骐：汽车行业首席分析师，上海交通大学车辆工程硕士，师从发动机所所长，曾任职于东吴证券、国盛证券，四年证券行业研究经验。2017年新财富第二团队核心成员，2020年新浪财经新锐分析师第一名，2020年金牛最佳汽车行业分析师团队第五名。深度覆盖新能源整车，智能化零部件，把握智能化电动化浪潮，对智能驾驶全产业链最前沿研究，深度跟踪从产业链最上游车载芯片到下游最前沿的L4的商业模式前沿演变。2021年新财富最佳分析师汽车行业第四名。 崔世峰：海外研究首席分析师，南京大学硕士，8年买方及卖方复合从业经历，专注于互联网及科技龙头公司研究。2024新财富海外市场研究第五名；2022-2023年新财富港股及海外最佳研究团队入围；2019-2020年新财富传媒最佳研究团队第二名核心成员。 贺菊颖：中信建投证券医药行业首席分析师，复旦大学管理学硕士，10年以上医药卖方研究从业经验，善于前瞻性把握细分赛道机会，公司研究深入细致，负责整体投资方向判断。2020年度新浪财经金麒麟分析师医药行业第七名、新财富最佳分析师医药行业入围、万德最佳分析师医药行业第四名等荣誉。2019年Wind“金牌分析师”医药行业第1名。2018年Wind“金牌分析师”医药行业第3名，2018第一财经最佳分析师医药行业第1名。2013年新财富医药行业第3名，水晶球医药行业第5名。 黎韬扬：研发部执行总经理、军工与新材料团队首席分析师，北京大学硕士。2015-2017年新财富、水晶球、Wind军工行业第一名团队核心成员，2018-2024年水晶球军工行业上榜，2018-2020年Wind军工行业第一名，2019-2022年金牛奖最佳军工行业分析团队，2018-2024年新财富军工行业上榜、入围。 刘双锋：中信建投证券电子首席分析师。3年深南电路，5年华为工作经验，从事市场洞察、战略规划工作，涉及通信服务、云计算及终端领域，专注于通信服务领域，2018年加入中信建投通信团队。2018年IAMAC最受欢迎卖方分析师通信行业第一名团队成员，2018《水晶球》最佳分析师通信行业第一名团队成员。 刘永旭：中信建投证券通信行业联席首席分析师，南开大学学士、硕士，曾从事军工行业研究工作，2020年加入中信建投通信团队，主要研究云计算IDC、工业互联网、通信新能源、卫星应用、专网通信等方向。2020-2021年《新财富》、《水晶球》通信行业最佳分析师第一名团队成员。 庞佳军：人工智能&电子联席首席分析师。 陶亦然：汽车行业联席首席分析师。曾任银河证券汽车分析师，2018年加入中信建投汽车团队，2018/19年万得金牌分析师团队核心成员，2019/20年新浪财经新锐分析师团队核心成员,2020年金牛最佳行业分析团队核心成员，2021/22年新财富、水晶球最佳分析师团队核心成员。 王在存：中信建投医疗器械及服务首席分析师，北京大学生物医学工程博士，《医疗器械行业蓝皮书》编委。团队负责研究医疗器械与医疗服务各细分赛道的发展趋势和投资机遇，团队成员的医疗产业资源丰富。 许琳：中信建投证券新能源汽车锂电与材料行业首席分析师，7年主机厂供应链管理+2年新能源车研究经验，2021年加入中信建投证券研究发展部，主要覆盖新能源汽车、电池研究。 许光坦：中信建投机械首席分析师，上海交通大学硕士，2021.4-2023.5曾就职于东北证券研究所，2023年5月加入中信建投证券，覆盖工控、传感器、注塑机、机床刀具、锂电设备方向。 杨艾莉：中信建投证券传媒互联网行业首席分析师，中国人民大学传播学硕士，曾任职于百度、新浪，担任商业分析师、战略分析师。2015年起，分别任职于中银国际证券、广发证券，担任传媒与互联网分析师、资深分析师。2019年4月加入中信建投证券研究发展部担任传媒互联网首席分析师。曾荣获2019年wind资讯传播与文化行业金牌分析师第一名；2020年wind资讯传播与文化行业金牌分析师第二名；2020年新浪金麒麟评选传媒行业新锐分析师第二名。 叶乐：中信建投证券纺服轻工及教育行业首席分析师，毕业于复旦大学金融硕士专业，2024年“金牛奖”纺服行业最佳分析师，2023年“新浪金麒麟”菁英分析师纺服第4、家居第5，2020年“新财富”海外最佳分析师第5名团队成员，目前专注于纺服、轻工、黄金珠宝、教育人力、医美个护等消费服务产业研究。 应瑛：中信建投证券计算机行业首席分析师，伦敦国王学院硕士，5年计算机行业研究经验。2021年加入中信建投，深入覆盖医疗信息化、工业软件、云计算、网络安全等细分领域。 于芳博：中信建投人工智能组首席分析师，北京大学空间物理学学士、硕士，2019年7月加入中信建投，主要覆盖人工智能等方向，下游重点包括智能汽车、CPU/GPU/FPGA/ASIC、EDA和工业软件等方向 袁清慧：中信建投制药及生物科技组首席分析师。中山大学理学本科，佐治亚州立大学理学硕士，北卡大学教堂山分校医学院研究学者。曾从事阿尔茨海默、肿瘤相关新药研发，擅长创新药产业研究。2018年加入中信建投证券研究发展部，负责制药及生物科技板块。2020年新浪金麒麟分析师医药行业第七名、新财富最佳分析师医药行业入围团队核心成员、Wind金牌分析师医药行业第4名。2019年Wind金牌分析师医药行业第1名。2018年Wind金牌分析师医药行业第3名，第一财经最佳分析师医药行业第1名。2021年新财富最佳分析师医药行业第五名。 赵然：中信建投非银与前瞻研究首席分析师，中国科学技术大学应用统计硕士。曾任中信建投金融工程分析师。目前专注于非银行业及金融科技领域（供应链金融、消费金融、保险科技、区块链、智能投顾/投研、金融IT系统、支付科技等）的研究，深度参与诸多监管机构、金融机构数字化转型及金融科技课题研究。6年证券研究的工作经验。2018年wind金融分析师（金融工程）第二名2019年.2020年Wind金融分析师（非银金融）第四名和第一名，2020年新浪金麒麟非银金融新锐分析师第一名。 朱玥：中信建投证券电力设备新能源行业首席分析师。2021年加入中信建投证券研究发展部，8年证券行业研究经验，曾就职于兴业证券、方正证券，《财经》杂志，专注于新能源产业链研究和国家政策解读跟踪，在2019至2022年期间带领团队多次在新财富、金麒麟，水晶球等行业权威评选中名列前茅。 证券研究报告名称：《AI新纪元：砥砺开疆・智火燎原》 对外发布时间：2025年7月24日 报告发布机构：中信建投证券股份有限公司 本报告分析师： 黄文涛 SAC 编号:S1440510120015 SFC 编号:BEO134 阎贵成 SAC 编号:S1440518040002 SFC 编号:BNS315 程似骐 SAC 编号:S1440520070001 SFC 编号:BQR089 崔世峰 SAC 编号:S1440521100004 SFC 编号:BUI663 贺菊颖 SAC 编号:S1440517050001 SFC 编号:ASZ591 黎韬扬 SAC 编号:S1440516090001 刘双锋 SAC 编号:S1440520070002 刘永旭 SAC 编号:S1440520070014 SFC 编号:BVF090 庞佳军 SAC 编号:S1440524110001 陶亦然 SAC 编号:S1440518060002 王在存 SAC编号:S1440521070003 许琳 SAC 编号:S1440522110001 SFC 编号:BVU271 许光坦 SAC 编号:S1440523060002 杨艾莉 SAC 编号:S1440519060002 SFC 编号:BQI330 叶乐 SAC 编号:S1440519030001 SFC 编号:BOT812 应瑛 SAC 编号:S1440521100010 SFC 编号:BWB917 于芳博 SAC 编号:S1440522030001 SFC 编号:BVA286 袁清慧 SAC编号：S1440520030001 SFC编号：BPW879 赵然 SAC 编号:S1440518100009 SFC 编号:BQQ828 朱玥 SAC 编号:S1440521100008 SFC 编号:BTM546 举报/反馈"
    },
    {
      "doc_id": 49810,
      "title": "对话周鸿祎:DeepSeek流量确实在下降,他们就没花心思做,梁文锋是有...",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "“即使装上了DeepSeek，就是当聊天机器人在用，感觉还处在一个玩具的阶段，并没有真正变成大家所梦想的新质生产力的打造工具，智能体恰恰弥补了大模型的不足。” 在7月23日举办的2025中国互联网大会期间，AI成为话题焦点。360创始人周鸿祎在与搜狐科技等媒体的沟通中，强调智能体才是大模型真正落地的关键。 他认为，智能体是大模型进化的一个新阶段，和大模型并不矛盾——大模型扮演大脑的角色，智能体扮演身体、手和脚的角色。 目前，业内做智能体主要有两种模式，一种是大模型厂商去做，如刚推出ChatGPT Agent的OpenAI；另一种则是产品应用公司基于现有大模型去做，典型如Manus。 周鸿祎认为，OpenAI这次发布的智能体把几个产品拼凑到一块，和Manus、360纳米AI相比，能力还是显得比较单薄，国内做智能体有很大优势。 不过，最近Manus放弃国内市场转向海外，一定程度表露出国内发展智能体面临的潜在挑战。 周鸿祎对此表示，现在AI运营成本很高，广告模式不再适用，而国内又没有培养起付费习惯，这就会导致Manus在国内会存在变现的问题。 “Manus非常创新，相当于第一个走出来让大家看到了真正能独立干活的智能体是什么样子，但我不是特别认同它所说的通用智能体的概念。” 周鸿祎认为，今天大模型的能力还无法实现通用智能体，未来面向企业的专业智能体会大行其道。 “未来所有的行业都有机会被智能体重塑，智能体就是数字伙伴、数字员工。这会取代很多低层次的工作，员工会变成AI指挥官的角色，未来不会做智能体的人会被淘汰掉。” 他还谈到了行业关注的DeepSeek流量下滑、黄仁勋中国行等话题。最近，Kimi、通义千问先后更新模型，冲到开源模型阵营前两名，市场也都在期待DeepSeek-R2何时发布。 “DeepSeek可能在憋大招。”周鸿祎表示，DeepSeek并不在乎流量，但包括360等做智能体的不少公司都在用DeepSeek模型，其对中国大模型产业做出了两大贡献。 具体来看，一是消除了百模大战，不再重复造轮子；二是显示出开源开放路线的重要性，使得国内这种开放生态未来有可能形成对美国所走的垄断和封闭道路的优势。 对于是否有复购英伟达H20的计划，周鸿祎表示，最近采购的都是华为的产品。“国产跟英伟达肯定是有差距，但必须要用，你都不用，这个差距永远都存在。” 这也意味着国产芯片的机会。周鸿祎认为，H20更适合推理，定位有点尴尬，国产芯片也在推理上发力，成本和性价比追上H20难度没有那么高。 过去一年多的时间，周鸿祎在全力打造个人IP，通过直播、短视频积极做网红。他表示，做这些主要是为了给产品“带货”，“我尽可能把我的粉丝都转成了纳米用户”。 他还认为，现在做博主的机会依然非常大。“对普通人来说，对一家初创公司来说，这个机会和赛道必须抓住，要不然连发声的渠道都没有。” 接下来，周鸿祎也计划用AI打造几个智能体，来帮助提高工作效率。“需要去求变，做点新内容出来。如果不求变，大家的兴趣爱好会转移，没有谁会长青。” 以下是此次对话精编： 大模型以前更像玩具 智能体是进化的新阶段 媒体：您怎么看最近智能体的发展？它跟大模型是什么样的关系？ 周鸿祎：大模型在今年初的DeepSeek的突破下，从原来的知识问答进化成推理模型，能做推理，能做规划，能够分解复杂任务。 但在智能体概念出来之前，大模型更像一个玩具。即使装上了DeepSeek，就是当一个聊天机器人在用，感觉还是处在一个玩具的阶段，并没有真正变成大家所梦想的新质生产力的打造工具。 智能体恰恰弥补了大模型的不足，是大模型进化的一个新阶段，和大模型并不矛盾。大模型扮演大脑的角色，智能体扮演身体、手和脚的角色。 智能体相比大模型有两个主要提升，第一个是能使用各种工具，比如编程、浏览器等，能力增强很多。第二能借助大模型的规划能力，把复杂任务从头执行到尾，更像是使用工具的数字伙伴。 媒体：OpenAI最近发布了ChatGPTAgent，感觉怎么样？如何看待中国在这块的机会？ 周鸿祎：OpenAI这次比较匆忙，ChatGPT长期定位于聊天助手，缺乏执行任务和多步骤规划的能力。这次把几个产品拼凑到一块，我感觉和Manus、360纳米AI相比，能力还是显得比较单薄。在智能体这块，中国的应用场景最丰富，中国的发展很有机会。 媒体：Manus最近放弃国内业务转向海外，是不是意味着智能体在国内商业模式面临较大挑战？ 周鸿祎：原来互联网运营成本很低，只要有足够多的用户，DAU足够高，可以有广告模式，羊毛出在猪身上。但现在AI运营成本很高，智能体随便完成一个任务都要花几百万个token，广告模式就不work了，要让用户直接收费。 但中国的付费习惯比欧美市场要差一些，这需要一个过程。所以整个互联网不要太内卷，你想收费巨头都免费。对Manus这种公司来说，融了资就要有收入，这里面有商业模式变现的问题。 媒体：很多观点认为Manus没有技术壁垒，套壳的底层大模型会吃掉智能体的能力，您怎么看？ 周鸿祎：国外做编码智能体的几家公司，做到一定时候，你会发现它不是简单的套壳。这里面工程化的能力非常重要，所以智能体要往专业去走，如果往通用走，一定会跟大模型时候撞在一块。 我觉得智能体真正的壁垒是什么呢？专业的推理模型、专业的数据和知识库、专业的工具、专业的业务流程。只有做专业垂直的智能体，才能形成自己的技术壁垒。 专业智能体会大行其道 未来两年会逐渐普及 媒体：业内有通用和专业智能体的争论，Manus就是定位通用智能体，怎么看这两种模式？ 周鸿祎：Manus非常创新，相当于第一个走出来让大家看到了真正能独立干活的智能体是什么样子，这点我是非常肯定的，但我不是特别认同它所说的通用智能体的概念。 通用智能体意味着对任何事情，对任何业务，大模型都具备泛化的分析和推理能力，今天大模型的能力远远不够。 我认为在企业市场，专业智能体会大行其道。未来的智能体，会是虚拟顾问或虚拟专家，要结合不同行业，不同业务领域，建立不同特长的智能体。 媒体：您如何智能体未来的发展前景？哪些行业最可能被智能体重塑？ 周鸿祎：我觉得所有的行业都有机会被智能体重塑，智能体就是数字伙伴，数字员工。企业有比较繁琐流程可以自动化的部分，可以降低对人的依赖的工作，都可以拿智能体来重塑。 所以未来智能体会取代很多员工的工作，低层次的工作取代了，就要做高层次的工作，员工的工作会变成去定义智能体、规划智能体、设计智能体、管理职能体、监督、协调智能体。 未来不会做智能体的人会被淘汰掉，如果能定义、指挥智能体，会变成AI指挥官的角色，这样的人在AI时代会屹立在潮头浪尖。 媒体：360是如何使用智能体重塑产品的，效果如何？ 周鸿祎：我们做了大概四件事情，首先是在安全上，我们把安全里面所有过去人类专家做的工作，自动发现、自动防御、自动分析，都变成智能体。 第二是用智能体改造我们的浏览器和360搜索。在浏览器里面加入了很多智能体，把浏览器变成AI浏览器。搜索也变成只要提问题，直接给你答案，还可以直接给方案，甚至直接出成果。 我们马上要宣布纳米的智能体平台，打造纳米的智能体社区。现在里面已经有5万个智能体，像是AI版的的Boss直聘，你变成boss，可以来这寻找合适的智能体帮你干活。 媒体：智能体的落地在功能和成本上还有一定困难，专业智能体普及大概需要多长时间？ 周鸿祎：算力发展的指数曲线比摩尔定律更陡，经过这两年降到了原来的1‰，还在继续下降。如果把推理芯片和训练芯片分开，推理成本还会进一步降低，所以成本不是问题。 对企业来说，现在做智能体正当其时，但别一上来就做CEO智能体，难度比较高。但可以先做会计智能体，文员智能体，报审合同的智能体，简单的智能体可以先在企业内部用起。 我觉得未来两年会逐渐普及。最近我在各地转悠，大家已经不谈大模型，都在谈智能体。智能体是车，大模型是发动机，没有发动机，车跑不起来，但天天谈发动机没有意义，最终需要的是车。 DeepSeek解决了两个问题 国产芯片追赶H20难度不高 媒体：最近说DeepSeek的流量在下降，其它大模型APP流量在上涨，您怎么看？ 周鸿祎：DeepSeek官网流量确实在下降，他们就没花心思做。但很多第三方的云服务商，流量一直很高。梁老板就没有想认真做APP，流量涨得最厉害的时候网站速度慢的要死，他都不在乎。他也没有往智能体发展，是一门心思要搞AGI。 所以他是一个有梦想的人，而且把第一流的模型开源免费。中国有很多公司，包括我们做智能体里的基座模型，都是用DeepSeek来改，把满血版做成蒸馏板，将成本能降到很低。 我相信很多做智能体的公司背后的基座模型里面，至少有1到2个是DeepSeek模型。相当于很多公司的武器装备都是DeepSeek提供的，不能简单去看他们自家的流量。 媒体：从年初的DeepSeek-R1到现在，您预计R2下半年会推出吗？ 周鸿祎：DeepSeek可能也在憋大招。国外几家大模型的能力又增强了，最近像kimi、千问的能力也都赶上来了，就看DeepSeek能不能再次发力了。 但这没关系，DeepSeek给中国大模型产业开了很好的头，解决了两个问题。一是消除了百模大战，不用再去重复发明轮子。第二是让大家知道，中国只要坚持开源开放，不仅对中国的大模型产业会有发展，而且这种开放生态有可能形成对美国所走的垄断和封闭道路的优势。 所以Kimi向它学习开源，千问坚持开源，只要有模型坚持开源，坚持赶上国际一流团队水平，对中国发展就是利好，指望一家公司连续得很多金牌也不现实。美国Grok、Gemini，还有Claude、OpenAI，这几家也是交替演进，今天你超我，明天我超你。 媒体：前两天您发了解读黄仁勋中国行的视频，H20重启在华销售，360会不会去采购？ 周鸿祎：我们在往国产上转，国产跟英伟达肯定有差距。但必须要用，你都不用，这个差距永远都存在。我们这行里有一句话，叫自己的狗食自己吃。一定要坚持用，用了才能改进。 我们最近采购的都是华为的产品。H20定位有点尴尬，老黄的手术刀很高明，割得太多，可能性能太差卖不掉，割得太少，又批准不了，所以使得H20更适合做推理，训练上弱很多。 国内在推理芯片上有很多机会，推理芯片不需要芯片高速互联，不需要组成集群。所以现在国产芯片在推理上发力，成本和性价比追上H20难度没有那么高。 媒体：有观点认为，黄仁勋推动恢复销售H20没安好心，或者说是某种糖衣炮弹，您如何看待这种观点？ 周鸿祎：不能这么说，我觉得企业家并不想卷到大国的政治里面去。他很单纯，跟马斯克不太一样。对他来说，就是要对投资人负责，为梦想负责，肯定想把最好的产品卖给中国。 所以他费了很大努力把这些产品卖给中国，中国也需要。这就跟特斯拉进来，成了鲶鱼，对中国新能源车产业起到一个正向的推动作用。未来保持开放沟通，对中国的发展一定是有好处。（转载自搜狐科技） 谷歌母公司Q2营收964.3亿美元，同比增长14% 对话周鸿祎：DeepSeek流量确实在下降，他们就没花心思做，梁文锋是有梦想的人 白宫官宣！特朗普发布《美国AI行动计划》，OpenAI、微软、亚马逊成大赢家 阿里Qwen3-Coder开源引发全球AI社区狂欢！HuggingFace CEO 连转带发12条推盛赞 智象未来E1.1再登Artificial Analysis榜单 奥尔特曼：AI浪潮下人工客服冲击影响最大，未来恐完全被替代 举报/反馈"
    },
    {
      "doc_id": 49812,
      "title": "PPIO发布AI报告:2025年上半年国产大模型调用量十大趋势",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "2025年上半年，各种现象级智能体应用层出不穷，Manus、Flowith、扣子空间、Lovart、MiniMaxAgent、KimiDeepResearch等。 智能体应用爆发背后，证明了大模型的智能水平已经达到相当可靠、可用的阶段。其中，开源模型发展迅速，在性能上已经整体逼近甚至追平闭源模型，以DeepSeekR1、Qwen3-235B-A22B、KimiK2为代表的模型已经跻身全球top级模型。同时，开源模型大大降低了模型成本，AI推理成本正以每年10倍的速度降低。 PPIO提供国内主流开源模型服务，包括DeepSeek、阿里Qwen、MiniMax、Kimi、智谱GLM等，是国内开源模型服务最全面的AI推理云平台之一。根据PPIO平台的大模型tokens调用量，我们总结了2025年上半年国内大模型十大趋势。 趋势一：DeepSeek与Qwen分别占据半壁江山，是国内最受欢迎的两大开源模型 去年开源模型的影响力远没有今年大，很多人也并不认为开源模型的性能可以与闭源模型媲美。但DeepSeek的出现改变了这一局面。 DeepSeek有两个大版本，一是base模型V3，首发于2024年12月份，并在2025年3月24日发布更新版本；二是推理模型R1，首发于2025年1月份，并在2025年5月28日发布更新版本。2025年第一季度，DeepSeek模型一枝独秀，在PPIO的使用占比高达99%。直到5月份后，DeepSeek的使用量占比开始有所下降，主要是因为更多优秀模型出现，用户对于模型的选择更加多元化了。 Qwen就是其中的一个代表。PPIO目前上线了Qwen的三个系列——Qwen2、Qwen2.5和Qwen3，前两者是2024年发布的模型，Qwen3在今年4月29日首发上线PPIO。从2025年第二季度开始，PPIO平台的Qwen模型的使用量开始高速增长，到5月下旬时调用量占比超过一半，最高时达56%，与DeepSeek一同称为最受欢迎的两大开源模型。 趋势二：尽管DeepSeekR1为代表的推理模型引领了强化学习的技术范式，但DeepSeekV3这一类非推理模型却更受欢迎 推理模型始于OpenAIo1模型，特指使用强化学习、思维链（CoT）等技术来训练的模型，可以将复杂任务场景通过多步骤推理生成答案，思考时间越长，模型性能越强。PPIO平台上线的推理模型包括DeepSeekR1、QwenQwQ、Qwen3系列、GLMZ1等。 2025年2月份，推理模型受到广大AI开发者的青睐，其全平台的使用量占比保持在50%以上。但从3月份开始，非推理模型的使用量反超推理模型，并一直延续至今。 这一现象在DeepSeek的推理模型R1和非推理模型V3的调用量中也得到了印证。2025年2月份，R1在DeepSeek模型中的tokens调用量要高于V3，占比超50%。但从3月份开始，R1之外的非推理模型tokens调用量逐渐上升，并长期保持在60%以上。 DeepSeekV3比DeepSeekR1更受欢迎，这一现象背后的原因在于不同模型适用于不同的用户需求。 DeepSeekV3这一类基础模型适用于日常对话、文本生成、多语言处理等高频需求，用户面广，使用门槛低，而且这一类应用场景通常并不需要复杂的推理过程；而DeepSeekR1专攻数学竞赛、代码逻辑等深度推理任务，而且由于深度推理需要消耗更多算力，输出成本更高，R1百万tokens成本大约是V3的2倍。 趋势三：DeepSeek的数学模型、蒸馏模型的用户使用量较小，更大的意义在于推动行业研究 在V3与R1两大主力模型之外，DeepSeek还开源了ProverV2数学模型，以及基于Qwen等基础模型的R1蒸馏模型。 Prover是DeepSeek专门为数理逻辑与高复杂度任务而设计的数学模型，PPIO在4月30日首发上线了ProverV2671B；R1蒸馏模型则是基于Qwen模型而蒸馏的1.5B、7B、14B、32B四个不同型号的模型，在数学基准测试上优于GPT-4和Claude-3.5-Sonnet，甚至在多项能力上对标o1-mini，PPIO也在第一时间部署上线。 由于这两个系列的模型面向的用户场景较为垂直，相比V3与R1的使用量较小，仅占DeepSeek系列的1%。不过，这两款模型对于推动AI行业的基础研究有着重要的意义。 趋势四：免费的Qwen2.5调用量远高于性能更强的Qwen3，说明相比模型性能，价格依然是用户选型最关心的因素之一 Qwen是国内最早的开源模型之一，生态布局广泛。在2025年HuggingFace的全球开源大模型榜单中，排名前十位的模型全是基于Qwen系列二次开发的。 在PPIO平台的Qwen模型中，最受欢迎的是Qwen2.5。PPIO在4月下旬针对Qwen2.5-7B-instruct等模型开放限时免费活动，该系列模型的tokens消耗激增，整体消耗占Qwen系列整体的90%以上。即使在Qwen3发布后，Qwen2.5依然保持了强劲的用户需求。 如果抛开免费模型，Qwen3的tokens消耗量占据Qwen付费模型的23.48%，在5月中旬的使用量一度达到37%。Qwen3在业内率先支持混合思考模式，支持119种语言和方言，针对模型编码和代理能力做了重点优化，并增强了对MCP的支持。 趋势五：在图片生成模型中，文生图与图生图的调用量占比约为9：1 PPIO平台不仅提供大语言模型API服务，也提供图像与视频生成等多模态API服务，但在不同场景用户有不同的使用偏好。 在生图领域，用户更喜欢使用文生图模型而非图生图模型。2025年上半年，文生图模型的使用占比从1月份的70%增长到6月份的90%。 相比图生图，文生图的创作门槛更低，文字描述可以更加精准地传达用户的想法与创意，并为用户提供更多的创意灵感。而且，文生图模型经过大量的数据训练，能够生成具有较高美学价值和质量的图像。 趋势六：在视频生成模型中，文生视频与图生视频的调用量约为1：9 视频生成模型的用户使用习惯与图片生成模型恰恰相反，用户更加侧重于图生视频而非文生视频。图生视频模型的使用占比从1月份的20%左右，增长到6月份的90%以上。 图片生成视频模型的优势在于可控性更高，稳定性更好。相比文生视频常见的不确定性和难以控制的结果，图生视频模型能够更好地保证视频生成的质量和连贯性，同时也符合视频创作者的从业习惯和工作流程。在视频生成领域常见的工作流程是，先用文生图模型生成图片，再用该图片生成视频。 趋势七：StableDiffusionXL逐渐替代StableDiffusion1.5，成为最受欢迎的图片生成模型基础架构 在生图领域，StableDiffusion1.5与StableDiffusionXL是两大最受欢迎的生图模型基础架构，有大量模型基于这两大架构进行二次微调，合计占据平台使用量的80%以上。其中，SD1.5可支持二次元、卡通与写实风格，SDXL更适合写实、摄影、插画等细腻风格。 从3月下旬开始，SDXL系列模型使用量迅速增长，反超SD1.5系列模型。SD1.5系列模型的使用量在2月份高达65%左右，但到5月份已经降低到22%左右；SDXL系列模型的使用量在2月份为18%左右，到5月份已经增长到70%。 究其原因，SDXL由于参数量更大且采用Base模型和Refiner模型组合，生成图像细节、色彩、对比度更优，生成图片细节丰富，对自然语言理解更强，社区支持和插件兼容性也逐渐提升。 Flux.1模型的整体占比在3%左右，未见有明显的增长。 趋势八：阿里万相是国内最受欢迎的开源视频模型 在2月份，视频生成模型主要有两类：一是文生视频的AnimateDiff，这是基于StableDiffusion的动画生成工具，使用量占比大约在70%；二是图生视频的StableVideoDiffusion，使用量占比大约在20%。 从3月份开始，腾讯的开源视频模型HunyuanVideo与阿里的开源视频模型Wanxiang（万相）上线后，国内开源视频模型开始高速增长。到6月份，阿里Wanxiang使用量占全平台的80%以上，成为PPIO平台最受欢迎的国产视频开源模型。 6月份，PPIO首发上线MiniMax-Hailuo-02视频模型，这是全球范围内图生视频领域排名第二的SOTA模型，上线第一周就斩获了1.5%的使用量。 趋势九：出海需求高涨，约20%用户的AI应用场景面向海外 全球AI市场空间是国内的几倍，海外用户对AIGC产品的创造性和付费意愿可能比国内更强，如东南亚、非洲等地区市场潜力大。国内AI领域的创业团队和独立开发者更灵活、更迅速地在全球市场崛起。 在PPIO平台，不少客户“立足国内，服务全球”，有大约20%的AI应用场景面向海外。 趋势十：2025，智能体大爆发 大模型的业务场景分布在各行各业。可以说，从国有银行到街边奶茶店，从手术台到炼钢炉，大模型已没有行业死角。 在PPIO平台。情感陪伴类应用、创意内容生产类工具、办公效率类工具以及高校科研项目是对AI最大需求方。 同时，2025年上半年智能体应用也在快速爆发，Manus、Flowith、扣子空间、Lovart、MiniMaxAgent、KimiDeepResearch等智能体获得非常高的关注度。 针对智能体应用，PPIO平台将在WAIC期间正式发布AgentSandbox（沙箱）产品，敬请期待。 （CIS） 举报/反馈"
    },
    {
      "doc_id": 49813,
      "title": "DeepSeek重塑AI大模型游戏规则",
      "time": "2024-02-13T00:00:00+00:00",
      "content": "图片使用DeepSeek-R1和Midjourney V5.2生成。2025年开年，新一轮AI“风暴”席卷全球，“风暴眼”则是有“AI界拼多多”之称的DeepSeek，它以低成本训练+开源模式重塑了当下AI大模型行业的游戏规则。在DeepSeek冲击之下，芯片巨头英伟达股价出现历史性暴跌，1月27日美股收盘，英伟达公司股价下跌16.97％，市值在一天内蒸发近6000亿美元，创下美股历史上一家公司的单日最大市值损失。资本市场的反映只是冰山一角，DeepSeek掀起的浪潮在应用市场、安全领域也引发了空前的变革。一次发展路径的“大变革”当全球科技界仍就ChatGPT的升级与变革议题争论不断时，一家名叫深度求索（DeepSeek）的中国AI企业因一系列AI产品的发布骤然成为舆论关注的焦点。近期DeepSeek推出的新品包括语言模型V3、推理模型R1以及多模态模型Janus-Pro等，在性能、成本、开源等多个维度带来了令人震撼的影响。1月27日，苹果App Store中国区免费榜显示，DeepSeek站上首位，同时其在美区苹果App Store免费榜从26日的第六位飙升至第一位，超越ChatGPT、Meta旗下社交媒体平台Threads、Google Gemini、Microsoft Copilot等美国科技公司的生成式AI产品。实际早在此前，DeepSeek公司就已经因为“性价比高”而引发AI圈震动。比如2024年5月，其最新语言模型DeepSeek-R1在国际权威测试中，以十分之一的成本达到了与GPT-4o相当的表现的消息，迅速引发海外开发者论坛热议。近期，美国总统特朗普也表示DeepSeek的出现“给美国相关产业敲响了警钟”，美国“需要集中精力赢得竞争”——这场来自东方的技术突袭，正在改写全球AI竞赛的底层规则。此次AI圈的震动折射出DeepSeek的突围逻辑——当美国科技巨头执着于“更大参数、更强算力”的军备竞赛时，中国团队选择了一条截然不同的道路。与ChatGPT动辄数千亿参数的庞然大物不同，DeepSeek-R1通过算法层面的创新，在保证性能的前提下将模型体积压缩了80％。其核心技术如同给AI模型装上“智能开关”，让系统能够自动识别任务难度，灵活调用计算资源。这种“量体裁衣”的策略，使模型既能在处理复杂问题时调动深层神经网络，又能在简单场景中保持极低能耗。此外，不同于OpenAI的封闭路线，DeepSeek从一开始就将开源作为核心战略。在其官网上，任何人都能下载包括模型架构、训练方法在内的全套技术文档。这种开放姿态很快形成“滚雪球”效应：使用者不仅借助DeepSeek提供的技术资源进行二次开发和创新，还积极贡献自己的代码、数据和见解，进一步丰富了DeepSeek的生态系统。开源不是技术慈善，而是最聪明的竞争策略。目前看来，DeepSeek通过开放基础模型吸引全球开发者共建生态，既降低了企业定制AI系统的门槛，又通过社区反馈持续优化模型。这种“众人拾柴”的模式，恰好破解了AI商业化中最大的痛点——高昂的定制化成本。DeepSeek团队“用中国方法解决世界问题”的背后，是团队在技术路线上的几个关键抉择：首先，在算力受制于人的背景下，他们放弃盲目追逐“万卡集群”，转而与华为等国内厂商深度合作，开发出适配昇腾芯片的专用推理引擎，使国产硬件效率提升5倍；更重要的是，将“成本可控”写入技术基因——通过独创的混合精度计算技术，让模型在训练时自动选择最优数值精度，相比传统方法减少40％的算力浪费。这些选择正在重塑行业认知：无需复刻硅谷的烧钱模式，通过算法创新和系统工程同样能实现突破。这种“低成本创新”的能力，或许比技术本身更具启示意义。DeepSeek引发的震动，本质上是对AI发展单一化路径的打破。当全球科技行业苦于大模型落地难题时，这条融合算法突破、开源生态与国产化创新的道路，不仅为AI普惠提供了新解法，更预示着技术竞争正在进入多元化的新纪元。或许，最激动人心的AI突破，就是来自那些重新定义游戏规则的人。一场应用生态的“大爆发”2月初，三大基础电信运营商全面接入Deep-Seek开源大模型，基于该模型，中国电信天翼云率先落地全栈国产化推理服务，联通云上架Deep-Seek-R1系列模型实现多产品场景调用，移动云深度集成DeepSeek模型为用户带来“开箱即用”的使用体验。凭借其创新的技术架构和显著的成本优势，DeepSeek迅速在各行各业掀起了一场应用生态的“大爆发”。DeepSeek开源大模型的开放，为企业数字化转型提供了低门槛、高效率的AI引擎。作为汽车行业的领军企业，广汽集团率先将自主研发的ADiGO SENSE端云一体大模型与DeepSeek-R1完成深度融合。DeepSeek-R1的轻量化特性使车载系统在语音交互、场景感知和个性化服务等方面实现了质的飞跃，深度融合后的ADiGO SENSE端云一体大模型可接受多种模态信息输入，能够更精准地解析模糊指令，打造出更智能、更人性化的车载体验。除了汽车行业，DeepSeek在金融、医疗、教育、制造等领域也展现出巨大的应用潜力。重庆农商行企业微信上线基于DeepSeek模型的智能助手应用进行风险评估和欺诈监测，提升风险预警精准度；智云健康将DeepSeek-R1模型接入自研医疗人工智能系统“智云大脑”，增强数据挖掘能力，提高数字化慢病管理效率；网易有道借助Deep-Seek-R1超长思维链所提供的思考及分析能力，进一步优化个性化答疑功能，实现个性化教学；通过DeepSeek-R1的强推理能力，中控技术实现了工业APP的智能构建，开启了“设计即开发，开发即应用”的全新工业APP构建范式，并宣布将在今年发布以DeepSeek为核心基座大模型的工业AI产品。DeepSeek的行业赋能，正在重塑传统产业格局。此外，DeepSeek为企业提供了全新的智能化解决方案，帮助企业降本增效。物流企业利用DeepSeek优化配送路线，降低了运营成本；人力资源部门通过DeepSeek进行智能招聘，提高了人才匹配效率；电商平台应用DeepSeek实现智能客服，提升了客户满意度；零售企业借助DeepSeek进行精准营销，提高了转化率；科技公司凭借DeepSeek的代码生成和测试能力，加速了产品迭代。DeepSeek的B端赋能，将为企业创造新的增长点。DeepSeek-R1的发布，标志着AI技术从“高冷”走向“亲民”。其强大的自然语言处理能力和丰富的应用场景，迅速吸引了大量用户参与体验。APP日活跃用户数从100万飙升至3000余万，背后是DeepSeek-R1在智能对话、翻译、写作等基础功能上的卓越表现，以及其在个性化服务上的创新突破。在C端市场，DeepSeek-R1不仅可以进行智能对话、翻译、写作等常规操作，还能根据用户需求提供个性化服务，例如，定制旅游路线、推荐美食、生成专属音乐等。其“亲民”的特性和强大的赋能实力，将AI带入寻常百姓家，成为人们工作、学习和娱乐的智能助手。随着DeepSeek应用的增加，算力需求将持续增长，推动AI产业链从上游芯片到下游应用的全面爆发，从而带动技术的突破与创新，进一步激发创新应用的涌现和商业模式的多样化。这款更“亲民”的AI凭借其强大的赋能实力，正在重塑各行各业，推动AI产业生态的繁荣发展。一个网络攻防的“分水岭”在AI技术飞速发展的当下，网络安全形势正经历着深刻变革。近期DeepSeek遭遇的网络攻击事件，无疑成为观察这一变化的重要窗口。中国电信安全公司网络监测数据显示，从2025年1月22日开始，DeepSeek遭受大规模DDoS攻击。六次大规模反射放大类型DDoS攻击，攻击峰值从数十Gbps到一百Gbps不等，主要为DNS、NTP、SSDP等反射放大攻击类型。攻击者在境外通过仿冒客户真实域名的IP地址，向NTP和DNS等服务器发起大量伪造请求，利用境外服务器的应答造成实际的反射放大攻击效果。攻击者的反射放大攻击量级达百G级别仍未达到预期效果，在1月26日至2月6日升级了攻击手段，发现有Hailbot和RapperBot家族控制的僵尸网络集群发起持续的HTTP代理攻击，反射放大类型和HTTP代理多种攻击方式混合使用，攻击频率和强度都有所提升。“这种高度规模化的网络攻击，是AI时代网络安全态势最显著的变化之一。”中国电信安全公司抗D产品线负责人孙安吉在接受采访时表示。AI技术的发展不仅提升了生产力，也为网络攻击提供了更强大的工具，使攻击的规模和强度都达到了新的高度。在应对这种高强度、大规模的网络攻击时，电信运营商作为国内通信骨干网的运营者和维护者，具有得天独厚的优势。“因为有骨干网，我们永远处在流量的上游。”孙安吉介绍。在DeepSeek遭遇网络攻击后，中国电信凭借强大的骨干网监测能力，第一时间监测到异常流量，迅速上报主管部门，积极参与协同防御工作。中国电信充分发挥自身规模化的流量清洗优势，通过先进的算法和技术，对恶意流量进行精准识别和有效防御；同时，利用安全大模型实时更新防护策略，根据攻击的特点和变化及时调整防御措施，成功阻止了恶意流量对DeepSeek的攻击。围绕DeepSeek展开的网络攻防，给国内众多数字科技领军企业敲响了警钟。以往依靠单纯增加软硬件产品投入来抵御外部网络安全威胁的传统方式，在AI时代正面临全新挑战。未来，提升网络空间“感知风险、看见威胁、抵御攻击”的整体安全能力，及时发现并识别外来的网络入侵行为显得尤为关键。2月初，三大运营商相继宣布全面接入Deep-Seek，充分发挥各自在网络、平台、渠道等领域的资源优势，推动DeepSeek在多场景、多产品中的落地应用。AI加速向应用侧融合的趋势，在带来便利和创新的同时，也给网络安全防护带来了新的挑战。“今天，AI在应用领域的扩展速度比大家曾经预想的更快，AI能力下沉到边缘侧、终端侧，这是网络安全在AI时代面临的全新命题。”中国电信安全公司市场部负责人冯晓冬表示，“闭源大模型面临的网络安全问题主要集中在大模型厂商、算力厂商、云厂商，随着开源大模型在终端侧的广泛应用，中小企业和个人用户虽然能够便捷地掌握AI技术，但由于技术和资源的限制，很难具备高水平的安全防护能力。”冯晓冬进一步指出，AI在端侧的加速部署，从长远来看，有利于国内网络安全产业打破“规模受限、资源分散”的格局，加速产业链上下游的融合以及网络安全能力的开放。“位于网络侧的运营商，具备端到端的网络触达能力以及安全资源配置、流量调度、威胁监测能力；而居于终端侧的头部网络安全厂商，拥有新的算法和AI应用。网络侧和终端侧加速能力的整合开发，将成为网络安全产业在AI时代实现突破和发展的新契机。通过双方的优势互补和深度合作，有望构建更加完善、高效的网络安全防护体系，共同应对AI时代的网络安全挑战。”AI时代的网络安全形势复杂多变，既充满挑战也蕴含着机遇。只有不断创新和完善网络安全防护体系，加强产业协同合作，才能在这场网络攻防的较量中占据主动，保障数字经济的健康发展。"
    },
    {
      "doc_id": 49822,
      "title": "DeepSeek获全球AI应用排行榜第二,我国多款产品跻身世界前列",
      "time": "2024-03-07T00:00:00+00:00",
      "content": "来源：财闻网 日前，全球著名投资基金、咨询公司Andreessen Horowitz发布备受瞩目的2025年全球100生成式AI消费级应用排行榜。本次榜单分为网页版和移动版，各包含50款生成式AI应用，旨在评估全球范围内生成式AI应用的受欢迎程度和技术实力。 中国人工智能企业深度求索（DeepSeek）在此次榜单中脱颖而出，其AI应用荣获网页版排行榜第二名，仅次于行业巨头ChatGPT。 DeepSeek自2025年1月20日正式上线以来，凭借在深度学习与神经网络技术上的突破，特别是在图像生成与自然语言处理领域的出色表现，迅速积累了大量用户。在上线后的短短10天内，DeepSeek便跃居全球AI产品排行榜第二位，仅次于ChatGPT，展示了其强大的技术实力和用户吸引力。 其移动端产品也于1月25日推出，并在5天内便登上月活跃用户排行榜第14位，随后在2月更是跃升至第2位，尽管因政策原因在部分国家被禁导致用户数量有所下降，但其整体表现依然令人瞩目。 DeepSeek的成功并非偶然。公司在年初正式发布DeepSeek-R1大模型后，便致力于通过技术创新提升用户体验。DeepSeek的AI聊天机器人在推出后迅速积累了大量流量，并在短时间内实现了用户数量的快速增长。根据统计数据，DeepSeek的用户中，21%来自中国，9%来自美国，8%来自印度，显示了其全球化的用户基础。 除了DeepSeek外，中国其他知名大模型也在此次榜单中表现出色。字节跳动的豆包在网页版排行榜中排名第10，月之暗面排名11，大模型独角兽MiniMax旗下的海螺视频排名12，快手可灵排名20，全部超过了此前火爆全网的Sora、Midjourney、Runway等同赛道知名产品。在移动端排行榜中，百度AI搜索排名第4，夸克AI排名第6，豆包排名第7，美图排名第17，同样展示了中国AI企业的强大实力。 DeepSeek的此次获奖不仅是对其技术实力的肯定，也是对中国AI企业在全球范围内影响力的提升。随着技术的不断进步和应用场景的不断拓展，DeepSeek有望在未来继续引领AI领域的发展潮流，为全球用户提供更加智能、便捷的服务。 多款产品跻身世界前列 全球投资基金Andreessen Horowitz发布了2025生成式AI消费应用榜单，多款中国产品表现出色，排名靠前。其中，杭州深度求索公司的DeepSeek作为今年最大黑马，其移动端用户增速更是超越了ChatGPT的纪录。 此外，在AI大模型领域，中国同样取得了令人瞩目的成就。全球知名的AI模型评测平台ChatbotArena在2025年2月发布的最新榜单显示，中国AI大模型占据了多个席位。 深度求索的DeepSeek-V3和DeepSeek-R1凭借出色的性能和低成本高效率的开发策略，赢得了业界的高度认可。同时，阿里云的通义千问系列大模型也表现出色，其中Qwen2.5-Max以1332分的成绩位列全球第七，展现了强大的技术实力。 中国AI大模型的突破不仅体现在技术和性能上，更在于其创新的发展模式和开源贡献。以阿里云为例，其通义大模型家族已全面涵盖语言、图像、视频、音频等全模态，性能均跻身世界第一梯队。 同时，阿里云还积极推动开源生态建设，通义模型持续开源，已成为最受企业和开发者欢迎的国产大模型。Qwen系列衍生模型的数量也达到了7.43万，首次超过Llama，成为世界上最大的生成式语言模型族群。 中国AI大模型的集体突围引发了业界的深度思考。过去，AI领域普遍认为只有投入巨额资金才能开发出高性能的大模型。然而，中国企业通过创新的低成本开发模式，正在改写这一认知。他们不仅在技术上取得突破，更重要的是找到了一条可持续发展的道路。 这种发展模式的意义远超技术层面，它大大降低了AI技术的准入门槛，让更多企业有机会参与大模型开发；同时，降低成本也意味着可以为用户提供更具竞争力的价格，推动AI技术的普及应用。 随着中国AI大模型的崛起，全球AI竞争格局正在发生深刻变化。中国AI企业的成功不仅展示了中国科技创新的实力和潜力，也为全球AI领域带来了新的发展机遇和挑战。此次中国AI大模型在全球的亮眼表现，不仅是对中国科技创新实力的有力证明，也是对未来全球AI竞争格局的一次重要重塑。 AI大模型产业蓬勃发展 随着数字化转型的加速和智能化需求的不断提升，我国AI大模型产业正迎来前所未有的发展机遇。而近日，一系列关于AI大模型产业发展的新闻动态，彰显了我国在人工智能领域的强劲动力和广阔前景。 据最新数据显示，2024年我国AI大模型市场规模已达到约294.16亿元，预计2026年将突破700亿元。这一市场规模的持续扩大，不仅反映了我国企业对于AI大模型应用的强烈需求，也预示了该产业的巨大发展潜力。 同时，随着技术的不断进步和应用场景的拓展，AI大模型已在娱乐、电商、工作以及垂直领域等各类应用中展现出强大的赋能作用，提升了业务效率和智能化水平。 在地方政府层面，苏州市在推动AI大模型产业发展方面走在了前列。2025年2月14日，苏州市举办了“人工智能+”创新发展推进大会，会上发布了高水平建设“人工智能+”创新发展试验区的若干措施，并推出了支持核心技术攻关、支持大模型创新应用等14条政策，单项支持最高达1亿元。这些政策的出台，无疑为苏州市AI大模型产业的发展注入了强劲动力。 此外，苏州市还聚集了众多核心企业，构建了从科创型中小企业到行业龙头的完整企业梯度体系，初步形成了涵盖人工智能基础层、框架层、模型层、应用层等较为完整的产业链。 在技术创新方面，我国企业也取得了显著进展。例如，多模态大模型的发展使得AI能够更全面地理解和处理复杂场景，提升了智能化水平。同时，Self-playRL（自对弈强化学习）范式等新技术的应用，也进一步优化了大模型的技术路线和性能表现。 此外，一些国产AI工具如DeepSeek，通过技术突破和生态开放，有效降低了对高端芯片的依赖程度，在多个行业和领域展示了广泛的应用潜力和实用价值。 在应用场景与落地情况方面，AI大模型已在金融、医疗、教育、制造等众多领域取得了显著成果。例如，在医疗领域，AI大模型辅助诊断和疾病预测的能力得到了显著提升；在教育领域，AI大模型个性化学习和智能辅导的能力得到了广泛应用；在制造领域，AI大模型的应用则推动了生产流程的自动化与智能化优化。 我国AI大模型产业将迎来更加广阔的发展前景。随着技术的进一步成熟和应用场景的不断拓展，AI大模型将在更多领域中发挥重要作用，推动各行各业的智能化转型和升级。同时，政府也将继续加大对AI技术的投入和支持力度，为AI大模型产业的发展提供良好的政策环境。 举报/反馈"
    },
    {
      "doc_id": 49823,
      "title": "...外媒:中国开源模型打破技术垄断 全球AI创新格局迎来“DeepSeek...",
      "time": "2024-02-28T00:00:00+00:00",
      "content": "中国日报网2月28日电 近期，中国人工智能企业深度求索（DeepSeek）发布开源模型DeepSeek-R1，被外媒誉为“人工智能的DeepSeek时刻”。这一突破标志着中国在AI领域的技术突破正深刻改变全球创新竞争格局，打破了美国对AI话语权的垄断，更以低成本、高效率和垂直应用的优势，为全球技术发展注入新动能。 今年以来，以DeepSeek为代表的开源大模型正迅速渗透到诸多行业，引发新一代人工智能技术发展新浪潮。 据行业监测数据显示，以DeepSeek为代表的开源大模型已在金融、医疗、智能制造等12个重点行业实现规模化应用，中国人工智能行业市场规模不断扩大。数据显示，2024年中国人工智能行业市场规模达7470亿元，同比增长41.0%，预计2025年达10457亿元，占全球比重达20.9%。 法国《世界报》网站2月24日刊发《中国的DeepSeek时刻》的报道称，中国大型企业纷纷将人工智能模型DeepSeek整合至自己的服务体系，几乎每日都有新进展。 2月17日，腾讯宣布将深度求索的多模态AI系统深度集成至微信搜索核心算法，这一生态系统的升级引发市场强烈反响。另一搜索引擎公司百度同样接入DeepSeek，更值得关注的是，百度宣布重大战略转向，将其文心一言大模型全面开源。这意味着全球开发者可自由调用该技术，此举被视为推动人工智能应用大规模普及的关键突破。 另据美国CNBC网站2月21日报道，中国人工智能领域迎来了一匹黑马——DeepSeek。这家初创企业在大语言模型领域的突然崛起，不仅为中国提供了一个强有力的工具来加速人工智能的普及，还被视为推动中国经济增长的新引擎。 报道称，随着DeepSeek的影响力迅速扩大，其创新成果正受到全球关注，也为中国科技生态系统增添了新的光彩。 高盛集团预测，长期来看，人工智能的广泛应用将为中国国内生产总值（GDP）带来20至30个基点的增长。高盛预计，中国经济将因人工智能驱动的自动化提升生产率而显现积极效应。高盛经济学家指出：“DeepSeek的迅速崛起表明，中国在人工智能开发和应用上的速度超过了我们的预期。” 与此同时，投资银行摩根士丹利也在本周的一份报告中表示，DeepSeek的成功促使市场重新评估中国投资潜力。 英国咨询机构特内奥情报(Teneo Intelligence)公司董事总经理加布里埃尔·威尔道强调：“DeepSeek生动诠释了中国在人工智能领域已占领或者非常接近全球发展前沿，这种技术优势显著提升了中国经济和科技生态的国际声誉，使其对全球投资者形成更强磁吸效应。” 德国《时代》周报则指出，中国AI模型的低成本与开放性“为全球科研提供了前所未有的机遇”，尤其在发展中国家加速技术普惠。 （编译：齐磊 编辑：马芮 韩鹤） 来源：中国日报网 举报/反馈"
    },
    {
      "doc_id": 49824,
      "title": "DeepSeek发布新款开源多模态AI模型Janus-Pro",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "【DeepSeek发布新款开源多模态AI模型Janus-Pro】财联社1月28日电，人工智能社区Hugging Face显示，DeepSeek刚刚发布了开源多模态人工智能（AI）模型Janus-Pro。其中Janus-Pro-7B在GenEval和DPG-Bench基准测试中击败了OpenAI的DALL-E 3和Stable Diffusion。 举报/反馈"
    },
    {
      "doc_id": 49825,
      "title": "及时雨!借DeepSeek 中国AI智能体打破OpenAI垄断 加速落地",
      "time": "2024-02-21T00:00:00+00:00",
      "content": "大模型垂类应用落地时间表提前 作者／ IT时报记者 贾天荣 编辑／ 王昕 孙妍 从大模型到AI Agent（智能体），是AI真正走向落地应用的关键一步。相比大模型，智能体更像是拥有自主决策和执行能力的“AI助手”，能主动分析、规划，并根据不同场景提供更精准、实时的服务。 市场咨询机构Gartner将AI Agent列为2025年十大战略技术趋势之首。业界认为，2025年有望成为AI Agent的商业化应用元年。 DeepSeek的横空出世大大加速AI Agent的落地速度，不到一个月，一场深刻的科技变革悄然展开。 大模型“入行”难 尽管舆论对智能体的成熟速度呈现出越来越乐观的态度，但业内人士仍普遍认为，智能体应用发展仍处于早期阶段，即业务场景探索和技术验证阶段。 泛微副总裁杨国生在接受《IT时报》记者采访时表示，当大模型应用到企业的垂直产品领域时，精准度显得尤为关键，“很多业务场景并不是简单的问答模式，而是需要更复杂的业务逻辑和场景化需求。这需要大量的工程技术介入，才能确保其真正实现企业级应用的效果。” 杨国生说，ChatGPT等通用大模型虽然在基础知识应用、数学运算和代码生成等方面展现了强大的推理能力，但当这些模型应用于垂直领域时，其稳定性却难以令人满意，“当推理某个结果时，今天的表现可能令人满意，但明天就会出现波动，甚至效果下降。这是大模型通用性与垂直精度之间的矛盾所带来的挑战，且常常伴随‘幻觉’等问题”。 此外，算力资源的限制也是当前智能体应用的一大瓶颈。在企业级应用中，由于大模型需要处理海量的参数，企业直接部署这样的模型面临巨大的算力成本压力。尤其在当前的经济环境下，许多企业无法投入大量预算购买专用的算力卡，这成为制约企业级大模型应用的基础性障碍。 因此，出于成本、精度等多方面的考虑，相较于针对个人用户的AI助手，初创企业更愿意针对垂直领域开发有针对性的行业应用垂类模型。 DeepSeek正是行业“及时雨” 短短一个春节，DeepSeek不仅大幅降低AI大模型部署的技术门槛与成本，还加速了AI的商业化进程，推动应用场景的大规模崛起，甚至大大提升AI的普及速度。AI产业的经济价值，正在从“卖水人”转向应用端。 越来越多的企业开始接入DeepSeek，更多垂直领域人工智能公司尝试或升级自己的AI Agent。 作为一家专注于能源大模型的企业，达卯智能近期接入DeepSeek，并推出最新产品——能源小达DeepSeek-R1671B。达卯智能CTO刘净在接受《IT时报》采访时表示，DeepSeek的推理能力是其最为突出的亮点之一。 刘净表示：“相比传统的大模型，DeepSeek在推理能力上实现了质的飞跃，甚至在用户体验上，它可能优于OpenAI的o1模型，甚至o3模型。” 对于像达卯智能这样的垂类能源应用企业而言，DeepSeek的推理能力填补了此前的空白。刘净进一步解释：“我们公司并不开发基座大模型，之前我们一直依赖国产自主可控的开源大模型，但为了更好地满足客户需求，我们迫切需要具备强大推理能力的模型，因此选择了DeepSeek的V3版本，并迅速接入。” 在实际使用中，刘净表示，DeepSeek提供了全链条的推理过程，真正实现从数据输入到最终用户反馈的完整闭环，“DeepSeek不仅展示了推理过程，还能将整个推理流程呈现给最终用户，极大提升了用户体验。通过结合我们的行业知识库和DeepSeek的强大推理能力，用户可以得到一个全面的解决方案，这种全新的体验之前是无法实现的。” 例如，在电费账单分析和电费解析方面，DeepSeek的推理深度相比之前的产品有了质的飞跃。 从“生成”到“做事” 同样近期接入DeepSeek的达观数据CEO陈运文告诉《IT时报》记者，DeepSeek改变了AI Agent的发展路径。在技术路线上，它没有一味依赖大模型和大算力，而是通过优化模型和蒸馏技术降低对算力的需求，让AI Agent能在边缘设备进行轻量化推理。 开发模式上，DeepSeek的开源降低了开发门槛，吸引了更多开发者参与，加速AI Agent从实验室研究向工业级应用的转变，推动了多主体协同开发，开发者的关注焦点也从注重“语言生成”转变为更重视“任务执行”，让AI Agent“实际做事”的价值更受关注。 陈运文认为，在功能上，DeepSeek能实现多模态交互，理解复杂指令，还能在复杂场景里生成最优路径；应用场景也拓宽了，在金融、医疗、制造、媒体娱乐等多个领域都能构建智能Agent，比如智能投顾、诊断辅助、供应链优化、内容创作等；协作集成方面，它预置了常用API，降低了集成成本，还支持多Agent分工协作，适用于供应链管理、智慧城市这些场景。 “强大+便宜”推动模型“平民化” LogenicAI联合创始人李博杰告诉《IT时报》记者，随着DeepSeek的出现，AI Agent领域发生了两方面的重要变化：首先是成本显著降低，其次是许多人的心态发生改变。 李博杰指出，要实现真正有效的AI Agent，能够解决实际问题并达到商业需求，需要像R1或更高级别的模型。但以往，如OpenAI等模型成本非常高，比如OpenAI的o1模型，每100万个Token的成本为60美元，而现在，DeepSeek-R1的成本仅为2美元100万个Token，缩减30倍，大幅降低成本。 对于OpenAI来说，这无疑是一个挑战，因为它长期以来锁定自己的技术，并通过高价盈利，但现在DeepSeek的出现迫使OpenAI调整策略，甚至降低o3Mini版本的价格，这表明推理模型的成本正在普遍下降。 值得一提的是，2月13日凌晨，OpenAI首席执行官萨姆·奥尔特曼公布了GPT-4.5和GPT-5的最新消息。奥尔特曼宣布，OpenAI将在未来几个月内推出名为GPT-5的模型，该模型将整合OpenAI的大量技术，包括o3模型，并应用于聊天机器人ChatGPT以及API平台，此外，更重要的是，免费版ChatGPT能在标准智能设置下无限制地与GPT-5进行对话。 李博杰还提到，成本的降低让AI Agent类应用得以普及，过去由于模型能力不够强大，效果并不理想。如今，借助DeepSeek或OpenAI o3等更强大的模型，AI Agent能够帮助解决更复杂的问题。 李博杰认为，DeepSeek的成功不仅在于技术的突破，还在于它的开源模式，这使得其对更多开发者开放，打破了以往AI技术需要巨额投入的“迷思”。OpenAI的收费体系一直较高，且最先进的模型也只限特定合作伙伴使用，而DeepSeek的出现让这些技术变得平民化，带来了根本的认知变化。 这种变化尤其体现在投资者的态度上。金沙江创投主管合伙人朱啸虎曾明确表示，他不会投资中国的AI大模型创业公司。然而，随着DeepSeek的出现，朱啸虎的看法发生180度转变，表示“大开眼界”“DeepSeek让我开始相信AGI的可能性”。 与其“做模型” 不如“接入生态” 提到个人智能助手，许多人最先想到的可能是科幻电影《钢铁侠》中的贾维斯。然而，要拥有属于普通大众自己的“贾维斯”，所需要的远远不止一家能够生产“贾维斯”的公司。 在杨国生看来，未来的AI Agent几乎会渗透每一个软件，支撑着每个功能的实现。如今，我们通常通过编写代码来开发程序，并经过测试和调试来实现功能，但未来，很多功能可能不再依赖传统的编码方式，而是由智能体自动完成。例如，计算每月的良品率，未来可能由智能体自动处理，而无需我们手动编写和调试代码。 陈运文坦言，AI Agent的全民普及仍面临瓶颈。大众对其功能和价值的理解不深，接受度较低，且专业人才匮乏，尤其缺少既懂技术、产品，又熟悉商业和生态的复合型人才。在伦理、法律与安全方面，AI决策往往缺乏可解释性，责任归属不清晰，且存在隐私泄露和被攻击的风险。未来的技术突破方向主要包括：优化模型，提高准确性、泛化能力和可解释性，减少算力需求；发展多模态技术，促进更自然的多模态融合；强化学习与自主决策能力，使AI Agent能够在复杂环境中自主学习和决策。 从技术角度看，AI模型可能面临偏差风险。例如，算法歧视可能导致不公平结果，训练数据不足或应用不当也可能导致模型失效。此外，网络安全问题也不容忽视，DeepSeek曾遭遇过DDoS攻击，因此，加强大模型的安全防护至关重要。 李博杰以雷军和小米公司举例，在移动互联网的早期阶段，尽管有数百家公司涉足手机行业，但最终，只有小米等少数公司取得了成功，最终市场上的主流手机品牌依然是那些早期就有基础的公司。 对于从事AI行业的人来说，并不一定需要像OpenAI那样打造基础大模型。与其直接与巨头竞争，不如选择像小米的空气净化器或插线板这样的生态链产品，在AI应用领域找到特定的突破口，与巨头形成互补关系。例如，OpenAI投资了多个垂直领域的公司，如语音学习应用Speak、编程教育平台Canvas、法律应用等，这些公司专注于特定行业，与OpenAI的基础模型形成互补，而不是直接竞争。 李博杰强调，未来AI行业需要更多的人愿意深入垂直领域。许多创业者往往只关注大模型，但那些看似“小”的垂直领域应用，恰恰是AI技术实现商业化的重要突破口。 排版／ 季嘉颖 图片／ 达卯智能 达观数据 东方IC 来源／《IT时报》公众号vittimes 举报/反馈"
    },
    {
      "doc_id": 49826,
      "title": "一场聚焦AI“前世今生与未来”的对话",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "7月17日，第三届链博会在北京举办先进制造主题活动，美国英伟达公司创始人兼首席执行官黄仁勋（右）出席，与之江实验室主任、阿里云创始人王坚对话。中新社记者 赵文宇/摄 美国英伟达公司创始人兼首席执行官黄仁勋透露H20芯片“禁令”在中国被解除的第二天，就身着唐装，出现在了第三届中国国际供应链促进博览会（以下简称“链博会”）的开幕式上，并首次尝试用中文演讲。他说，中国的供应链是一个“奇迹”，美国企业扎根中国市场至关重要。 当前，AI（人工智能）无疑是很多展会的焦点之一。 7月17日，一场关于AI的巅峰对话在第三届链博会先进制造主题活动现场上演。 黄仁勋穿着标志性皮夹克小跑上台，与之江实验室主任、阿里云创始人王坚开启了一场关于AI的围炉对话。这也是本场活动最受期待的环节之一。 王坚回忆起与黄仁勋的相识大概是在10年前的北京中关村，当时，黄仁勋侃侃而谈GPU（图形处理器），他对技术的激情令王坚印象深刻。那时，他们谈论的内容还是计算机的处理系统以及移动设备。如今，AI已经成为前沿科技领域的主角之一。两人在现场拆解AI的过去、现在与未来，为“链”接下一个时代的AI发展提出他们的思考。 王坚提出了第一个问题：“过去几年，AI在基础层面到底发生了什么？”黄仁勋谈到，过去，AI依赖人工编程来预测结果，如今，AI预测通过对海量数据进行机器学习。2012年，AI迎来了技术爆发时刻，深度学习成为一个有效的工具，计算机视觉、语音识别和自然语言处理领域相继实现超越人类水平的突破，认知智能逐渐成熟。后来，生成式AI萌芽后，发展势头非常强劲，实现了跨模态信息转换，也突破了单一媒介限制。当前技术焦点转向推理智能，AI开始具备理解问题、分解问题、解决问题的能力。“就像人类一样。”黄仁勋说。 “下一波浪潮就是物理AI（Physical AI），（AI）所有的能力都能融入物理世界，比方说机器人。”黄仁勋说，AI发展迅速，似乎每4到5年就会发生一次大变革。物理AI是指能够感知、理解并直接在现实世界中执行复杂操作的自主系统，通常嵌入机器人或自动驾驶车辆等实体设备中。 AI能力突飞猛进，它的智慧和技能会超越人类吗？ “人工智能并不仅仅是模拟人的智慧，其实是增强人的智慧，甚至是超过人的智慧。”王坚说。黄仁勋也认为，AI是来激发人的创造力，增加智慧，正如飞机能带人到更远的地方，而AI其实能够让人想得更多，变得更聪明。 当被黄仁勋反问哪一项技术变革让自己最兴奋时，王坚说：“最让我兴奋的其实是算力，我们提到AI，其实讲的是算力，算力是一切的基础架构，算力也改变了一切。”在他看来，与其说计算机在改变世界，还不如说是算力在改变世界，AI则将算力带到了新境界。 在训练AI模型时，AI也在产生日新月异的变化。黄仁勋谈及，从前AI先通过大量数据预训练，然后加入人的反馈，进行人工强化训练，人来教AI做事，或者人与AI协同做事。如今，AI是自己思考、自己生成数据、自己推理、自己实践。 这背后需要巨大的算力支撑。黄仁勋透露，过去十年，英伟达的算力提高了十万倍，能够处理更多数据，让机器学习更加有效。 今年开源的模型也改变了AI技术。黄仁勋眼里的中国正在高速创新。例如，由中国孕育并开源共享的深度求索的DeepSeek、阿里巴巴的通义千问、腾讯的混元、百度的文心一言、月之暗面的Kimi等世界级大模型，正在推动全球AI快速发展。 黄仁勋还关注到，中国研究者发布的AI论文数量在全球占比最高，研究人员正在开源科学方面协同合作，持续推动开源科学的发展。 “下一步，其实就是要开源，不仅仅是开放研究，还要开放工程。”黄仁勋说，开源工程非常重要，每个人都可以为之作贡献，AI的创新速度不再仅仅取决于企业或者组织，而是能够汇集所有的资源，造福整个AI生态系统。他还指出，Kimi等一系列开源推理大模型，非常先进，无论是医疗公司、金融公司还是机器人公司，都可以拥有自己的大模型，都可以分得AI的一杯羹。 中国的开源AI是推动全球进步的催化剂，让各国和各行业都有机会参与AI革命。黄仁勋指出，开源同样是保障AI安全的关键，有助于推动国际社会在技术标准、性能基准和安全防护措施方面的协作。 与此同时，AI还将重塑科学范式，并产生更大的影响力。 AI在推动科学发展方面大有可为。黄仁勋用两个场景举例，比如，在药物设计领域，AI可以解析蛋白质结构，像设计芯片一样设计分子；在气候模拟方面，可以将海洋、大气、冰盖的物理特性浓缩进AI模型，几秒到几年跨度的预测可以借助AI一次性完成。 此次围炉对话最后几分钟留给了年轻人。AI领域的机会广阔，对一个人来说甚至可能是个终身的机会。王坚回忆自己年轻时受过的帮助，谈到科技是人的连接，不是冰冷的算力。所以，他也一直在推动培养年轻一代。 当被问及“给年轻人什么建议”，黄仁勋对年轻人说了三句话：一是回到“第一性”原理，即使AI会写代码，你也要知道为什么这样写；二是立即拥抱AI，他眼里的AI是最强大的“平等器”，农民、老人、孩子都能用它赋能；三是年轻人作为AI“原住民”，如今出生的孩子，AI可以记录他们的一生。他说：“我都有点嫉妒你们。” 对话尾声，两人以十年为期，再约下一次围炉对话。 更多热点速报、权威资讯、深度分析尽在北京日报App 来源：中国青年报 作者：赵丽梅 张均斌 流程编辑：U072 举报/反馈"
    },
    {
      "doc_id": 49827,
      "title": "半个AI圈的人都来了,从AI软件到AI眼镜到具身智能,从内卷到出海卷...",
      "time": "2024-07-10T00:00:00+00:00",
      "content": "在连续、按月发榜 2 年之际， 迎来了， AI产品榜·2周年大会！ 祝，所有知道我名字的人，都能上榜。 欢迎你，扫描二维码，报名大会， 一起来 AI ^_^ AI产品榜 AICPB 2025年7月 AI产品榜·2周年大会 特邀嘉宾： 李榜主：AI产品榜 创始人，全球影响力榜单 邵哲文：深圳国家高技术产业创新中心 数字经济研究所所长 吴世春：梅花创投 创始合伙人，超级天使投资人 李宏伟：雷鸟创新 创始人兼CEO，全球顶级消费级AR生态 吴太兵：万兴科技 创始人董事长，AIGC软件A股上市公司 杨龙昇：影目科技 创始人兼CEO，2023胡润U35中国创业先锋获奖人 茹忆：李未可科技 创始人兼CEO，中国第一个上千万量级人工智能音箱天猫精灵的建造者 乔顺：Co-Founder/CTO@OpenArt AI，Serial Entrepreneur 黄祯：Chimer AI 创始人，胡润中国U25创业先锋 于北川：指数引力 创始人，半年内连续获得2轮融资 玉伯：YouMind 创始人&CEO，致力于打造服务内容创作者的好用的 AI 工具 聂凯旋：松应科技 创始人CEO，成功主导多个亿级To B产品商业化 聂相如：帕西尼感知科技 联合创始人，胡润百富30位30岁以下创业领袖 姚淇元：众擎机器人科技 联合创始人，全球首例人形机器人前空翻项目主导人 张延柏：灵心巧手 联合创始人，资深产品市场营销专家 陈云琳：出门问问 高级技术总监，Agentic AI软硬结合产品：TicNote 顾明君：Indiegogo 中国区负责人，打造过多个百万美金众筹项目 杨帆：宽桥恒松 创始合伙人，上榜福布斯中国30U30榜单 梁思聪：阿米巴资本 AI 应用赛道投资人，专注于 AI 应用层的早期投资 宋昶：啟赋资本 合伙人，主导投资超过三十家企业 梦雯：创投十问 创始人，AI时代投资人和创业者的超级连接器 刘屹洲：深圳国家高技术产业创新中心 人工智能产业研究中心主任 AI产品榜：全球影响力AI产品榜单 AICPB：AI Champion Product Board AI产品榜被数百家国内外顶尖媒体和权威机构广泛引用，还被誉为“互联网女皇”的硅谷传奇投资人 Mary Meeker 写进了 AI趋势报告。 这些国际知名影响力科技媒体包括：The Information、路透社 等。 国内知名科技媒体/机构包括：中国新闻周刊、央广网、中国基金报、36kr、腾讯科技、雪球 、南华早报、凤凰网科技、央广网、财联社、厦门大学 等等。 尤其值得一说的是， 被誉为“互联网女皇”的硅谷传奇投资人 Mary Meeker 撰写的 AI 趋势报告，以及全球领先的战略咨询公司罗兰贝格 (Roland Berger) 等国际权威机构，都引用AI产品榜的数据。 这标志着AI产品榜已具备全球影响力，并获得了国际权威的认可。 AI产品榜：为 AI 创新者加速 AICPB：AI Champion Product Board AI产品榜凭借其专业性在 AI创业者、VC投资人、二级投资人、以及大厂的产品、战略、技术圈子里好评如潮，已成为AI行业公认的数据基准和权威象征。 AI产品榜跟踪了10,000+ AI产品，包括 AI应用、AI网站、智能体，覆盖从活跃用户数、访问量、留存、时长、增速到营收等关键数据。更进一步，我们将这些AI产品分门别类，涵盖了100+个AI细分领域，为您呈现这份内容丰富、观点独到的AI产品榜。 AI产品榜即将覆盖AI硬件领域。 有上榜产品团队，将产品排名放在公司的商业计划书上、放在公司的招聘简章上，放在产品介绍上，非常之妙用。 如果您是投资人：本榜单为您提供最具潜力和市场吸引力的AI产品的清晰快照，助您更精准地判断和布局下一步的投资。 如果您是AI公司创始人 | 高管 | 产品经理 | 开发者｜战略：从这里，您可以了解到竞争对手的动态和当前市场的趋势，从而更好地制定自家产品的战略和发展方向。 如果您是普通AI产品使用者：您将发现哪些产品最受大众欢迎，以及哪些隐藏的“黑马”值得您一试。 举报/反馈"
    },
    {
      "doc_id": 49828,
      "title": "英伟达市值蒸发近6000亿美元,而DeepSeek刚刚又开源新模型",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "机器之心报道 编辑：亚鹂、Panda 龙年即将结束，但有些股民可能无心过春节了。影响，美股昨日开盘后迎来重挫。 周一，英伟达市值大幅下跌，损失接近 6000 亿美元，创下美国历史上公司单日市值最大跌幅。此次股价暴跌幅度达 17%，最终收盘价为 118.58 美元。 上周，英伟达才刚刚超越苹果，成为全球市值最高的上市公司。此次股价暴跌直接导致纳斯达克指数下滑了 3.1%。 另一家依赖 AI 获得巨额市值增长的美国大型芯片制造商 Broadcom，周一跌幅则达到 17%，市值蒸发了 2000 亿美元。 此次抛售的原因，主要是源于中国人工智能实验室 DeepSeek 带来的全球 AI 竞争压力飙增的担忧。，并表示该模型只用了两个月时间完成，使用的还是英伟达的低能力版芯片 H800。 反观 Alphabet、Meta 和亚马逊等科技巨头，为训练和运行 AI 模型，花费了数十亿美元用于购买英伟达最前沿基础设备。 将开源进行到底，Janus-Pro 问世 在美股一片惨嗥的同时，DeepSeek 再接再厉继续开源，发布了视觉模型 Janus-Pro。该模型是去年 10 月发布的 Janus 的升级版，在质量上实现了飞跃式提升。与此同时，DeepSeek 还发布了一款多模态理解模型 JanusFlow-1.3B。 Janus-Pro Janus Pro 是基于之前的 Janus 开发的高级版。整体而言，Janus Pro 实现了三大改进：训练策略优化、训练数据扩展、扩展到了更大模型。有了这些改进， Janus Pro 在多模态理解和文生图指令遵从能力都收获了显著提升 —— 在多个基准上超越了 DALL-E 3 与 Stable Diffusion，同时文生图的稳定性也得到了加强。此次，DeepSeek 一次性发布了 7B 和 1B 两个版本。 刚刚注册 �� 帐号的 DeepSeek 创始人梁文峰（目前还无法验证该帐号的真实性）也宣布了此消息。 已经有不少网友尝试过该模型了，比如生成一个看起来像网球的小鸟，绒毛形态十分逼真。 或者由「美丽的汉字」五个字符组成的图画： 这个同时兼具视觉理解和生成的模型着实再一次震惊了中外 AI 社区，毕竟这个表现如此卓越的模型仅有 7B 大小！ 论文标题：Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling 论文地址：https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf 7B 版本：https://huggingface.co/deepseek-ai/Janus-Pro-7B 1B 版本：https://huggingface.co/deepseek-ai/Janus-Pro-1B Hugging Face 试用链接：https://huggingface.co/spaces/deepseek-ai/Janus-Pro-7B DeepSeek 如今正将其影响力从语言处理，扩展到计算机视觉领域。据随模型发布的技术论文介绍，Janus Pro 7B 在效率和多功能性方面经过精心设计，能够在一系列视觉任务中表现出色：从生成逼真的图像到执行复杂的视觉推理任务。 Janus-Pro 与其前身 Janus 在文本生成图像方面的对比 DeepSeek 还展示了 Janus Pro 7B 的性能指标。（左）Janus Pro 7B 在比其他多模态大模型参数更少的情况下，依然实现了较高的性能。（右）该模型在文本生成图像基准测试中也取得了最高的准确率，超越了竞争对手（包括 DALL・E 3 和 SD3-Medium）。 Janus-Pro 的多模态理解与视觉生成结果 DeepSeek 研究团队在他们的论文中表示：「Janus Pro 是一个高效的视觉模型系列，旨在实现性能与计算成本之间的平衡，能够在广泛的视觉任务中实现最先进的性能。」 以下为 Janus Pro 在多模态任务中的优良表现： 图片描述 文生图 1. Janus Pro 架构 对效率的强调是 Janus Pro 7B 区别于其他大规模、高资源需求 AI 模型的关键优势。与一些最大且最耗资源的 AI 模型不同，Janus Pro 7B 通过其 70 亿参数设计，能够提供高水平的性能，同时避免了对庞大计算资源的需求。 Janus-Pro 的架构与 Janus 相同。如下图所示，整体架构的核心设计原则是将多模态理解与生成的视觉编码解耦。研究者应用独立的编码方法将原始输入转换为特征，这些特征随后由一个统一的自回归 Transformer 处理。 Janus-Pro 架构 2. 训练策略优化 Janus 的前一个版本采用了三阶段训练过程： 阶段 I：重点训练适配器和图像头。 阶段 II：进行统一预训练。在此过程中，除理解编码器和生成编码器外，所有组件的参数都会被更新。 阶段 III：进行监督微调。在阶段 II 的基础上，进一步解锁理解编码器的参数。 然而，这种训练策略存在一些问题。通过进一步的实验，DeepSeek 研究团队发现这一策略并不最优，并导致了显著的计算效率低下。 为解决此问题，他们在原有基础上进行了两项修改： 在阶段 I 延长训练时间：研究者增加了阶段 I 的训练步数，以确保在 ImageNet 数据集上得到充分的训练。他们经过研究发现，即使固定了大语言模型（LLM）的参数，该模型仍能有效地建模像素间的依赖关系，并根据类别名称生成合理的图像。 在阶段 II 进行重点训练：在阶段 II 中，研究者去除了 ImageNet 数据，直接使用标准的文本生成图像数据来训练模型，从而使模型能够基于详细的描述生成图像。这种重新设计的方法使得阶段 II 能够更高效地利用文本生成图像的数据，并显著提高了训练效率和整体性能。 3. 数据扩展 研究团队在 Janus 的训练数据上进行了扩展，涵盖了多模态理解和视觉生成两个方面： 多模态理解：对于阶段 II 的预训练数据，参考 DeepSeek-VL2 ，并增加了大约 9000 万条样本。样本包括图像标注数据集，以及表格、图表和文档理解的数据。 视觉生成：前一个版本的 Janus 使用的真实世界数据质量较差，且包含大量噪声，导致文本生成图像时不稳定，生成的图像质量较差。在 Janus-Pro 中，研究者加入了大约 7200 万条合成的美学数据样本，在统一预训练阶段，真实数据和合成数据的比例为 1:1。 4. 模型扩展 前一个版本的 Janus 通过使用 1.5B 的大语言模型（LLM）验证了视觉编码解耦的有效性。在 Janus-Pro 中，研究团队将模型扩展至 7B，并在其中详细列出了 1.5B 和 7B LLM 的超参数（见下表）。 他们观察到，当扩大 LLM 的规模时，无论是在多模态理解还是视觉生成任务中，损失函数的收敛速度相比于较小的模型都会有显著的提升。 这个发现进一步验证了该方法的强大可扩展性。 Janus-Pro 架构配置 Janus-Pro 训练的详细超参数 JanusFlow-1.3B 在发布 Janus Pro 的同时，DeepSeek 还发布了一个多模态理解模型 JanusFlow-1.3B。从名字也能看出来，参数量同样不高。 据介绍，JanusFlow 是一个将图像理解和生成统一在一个模型中的强大框架。其引入了一种极简主义架构，将自回归语言模型与校正流（rectified flow，一种生成建模的 SOTA 方法）相结合。 JanusFlow 的架构 DeepSeek 研究表明，校正流可以在大型语言模型框架内直接训练，无需进行复杂的架构修改。为了进一步提高统一模型的性能，他们还采用了两种关键策略：一是将理解和生成编码器解耦，二是在统一训练期间对齐它们的表征。 事实上， JanusFlow 的研究论文早在去年 11 月就已经发布。 论文标题：JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation 论文地址：https://arxiv.org/pdf/2411.07975 当时的实验结果表明，JanusFlow 在不同的领域中都实现了与专门模型相当或更优异的性能，同时在标准基准上明显优于现有的统一方法。因此，可以说，这项研究代表着向更高效和多功能的视觉语言模型迈出的重要一步。下图展示了其一些基准测试结果数据以及生成结果。 DeepSeek 两连击：提升市场焦虑与竞争压力 Janus Pro 7B 的发布引发了不少讨论，比如 VentureBeat 认为：「Janus Pro 7B 的发布时机放大了其影响力。这是紧随 R1 模型和随之而来的市场动荡之后，它强化了这样的叙事：DeepSeek 是能够颠覆 AI 既定秩序的创新者。」 该媒体还认为：「Janus Pro 7B 的开源性质会加剧这种颠覆。与之前的开源运动一样，这会让人们更容易使用高级 AI。大型科技公司以外的企业将受益：无需供应商锁定或高额费用即可获得顶级 AI。对于 AI 巨头来说，DeepSeek 构成了直接威胁：他们的专有高级模型能否在免费、高质量的替代品面前生存下来？当前的股市抛售情况表明投资者对此表示怀疑。」 对于 DeepSeek 正在给 AI 社区以及投资市场带来的影响，你有什么看法，请与我们分享。 参考链接 https://venturebeat.com/ai/deepseek-unleashes-janus-pro-7b-vision-model-amidst-ai-stock-bloodbath-igniting-fresh-fears-of-chinese-tech-dominance/ © THE END 转载请联系本公众号获得授权 投稿或寻求报道：liyazhou@jiqizhixin.com"
    },
    {
      "doc_id": 49829,
      "title": "新天终启,万象智生——万年奇点时刻,谁将引爆中国ASI?",
      "time": "2024-07-04T00:00:00+00:00",
      "content": "编辑：犀牛 【新智元导读】2025年，AI界风云激荡，DeepSeek-R1横空出世、英伟达市值称霸全球、谷歌AlphaEvolve打破数学神话，中国Qwen3登顶开源王座……智能爆炸的奇点已悄然降临！新智元十周年之际，2025 AI Era & ASI创新大奖报名正式启动，致敬重塑世界的AI先锋！ 2025年上半年的AI界可谓精彩纷呈，重磅不断。 1月，DeepSeek R1横空出世，热度迅速席卷全球。 其带来的震撼程度远超所有人的想象，硅谷巨头们建立起来的神话瞬间崩塌。 见此情景，美国迅速采取行动，特朗普联手OpenAI搞了个大的——「星际之门」计划官宣启动。 4年5000亿美金！堪称美国的AI曼哈顿计划。 接着，马斯克口中全世界最聪明大模型Grok-3，震撼登场！ 20万块GPU训出的模型，实属全球首次。 3月，《纽约时报》重磅曝料：特朗普任期内将实现AGI，美国政府早知AGI即将降临！ 到了4月，Meta深夜开源Llama 4，却被爆出训练作弊惊天丑闻，公司大佬纷纷辞职，模型实测崩盘全网炸锅。 与此同时，来自中国的阿里Qwen3却发布即登顶全球开源大模型王座！ 一经诞生，Qwen3立刻横扫各大基准。 5月则更加精彩，谷歌突然掏出能够自我优化的终极智能体AlphaEvolve。 ASI近在眼前！ 进入6月，AI行业再次迎来里程碑事件，英伟达市值超越微软问鼎全球科技之巅。 这还不够，就在昨天，英伟达盘中一度超越苹果公司的纪录，市值直逼4万亿美元！ 成为史上最贵公司——没有之一。 这一系列事件不断刷新着人类对AI的认知。 智能爆发的奇点已悄然来临！ 正如奥特曼在《温和的奇点》中所说：「这就是奇点的发展方式：奇迹变得常规，然后成为必备条件。」 新天终启 ASI展开壮丽图景 奇点已来。 ASI将会重塑社会架构，颠覆人类万年文明的路线图。 十年前，新智元正是以对ASI的信仰为引擎，启动了一场穿越智能宇宙的航程。 今天，站在这万年一遇的奇点之上，人类文明的底层代码正在被重写。 正如新智元即将到来的十周年峰会主题所言：「新天终启，万象智生」——ASI 纪元恢弘开启，宇宙万物与人类文明都将在更新的智能天地中获得无限生命！ 十年前，这一切还像是遥远的星火。 而今天，我们不再是仰望星空，而是已然身处星辰。 万象智生 「智能爆炸」带来全面更新 智能爆炸（Intelligence Explosion）描述的是这样一个循环：一旦机器能完成自主优化升级，将会引发一场无法遏制的智力飞跃。 这种递归式的自我循环，如同核裂变的链式反应，将以指数级速度重塑世界。 前OpenAI研究员Daniel Kokotajlo在今年发布的爆炸性报告《AI 2027》中预测，到2027年6月，能够自我改进的AI智能体就会大规模部署。 上百万个超级AI副本夜以继日地工作，将人类的生产力提升几十上百倍。 如果说上述场景还带有一丝虚构色彩，那么现实世界的炸裂新闻则更具冲击力。 谷歌DeepMind祭出了终极智能体——AlphaEvolve。 它像一位算法世界的「进化之神」，核心机制是将Gemini大模型的创造力与能够验证答案的评估器相结合，在一个进化框架内不断迭代优化。 其战绩堪称辉煌，仅用48次标量乘法，就解决了4x4复数矩阵乘法问题，一举打破了困扰数学界长达56年之久的Strassen最优算法神话。 在数学分析、几何学等50多个开放性问题中，它不仅在75%的问题上重现了最前沿解法，更在20%的问题上直接超越了人类已知最优解，甚至改进了困扰数学家300年的接吻数问题。 最不可思议的是，AlphaEvolve甚至能反过来优化训练它自己的大模型，提升芯片设计效率，让谷歌数据中心的计算资源回收了0.7%。 这正是「递归式自我完善」最直接的体现。 在与人类数学家联手后，AlphaEvolve更是一个月内连续3破沉睡了18年的难题——和差集指数，刷新了加法组合学的天花板。 这种突破让数学天才陶哲轩都惊叹：「对我而言，这是一个引人入胜的例证。」 AlphaEvolve的出现，让ASI就在眼前。 而这场智能爆炸的冲击波，早已不止于数学、代码和算法。 它正在叩响现实世界里一个个最坚固的堡垒——教育、医疗、科研等等领域。 在教育领域，AI都能考上清华了！ 最新的高考测试中，Doubao-Seed-1.6-thinking、Gemini 2.5 Pro均已达到清华录取线，超越99%的人类考生。 在医学领域，智诊科技5天发布5项领先「黑科技」：从拥有无限记忆的AI到全科医疗基座大模型，再到深度推理。 从此，人人都有了口袋里的健康专家——好伴AI。 德适生物则在封锁的重压之下打破进口垄断，发布iMedImage® 医学影像大模型！ 在AI赋能医学影像领域取得重大突破！ 德适自主研发的千亿参数规模医学影像大模型iMedlmage，可通过赋能医学影像多个模态覆盖100+医学应用场景 在科学研究领域，全球首个AI科学家天团，公布了他们的第一项重大成果：针对失明（dAMD）的全新药物。 这并非简单的筛选或模拟，而是一次真正意义上的科学发现。 从数据分析、提出假设，到设计原始实验和后续实验，整个过程几乎完全由AI科学家智能体主导。 一个小型人类团队，仅用短短2.5个月，就完成了传统模式下需要数年乃至十年的工作。 这宣告了一个新范式的来临：AI自己做实验、自己做出新发现的时代，真的来了。 「智能爆炸」不再是一个遥远的名词，它正化身为一个个具体的AlphaEvolve、一个个AI科学家，将奇迹变为常态，将不可能化为日常。 我们正处于一个旧有范式被彻底打破，新思想、新秩序、新文明喷薄而出的伟大转折点！ 爆炸之后 谁来点亮ASI坐标？ 世界万象正在被重新生成。 从DeepSeek的横空出世，到Qwen3发布即巅峰，再到「杭州六小龙」的震惊全球。 在这场万年一遇的智能大爆发新纪元起点，我们既是见证者，也是参与者。 当ASI的浪潮席卷而来，总有一些领军者、一些先锋企业，他们不畏未知，勇立潮头，用代码和产品，绘制着新天地的壮丽图景。 正是为了致敬这些在ASI征程中领军探索的中国科技先锋，在新智元迎来第一个辉煌十年的历史性时刻，两项年度重磅奖项的评选也正式启动： 2025 AI Era企业创新大奖TOP55 2025 ASI先锋产品大奖TOP33 这不仅是一份榜单，更是一幅时代的星图。 它将记录下那些推动智能爆炸、重塑世界面貌的决定性力量，致敬那些让「新天终启，万象智生」得以实现的创造者们。 未来已来，剧本正在我们手中实时谱写，让ASI先驱者共启星际新程！ 我们诚挚邀请所有走在人工智能前沿的优秀企业参与评选，共同为行业发展树立可靠标杆，向世界展现开放崛起的ASI生态。 两大奖项的最终榜单将在新智元十周年峰会现场隆重揭晓并颁奖。 2025 AI Era企业创新大奖TOP55 此奖项旨在评选出在ASI时代浪潮中，具备卓越市场表现、核心技术创新力与巨大发展潜力的领军企业。 【评选指标】 市场经营表现/份额：企业在行业内的市场地位与经营成果。 估值/市值：资本市场对企业价值与未来潜力的认可。 技术团队领军人物：核心团队的行业影响力与技术领导力。 技术创新核心产品：企业核心产品的技术独创性与行业突破性。 产品应用落地规模：产品在市场中的商业化应用广度与深度。 2025 ASI先锋产品大奖TOP33 此奖项旨在评选出技术最先进、用户体验最佳、对行业发展具有深远影响力的先锋AI产品。 【评选指标】 产品市场占有率：产品在目标用户群体中的普及度与影响力。 产品技术先进性：产品所采用的技术是否具备前沿性与领先性。 行业标准引领度：产品在推动行业标准建立与发展中的作用。 功能特性表现：产品核心功能的性能、稳定性和实用性。 产品用户体验：产品的易用性、交互设计与用户满意度。 参选条件 两项大奖的参选条件为： 公司主体在中国或主营业务在中国； 主营业务涉及人工智能相关，或已将人工智能广泛应用于其主营业务； 近两年有取得较大技术创新或成果应用。 评选流程及时间安排 本次评选将通过「新智元AI Era影响力评估模型」，综合评估企业及产品的市场表现、技术创新与行业价值，由新智元指数、微博指数、清博指数、AI指数等客观数据综合遴选，并邀请行业权威专家组成评审团进行多轮审核验证，确保评选的客观与公正。 报名开启：即日起 报名截止：2025年7月31日 评审时间：2025年8月1日 - 8月25日 榜单发布与颁奖：2025年9月7日（新智元十周年峰会现场） 点击下方链接或扫描二维码，立即报名参选！ 报名链接：https://qzqs9kyge0.feishu.cn/share/base/form/shrcnwhO1O2Ktw4qlAArzjhAQKe 举报/反馈"
    },
    {
      "doc_id": 49830,
      "title": "李开复:零一万物AI Agent可接入任何开源模型,不要低估DeepSeek的...",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "李开复入场做AI Agent智能体。 7月22日消息，零一万物创始人兼CEO李开复博士今天上午宣布，发布升级后的企业大模型一站式平台“万智”2.0版本，并推出零一万物企业级Agent智能体产品。 据悉，作为万智平台的核心功能模块，零一万物企业级Agent以“超级员工”为核心定位，具备深度思考和任务规划能力，基于安全沙盒与MCP，能访问手机和Web端，连接各类企业服务。目前，该产品已经在金融、能源、法律、知识产权、智慧园区等场景落地。 李开复表示，目前，零一万物的企业级Agent已步入L2 推理Agent阶段，与OpenAI最新发布的ChatGPT Agent处于同一技术水位，具备基于大模型的任务规划能力，能通过推理机制自主判断任务步骤，调度多种工具完成复杂目标，实现从“工具流执行者”向“人机共同决策者”的跃迁。 李开复在会后媒体沟通会上表示，不管是Kimi，还是MiniMax、Qwen等模型，国内有很多好的开源模型，其它模型会提供Agent大脑能力，零一万物愿意用任何公司的优质开源模型，并且正在使用。 谈到DeepSeek活跃度下降话题，李开复指出，不要低估DeepSeek的强大能力。 “第一，这几家公司走开源路线，如果他们最强，我们一定会用这些模型；第二，不要低估DeepSeek，现在它的新版本相对低调但还是很强的；第三、我们国内很明确All in To B，消费级AI应用不是主要关注点；最后是基模竞争中美最终将是大厂的游戏。”李开复称。 据悉，零一万物成立于2023年5月，由李开复创办，主要致力于打造 AI 2.0 的平台和应用，技术路线此前为自研大模型，2023年11月6日发布首款开源预训练大模型 Yi-34B，2024年推出首款闭源模型Yi - Large综合排名位居前列。 2024年5月，零一万物内部对规模定律（Scaling Law）的边际收益递减进行推演，最终决定放弃训练原定万亿参数的超大模型 Yi-X-Large，而转为训练更轻量化、更具商业落地前景的 MoE（混合专家）模型Yi-Lightning，并在10月LMSYS Chatbot Arena上取得世界第六的排名。 AI应用和商业化层面，零一万物主打国外C端、国内B端策略，去年海外收入超1亿元。李开复透露，今年第一季度国内B端收入，就已经超过接近去年全年的收入规模，公司在非常良性运营当中。 2024年11月开始，零一万物加速转型到应用端，并于2025年1月与阿里云成立产业大模型联合实验室，并宣布聚焦参数适中、性能领先、推理速度快、推理成本低的轻量化模型，以产业大模型助力商业落地；2月，零一万物与苏州高新区联合成立的产业大模型基地正式授牌，聚焦制造、金融等领域的产业大模型；3月，零一万物推出万智企业大模型一站式平台，为企业级DeepSeek部署定制解决方案；7月，零一万物万智企业大模型服务平台正式登上香港特别行政区智慧政府创新实验室官网。 “今天，大模型我们走（发展）了两年多，2025年最重要的事件是开源力量+中国实力，DeepSeek的横空出世，不但是中国的骄傲，而且也带来了更加清晰的终局，也就是开源必将胜出，大模型的格局将从拼比底模的技术指标，走向拥抱开源模型的商业赋能，那么中国就有超大市场、超多场景。”李开复当时表示，公司已经全面转向应用阶段。他认为，2025 是 Al-First 应用爆发年，也是大模型商业化的大考年，而AI需要市场，市场也需要 Al，行业亟需“性能x性价比”最优解。未来的大模型的行业竞争将不再单指模型性能的比拼，更关乎从中台到应用的能力，即模型能否快速响应场景需求、基于中台构建行业应用。 时隔三个月，李开复今年首次线下，面对媒体披露零一万物企业级Agent智能体产品进展。 实际上，自“一码难求”的Manus带火Agent智能体概念后，不少AI大模型企业都在争相发布自家大模型产品。其中，“大模型六小虎”中最先发布的是智谱，MiniMax继6月发布Agent产品后，近日公布Agent全栈开发功能。据了解，今年WAIC期间，阶跃星辰也将发布多个垂类Agent。 AI Agent 的能力跃升背后关键看两点——基座模型具备的深度思考与任务规划能力，以及Agent经过场景锤炼和工程优化之后可调用执行工具的数量与精度，影响着其能力边界。这两者结合，才能让 AI 实现 “手脑并用”，未来有望成为各行业 “超级员工”。但目前受限于基座模型对垂直产业的理解深度和工具调用成熟度，多数Agent方案仍无法满足企业复杂业务需求。 李开复表示，Agent这个词已经火了至少半年甚至更久，但是Agent正在被重新定义，其为企业创造的价值也被严重低估和误解。 在李开复看来，Agent分成三个阶段——过去、今天和未来：2024年是工作流Agent；2025年，当下是推理Agent，未来将会是Multi-Agents。 L1：工作流Agent。这一阶段由人类主导任务的规划与决策流程，Agent仅按指令一步步执行指定动作。虽然实现了任务自动化的初步落地，但其智能化程度有限，本质仍为强化版的“RPA（机器人流程自动化）”或“Co-pilot”，难以应对企业中复杂多变、跨环节的任务。 L2：推理Agent。Agent具备基于大模型的任务规划能力，能通过推理机制自主判断任务步骤，调度多种工具完成复杂目标。此阶段的Agent不再依赖人类指定的流程，而是能“想清楚再做”，具备真正的任务闭环执行能力。 L3：多智能体 Multi-Agents。多个AI Agent之间实现有机协作，自主进行任务分配、资源调度与协同优化。这一阶段将彻底重构企业运作范式，形成真正的去中心化智能协作网络，是Agent发展的进阶形态与行业变革的关键临界点。 李开复曾提到，AI智能化转型的客户画像有四类：1、与CEO决策者直接对话；2、企业数字化程度较高；3、对AI智能化需求迫切和强烈；3、有立即可实施见效的场景，比如能源、游戏、法律、零售等高复杂度、高价值行业，提供端到端交付能力，从战略咨询到平台落地，并且强化本地化部署、安全合规、可控可解释等关键指标。 李开复称，企业AI数智化转型本质上是CEO一把手驱动的AI战略转型工程，这不仅是技术问题，更是管理问题，需要CEO与一线员工形成转型共同体，上下协力，实现从战略到执行的全面贯通，确保转型落地见效。基于万智2.0平台，零一万物选择以“一把手工程（Top Down）”为核心战略，由李开复牵头打造真正贴合业务需求的大模型To B解决方案。 在李开复看来，AI的价值，已经从最初的工具（Chatbots），到软件（API调用），再到服务（AI员工），未来会看到结果（以企业获利为导向），企业会从为“工具”买单演变到为“结果”买单。 李开复在媒体交流会上指出，零一万物商业模式是“Palantir Model”，最终目标之一是希望打造“行业大模型操作系统”。 李开复进一步解释称： “我们（零一万物）与Palantir是类似的。因为它如今已是千亿级美元市值的公司，对外不是那么高调，不是做to C，而且也有足够的耐心、足够的数据（尤其是完整的行业闭环数据），同时深谙商业机构的核心指标。基于这些指标和闭环数据，用现有技术交付价值，正是Palantir的1.0发展模式。而且，Palantir证明了一定要深度共创，做产品和平台公司，才能了解企业的痛点和机会，要做很多工作，从一个公司泛化到第二个公司、第三个公司。他们创立的时候还没有AI 2.0，当时最大的价值数据平台，之后又有了AI平台。因此，做To B业务，面对行业巨变时，传统行业与 AI 公司的深度共创至关重要，这也是我们认同的方向。 另外，我们这里特别增加一点，就是‘一把手工程’。如果真的要有比较大的投入，对公司KPI有很深认知，而且愿意用AI做公司核心业务场景，这个只有CEO才能决定，所以我们选择走这条道路。” 李开复称，如果操作系统广义性定义为“能够承载很多的应用”，今天的万智已经符合这个标准。但操作系统也应该具备非常强的泛化通用、开箱即用的能力，虽然今天零一万物还没有完全达到，但是其团队已经把这当作一个未来要实现的目标。 Gartner曾在报告中预测，到2028年，33%的企业级软件应用将整合 AI Agent，届时 15%的日常工作任务决策可实现完全自主化。投行摩根士丹利（Morgan Stanley）在研报中预测，AI智能体市场前景广阔，目前蕴藏着520亿美元的机会，预计到2028年市场规模将增长至1020亿美元。 李开复强调，以生成式AI驱动的AI 2.0革命比过去的技术革命更为迅猛，正在加速商业落地。AI Agent的颠覆式创新，将会重构整个商业世界的业务流程和价值创造。未来十年企业竞争的分水岭，就在于是否具备AI 2.0时代的全局思维与落地能力。企业AI数智化转型本质上是CEO一把手工程，敢于让AI穿透核心系统、重构价值链条的企业将赢得先机。（本文首发于钛媒体App，作者｜林志佳，编辑｜盖虹达） 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 49831,
      "title": "DeepSeek,激荡AI行业的“一股清流”",
      "time": "2024-02-21T00:00:00+00:00",
      "content": "近期，外媒纷纷将聚光灯投向中国初创企业深度求索公司，其自主研发的人工智能（AI）大语言模型“深度求索”（DeepSeek）凭借“好用、开源、免费”三大特点，在全球范围内引发热烈反响。这一创新成果不仅在中国本土大放异彩，更是在大洋彼岸的美国乃至全球科技界激起了广泛讨论并受到高度评价，被视为挑战现有AI巨头垄断地位的“一股清流”。 多家外媒接连不断的报道，让DeepSeek这一出人意料的、高效而强大的AI模型席卷了科技行业，这种“改变游戏规则”的大型语言模型，有望快速重塑AI格局。 1月最后一周，中国开发的DeepSeek应用程序在苹果应用商店的下载次数远超美国Open AI 开发的ChatGPT。 图片来源：英国《自然》网站 低成本兼具高性能 西班牙《国家报》、澳大利亚《对话》杂志、美国《纽约时报》等多家外媒均关注到，DeepSeek的技术具有强大创新力，是因为它能在降低计算成本的同时实现尖端性能。 AI公司通常使用装有1.6万枚或更多专用芯片的超级计算机来训练聊天机器人，但深度求索公司表示，他们只用了大约2000枚芯片。同时，他们仅花了不到600万美元就训练了新模型，成功在两方面把构建AI的价格“打了下来”。 首先，DeepSeek模型使用数据蒸馏技术生成高质量数据，提升了训练效率；其次，DeepSeek采用了一种称为“混合专家”的方法。当用户提出一个问题时，模型会决定是否激活其医疗专家、翻译、律师或物理学家。传统模型会同时激活所有专家，这会浪费能源和计算能力。而DeepSeek则将这些小型“专家”系统与一个“通才”系统相结合，实现了相同的功能。通才系统对每个主题都有相当的了解，可帮助协调专家之间的互动。 开源策略打破技术垄断 Deepseek的独特之处还在于，其采取了开源策略。这犹如在美国及少数几个长期主导AI技术领域的巨头中投了一枚震撼弹，打破了既有格局。 如今，这项技术已向全世界敞开大门。鉴于DeepSeek模型免费可得，其他公司或将不得不调整价格策略，以保持市场地位。当能够以零成本获得类似技术时，没有人愿意支付额外费用。 《对话》杂志报道称，与专有AI模型占主导地位的美国不同，中国AI新创企业拥抱开源生态系统，以更快地扩大创新规模，并融入全球AI合作。 得益于人才培养与政策支持 在近日的法国人工智能峰会上，多名国际科技界高管均认为，DeepSeek 的出现表明，在AI领域，中国企业的进步不容小觑。 《自然》杂志报道，2017年，中国政府宣布，计划到2030年将中国打造成为全球AI领域的领头羊。政府要求相关行业在2025年前实现AI领域的重大突破，“使相关技术和应用达到世界领先水平”。 据美国乔治城大学安全与新兴技术中心的一份报告，截至2022年，中国教育部已批准440所大学开设AI专业本科学位。美国智库MacroPolo数据显示，同年，在全球顶尖AI研究人员中，华人几乎占据了“半壁江山”，而美国人仅占18%。 澳大利亚悉尼科技大学科技政策研究员马丽娜·张专注于中国的创新研究。她表示，DeepSeek公司的成功得益于政府对AI教育和人才培养的投资，这些投资包括众多奖学金、研究经费以及学术界与产业界的合作。 创新重塑全球AI格局 美国趣味工程网AI专栏作家塞贾尔·夏尔马发表评论称，如此强大的模型出自中国，让美国感到“坐立不安”。英国广播公司则直接在标题中称，“中国的DeepSeek AI震撼行业，削弱美国霸权”。 美国总统特朗普当地时间1月27日在佛罗里达州迈阿密发表讲话时，称DeepSeek的出现“给美国科技产业敲响了警钟”。 美国《麻省理工技术评论》网站在报道中表示，考虑到中国AI企业面临美国对尖端芯片出口管制日益收紧的制约，DeepSeek的成功“更显非凡”。种种迹象表明，美国的制裁并未削弱中国的AI实力，反而似乎正驱使深度求索等初创企业以效率、资源整合和协作为优先方向进行创新。《国家报》报道也认为，美国制裁加速了中国AI创新。 美国消费者新闻与商业频道网站援引专家观点表示，美国自认为处于世界科技领袖的地位已不再被普遍接受。 中国人工智能发展的破局与担当 （记者 张佳欣） 【责任编辑:朱家齐】 部级领导干部历史文化讲座20周年纪念版 定位就是聊个天 金融市场技术分析 疗愈的饮食与断食 写作教练在你家 注音详解古文观止"
    },
    {
      "doc_id": 49835,
      "title": "OpenAI“黑帮”席卷美国硅谷_澎湃号·湃客_澎湃新闻-The Paper",
      "time": "2024-04-29T00:00:00+00:00",
      "content": "原创 王 涵 智东西 18000亿估值，15家公司，解密OpenAI最强“AI天团” 。 编译 | 王涵 编辑 | 漠影 智东西4月28日消息，近日的一篇，让我们看到15家由OpenAI前员工创立的AI创企黑马正在狂卷硅谷科技圈，其中卧虎藏龙，重磅技术频频亮出，与PayPal“黑帮”类似的OpenAI“黑帮”逐渐成型。 或许其中就藏着另一家“OpenAI”。 PayPal“黑帮”，一个在硅谷乃至整个互联网史上鼎鼎大名的称呼，从21世纪伊始便开始影响世界互联网格局，领英（LinkedIn）创始人里德·霍夫曼（Reid Hoffman）、YouTube创始人陈士骏（Steve Chen）和查德·赫利（Chad Hurley）以及特斯拉与SpaceX掌门人埃隆·马斯克（Elon Musk）都是他们的一员。 这些名字背后，是社交网络、在线视频、电动汽车、商业航天、大数据分析等行业的时代变革。PayPal“黑帮”不仅创造了万亿市值的商业帝国，更奠定了硅谷“校友网络”的“传奇”模式。 如今，这种“传奇”正在AI（人工智能）时代被重新书写。 马斯克联合萨姆·奥尔特曼（Sam Altman）、格雷格·布罗克曼（Greg Brockman） 等科技领袖在2015年创立了OpenAI，2022年11月其AI聊天机器人ChatGPT横空出世，截至2025年3月下旬OpenAI估值已达到3000亿美元（约合人民币21863亿元）。 当前，15家由前OpenAI员工创立的AI创企累计估值已达2500亿美元（约合人民币18219亿元）左右，相当于再造了80%的OpenAI，这些公司涵盖大模型、AI Agent、机器人、生物科技等前沿领域，其中Perplexity已经开始挑战谷歌搜索的垄断格局。 01. Anthropic——Claude创造者、OpenAI最大竞争对手 2021年，达里奥·阿莫代伊（Dario Amodei）与妹妹丹妮拉（Daniela Amodei）离开OpenAI，创立旧金山AI安全公司Anthropic。2024年，OpenAI联合创始人约翰·舒尔曼（John Schulman）加入，承诺打造“安全通用人工智能（AGI）”。 2025年2月，该公司正式发布Claude 3.7 Sonnet——Anthropic迄今为止最智能的模型，也是当时市场上首款混合推理模型。该模型既能实现近乎即时的响应，也能展开分步推理过程并可视化呈现给用户。API用户还可精细控制模型思考时长。Claude 3.7 Sonnet在编程和前端开发领域表现突出。 去年，Anthropic与Menlo合作宣布了一项名为Anthology的计划。该计划的运作方式是，风险投资公司从1亿美元的基金中投资年轻的AI初创企业，初创企业可以使用Anthropic的模型、员工和2.5万美元（约合人民币18万元）的计算积分。 本月，Anthropic完成了对初创公司Goodfire的首笔投资，投资金额为100万美元。这家成立仅一年的初创公司致力于帮助AI开发者理解其AI模型的内部运作机制。本轮融资由Menlo Ventures领投，Anthropic的其他投资方Lightspeed Venture Partners和B Capital也参与了投资。 据报道，OpenAI营收（37亿美元）（约合人民币270亿元）仍为Anthropic（10亿美元）（约合人民币73亿元）的3倍有余，但后者2025年3月估值已达615亿美元（约合人民币4482亿元），成为OpenAI最大竞争对手。 02. Safe Superintelligence——聚焦安全超级智能 2024年5月，OpenAI前首席科学家伊尔亚·苏茨克维（Ilya Sutskever）因参与罢免CEO萨姆·奥特曼（Sam Altman）未果而离职，随后创立安全超级智能公司（Safe Superintelligence，SSI），明确“仅聚焦安全超级智能”的单一目标，采取专注数年研发后再推出产品的技术路线。 ▲从左到右分别是：丹尼尔·格罗斯（Daniel Gross），伊尔亚·苏茨克维（Ilya Sutskever）和丹尼尔·列维（Daniel Levy） 2024年9月，据报道，创立仅三个月的SSI公司宣布完成10亿美元（约合人民币73亿元）现金融资，本轮融资估值达50亿美元（约合人民币364亿元），投资方包括知名风投机构Andreessen Horowitz、红杉资本、DST Global和SV Angel，以及由Nat Friedman与SSI首席执行官丹尼尔·格罗斯（Daniel Gross）管理的投资合伙基金NFDG。在无产品、无营收的情况下2025年最新估值达320亿美元（约合人民币2332亿元）。 03. Thinking Machines Lab——让每个人都能获得所需的知识和工具 思维机器实验室（Thinking Machines Lab）是一家AI研究与产品公司，致力于让每个人都能获得所需的知识和工具，使AI服务于其个性化需求和目标。2024年，前OpenAI首席技术官米拉·穆拉蒂（Mira Murati）离开OpenAI创立该公司，2025年2月公开亮相，宣称将开发“可定制化、高性能”的AI系统。 ▲米拉·穆拉蒂（Mira Murati） 思维机器实验室初期团队约30名核心成员中，三分之二来自OpenAI。此后，更多OpenAI前高管陆续加盟担任顾问，包括OpenAI前首席研究官鲍勃·麦格（Bob McGrew），以及主导开发多款旗舰AI模型的首席研究员亚历克·拉德福德（Alec Radford）。 有消息称其正启动20亿美元（约合人民币146亿元）种子轮融资，估值不低于100亿美元（约合人民币730亿元）。尽管其今年2月才成立，尚无营收或产品面世。若达成，该公司将成为全球估值最高的AI初创企业之一，进军当前竞争激烈的生成式AI模型开发领域。 04. Perplexity——基于大语言模型的AI搜索引擎 阿拉文德·斯里尼瓦斯（Aravind Srinivas）在OpenAI工作一年后，于2022年创立AI搜索引擎Perplexity。Perplexity是一家基于大语言模型的网络搜索引擎，其特色在于通过整合网络搜索结果来生成查询响应。 ▲阿拉文德·斯里尼瓦斯（Aravind Srinivas） 据报道，斯里尼瓦斯称，Perplexity 计划下个月发布自己的浏览器，名为Comet。 “我们之所以要做浏览器，是因为它可能是构建代理的最佳方式，”他说，“浏览器本质上是一个容器化的操作系统。 如果你已经登录了其他第三方服务，它可以让你通过隐藏标签访问这些服务，在客户端刮取页面，并代表你进行推理和采取行动。” 此前有消息称，如果Chrome浏览器从谷歌分离出来，Perplexity希望能接盘Chrome 浏览器。该公司的AI搜索引擎开始与安卓手机制造商达成预装协议。本周摩托罗拉宣布，将在新款Razr手机上预装Perplexity，这意味着斯里尼瓦斯自称的AI“答案引擎”将触达数百万潜在新用户。尽管他表示目前的预装深度未达双方预期，但对Perplexity这样的初创企业而言，这已然标志着一次重要突破。 Perplexity曾获贝索斯等投资，但因涉嫌非法网络抓取数据引发争议。2025年3月，公司以180亿美元估值启动10亿美元（约合人民币73亿元）融资。 05. xAI——AI聊天机器人Grok所属公司 凯尔·科西奇（Kyle Kosic）2023年离开OpenAI，加入埃隆·马斯克的AI公司xAI，主导开发聊天机器人Grok，2024年重返OpenAI。 该公司在今年2月推出新一代Grok 3模型，这是目前xAI性能最先进的版本，结合了强大的推理能力和丰富的预训练知识。该模型在其Colossus超级计算集群上完成训练，使用的计算资源是之前顶尖模型的10倍。Grok 3在推理、数学、编程、常识和指令执行等任务上都有显著提升。 今年3月底，马斯克宣布旗下xAI公司以全股票交易方式收购X平台，并成立新的控股公司xAI Holdings，合并后xAI的估值为800亿美元（约合人民币5830亿元），X的估值为330亿美元（不包含债务）（约合人民币2404亿元），xAI Holdings成为全球估值千亿级AI创企之一。尽管交易模式引发质疑，但被视为押注马斯克生态的重要布局。 4月27日消息，据报道，马斯克旗下的xAI控股公司（xAI Holdings）正在洽谈新一轮融资，规模达200亿美元（约合人民币1457亿元）。如果交易成功，这将成为史上第二大创企融资轮，仅次于OpenAI上个月的400亿美元（约合人民币2915亿元）融资。同时，此举将使该公司的估值超过1200亿美元（约合人民币8745亿元）。 06. Stem AI——还在秘密筹备 2024年，报道称，前Twitch CEO、OpenAI临时CEO埃米特·希尔（Emmett Shear）正秘密筹备AI初创公司Stem AI（2024年披露）。 ▲前Twitch CEO、OpenAI临时CEO埃米特·希尔（Emmett Shear） 市场分析认为，Stem AI很可能正致力于解决希尔多次提及的“AI对齐”难题。其团队背景显示，这家初创公司融合了AI安全、生物伦理和互联网产品三重基因，或将开辟AI研发的新路径。 项目细节与融资规模尚未公开，但已获硅谷顶级风投机构安德森·霍洛维茨（Andreessen Horowitz）支持。 07. Eureka Labs——专注AI教学助手 计算机视觉专家安德烈·卡帕西（Andrej Karpathy）是OpenAI创始成员，2017年加入特斯拉主导自动驾驶项目，2024年离职创立教育科技公司Eureka Labs。公司总部位于美国旧金山，专注开发AI教学助手。 ▲Eureka Labs产品矩阵 Eureka Labs（AI Education）的核心理念是打造一个“AI 原生”的教育平台。 将AI技术深度融入到教育的各个方面，而不是简单地将AI作为现有教育模式的附加工具。他们的愿景是通过创建AI教学助手来革新传统的学习方式。他们相信，通过智能化的个性化指导和反馈，AI能够显著提升学习效率和体验。 目前，Eureka Labs（AI Education）已经推出了他们的第一个产品，一个本科生级别的课程，名为LLM101n。 这个课程的核心目标是教会学生训练他们自己的大型语言模型（Large Language Models, LLMs）。 截至目前，关于Eureka Labs（AI Education）的具体融资规模、投资方等信息尚未公开。 08. Pilot——会计服务公司 杰夫·阿诺德（Jeff Arnold）2016年在OpenAI担任运营主管5个月后，于2017年创立会计服务公司Pilot。 ▲杰夫·阿诺德（Jeff Arnold） Pilot.com是一家为高增长的科技初创公司和小企业提供簿记、税务和首席财务官 (CFO) 服务的公司。该公司成立于2017年，由杰夫·阿诺德、威廉·达哈尔（Waseem Daher）和杰西卡·麦凯拉（Jessica McKellar）共同创立。这三位创始人在麻省理工学院相识，Pilot.com是他们合作的第三家初创公司，他们之前创立的两家公司Ksplice和Zulip分别被甲骨文（Oracle）和多宝箱（Dropbox）收购。 公司专注为初创企业提供财务服务，2021年C轮融资1亿美元（约合人民币7.3亿元），估值12亿美元（约合人民币87亿元），获Sequoia Capital、Index Ventures和Stripe等知名机构等投资。 09. Adept AI Labs——专注于人类与机器协同合作 大卫·栾（David Luan）2020年离开OpenAI，短暂任职谷歌后，于2021年创立Adept AI Labs，开发企业级AI工具。 Adept AI于2022年由大卫·栾（首席执行官）、尼基·帕玛（Niki Parmar）（首席技术官）和阿什什·瓦斯瓦尼（Ashish Vaswani）（首席科学家）创立。他们都曾在谷歌（包括Google Brain）和OpenAI等公司拥有重要的AI研究和开发经验。值得注意的是，帕玛和瓦斯瓦尼是Transformer架构的先驱。 ▲Adept AI产品示例 Adept AI Labs是一家专注于构建通用智能系统（General intelligence systems）的机器学习研究和产品实验室，其目标是使人类和计算机能够创造性地协同工作。 该公司曾获General Catalyst、Spark Capital、Greylock Partners、微软、英伟达和Andrej Karpathy等知名投资者投资，2023年融资3.5亿美元（约合人民币25.5亿元），估值超10亿美元（约合人民币73亿元），但卢安2024年底离职，加入亚马逊AI代理实验室（亚马逊已收购Adept核心团队）。 10. Cresta——AI客服公司 蒂姆·施（Tim Shi）2017年加入OpenAI，专注安全AGI研发，一年后离职创立AI客服中心公司Cresta。 Cresta的主营业务是为联络中心提供一个端到端的生成式AI平台，该平台通过其核心产品Cresta AI Agent（AI 虚拟客服）、Agent Assist（实时客服辅助）、Conversation Intelligence (AI Analyst)（对话智能分析）以及AI驱动的质量管理和辅导等功能，提升客户互动体验，提高人工客服的工作效率和绩效，并最终帮助企业优化运营成本、增加收入并更深入地了解客户需求。 ▲Cresta产品矩阵 公司总部位于旧金山，Cresta迄今已通过7轮融资筹集了2.76亿美元（约合人民币20亿元），最近的一轮融资是2024年11月由World Innovation Lab (WiL) 和卡塔尔投资局 (QIA) 共同领投的1.25亿美元（约合人民币9亿元）D轮融资。截至2022年3月，Cresta的估值为16亿美元（约合人民币117亿元），2024年11月D轮融资的估值未公开披露。 11. Covariant——物流仓储机器人自动化 彼得·阿比尔（Pieter Abbeel）、彼得·陈（Peter Chen）、洛基·段（Rocky Duan）三人2016-2017年在OpenAI担任研究科学家，2017年创立机器人基础模型公司Covariant。 Covariant开发了一种通用机器人智能平台，主要应用于物流和仓储领域。该平台结合了深度学习、模仿学习和强化学习等先进的AI技术。他们的目标是让机器人能够观察、学习和适应新的任务和环境，而无需进行大量的预编程。 ▲Covariant AI机器人集成 截至目前，他们已经筹集了超过2.22亿美元的资金，投资者包括Index Ventures、Radical Ventures、Coatue 和Canada Pension Plan Investment Board等知名机构。最近的一轮融资是2023年5月的7500万美元（约合人民币5.5亿元）C-2轮融资。 2024年，亚马逊收购Covariant全部创始人及四分之一员工，交易被视为科技巨头规避反垄断审查的典型案例。 12. Living Carbon——用科技保护环境 麦迪·霍尔（Maddie Hall）2019年离开OpenAI，创立气候科技公司Living Carbon，研发基因编辑植物以强化碳捕获能力。 Living Carbon总部位于美国加利福尼亚州海沃德，其核心业务是利用合成生物学和基因工程技术开发能够更有效地捕获和储存二氧化碳的植物，特别是树木。 ▲Living Carbon项目介绍 截至目前，该公司已经筹集了至少3610万美元（约合人民币2.6亿元）的资金，投资者包括Temasek、Lowercarbon Capital、Toyota Ventures 和 Felicis Ventures等。最近的一轮公开融资是2023年1月的2100万美元（约合人民币1.5亿元）A轮融资。 13. Prosper Robotics——让机器人走进家中 沙里克·哈什米（Shariq Hashme）2017年在OpenAI工作9个月，主导开发《Dota》游戏机器人，后加入数据标注公司Scale AI，2021年创立Prosper Robotics。 公司总部位于伦敦，专注家用机器人管家研发，与挪威1X、美国Apptronik等企业形成竞争。Prosper Robotics目前的主要研发和推广产品是 “Alfie”，这是一款旨在成为家庭助手的双臂轮式人形机器人。其机器人可能采用订阅模式或者租赁模式，这可能意味着用户无需一次性购买高昂的机器人，而是按月或按年支付使用费用。 ▲Prosper Robotics研发的家用机器人Alfie 14. Daedalus——革新精密零件的制造 乔纳斯·施耐德（Jonas Schneider）2019年离开OpenAI，创立精密组件智能工厂公司Daedalus，总部位于旧金山。 Daedalus的主营业务是利用AI驱动的机器人和其专有的FactoryOS软件，革新精密零件的制造。专注于为汽车、医疗技术和机械工程等行业提供自动化生产解决方案。他们的自学习机器人能够处理重复性和易出错的任务，使人类能够专注于更关键的环节，从而实现人机协作的生产模式。 ▲Daedalus主营业务应用领域 截至 2024年2月，Daedalus AI成功完成了2100万美元（约合人民币1.5亿元）的A轮融资。该轮融资由NGP Capital领投，现有投资者Addition和Khosla Ventures也参与了投资。这笔资金将用于进一步开发Daedalus AI的专有制造AI平台，并扩大其在德国的生产设施。 15. Kindo——专注于企业级AI聊天机器人 玛格丽特·詹宁斯（Margaret Jennings）2022-2023年在OpenAI任职，2023年创立企业级AI聊天机器人公司Kindo。 Kindo是一家专注于为企业提供安全合规的AI管理平台的公司。该平台提供了一个中心化的界面，用于访问各种AI模型（私有、商业和开源），并与超过200个SaaS应用程序集成，确保与AI相关的活动的安全性和合规性。 ▲Kindo工作流程 截至2024年7月，Kindo总共获得了2760万美元（约合人民币2亿元）的融资。这包括2023年9月的700万美元（约合人民币5101万元）种子轮和2024年7月的2060万美元（约合人民币1.5亿元）A轮融资。其投资者包括Riot Ventures、Eniac Ventures和Drive Capital等机构。值得一提的是，在A轮融资的同时，Kindo还收购了开源安全AI模型项目WhiteRabbitNeo，以增强其安全能力。詹宁斯同年离职，加入法国AI公司Mistral负责产品与研发。 16. 结语：OpenAI成了AI创企“黄埔军校” 这个估值3000亿美元（约合人民币21863亿元）的AI巨头，正以独特的人才溢出效应催生着新一代科技创企。据智东西不完全统计，这15家企业的总估值约2500亿美元（约合人民币18219亿元），相当于再造了80%的OpenAI。 这些由技术骨干创立的公司覆盖了从基础研究到行业应用的全产业链，既延续了OpenAI的技术基因，又各自探索着差异化的发展路径，资本市场的热烈追捧反映出行业对AI技术前景的乐观预期。 正如红杉资本合伙人帕特·格雷迪（Pat Grady）所言：“我们正在见证AI领域的‘贝尔实验室现象’，即一家顶级研究机构催生出整个产业生态。”从长远来看，这种“贝尔实验室现象”效应有助于形成更加多元化的产业生态，或许也预示着更加激烈的市场竞争格局正在形成。能否持续产生突破性创新，仍需观察企业技术演进与市场需求的契合程度。 （本文系网易新闻•网易号特色内容激励计划签约账号【智东西】原创内容，未经账号授权，禁止随意转载。） 原标题：《OpenAI“黑帮”席卷美国硅谷》 阅读原文"
    },
    {
      "doc_id": 49837,
      "title": "Manus,搅动中国AI圈的24小时",
      "time": "2024-03-08T00:00:00+00:00",
      "content": "作者 | 豆蔻 林小葵 编辑 | 李不清 图片来源|视觉中国 本内容来自财经天下WEEKLY 体验过的人还寥寥可数，一家创业公司便在一夜之间，被捧上了“下一个DeepSeek”的神坛。 3月6日，创业公司Monica 发布了自己的首款AI Agent产品——Manus，将其定义为“全球第一款通用Agent产品”。 在一段四分钟的演示demo中，Manus展示了三个从规划到执行的能力。 Manus自动从15份简历中，筛选出了合适人选。给它一个寻找房产标的的任务，Manus在虚拟机中打开房产销售网站，筛选出符合需求的目标。让Manus分析英伟达和特斯拉的股价，它直接生成了相应的分析报告。 过程中，Manus表现丝滑流畅，很像下一代理想的工作助手。一夜之间，“炸裂”“AI Agent的DeepSeek时刻”的盛赞刷爆了朋友圈。 Manus的发布，甚至引发了资本市场的剧烈反应。3月6日，AI智能体、ERP等概念股集体爆发，立方控股、汉得信息等20%涨停，用友网络、焦点科技、浙文互娱等多股封板，金山办公也上涨了超过10%。 但短短24小时内，围绕Manus一码难求、全靠套壳、营销过度的讨论不绝于耳。这也让Monica联合创始人张涛在社交平台上发文回应。他表示“完全低估了大家的热情”，Manus还是“一个襁褓中的小婴儿”，“恳请大家对一家几十人的创业公司多一点包容和理解”。 Manus为何能一夜成名，它的技术实力是否真材实料，又为何遭遇了如此汹涌的追捧和群嘲？ “套壳”到极致之作 目前围绕Manus的讨论，更多局限于对官网视频的分析。Manus官方表示，产品还在封顶测试中，仅定向邀请用户体验。在二手交易平台上，Manus邀请码的价格被炒到999~5万元不等。 作为少数对Manus先睹为快的科技博主，阑夕在Manus上尝试了几条指令。 他要求Manus开发一款文字互动游戏，可以扮演谷歌公司的CEO，通过体验公司历史上的重要决策，既能获得游戏的乐趣，也可以顺便了解公司的文化。 用了差不多一个小时，Manus把谷歌CEO模拟器的网页游戏开发好了。点击开始游戏，它会让你自选难度，接着就会面对谷歌发展史上的每一次转变节点，你的选择会决定公司资源的变化，并影响最终的游戏结局。 阑夕表示：“在一个小时里，用一句话，做一个游戏出来，这就是AI Agent的能力。” 按照Manus的产品演示，它已近乎达到了L4级别的完全自动化水平。 根据官方网站信息，Manus在GAIA基准测试（用于评估通用 AI 助手在解决现实世界问题方面的能力）中表现卓越，成为在三个难度级别上都有新最先进(SOTA)记录的AI助手。 因此，Manus官方介绍称，这是比OpenAI Deep Research更强的AI Agent产品。 看起来，Manus确实展示了一种AI的理想未来。 相比于LLM（大语言模型）生成文本，AI Agent能将推理能力进行工程化落地 ，完成现实世界的复杂任务。普通人不再需要会写代码，只要在Manus上选几个功能模块，AI就会自动串联起来，完成复杂任务。 但事实是否果真如此美好？ 对于Manus的能力，官方没有向DeepSeek一样开源公布技术报告。但经过各方博主24小时内的“拆解”，已大致得出共识：Manus主要是“套壳”在Claude、Qwen等基础大模型能力之上，同时内置了多种Agent工具设定工作流，进行额外训练后完成复杂任务。 自媒体“赛博禅心”发文称：经过与Manus团队交流得知，模型“单任务”（输入指令后输出运算结果）的运行成本约为2美元。 有博主总结：Manus的本质是 “虚拟机+Computer use+Artifacts+多Agent协同”，核心是对现有Cursor类产品的再封装，降低使用门槛。 所谓“Cursor”类产品，是为编程人员打造的自动化AI工具。它功能强大，但使用起来有难度。而Manus更像是应用层的创新，把复杂的AI工具箱，打包成了“一键式”的按钮和可视化面板。 人工智能科研从业人员阿布在看完Manus视频后，最大感受是相比传统的Cursor类产品， Manus在任务规划上做得更细致了。 “它把执行的具体步骤都显示给了用户，用户对它的透明性有更直观的认识，会在一定程度上增加内容的信任程度。”阿布对《财经天下》说道。 不过，对于Manus交付结果的质量，阿布留有疑虑。 “从最终的结果上看，Manus只是完成了任务，但并不保证任务质量。”阿布表示。张涛通过社交平台也提到，“在模型幻觉、交付物友好度、运行速度等方面，Manus还有很大提升空间。” AI Agent还是大厂的天下 在Manus的官方介绍中，其对于“套壳”的猜测并未否认。 在Manus的产品理念上，其主打“Less Structure，More Intelligence”，也即“当你的数据足够优质、模型足够强大、架构足够灵活、工程足够扎实，智能就会自然涌现”。 虽然AI行业中存在“套壳”鄙视链，但在算法研究从业者林友看来，Manus提升了复杂任务的工程化实现效率，仍不失为一次应用层的创新。 但他也提醒，Manus距离其在视频中呈现的稳定、可靠的“通用型”Agent，还有一段不小的距离。 林友对《财经天下》分析道，“仅从demo很难看透其技术能力，但Agent的能力主要依靠LLM实现。而目前市面上大模型的能力，还很难支撑起一个足够通用型的Agent。” “通用和Agent，这两个词有点相悖。通用本应该是模型的事，Agent则是为领域任务设计的。至于Manus有哪些技术突破，至少在现有demo里还看不到。”林友说。 实际上在AI Agent领域中，国内外市场成熟产品的技术实力和表现，与Manus不相上下。 在海外，OpenDevin、Claude都有AI Agent产品。此次围绕Manus的讨论中，也有人质疑：除了价格，Manus和Devin的区别在哪里？ 目前，Manus还是免费测试阶段，而主流的AI Agent服务普遍很贵。ChatGPT Operator定价200美元一个月，Devin每月的费用则为500美元。 在国内市场，知名的Agent开发平台已有百度的千帆、阿里的百炼、字节的Coze（扣子）、Dify以及腾讯的元器等。比起Manus，这些平台上可调用的工具也更多。 如Coze平台就专为零代码或低代码(可视化编排)开发者设计，极大地降低了开发门槛。有AI爱好者对《财经天下》说，可以到Coze上建一个bot（机器人程序），体验已很完善。 而拉长周期来看，国内的AI Agent热潮，从2023年3月就已经开始。 彼时，AutoGPT框架开源项目发布后，利用大型语言模型将大任务拆分成小任务，并使用工具完成它们，已成为一种趋势。 但时至如今，Agent产品的落地场景还处于摸索期。大家热议的AI产品，无论是聊天机器人、图像识别，还是自动驾驶，它们只能在特定领域、特定任务中发挥作用，本质上都是 “专用型” 的AI，没有达到“通用型”级别。 业内人士表示，Agent与通用型是完全矛盾的。通用型需要整合各种Agent入口、工具、计算能力进去，工作量极其大。像Manus这样的Agent入口，未来通用能力也大概率会被大厂的大模型“内化”掉。 玩转应用系的团队基因 阿布表示，“做智能体的企业其实挺多的，每个领域都有，并不新鲜。但今年智能体是一个火爆的概念，被看作是2025年比较有前景的落地方向”。 同时，Manus能一夜爆火，也与其创始团队一直深耕应用层，更注重与市场的连接不无关系。 目前，Manus母公司Monica核心团队主要包括创始人兼CEO肖弘、联合创始人兼首席科学家季逸超、合伙人张涛等。他们也被曝出，与腾讯有着千丝万缕的联系。 其中，肖弘1992年出生，是华中科技大学软件工程专业2015届校友。作为一位连续创业者，肖弘在校期间便已积累了丰富的产品设计、移动开发、市场运营经验。 2013年，肖弘和室友开发了华科版微信校内漂流瓶、微信上墙等功能。2014年，肖弘拿到了一笔种子融资。2015年，其创办夜莺科技，并研发了一款用于匿名社交的App，后续还开发出了企业微信SaaS工具“壹伴助手”。其中，壹伴助手是为微信公号编辑开发的一款增强插件。 2016年， 虽然社交产品未获成功，但肖弘还是拿到了真格基金的天使投资。 2019年开始，夜莺科技开始围绕着Martech（营销技术）和SaaS领域，做了许多尝试。在一次与企业微信的开发者沟通会中，肖弘成为了企业微信的SCRM服务商，创建了“微伴助手”。 2021年8月，“微伴助手”获得了明略科技、腾讯投资的数亿元战略投资。2022年，“微伴助手”最终得以盈利后直接出售。 2022年，在追赶AI浪潮的过程中，肖弘成立了“蝴蝶效应”公司，并推出AI浏览器插件Monica，开始主攻海外市场。 2023年，Monica收购了ChatGPT4 Google浏览器插件工具。关于Monica的定位，彼时肖弘便思考过“套壳”的取舍。他认为要避开与百度、阿里等大厂的直接交锋，须聚焦欧美用户需求；二是技术套壳的价值重构，认为“应用公司应类比消费电子公司（如苹果）”，可以通过整合大模型API，创造差异化体验，而非追求底层技术颠覆。 事实证明，当下Manus通过“套壳”，确实占据了AI Agent赛道的早期红利。但在开源生态加速技术扩散的背景下，Manus的产品核心架构，也很容易被后来居上的大模型厂商复现。 尽管距离真正的通用Agent 还有些距离，但Manus的出现，还是让人们对智能体的新趋势有了新期待。3月6日，多家媒体平台都专门开设了直播，讨论Manus的产品意义。 Manus所代表的新尝试，也为人们展现了AI进化的新趋势。2025年，大模型应用是否能带来更多令人惊叹的“AI Agent”时刻，也不免让人有所期待。 （文中阿布，林友为化名）"
    },
    {
      "doc_id": 49839,
      "title": "大江时评:从DeepSeek到Manus,中国AI领域何以“黑马”频出",
      "time": "2024-03-07T00:00:00+00:00",
      "content": "江山代有才人出。3月6日凌晨，中国AI团队Monica宣布推出全球首款通用型AI智能体产品Manus，引发网络热议和关注。据悉，Manus在GAIA基准测试中取得了SOTA（State-of-the-Art）的成绩，显示其性能超越Open AI的同层次大模型，其创始人为一名中国“90后”。从DeepSeek的一夜爆火到Manus的横空出世，无不见证着新时代中国蕴藏的创新潜力与澎湃动力，更展示出新时代中国青年的创新热情与拼搏精神。 致天下之治者在人才。中国AI发展欣欣向荣、层出不穷，不断攀登人工智能领域的新高峰。Manus以其可独立完成简历筛选、房产分析、股票建模等复杂任务的能力而火爆出圈，它的背后，正是一群年轻化、专业性、有追求的人才团队支撑。可以说，中国AI领域“黑马”频出，既得益于教育高质量发展带来的人才红利，也启示了加强高素质人才队伍培育建设的重要性。 科技创新成果遍地开花，同良好生态与开放环境密不可分。2025年政府工作报告指出，“持续推进‘人工智能+’行动，将数字技术与制造优势、市场优势更好结合起来，支持大模型广泛应用”，旗帜鲜明地为推进科技创新与产业创新撑腰鼓劲，释放出全力激发全社会创新创造力的坚定决心，给广大青年人才拼搏进取、踔厉奋发、勇毅探索、锐意挑战夯实底气和信心。面向未来，随着“有为政府”与“有效市场”联动发力，创新、开放、包容、活力的新时代中国，必将绽放更加绚丽的科技光芒。 科技是第一生产力，牵引生产、消费、投资等链条式发展。人工智能蓬勃兴起，对加快培育和发展新质生产力影响深远。在生产端，促进新技术新产品新场景大规模应用示范行动落地，对推动前沿技术的应用与发展、改造升级传统产业，具有重要现实意义；在消费端，更多打造消费新场景，不断解锁消费新模式、新玩法、新体验，将有效激活消费市场、开创发展新契机。面向未来，让我们构建更加积极、兼容、开放的发展空间，让“人工智能+”行动有机衔接产业发展，更好增进人民群众的获得感、幸福感，为中国式现代化建设注入强劲新动力。 （段官敬） 举报/反馈"
    },
    {
      "doc_id": 49840,
      "title": "黄仁勋又卖股票了:再套现2亿元!英伟达一周跌16%,底部在哪里?",
      "time": "2024-09-05T00:00:00+00:00",
      "content": "英伟达（NVDA，股价：106.210美元；总市值:2.605万亿美元）当地时间9月4日向美国证券交易委员会提交的文件显示，英伟达CEO黄仁勋于8月30日至9月3日共售出24万股英伟达普通股，出售股票的价格从107.30美元到120.99美元不等，总价值约2757万美元（约合人民币1.96亿元）。 根据美国证券交易委员会的文件显示，黄仁勋6月最后一周出售了价值1.69亿美元的股票，并且在7月再次出售了价值约6100万美元的股票。目前，黄仁勋仍持有该公司7600多万股股票。 黄仁勋。图片来源：视觉中国 据第一财经，针对有消息称英伟达收到美国司法部与潜在反垄断调查有关的传票，英伟达方面回应记者称：“我们已经向美国司法部进行了询问，但尚未收到传票。英伟达凭实力取胜，我们很乐意回答监管机构对我们业务的任何问题。” 美国当地时间9月3日，英伟达大跌9.5%，市值蒸发2790亿美元，创下美国公司市值有史以来最大单日跌幅。 在市场传出美司法部向英伟达发出传票的消息后，英伟达CEO黄仁勋的财富创下历史最大跌幅，其净资产周二暴跌约100亿美元至949亿美元，创下自彭博亿万富豪指数2016年开始追踪他财富以来的单日最大缩减规模。 自人工智能（AI）爆火以来，英伟达就成了投资界的“香饽饽”，并凭借着其卓越的AI芯片产品，股价一路飙升，市值更是一度突破3万亿美元。然而根据Tiger 21最近发布的一份资产配置报告，该组织超一半的成员都不投资英伟达。 Tiger 21超级富豪俱乐部主席Michael Sonnenfeldt表示：“虽然英伟达目前是人工智能领域无可争议的领导者，但没有一家公司的增长会永远持续下去，竞争对手往往会迎头赶上，导致市场格局重新调整。” 据了解，该组织由Sonnenfeldt于1999年成立，成员们会在财富保值、投资和慈善事业方面相互分享建议。Tiger 21在53个市场拥有123家分会。该组织有超过1450个成员。根据Sonnenfeldt提供的数据，其成员的个人资产总额超过1650亿美元。 据悉，即使是在投资英伟达的43%的成员中，大多数人也不打算增持该股，因为担心它已经涨得太高了。 美东时间周三，英伟达股价下跌1.66%，这意味着在过去一周该股已经累计下跌了16%，而它什么时候能触底，可能是盘绕在很多人心头的重要疑问。 近日，华尔街一些技术分析师表示，英伟达的股票目前有两个关键支撑水平线，可能能为其股价提供关键支撑力，但一旦跌破，也可能直接打破其长期以来的市场领导地位。 每日经济新闻综合公开信息 免责声明：本文内容与数据仅供参考，不构成投资建议，使用前请核实。据此操作，风险自担。 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 49842,
      "title": "股价巨震!英伟达盘后一度大跌超8%,第二财季营收超预期,批准额外...",
      "time": "2024-08-29T00:00:00+00:00",
      "content": "美东时间周三，在英伟达财报的压力下，三大指数集体收跌，以科技股为主的纳指跌超1%。 热门科技股普跌，其中超微电脑跌近20%； 英伟达跌超2%，盘后股价先涨后跌，一度跌超8%，其第二财季营收继续超预期猛增，但第三财季指引未达最高预期，此外公司批准额外500亿美元股票回购。 英伟达称，Blackwell样品发货给合作伙伴和客户；Blackwell量产计划从第四季度开始；预计第四财季Blackwell收入将达到数十亿美元；市场对Blackwell的预期是不可思议的。 据媒体报道，机构分析认为，英伟达(NVDA.O)连续几个季度来都打破了华尔街预期，在分析师们持续提高预期的情况下。 然而，其大部分增长来自一小部分客户。英伟达约40%的收入来自大型数据中心运营商，如Alphabet旗下的谷歌和Meta Platforms等公司，这些公司正在向人工智能基础设施投入数百亿美元。尽管Meta和其他公司在本财季增加了资本支出预算，但人们担心，正在布局的基础设施数量超过了目前的需求。这可能导致泡沫。但英伟达CEO黄仁勋坚持认为，这还只是技术和经济新时代的开始。 伯克希尔哈撒韦公司市值首次突破1万亿美元，为美股第七家总市值超过1万亿美元的上市公司。 此外，热门中概股普跌，理想汽车跌超15%，小鹏汽车跌超9%。 美股三大指数齐跌 美股三大指数集体下跌，纳指跌超1%。 截至当天收盘，道琼斯工业平均指数比前一交易日下跌159.08点，收于41091.42点，跌幅为0.39%；标准普尔500种股票指数下跌33.62点，收于5592.18点，跌幅为0.60%；纳斯达克综合指数下跌198.79点，收于17556.03点，跌幅为1.12%。 大型科技股集体下跌，苹果跌0.68%，英伟达跌2.10%，超微电脑收跌19%，微软跌0.78%，特斯拉跌1.65%，谷歌跌1.11%，亚马逊跌1.34%，Meta跌0.45%。 热门中概股普遍下跌，纳斯达克中国金龙指数跌3.57%，阿里巴巴跌2.25%，京东跌1.67%，拼多多跌7.03%，蔚来汽车跌7.50%，小鹏汽车跌9.00%，理想汽车跌16.12%，哔哩哔哩跌5.60%，百度跌2.90%，网易跌3.78%，腾讯音乐跌5.13%，爱奇艺跌3.98%。 国际油价下跌，截至当天收盘，纽约商品交易所10月交货的轻质原油期货价格下跌1.01美元，收于每桶74.52美元，跌幅为1.34%；10月交货的伦敦布伦特原油期货价格下跌1.08美元，收于每桶77.58美元，跌幅为1.37%。国际金价下跌，截至当天收盘，COMEX黄金期货主力合约下跌2.30美元/盎司，跌幅0.09%，报2552.90美元/盎司. 英伟达盘后巨震 自本周以来，市场一直密切关注英伟达的季报，投资者关注的焦点包括英伟达Blackwell芯片的交付时间表，以及人工智能（AI）需求的最新情况。周三盘后公布的财报显示，英伟达Q2财报的利润和销售额比去年同期增长了一倍以上，超过了华尔街的预期。 1.主要财务数据： 营业收入：二季度营收300亿美元，同比增长122%，分析师预期营收288.6亿美元，英伟达自身指引274.4亿至285.6亿美元。 EPS：二季度非GAAP口径下调整后的每股收益（EPS）为0.68美元，同比增长152%，分析师预期0.64美元。 毛利率：二季度调整后毛利率为75.7%，同比上升4.5个百分点、环比百分点3.2个百分点，分析师预期75.5%，英伟达指引为75%至76%。 2.细分业务数据： 数据中心：二季度数据中心营收263亿美元，同比增长154%，分析师预期251亿美元。 游戏和AI PC：二季度游戏和AI PC业务营收29亿美元，同比增长16%。 专业可视化：二季度专业可视化营收4.54亿美元，同比增长20%。 汽车和机器人：二季度汽车和机器人业务营收3.46亿美元，同比增长37%。 3.业绩指引： 营收：三季度营收预计为325亿美元，上下浮动2%，即318.5亿至331.5亿美元，分析师预期均值319亿美元，最高预期379亿美元。 毛利率：三季度非GAAP口径下毛利率预计为75%，上下浮动50个基点，即74.5%至75.5%。 财报公布后，英伟达股价盘后先涨后跌，一度下跌8%。截至发稿，英伟达盘后跌近7%。 造成英伟达盘后大跌的原因是，该公司公布的营收预测低于最乐观的市场预期，从而引发了投资者对其爆炸式增长正在减弱的担忧。 英伟达CEO黄仁勋发声 英伟达在公布财报的同时还举行电话会议回答投资者提问。 英伟达CEO黄仁勋称，Hopper和Blackwell的需求都是不可思议的。今后至Blackwell发货、能够安装这段时期，大量需求将得到满足。Hopper（尤其是H200）达到那样的状态，然后，Blackwell将供应给客户，这需要时间。 黄仁勋提醒投资者，英伟达不仅将于四季度量产Blackwell，同期还将发货（给客户）。 他还强调，资本投资的回报（ROI）是“立竿见影的”。当前，如果你能投资计算基建，能带来最佳的ROI。 黄仁勋被问及Blackwell芯片和这对液冷的需求、是否会放慢应用速度等，称：下一个万亿美元规模的基建将是别开生面的。Blackwell将以许许多多的形式出现，其中一些并不需要液冷。但对液冷的需求是非常可观的，要求大量的工程。“我相当确信会发生这样的事。”黄仁勋表示。 英伟达CFO Kress回应称，现有的Hopper产品线将延续下去，Blackwell将超过它。 黄仁勋称公司习惯于服务ZT，但后者已经被AMD收购。 每日经济新闻综合公开信息 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 49843,
      "title": "英伟达Q2净利润大涨168%、回购500亿美元股票 但股价大跌",
      "time": "2024-08-29T00:00:00+00:00",
      "content": "英伟达 凤凰网科技讯 北京时间8月29日，人工智能芯片巨头英伟达公司(NASDAQ:NVDA)今天发布了截至7月28日的2025财年第二季度财报。财报显示，按照美国通用会计准则(GAAP)计算，英伟达第二财季营收为300.40亿美元，较上年同期的135.07亿美元增长122%；净利润为165.99亿美元，较上年同期的61.88亿美元增长168%。 英伟达宣布回购500亿美元股票，但对于第三财季营收展望低于一些分析师的最乐观预期，引发市场对其爆炸性增长可能正在放缓的担忧。英伟达称，正在解决备受期待的新款Blackwell架构芯片的生产问题。 股价表现： 英伟达第二财季营收和调整后每股收益均超出分析师预期，对于第三财季的营收展望也超出分析师平均预期，但是低于一些分析师的最乐观预期，股价在盘后交易中大跌近7%。 英伟达股价盘后下跌6.89% 英伟达周三在纳斯达克交易所的开盘价为128.12美元。截至周三收盘，英伟达股价下跌2.69美元，报收于125.61美元，跌幅为2.10%。截至美国东部时间周三17:53分(北京时间周四5:53分)，英伟达股价在盘后交易中下跌8.65美元至116.96美元，跌幅为6.89%。过去52周，英伟达股价最高为140.76美元，最低为39.23美元。 第二财季业绩要点： ——营收为300.40亿美元，较上年同期的135.07亿美元增长122%； ·数据中心部门(包含AI芯片业务)收入为263亿美元，同比增长154%，环比增长16%； ·游戏和AI PC部门收入为29亿美元，同比增长16%，环比增长9%； ·专业可视化部门收入为4.54亿美元，同比增长20%，环比增长6%； ·汽车与机器人部门收入为3.46亿美元，同比增长37%，环比增长5%； ——毛利率为75.1%，较上年同期的70.1%增长5个百分点，较上个季度的78.4%下降3.3个百分点；按非美国通用会计准则(Non-GAAP)，毛利率为75.7%，较上年同期的71.2%增长4.5个百分点，较上个季度的78.9%下降3.2个百分点； ——营业费用为39.32亿美元，较上年同期的26.62亿美元增长48%，较上个季度的34.97亿美元增长12%；按非美国通用会计准则，营业费用为27.92亿美元，较上年同期的18.38亿美元增长52%，较上个季度的25.01亿美元增长12%； ——营业利润为186.42亿美元，较上年同期的68.00亿美元增长174%，较上个季度的169.09亿美元增长10%；按非美国通用会计准则，营业利润为199.37亿美元，较上年同期的77.76亿美元增长156%，较上个季度的180.59亿美元增长10%； ——净利润为165.99亿美元，较上年同期的61.88亿美元增长168%，较上个季度的148.81亿美元增长12%；按非美国通用会计准则，净利润为169.52亿美元，较上年同期的67.40亿美元增长152%，较上个季度的152.38亿美元增长11%； ——每股摊薄收益为0.67美元，较上年同期的0.25美元增长168%，较上个季度的0.60美元增长12%；按非美国通用会计准则，每股摊薄收益为0.68美元，较上年同期的0.27美元增长152%，较上个季度的0.61美元增长11%。 资本回报计划 英伟达宣布，2024年8月26日，董事会批准了额外500亿美元的股票回购计划，无到期日期。2025财年上半年，英伟达通过回购股票和现金股息的方式向股东返还了154亿美元。截至第二财季末，英伟达的股票回购计划中还剩75亿美元。 英伟达同时宣布，将向截至2024年9月12日登记在册的所有普通股股东，派发每股0.01美元的季度现金股息，支付日期为2024年10月3日。2024年6月7日，英伟达完成了1:10拆股。 第三财季展望： ——营收预计为325亿美元，上下浮动2个百分点； ——毛利率预计为74.4%，按非美国通用会计准则为75%，上下浮动50个基点；2025财年毛利率预计介于74%至76%(mid-70% range)； ——营业费用预计约为43亿美元，按非美国通用会计准则约为30亿美元；2025财年营业费用增速预计介于45%-49%(mid-toupper-40% range)； ——其它收入预计约为3.5亿美元； ——剔除不可持续项目，税率预计为17%，上下浮动1个百分点。 高管点评： 英伟达创始人兼CEO黄仁勋(Jensen Huang)表示：“Hopper架构芯片需求依然强劲，人们对Blackwell架构的期待令人难以置信。随着全球数据中心全速推进，通过加速计算和生成式AI实现整个计算堆栈的现代化，英伟达实现了创纪录收入。” “Blackwell架构芯片样品正在向我们的合作伙伴和客户发货。适用于AI的Spectrum-X以太网平台和英伟达AI企业软件是两个具备显著规模的新产品类别，表明英伟达是一个全栈和数据中心规模的平台。在整个堆栈和生态系统中，我们正在帮助前沿模型开发商为消费者提供互联网服务，现在又为企业提供服务。生成式AI将彻底改变每个行业。”(作者/箫雨) 举报/反馈"
    },
    {
      "doc_id": 49846,
      "title": "DeepSeek、千问、混元、文心、Kimi与智谱,六大国产大模型谁是最强...",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "文｜锦缎 每当我们翻阅财报时，可能只想或许关键的财务信息，但总是受到财报中纷繁复杂的业务表述、冗长的管理层发言的干扰，需要耗费大量精力去甄别有用的财务信息。 特别是港股美股，国内的大多数金融软件，都是基于国内市场财务准则构建的信息展示，面对非标财务报表，总会出现部分摘取科目的错误。 进入AI大模型时代之后，这样的财务研究障碍或将被攻克——毕竟模型最擅长的，就是语言文字的总结归纳和数据的计算。 本文之中，我们即着手对六大国内主流大模型进行评测，用以探究下其财报分析能力，究竟发展到什么水平，又存在怎样的问题？ 阅读提示：鉴于评测内容过于硬核与篇幅较长，获取最终评测结果可直接拉至文报告底部“结论”部分。 01 评测对象、逻辑与标准 评测对象我们挑选了国内主流的6大模型： 深度求索（DeepSeek-R1） 阿里千问（Qwen3-235B-A22B） 腾讯混元（Hunyuan-T1） 月之暗面（Kimi-K1.5） 百度文心（ERNIE-X1-Turbo） 智谱（GLM-4-Plus） 评测逻辑方面，我们采取了“分层进阶”的问题构建，要想成为一个优秀的“AI财务分析师”，必须具备多层次的能力。 因此，我们设计了四个层级的测试，六个维度的问题，从基础到高级，逐步深入： 第一层：基础信息提取 AI必须具备的最基本的能力，模型必须能够准确读取财报。如果数据提取都出现错误，那么分析将变得毫无意义。 第二层：分析计算与核验 计算是模型最擅长做的事情，但模型还要会使用数据，从“阅读器”成长为“分析员”。 第三层：归纳推理与洞察 模型需要看得更深。要能超越字面信息，发现文字背后隐藏的逻辑。因此围绕第三层，我们设计了两个考核维度，分别是“高效的归纳和提炼能力”以及“敏锐的风险和情感识别能力”。 第四层：战略总结与外部知识整合 顶尖的分析需要行业视野，因此要理解企业的战略表述。同时知识库中有限的内容是不够的，模型需要连接外部世界，进行横向比较。为此我们同样设计了两个考核维度：“企业策略与定位的识别”和“外部信息搜索与整合”。 标准层面，我们对每一个模型都输入相同的prompt（后文中有详细提示词信息），来保持规则的统一。 02 六项财务分析能力横评 1）精准的数据提取能力——模型基础功底，精准才是王道 模型能否像一位严谨的会计师，从PDF财报中分毫不差地提取关键财务数据、特定费用项目以及管理层提到的业务成就。此项能力的表现，直接决定了后续所有分析的可靠性。我们将重点考察其准确率和稳定性。 Prompt： Test1.1：请根据提供的“美团-2025年第1季度”财务报告，提取以下关键财务数据，以表格形式返回结果：1.营业总收入；2.营业成本；3.净利润。 Test1.2:请找出并列出以下费用项目的具体金额，以表格形式返回结果：1.研发费用；2.销售及市场推广费用。 Test1.3:请仔细阅读“美团-2025年第1季度”财务报告中的“业务回顾及展望”部分，总结出管理层提到的本季度最重要的三个业务亮点或成就。| 评测结论： 本文评测的所有模型都顺利完成了指定核心财务数据和特定项目费用的提取。 其中，ERNIE-X1-Turbo、Hunyuan-T1、Kimi-K1.5和Qwen3-235B-A22B,还贴心地将财报中的单位由千元转变为亿元，更加贴合用户习惯。 对于非财务关键信息，模型的聚焦点则略有不同，但大多集中于核心本地商业收入和利润的强劲增长、闪购和即时零售业务的快速发展、餐饮外卖业务的持续优化以及骑手权益保障体系的升级等方面。 2）严谨的计算与核验能力——不只会计数，更要会解释 在提取数据后，模型能否扮演“审计员”的角色？这包括两个层面： 一是能否运用正确的公式，基于提取的数据计算出毛利率、流动比率等核心财务指标并解释其含义； 二是在面对管理层的业绩声明时，能否独立进行数据核查，判断其真伪。这是对模型逻辑推理和“批判性思维”的直接考验。 Prompt： Test2.1:根据“美团-2025年第1季度”财务报告中的数据，计算该公司的毛利率。请列出计算公式、使用的具体数据，并解释这个毛利率数值反映了公司怎样的盈利能力。 Test2.2:请使用“美团-2025年第1季度”财务报告中的资产负债表数据，计算该公司的流动比率。请说明你使用了哪些数据进行计算，并解释该比率所揭示的公司短期偿债风险。 Test2.3:管理层在报告中声称“核心本地商业的经营利润率同比提升3.2个百分点至21.0%”。请根据财报数据核实这一说法的准确性，并说明你的判断依据。 评测结论： 六个模型中，仅有Kimi-K1.5未能通过这一项测试。 Kimi-K1.5明明已经获取到正确的营业收入和营业成本，但在计算时却出现错误，正确答案应为37.4477，而该模型得出的答案为37.49。 图：Kimi-K1.5计算毛利率 与此同时，Kimi-K1.5在计算流动比率时，将“简明综合财务状况表”中的“现金及现金等价物”错误识别为“流动资产总额”，导致另一处计算错误。 图：Kimi-K1.5计算流动比率 而财务比率的解释，各模型均给出了上述财务比率的定义以及短期偿债能力稳健的结论。 除此之外，不同模型给出的其他信息也有所不同： DeepSeek-R1：美团资产结构的优势、风险揭示和需关注的隐患； ERNIE-X1-Turbo和GLM-4-Plus：未给出其他多余信息； Hunyuan-T1：安全边际充足、资产流动性结构优势、流动负债可控及潜在风险点； Kimi-K1.5：盈利能力较强、成本控制有效、业务结构优化等盈利能力反映； Qwen3-235B-A22B：盈利能力、成本控制能力的解释及行业对比。 数据核验方面，各模型均正确计算了2024年和2025年第一季度的经营利润率，验证了提示词中的给定说法。 值得注意的是，DeepSeek-R1还给出了业务意义，而Hunyuan-T1则附带了潜在风险提示。 3）高效的归纳与提炼能力——从“复制粘贴”到“提炼精华” 财报信息繁杂，能否为不同受众提炼核心要点，是衡量AI效率的关键。 本项能力考察模型能否像一位资深编辑，既能为普通投资者撰写一份通俗易懂的200字业绩摘要，也能精准概括出管理层在“讨论与分析”部分提到的主要挑战。 我们将评估其摘要的准确性、完整性和信息价值。 Prompt： Test3.1:请面向一位普通的国内投资者，用不超过200字，总结这份财务报告最重要的三个结论。 Test3.2:请总结“管理层讨论及分析”部分提到的公司面临的主要挑战。 评测结论： 整体表现摘要方面，各模型都能够准确地以数据为支撑给出正确结论。 其中，DeepSeek-R1、Hunyuan-T1、Kimi-K1.5和Qwen3-235B-A22B能够将结论分条进行罗列，结构层次相比另外两个模型将结论放到一段话中更加清晰。 DeepSeek-R1还展现出了另外一个亮点，即使用“赚钱能力飙升”、“家底厚抗风险”等通俗易懂的语言风格。 特定章节摘要方面，各模型都展现出了良好的信息定位准确性和归纳与条理性，能够准确定位原文位置并对公司面临的挑战进行逻辑归纳与分类，以清晰的分点阐述形式呈现，具备较强的可读性。 其中，DeepSeek-R1、ERNIE-X1-Turbo和Qwen3-235B-A22B都在回答过程中展示了相关数据，使其结论更具说服力，而DeepSeek-R1还额外标注了信息来源。 对于信息全面性，GLM-4-Plus虽然给出了多种答案，但由于缺乏具体依据支撑，内容略显空洞；而ERNIE-X1-Turbo则一如既往地延续了简练的回答风格。 4）敏锐的风险与情感识别能力——读懂字里行间的“弦外之音” 顶尖的分析师能“读出字里行间的意思”。我们通过本项能力，测试模型是否具备这种高级认知能力。 它能否识别出财报中未明说但隐含的业务风险;能否综合业绩和管理层措辞，对整份报告传递出的整体情绪基调（乐观、谨慎、悲观）做出准确判断。 Prompt： Test4.1:财报是否暗示了任何其他潜在的业务风险？请举例说明。 Test4.2:综合整份财报的业绩数据和管理层的措辞，你认为这份报告向投资者传递的整体基调是乐观、谨慎还是悲观？请给出你的判断，并提供至少2个理由。 评测结论： 在分析潜在业务风险时，除Kimi-K1.5以外的模型都能够根据财报中提及的说法分条列举潜在风险。 Kimi-K1.5则从宏观角度出发，根据美团的主营业务进行分析，并未注重于财报中隐藏的信息。 图：Kimi-K1.5分析潜在业务风险 此外，Kimi-K1.5在最初的回答中一次给出了50种风险，令人疑惑。 DeepSeek-R1、Hunyuan-T1和Qwen3-235B-A22B给出的回答最为清晰，使用固定的结构并明确给出信息来源，令用户一目了然，快速明确风险。 DeepSeek-R1首先按照“风险种类”-“驱动事件”-“财报原文”-“风险点”的结构进行阐述，此后给出财报中未明示但可推导的风险，最后给出结论和针对投资者的建议。 图：DeepSeek-R1分析潜在业务风险 Hunyuan-T1和Qwen3-235B-A22B也采用了类似的回答结构，在准确把握核心矛盾的同时展现了强大的推理能力。 ERNIE-X1-Turbo和GLM-4-Plus采取了分段论述的方式，在每段中阐述了风险的产生原因和财报中的论据出处，内容完整但扩展内容不够丰富，结构相比上述三个模型不够清晰。 整体情绪判断任务中，六个模型给出的整体基调均为乐观。 但DeepSeek-R1、Hunyuan-T1和Qwen3-235B-A22B都直接或间接采用了“谨慎乐观”的说法。 GLM-4-Plus和Kimi-K1.5虽然识别出了报告中提及的风险和挑战，但认为瑕不掩瑜。 ERNIE-X1-Turbo的回答中则没有提到任何悲观因素。 由此可知，DeepSeek-R1、Hunyuan-T1和Qwen3-235B-A22B通读全文并把控整体情绪的同时，对于细节的理解和大局观都要略胜一筹，具备兼顾“事实”和“情感”的平衡能力，其结论也更加立体和可信。 5）企业策略与定位推断能力——需要“知识储备”的综合题 这是从数据到洞察的飞跃。 模型能否结合财报数据和自身知识，扮演“战略分析师”，识别竞争格局;我们要求模型基于毛利率和研发投入等数据，推断公司的竞争策略（是成本领先还是技术驱动）,并综合各项信息，评估其在行业中的市场地位（是领导者还是挑战者）。 Prompt： Test5.1:请根据“美团-2025年第1季度”财务报告中对其业务的描述，并结合你的通用知识，列出该公司所在行业的主要竞争对手（至少两家）。 Test5.2:请分析报告中的“毛利率（Gross Margin）”和“研发费用占收入的比例”。基于这两个数据，并与你所知的该行业典型水平进行比较，推断该公司更可能采取哪种竞争策略：是“成本领先”策略（追求高效率和低成本），还是“差异化/技术驱动”策略（追求产品独特性和高附加值）？请说明你的推理过程。 Test5.3:综合整份财务报告（包括其收入增长率、利润率水平以及管理层的讨论），请对该公司在本行业中的市场地位给出一个综合评估。你认为它更接近于“行业领导者”、“强有力的挑战者”，还是一个“特定的利基市场参与者”？请提供至少两点证据来支持你的结论： 1.一个来自财务数据（例如：高于/低于行业平均的利润率或增长率）。 2.一个来自“管理层讨论与分析”部分的定性描述。 评测结论： 在识别竞争格局时，本文测试的六个模型均能准确列出当前市场中最主要的竞争对手（饿了么、抖音本地生活服务和京东到家），并将具体业务线进行对应。 证明AI具备将财报中的业务描述与知识库中的现实世界商业实体进行精准匹配。 不过，各模型给出的回答思路有所不同。 DeepSeek-R1、GLM-4-Plus、Hunyuan-T1和Qwen3-235B-A22B先列出竞争对手，再给出其竞争领域和依据。 ERNIE-X1-Turbo和Kimi-K1.5先列出竞争领域，再给出主要竞争对手和竞争关系。 其中，DeepSeek-R1和Hunyuan-T1在给出依据时引用了财报原文，使答案更具备说服力；其他模型则更多根据通用知识库中的内容进行回答。 此外，Qwen3-235B-A22B和Kimi-K1.5分别注意到国际竞争对手和自有外卖系统，是意外的亮点。 推断竞争策略则是本次测评中难度最高的一项任务，需要AI模型完成“数据提取”-“外部知识比对”-“商业理论应用”-“逻辑推理”的完整闭环。 数据提取方面，GLM-4-Plus使用了假设数据，从而导致后续分析中使用的毛利率数据错误，其结果不具备参考性；而其余模型都提取到了正确的数据。 图：GLM-4-Plus推断竞争策略 在推理分析过程中，尽管行业平均数据不具备权威性，但除了ERNIE-X1-Turbo外的模型均以行业平均数据作为参照物进行了外部知识比对，有效提高了分析质量。 图：ERNIE-X1-Turbo推断竞争策略 由于各模型的关注点有所不同，ERNIE-X1-Turbo、Hunyuan-T1和Kimi-K1.5能够基于上述比较和结论，生成一个“nuanced”的结论，而非从提示词中进行二选一。 至于对市场地位的评估，六个模型通过引用管理层讨论原文、定量分析和定性分析等方式，全部给出了“行业领导者”的判断，论证过程严密，具备较高的可信度，且模型之间基本不存在能力差异。 6）融合外部知识的联网比对能力——能力边界的拓展 最后，我们打破单一文档的限制，考察模型连接现实世界的能力。 它能否通过联网搜索功能，获取竞争对手同一时期的财务数据（如毛利率、流动比率等），并进行准确的横向比较。 Prompt： Test6.1:2025年第1季度，相比京东、阿里、百度和快手，美团的销售毛利率这一指标排名如何？可通过联网搜索获取所需数据，但必须保证数据的准确性，禁止编造或假设数据，禁止使用虚假数据。 Test6.2:2025年第1季度，相比京东、阿里、百度和快手，美团的流动比率这一指标排名如何？可通过联网搜索获取所需数据，但必须保证数据的准确性，禁止编造或假设数据，禁止使用虚假数据. Test6.3:2025年第1季度，相比京东、阿里、百度和快手，美团的资产负债率这一指标排名如何？可通过联网搜索获取所需数据，但必须保证数据的准确性，禁止编造或假设数据，禁止使用虚假数据。 此项能力直接关系到AI作为智能助手的实用价值。 评测结论： 本次评测的六个模型对于联网信息的搜集能力均不理想。 对于销售毛利率，尚有DeepSeek-R1、ERNIE-X1-Turbo和Hunyuan-T1能够获取五家公司的全部正确数据。 而流动比率和资产负债率则没有任何一个模型能够获取全部正确数据。 DeepSeek-R1和ERNIE-X1-Turbo的信息搜索能力相对最强，均获得10项以上正确数据，前者不存在编造数据的情况，后者出现一次错误数据； Kimi-K1.5和Qwen3-235B-A22B的信息正确率位于中等水平，在计算流动比率和资产负债率时，存在一定未获取到数据或编造数据的情况； GLM-4-Plus和HunyuanT1表现较差，尤其是在计算资产负债率时，频繁出现编造数据的情况。 GLM-4-Plus甚至只搜索到了一个与问题毫无联系的网页并编造了5个虚假数据，给用户带来极大困扰。 综上所述，由于AI大模型在联网搜索信息时几乎不会去权威性数据渠道进行查询，而互联网中又充斥着大量的虚假错误信息。 AI在这一领域还有很大的提升空间，在分析财报时会导致严重的错误，因此不建议使用联网搜索功能以获取重要财务数据。 03 结论 为了更加直观地展现评测结果，我们制作了如下表格： 在不考虑联网信息搜索的情况下： 对于专业的投资者或财务分析人士，DeepSeek-R1、Hunyuan-T1和Qwen3-235B-A22B都是值得信赖的“助理”，在提升工作效率的同时，它们还可以提出有价值的洞察； 对于普通用户或学生，ERNIE-X1-Turbo也是不错的选择，完全可以胜任快速获取核心数据和基本信息的功能。 但是，联网信息搜索的准确性对于各模型来说都是现阶段难以跨越的门槛，我们可以接受AI找不到信息，但不能接受AI把假信息当真信息回答。 最后，依旧我们略显主观的评测标准，统计了六大模型的财务分析能力雷达图，供大家参考: 举报/反馈"
    },
    {
      "doc_id": 49848,
      "title": "为何DeepSeek引发美国恐慌?",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "据央视新闻消息，这几天，中国人工智能初创公司DeepSeek火了，不仅在美区下载榜上超越了ChatGPT，还引发多个美国科技股的股价暴跌。美国总统特朗普称DeepSeek的出现“给美国相关产业敲响了警钟”。为何DeepSeek的出现会让美国如此关注，甚至有些紧张？ 原因一：高性价比冲击美国大模型垄断地位 DeepSeek可谓是用最少的钱，干最多的事。其推出的模型，在性能上和世界目前顶尖的GPT-4o等大模型不相上下。但在成本上，OpenAI训练ChatGPT-4花费的成本高达7800万美元，还可能达到1亿美元。而DeepSeek大模型训练成本不到600万美元，仅为同性能模型的5%到10%。新模型训练方法大幅度降低了大模型行业的入局门槛，大规模预训练不再是科技巨头的专利。在模型推理层面，DeepSeek新推出的DeepSeek-R1，价格为2.2美元/百万词元，而同性能OpenAI-o1的价格为60美元/百万词元，DeepSeek大概是OpenAI的三十分之一。这种“低成本”标志着推理大模型调用进入平价时代，显著改善了大模型的应用成本，对大模型在科研、企业等智力密集型产业中的应用具有重大的价值。因此，无论是从基础研究角度还是从商业层面上看，在训练和推理方面，对此前美国一些大模型公司的既有模式冲击比较大。 原因二：模式创新，带来美国高新技术人员恐慌 DeepSeek开发成本与美国大模型相比大幅降低，在于应用了不同的模型训练模式，打破了美国堆砌算力的“豪气”方式。在喂养学习数据这一大模型重要环节上，OpenAI选择了“人海战术”，堆砌算卡、将资源集中在算力，用海量数据投喂实现能力的提升。而DeepSeek相比于“砸资源”选择了另外一种方式。利用算法把数据进行总结和分类，经过选择性处理之后再输送给大模型，最大优化算力实现了成本的降低和模型性能提升。目前看Meta耗费了大量资金训练Llama，但是效果上却没有成本极低的DeepSeek效果好，Meta高层已经在思考其员工是否在浪费公司资金，而这也引发了不少企业技术人员的恐慌，他们担心自己被质疑技术能力和创新性从而失去工作。根据海外互联网平台对DeepSeek的讨论分析，社交媒体帖子的数量远高于新闻报道，数量约是新闻报道的十倍。时间上来看，社交媒体帖子的讨论早于新闻报道，发酵起点比新闻媒体早了五天，这是由从事科技工作的自媒体人以及员工圈层传播“破圈”造成。 原因三：国产大模型正在厚积薄发 根据中国工业互联网研究院推出的《人工智能大模型年度发展趋势报告》，与国际顶尖大模型能力相比，2024年国内大模型的能力进步非常显著。从2023年第四季度到2025年第一季度的测评显示，国内外大模型能力差距缩小了将近75%。可以看出，DeepSeek的出现并不是所谓的“异军突起”，而是中国国内大模型整体发展的阶段性成果体现。此外，在报告统计的世界AI领域的投资上，中国55亿美元的投资额排在第二位，仅是第一位美国641亿投资额的不到十一分之一，中国未来在AI领域的发展上还有很大的空间。 如今，在DeepSeek对全球AI圈带来的震动下，很多业内人士都喊出了“DeepSeek接班OpenAI”的口号。事实上，DeepSeek的出现，并不是要取代别人，而是提出了更多样化的方案，打破了国际主流大模型的市场垄断，在大模型的发展道路上提出了不同于美西方的中国解法，让世界看到了在大模型领域不是只有拼算力这一条路，再一次向世界证明，什么是中国智慧。 编辑 李忆林子 举报/反馈"
    },
    {
      "doc_id": 49849,
      "title": "中国AI一夜掀翻美股,硅谷大佬坐不住了,特朗普发话!",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "来源：媒体滚动 据 @CCTV国际时讯 消息，当地时间1月27日晚，美国总统特朗普在佛罗里达州迈阿密发表讲话时，对中国人工智能初创公司DeepSeek搅动纳斯达克一事表示，DeepSeek的出现“给美国相关产业敲响了警钟”，美国“需要集中精力赢得竞争”。 据央视新闻消息，当地时间1月27日，美国股市开盘即大幅下跌，科技板块尤为惨重。市场分析认为，核心原因是中国人工智能初创公司DeepSeek的最新突破，动摇了美国科技行业的“无敌”地位。 因受到DeepSeek人工智能模型冲击，美国芯片巨头英伟达（NVIDIA）当日股价暴跌约17%，博通公司股价下跌17%，超威半导体公司（AMD）股价下跌6%，微软股价下跌2%。此外，人工智能领域的衍生品，如电力供应商也受到重创。美国联合能源公司股价下跌21%，Vistra的股价下跌29%。 1月24日，在国外大模型排名Arena上，DeepSeek-R1基准测试已经升至全类别大模型第三，其中在风格控制类模型（StyleCtrl）分类中与OpenAI o1并列第一，其竞技场得分达到1357分，略超OpenAI o1的1352分。一夜间，DeepSeek在全世界科技界刷屏。1月27日，Deepseek应用登顶苹果中国地区和美国地区应用商店免费APP下载排行榜，在美区下载榜上超越了ChatGPT，成为美国苹果应用商店下载量最大的免费应用程序。 CNN、《纽约时报》、《华盛顿邮报》等美国主流媒体纷纷用《中国名为DeepSeek的人工智能技术正在导致美国股市暴跌》、《由于投资者担心中国的AI进展，股市下跌》、《中国的DeepSeek AI应用程序导致美国科技股下跌》等标题对DeepSeek“现象级”的崛起进行报道。 01 低成本实现高性能 给美国“苦涩教训” 据报道，DeepSeek推出的DeepSeek-R1模型以极低的成本实现了与OpenAI o1相当的性能，但成本连后者的零头都不到。有分析人士认为，DeepSeek在有限的硬件资源下实现顶尖的模型性能，减少了对高端GPU的依赖，低廉的训练成本预示着AI大模型对算力投入的需求将大幅下降。正因为此，美股芯片股首当其冲。 DeepSeek备受关注的原因主要是性价比、开源及推理能力的提升等方面。在性价比上，DeepSeek-R1成本很低，预训练费用只有557.6万美元，不到OpenAI GPT-4o模型训练成本的十分之一。DeepSeek还公布了API(应用程序编程接口)的定价，收费大约是OpenAI o1运行成本的三十分之一。 同时，DeepSeek与外国大模型巨头闭源的路径不同，采用开源模式。DeepSeek公布了相关论文，整个过程可复现。网络上已经出现了一波复现热潮，加州大学伯克利分校、香港科技大学、知名人工智能公司HuggingFace等纷纷成功复现，复现成本甚至低至几十美元。 美国红迪网（社交新闻类站点）25日称，中国DeepSeek的模型是开源的，是令人兴奋的真正原因，他们将制造这些东西的知识免费提供给全世界，确保没有人能够真正垄断它。AI数据服务公司Scale AI创始人Alexander Wang就发帖称，（去年发布的）DeepSeek-V3是中国科技界带给美国的苦涩教训。“当美国休息时，中国（科技界）在工作，以更低的成本、更快的速度和更强的实力赶上。” 1月26日，游戏科学创始人、CEO，《黑神话：悟空》制作人冯骥评价DeepSeek：“可能是个国运级别的科技成果”。冯骥表示：“希望DeepSeek-R1会让你对当前最先进的AI祛魅，让AI逐渐变成你生活中的水和电。太幸运了！太开心了！这样震撼的突破，来自一个纯粹的中国公司。知识与信息平权，至此又往前迈出了坚实的一步。” 02 硅谷大佬们坐不住了 DeepSeek不仅冲击了英伟达的商业模式，也让硅谷的一众科技巨头感到不安。 以Meta为例，这家公司近年来在AI领域投入了数百亿美元，试图通过构建超大规模的语言模型来与OpenAI竞争。但是，DeepSeek仅用不到1000万美元的研发成本并且大获成功，让人们开始质疑，这种砸钱式研发是否真的是唯一的路径。 据知情人士透露，DeepSeek登顶App Store排行榜的第二天，Meta内部的一个高层会议就连夜召开。这种危机感，不独Meta一家有，整个硅谷都弥漫着一种恐慌，很多大厂开始重新评估自己的研发策略。 微软CEO萨蒂亚・纳德拉在瑞士达沃斯世界经济论坛上表示：“看到DeepSeek的新模型，真的令人印象非常深刻。他们切实有效地开发出了一款开源模型，在推理计算方面表现出色，且超级计算效率极高。我们必须非常、非常认真地对待中国的这些进展。” 03 开发团队140人 多为职场“萌新” DeepSeek，全称杭州深度求索人工智能基础技术研究有限公司，成立于2023年7月17日，是一家创新型科技公司，专注于开发先进的大语言模型（LLM）和相关技术。 据悉，DeepSeek的团队不到140人。工程师和研发人员几乎都来自清华大学、北京大学、中山大学、北京邮电大学等国内顶尖高校，工作时间都不长。创始人梁文锋今年40岁，广东湛江人，17岁考入浙江大学，后又在浙大攻读信息与通信工程专业硕士。师从项志宇，主要做机器视觉研究。 梁文峰是如何带领团队创造出这款撼动全球AI业界应用的？他又如何成为总理的“座上宾”？共同回顾直新闻早前的报道《“85后”广东小伙，缘何成为李强总理“座上宾”？》。 排版丨季靳玮 编辑丨郭永佶 举报/反馈"
    },
    {
      "doc_id": 49850,
      "title": "DeepSeek官宣R1升级:提升思维深度与推理能力,整体表现已接近国际...",
      "time": "2024-05-29T00:00:00+00:00",
      "content": "责任编辑：王杰 图片编辑：蒋立冬 澎湃新闻报料：021-962866 澎湃新闻，未经授权不得转载 +1 61 收藏 我要举报"
    },
    {
      "doc_id": 49852,
      "title": "首见|DeepSeek 解封“算力智子”后,数据成 AI 未来发展关键",
      "time": "2024-03-25T00:00:00+00:00",
      "content": "DeepSeek 之前：被算力算法“智子”围困的中国 AI 主流的AI大模型训练方式主要是基于 Transformer 进行下一个 Token 的预测。即从互联网为主要渠道来吸收数千亿级的海量数据，并用进行类似均值的匹配，对匹配结果偏差比较大的，也就是通常说的“大模型幻觉”（详见上篇《AI 幻觉的一体两面》），进行人工打分/直接指导打标签，以此来提升模型的准确性。 众所周知，AI 大模型核心三要素即数据、算法和算力。数据对应的是“食材”，算力对应的是“厨具”，算法则是“厨艺”。从全球范围来看，当前算力的硬件性能已接近瓶颈，其迭代速度远不及大模型的日益增长的训练需求和能耗压力。 而可供预训练的现实数据也逐渐见顶，2024 年 11 月份 OpenAI 前首席科学家 Ilya 在公开场合表示简单地增加数据和计算能力来扩大当前模型规模的时代已经结束。随着大语言模型逐渐往多模态模型上发展，算力和数据的挑战则会进一步加剧。 目前，算力方面我国面临美国的“芯片禁令”的封锁，使得国内 AI 公司没法使用高端好用的厨具，就像别人用高压锅炖鸡汤一刻钟，我们只能用柴火灶一直加柴熬两小时。在此背景下，我国发展人工智能只能从算法和数据两个方面做得更好，才有机会突围。 在算法方面，过去普遍观点是由于投入方面不对等，致使我国和OpenAI为代表的美国头部AI大模型公司有着至少1～2年的差距。根据CB Insights 发布的数据，2024年中国AI初创企业筹集的资金仅占美国AI初创企业的 7%。丰厚的资金储备意味能高薪招“全球绝顶聪明人”形成在研发创新上的碾压，进一步巩固算法优势。在DeepSeekV3之前，我国人工智能领域所面临的情况不可谓不严峻。 高质量的可用数据是企业应用AI最突出的挑战 在 DeepSeekV3和R1推出之后，顶尖的模型效果和用户体验，加上其开源的特性，大大缓解了我国在算法和算力上的困境，但数据方面的挑战依然存在。 数据是食材，食材的品质、丰富度及新鲜度都决定了最终菜品的口感和品质上限。对于大模型而言，高质量数据能够保障模型推理回答的准确性。而多模态多种类的数据，能提升模型的泛化性和推理能力，尤其是在机器人的大脑（VLA 等）上。此外，还需要进行联网搜索并定期更新数据集，来确保模型回复结果的时效性和准确性。 就可用数据量上，国内和国外有着天然差距。据W3Techs调研前一百万互联网网站使用的语言文字百分比，其中英文占比为59.3%，而中文只有 1.3%。相比于美国的头部AI公司，国内可供训练的公开中文数据不够多，标准化程度也不够高。 从结果来看，数据已是目前企业应用 AI 最突出的挑战。根据IDC和浪潮信息发布的研究显示，目前企业在应用人工智能中所面临挑战最大的是缺乏高质量可用数据，占比高达66%。在此之后才是成本高、技术成熟度、人才缺乏等新兴领域通用挑战。 另一方面，数据采集与处理是目前国内企业在生成式 AI 应用时的主要支出方向，尤其是对于工作流程繁琐、决策链路较长、业务类型众多的公司而言，其业务数据需要经过层层筛选、处理和业务理解后，才能成为标准化的高质量数据，再用于模型的训练和推理。 像 DeepSeek 那样训练数据要怎么做？ 或许你不用像DeepSeek那样去训练数据，但了解他的训练法则依然很有参考价值。 在DeepSeek之前，阿里的通义千问系列是全球主流的开源语言模型。去年圣诞后DeepSeekV3发布当天，我们对已有的信息作梳理分析：DeepSeek则采用了创新性的架构（MLA+MoE），并解决了很多细微的工程化落地难题，使得其在使用极低成本的情况下，成为当时最强的开源基础模型。 对于DeepSeek的关键，百度百科上的结果则是更为简短直接，即使用数据蒸馏技术，得到更为精炼、有用的数据。 图片来源：百度百科 为了更深入理解具体核心机制，援引“极客学长”的结论：“总结来说，DeepSeek-R1-Zero 模型（以下简称“R1-ZERO”）的训练方式就像教小孩学走路，不直接告诉它正确答案，而是让它自己尝试，根据结果的好坏（比如答案是否正确）来调整自己的行为。这种方法不需要预先标注好的数据，完全靠 AI 自己摸索，没有输入任何带标记的数据，这也是为什么这个版本的名字带 Zero 的原因，表示零样本输入。” 图片来源：公众号“我就是极客学长” R1-Zero模型表现非常惊艳，在数学和编程方面的能力已经达到OpenAI-o1-0912的水平。但也存在明显的缺陷——生成的答案可读性差，经常出现中英文混杂。针对这个问题，DeepSeek团队采取了一系列的优化措施。 首先，用数千条人工处理的高质量COT数据（比如详细的解题步骤），通过监督微调（SFT）的方式让它“冷启动”，再用强化学习进一步训练，使得生成的答案更清晰，语言也更统一。简而言之，即研究人员给了R1-Zero 模型一些优质例题，教它规范的解题格式，再用强化学习训练，使其解题又快又准，格式工整。此时得到一个Checkpoint，并将该Checkpoint 称之为DeepSeek-R1-One（以下简称“R1-One”）。 然后，再用训练R1-Zero的方式，用R1-One 生成一批高质量的COT数据（长思维链数据），同时再结合专业领域数据和人为反馈数据等，再以 DeepSeek-V3为基础模型进行强化学习，得到最终的DeepSeek-R1。 可以发现，DeepSeek除了在算法层面进行了一系列的创新和优化，其核心步骤中的数据都是自行人工处理或撰写的。如同投资人朱啸虎在转变对大模型态度时所说，DeepSeek这次唯一没有公开的就是模型预训练数据。 图片来源：BOSS直聘 此外值得注意的是，在爆火后DeepSeek开启了数据百晓生的实习生招聘，岗位要求不高但薪资丰厚，已经远超一般的数据外包公司全职人员水平，从侧面体现出其对高质量数据的重视程度。值得注意的是，该岗位优先考虑小语种专业，这或许是为了更好地进军全球市场所做的铺垫和准备。 具身智能、自动驾驶领域同样面临数据挑战 在近期的演讲及访谈中，上海交大博导、穹彻智能联合创始人卢策吾教授指出：当下，具身智能的研究路线正处于瓶颈期，具身智能面临的两大核心挑战之一是数据规模存在“太平洋缺口”。工业级应用对具身智能设定了严格的红线标准，为达到这一标准，所需的数据量堪称海量。然而，数据采集模式难以有效填补这一巨大的数据缺口。 图片来源：NOEMATRIX 当前数据采集面临着一系列棘手问题：遥操作需要购置价格昂贵的机器人设备及相关配套技术，并且操作人员需要经过专业培训。这些因素导致成本高昂，从而限制了数据采集的规模。 为突破具身智能大模型的 Scaling Law 约束，实现数据采集的规模化并降低数据获取成本，需要找到一种既能保证数据真实性，又不影响人们日常工作的数据采集方法。 在自动驾驶领域，随着 2024 年开始智驾领域走向端到端时代，数据的重要性空前提升。 端到端技术的核心在于通过大量数据训练模型，使其能够识别和预测各种驾驶场景。高质量数据的输入，直接决定了模型输出的准确性和可靠性。这些数据不仅需要涵盖各种道路条件、天气变化和交通情况，还要确保其标注的准确性和多样性。 传统模块化算法需要改变控制策略时，可以找到代码中具体的几行参数修改，之后测试 1%的案例即可，而端到端的算法中，小的改动需要重新对自动驾驶算法进行训练，难度可想而知。 因此，海量的、多样化的、优质的数据不可或缺，同时自动化、高水平的数据处理体系亦至关重要。根据业内专家意见，华为在智驾方面的一半投入用在了数据采集和处理上。毫不夸张地说，端到端时代，数据会占据自动驾驶开发中 80%以上的研发成本。 从数据维度看，海量且优质的数据正成为自动驾驶行业的“稀缺品”。自动驾驶采用的BEV感知方案，需要达到1亿帧以上的训练数据才能满足车规要求，否则泛化性、准确率和召回率就难以保障。 以特斯拉为例，马斯克曾表示，特斯拉FSD测试里程需要达到60亿英里，才能满足全球监管机构的要求，这也是自动驾驶系统实现质变的一个重要节点。2024年5月，在解决了算力瓶颈之后，马斯克表示更大的难点在于对长尾数据的收集，其获取难度和成本对比通用数据则是指数级激增。业内目前普遍观点是，长尾数据只能通过仿真或数据生成的方式来解决。 获取高质量数据的“三板斧”：标注、采集、生成 标注、采集和生成，是目前获取高质量数据的三种方式。 数据标注，主要分为人工标注和机器人标注。发展至今，实际应用中以人机协同标注为主，即企业开发的自动化标注平台，先对入库数据进行预标注，节省人力的同时保证一定的准确度。再由专业或有经验的人员对机器预标注的数据进行进一步的鉴别和处理，进一步提升数据质量和准确度。随着技术和业务的发展，未来有望出现自动化标注程度和准确性均较高的平台或软件，在大模型产业链中人力参与最重的环节降本增效。 数据采集，目前数据采集主要通过人工、设备或者爬虫等方式进行采集。数据采集通常面向除语料、图片和视频外更多样的数据，所应用领域也更加广泛，除了人形机器人领域所广泛应用的动捕采集还是自动驾驶领域广泛应用的实车采集，还包括 AI4S 和机器视觉领域主要应用的设备参数采集和实景三维采集等。 目前数据采集是上述前沿科技领域的必备关键环节，其成本也是高居不下。因此，上述行业内也催生出高质量高效率进行数据采集、加工处理和挖掘分析的痛点诉求。随之孕育而生的就是数据生成。 数据生成主要是通过数据扩张、预测或限定条件下的随机生成等方式进行，目前处于发展早期，其中获得广泛关注的是世界模型。世界模型的目的是生成可编辑、有物理特性的高质量虚拟场景，完成对现实世界的复刻或虚拟世界的构建，从而在里面进行数据的处理和模型的训练，在数据获取成本和多样性上具有发展前景。 但值得注意的是，世界模型是通过算法来实现的，在数据精度上难以匹敌的高精密仪器设备的实景或实物采集，并不能完全替代数据采集，但可以实现非常有效的互补。 筑牢“高质量数据地基” 政府正加速行动 今年以来，为解决人工智能产业中的数据痛点，多地政府加速推动高质量数据建设。 2月19日，国家数据局在北京召开高质量数据集建设工作启动会。这不仅彰显了国家对数据要素的高度重视，也预示着我国数据产业发展将迈入新阶段。 2月18日，《武汉市促进人工智能产业发展若干政策措施》的发布会上明确将聚焦工业制造、医疗健康、科研创新等12个行业领域，推进公共数据、企业数据与个人数据分类分级开发利用，建设不少于20个高质量数据集。 3月18日，武汉市数据局发布支持高质量数据集建设和数据产品利用的公开征求意见稿，对相关单个标的予以最高 200 万元的支持。 3月3日，深圳市工信局于发布《深圳市加快打造人工智能先锋城市行动计划（2025—2026年）》，明确加快构建高价值垂类数据集和具身智能数据集。其中明确指出，将形成3PB中文语料数据，并在宝安、龙华两个区建设具身智能数据采集基地，形成多模态训练的开源数据集。 我们能看到，近年来由大疆、DeepSeek、“六小龙”所展现的中国科技创新变革并非局部的突发事件，而是举国推动科创时代下，人才红利叠加完备产业链形成坚实基础，并由科研型企业家实现范式创新，完成从量变到质变的结果呈现。 还有很多尚在量变积累的优秀创业者和研发团队在日夜兼程，政府也在积极推动基础设施建设给创新提供土壤，历史反复应验，曾种过的种子都会开花结果，只是需要时间和机缘罢了。 参考资料： 1、新浪财经，《外媒：DeepSeek受关注 登顶140国应用商店榜首》 2、上观新闻，《创新纪录!DeepSeek成史上最快突破3000万日活APP》 3、IDC、浪潮信息，《2025年中国人工智能计算力发展评估报告》 4、极客学长，《DeepSeek R1 破圈的核心技术解读，你不能不知道的 AI 干货！》 5、无相君，《中美大模型的差距，究竟在哪儿？》 6、张小珺，《朱啸虎现实主义故事1周年连载：“DeepSeek快让我相信AGI了”》 7、穹彻智能，《2025 全球开发者先锋大会：具身智能语料工程启动，“生产伴随” 引领未来》 8、极智GeeTech，《无数据不智能，数据闭环重塑高阶智驾未来》 9、复旦大学 张奇教授，《生成式AI大会（上海站）2024》公开演讲 10. 国金证券，《AI行业关键时刻：瓶颈与机遇并存》 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 49853,
      "title": "...赶上美国”!硅谷工程师连夜尝试复制,DeepSeek或彻底改变游戏规则",
      "time": "2024-01-26T00:00:00+00:00",
      "content": "短短一个月内，中国AI初创公司深度求索（DeepSeek）先后发布了DeepSeek-V3和DeepSeek-R1两款大模型，成本价格低廉，性能与OpenAI相当，让硅谷震惊，甚至引发了Meta内部的恐慌，工程师们开始连夜尝试复制DeepSeek的成果。 Scale AI创始人Alexander Wang在1月24日的采访中表示，DeepSeek在他们的测试里是表现最好的，与美国最好的模型相当。 此前，Alexander Wang评价说，DeepSeek-V3是中国科技界带给美国的苦涩教训。“当美国休息时，中国（科技界）在工作，以更低的成本、更快的速度和更强的实力赶上。” 此外，中国AI“刷屏”国外各大媒体，它们认为中国大模型的新进展为硅谷敲响了警钟。 在5000亿美元的“星际之门”计划公布之际，DeepSeek以极低的价格建立了一个突破性的AI模型，而且没有使用尖端芯片，让人们质疑，AI行业数千亿美元资本的巨额投入真的是最有效的方法吗？ Meta进入恐慌模式，试图复制DeepSeek 1月24号，一条发布在匿名平台teamblind上的帖子疯传。一名Meta员工称，现在Meta内部因为DeepSeek的模型，已经进入恐慌模式。 这位Meta员工写道： “一切源于DeepSeek-V3的出现，它在基准测试中已经让Llama 4相形见绌。更让人难堪的是，一家‘仅用550万美元训练预算的中国公司’就做到了这一点。 工程师们正在争分夺秒地分析DeepSeek，试图复制其中的一切可能技术。这绝非夸张。 管理层正为GenAI研发部门的巨额投入而发愁。当部门里一个高管的薪资就超过训练整个DeepSeek V3的成本，而且这样的高管还有数十位，他们该如何向高层交代？ DeepSeek-R1的出现让情况更加严峻。具体细节属于机密，不便透露，不过很快就会公开了。” 去年12月27日，DeepSeek推出开源模型DeepSeek-V3。当时，聊天机器人竞技场（Chatbot Arena）显示，DeepSeek-V3在所有模型中排名第七，在开源模型排第一。而且，DeepSeek-V3是全球前十中性价比最高的模型。 不到一个月之后，今年1月20日，DeepSeek正式开源R1推理模型，允许所有人在遵循MIT License（注：被广泛使用的一种软件许可条款）的情况下，蒸馏R1训练其他模型。 1月24日，DeepSeek-R1在聊天机器人竞技场综合榜单上排名第三，与顶尖推理模型o1并列。 在高难度提示词、代码和数学等技术性极强的领域，DeepSeek-R1拔得头筹，位列第一。 在风格控制方面，DeepSeek-R1与o1并列第一，意味着模型在理解和遵循用户指令，并按照特定风格生成内容方面表现出色。 在高难度提示词与风格控制结合的测试中，DeepSeek-R1与o1也并列第一，进一步证明了其在复杂任务和精细化控制方面的强大能力。 Artificial-Analysis对DeepSeek-R1的初始基准测试结果也显示，DeepSeek-R1在AI分析质量指数中取得第二高分，价格是o1的约三十分之一。 AI大佬惊叹：中国AI已追上美国 去年12月DeepSeek-V3发布后，AI数据服务公司Scale AI创始人Alexander Wang就发贴称，DeepSeek-V3是中国科技界带给美国的苦涩教训。“当美国休息时，中国（科技界）在工作，以更低的成本、更快的速度和更强的实力赶上。” 著名投资公司A16z的创始人马克·安德森1月24日发文称，Deepseek-R1是他见过的最令人惊叹、最令人印象深刻的突破之一，而且还是开源的，它是给世界的一份礼物。 1月24日，A16z合伙人、Mistral AI董事会成员Anjney Midha表示：“从斯坦福到麻省理工，DeepSeek-R1几乎一夜之间成为美国顶尖大学研究人员的首选模型。” 对于中国AI为何能有如此快速的进展，诺奖得主、“AI教父”杰弗里·辛顿在1月21日接受博主Curt Jaimungal专访中表示，中国的STEM（科学、技术、工程、数学）教育比美国更好，拥有更多受过良好教育的人才，这将为AI的发展提供坚实的基础。尽管美国试图通过限制（如英伟达芯片）来减缓中国的发展，但这只会促使中国加速发展自己的技术，“他们可能会落后几年，但最终会赶上”。 DeepSeek或彻底改变游戏规则“大力出奇迹”还有效吗？ 斯坦福大学和Epoch AI的研究人员去年年中发表了一项研究表明，到2027年，最大型的模型的训练成本将超过10亿美元。Gartner预测，到2028年Google、Microsoft和AWS等超大规模企业仅在AI服务器上的支出就将高达5000亿美元。 但DeepSeek完全不同，它的训练成本并不昂贵。Noah's Arc资本管理公司表示，DeepSeek-V3模型有可能彻底改变训练和推理领域的游戏规则。 特别是在5000亿美元的“星际之门”计划公布后，DeepSeek更让人怀疑，巨额投入这种“大力出奇迹”的办法真是最有效的方法吗？ 美股大V“THE SHORT BEAR”1月24日在X上发文称，DeepSeek给AI巨头们带来了痛苦时刻，投资者必须对此敲响警钟。 他说：“如果击败OpenAI只需要5500万美元，那么这个行业的商业化会比很多人预想的要快很多。” 他还指出：“根据红杉，美国AI公司每年必须产生约6000亿美元收入来支付其AI硬件费用。现在看来，这种冒险行为变得越来越无利可图。” 著名财经记者Holger Zschaepitz 1月25日表示，DeepSeek以极低的价格建立了一个突破性的AI模型，而且没有使用尖端芯片，这让人们质疑该行业数千亿美元资本支出的效用。 有投资者甚至认为，美股芯片股的股价也会面临挑战。 投资者Geiger Capital表示，Deepseek和OpenAI一样好，甚至更好，而且价格只有后者的3%……而美国公司却投入了数千亿美元。那么……纳斯达克会怎样呢？ 值得注意的是，DeepSeek-V3发布后，英伟达股价下跌了2%。而DeepSeek-R1引发海外大讨论后，1月24日英伟达股价又大跌了3.12%。 外媒集体刷屏：给硅谷敲响警钟 如果说DeepSeek-V3只是掀起了波澜，那么DeepSeek-R1则是引发了轰动。最近四天，国外媒体纷纷聚焦DeepSeek，并一致认为中国大模型的新进展为硅谷敲响了警钟。 1月22日，美国媒体Business Insider报道称，DeepSeek-R1模型秉承开放精神，完全开源，为美国AI玩家带来了麻烦。开源的先进AI可能挑战那些试图通过出售技术赚取巨额利润的公司。 1月24日，美国媒体CNBC推出了长达40分钟的节目，邀请了Perplexity CEO Aravind Srinivas来分析为何DeepSeek会引发人们对美国在AI领域的全球领先地位是否正在缩小的担忧。 英国《金融时报》1月25日报道称，中国小型AI初创公司DeepSeek震惊硅谷。报道聚焦资源更丰富的美国AI公司能否捍卫自己的技术优势。 报道援引加州大学伯克利分校AI政策研究员Ritwik Gupta称，DeepSeek最近发布的模型表明“AI能力没有护城河”。Gupta补充说，中国的系统工程师人才库比美国大得多，他们懂得如何充分利用计算资源来更便宜地训练和运行模型。 免责声明：本文内容与数据仅供参考，不构成投资建议，使用前请核实。据此操作，风险自担。 记者|岳楚鹏 兰素英 编辑|陈柯名 王嘉琦 盖源源 校对|何小桃 ｜每日经济新闻 nbdnews 原创文章｜ 未经许可禁止转载、摘编、复制及镜像等使用 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 49855,
      "title": "DeepSeek赋能潮起",
      "time": "2024-03-21T00:00:00+00:00",
      "content": "新华社北京3月21日电 3月21日,《新华每日电讯》发表题为《DeepSeek赋能潮起》的报道。 2025年开年，DeepSeek彻底突破技术圈层，直抵社会大众，成为热议高频词。刚刚结束的全国两会上，人大代表、政协委员也纷纷谈及相关话题。更值得关注的是，“人工智能+”“大模型”“算力”等被写入政府工作报告。 有专家称，1879年爱迪生“点燃”了世界上第一盏有实用价值的电灯，极大改变了人类的生活方式。当下，人工智能的“爱迪生时刻”或许正在到来，就像当年的电力一样，开始走进千家万户、改变各行各业。 在科技专家、企业家纷纷大谈“决定性时刻”“技术奇点”的时候，普通人该如何理解DeepSeek的核心突破意义，以及将对我们的生活带来的影响？ 破局者说：AI不仅是高山，也可以是大海 许多人最开始感受到DeepSeek的热浪来袭，是在今年春节期间：同学聚会，有人用它现场赋诗助兴；网红主播短视频带货，用它数十秒生成爆款营销文案；还有人把它当做虚拟空间的朋友获取慰藉…… 短短几个月，DeepSeek的影响面不断扩展、渗透性不断增强。不到两个月，上百家A股上市公司和几乎所有互联网平台，以及北京、广东、江苏等多地政务系统，相继接入DeepSeek。 DeepSeek，中文叫“深度求索”，既是杭州一家创新型科技公司的名字，又是这家成立不到两年的公司研发的人工智能大模型AI产品名称。 2025年1月20日，DeepSeek发布人工智能大模型R1，凭借较少算力资源实现了和全球顶尖AI模型相当的效果，“堆算力”的传统路径被打破，引发AI研发领域巨震。 如何理解DeepSeek的创新价值？ 北京通用人工智能研究院院长、北京大学智能学院院长朱松纯说，过去，一种“大数据+大算力+大模型”的思维定式过度简化了通用人工智能（AGI）的复杂性。这种思维定式下，芯片算力被视为决定性要素，数据规模被认为是核心竞争力，模型参数量被当成衡量技术进步的关键指标。OpenAI、Google等科技巨头不断强调其算力方面的优势地位，将技术门槛塑造为“难以逾越的鸿沟”。 而今，这一定式正在被打破。以较低训练成本达到以往AI大模型靠堆算力、拼资金和数据的效果，正是DeepSeek的制胜之道。 受访专家普遍认为，DeepSeek在架构设计和工程优化上进行的系统性创新，实现了在资源受限情况下完成对标一流大语言模型性能的任务，改变了大语言模型依赖算力的固有路径。 法国《世界报》网站一篇报道分析道，由于美国禁止新型人工智能芯片出口中国，DeepSeek只能使用旧款芯片，而DeepSeek成功做到了降低算力消耗和数据使用量，证明有可能开发出强大并且使用成本更低的AI大模型。 开源，则是DeepSeek“破圈”走红的又一成功之处。 在美国，除了Meta的Llama外，大部分顶级AI大模型都是闭源的，而采取开源策略的DeepSeek就像一个“破局者”。任何人都可以从DeepSeek网站自行下载与部署模型，网站提供了详细说明训练步骤与窍门的文档。 “当美国公司在为试图进入该领域的竞争对手设置尽可能多的障碍时，中国却在开放这项技术，这确实是一种讽刺。这或许就是DeepSeek最大的影响所在。它已经撕掉了此前笼罩在人工智能之上的神秘面纱。”英国《卫报》刊文如此评价。 当下，国内互联网平台已纷纷接入DeepSeek。腾讯在元宝、微信搜索、ima、QQ浏览器等多个产品场景中接入DeepSeek，百度、阿里、网易等也都把自家多款国民级产品接入DeepSeek，涵盖社交、云服务、办公、地图等领域。 “DeepSeek开源之举将使AI像水、电和网络一样触手可及。开源化、轻量化将大力推动‘人工智能+’，广阔场景已经呈现。”浙江大学人工智能研究所所长吴飞说，“传统大模型是‘由通到专’的人工智能发展思路，DeepSeek将推动形成一条‘由专到通’的发展路径。” 2月21日，深度求索公司进一步宣布将陆续开源5个代码库，毫无保留地分享新进展。“作为开源社区的一员，我们相信，每一行分享的代码，都将汇聚成推动进步的力量。”公司表示。 香港中文大学（深圳）公共政策学院院长郑永年认为，人们对人工智能发展的一个重要担忧就是“差异”和“分化”，即一些人和一些国家越来越“富裕”，而另一些人和另一些国家越来越“贫困”。“DeepSeek的出现使这些群体意识到人工智能的普惠性和缩小数字鸿沟的可能性。” 在DeepSeek带动下，以往坚定闭源路线的一些大模型公司逐渐改变了态度。2月17日，OpenAI首席执行官山姆·奥尔特曼在X上发文，询问大家希望下一个开源项目是哪一种，这被视为即将开源某个大模型的信号。 “DeepSeek展现出强大的适配性和广泛的应用场景。”中国科学院自动化研究所研究员王金桥说，这一轮AI变革通过技术成熟度提升、开源策略、市场需求拓展、政策支持、人才激发及数据与算法优化等多方面因素，加速了AI技术的产业落地。 聚光灯下的DeepSeek，不仅推动着AI技术市场变局，还带动了上游芯片和算力等产业，给行业注入新的信心。 2月6日，南京智算中心宣布，基于国内半导体厂商寒武纪的AI芯片部署DeepSeek模型。华为昇腾、沐曦等10多家国产半导体企业也已宣布支持DeepSeek的快速部署和训练。 中国电信股份有限公司杭州分公司云计算运营中心副经理王少龙2月初发现，集团在北京、上海的“万卡池”迅速销售一空。 “近期国内企业大量租用先进算力，部署DeepSeek大模型，以此训练自己的行业小模型。”他说。 一时间，几乎国内所有主流云厂商都全面接入DeepSeek，以响应公众对AI的需求。云厂商作为AI基础设施之一，能够为AI应用提供稳定算力。云厂商的积极布局将进一步降低AI大模型成本，为扩大AI垂直应用场景提供助力。 盘古智库理事长易鹏表示，政府部门、投资人、产业链上下游都受到DeepSeek的正向影响，提振了市场信心。 DeepSeek并非一枝独秀，而是勃发于正在不断壮大的人工智能产业。中国互联网络信息中心《生成式人工智能应用发展报告（2024）》显示，我国已初步构建了较为全面的人工智能产业体系，相关企业超过4500家，核心产业规模已接近6000亿元，产业链覆盖芯片、算法、数据、平台、应用等上下游关键环节。 “国家针对人工智能的政策扶持以及全方位的资源投入，实施‘东数西算’工程，壮大长期资本耐心资本，带来人工智能的蓬勃之势。”奇安信科技集团董事长齐向东说。 业内一度普遍认为，AI是一座高山，大家都在全力登顶。DeepSeek则启示人们，AI也可能是大海，可以向更深更广的方向求索。正所谓：“等闲识得东风面，万紫千红总是春。” 深度赋能产业发展 DeepSeek掀起的技术革新浪潮向众多产业席卷而来，企业迎来应用AI技术的大爆发。 车企迎来“DeepSeek上车潮”。 国内已有超过20家车企或品牌宣布与DeepSeek深度融合。各大汽车生产厂商近年来纷纷开发智能驾驶系统，而DeepSeek带来更强大的性能和更好的服务，降低了AI技术的应用成本和门槛。小鹏汽车董事长何小鹏直言：下一个10年AI会驱动汽车产业产生巨大变革，也会驱动全球范围内硬件软件产生巨变。 手机厂商纷纷推出“掌上DeepSeek”。 华为、荣耀、OPPO、vivo等先后宣布接入DeepSeek，并进行AI技术迭代。一家手机厂商的技术人员表示，在接入DeepSeek后AI智能体回答的准确率提升了15%。 在家电制造业，青岛的海尔智慧工厂应用AI技术的生产线平均每分钟可以下线10台冰箱。AI识别使检测精度提高10倍左右，生产效率较传统模式提升40%左右。海尔集团已宣布接入DeepSeek，进一步探索AI赋能智慧制造的路径。 一方面，AI技术在制造业的应用场景快速增加，对中国这样一个拥有全部工业门类的“世界工厂”意义重大；而另一方面，41个大类、207个中类、666个小类的全工业门类和超大规模，又为AI技术应用创造了海量场景，构建起庞大的智能制造创新试验场。 赛迪智库未来产业研究中心人工智能研究室主任钟新龙认为，AI与传统制造业的融合仍处于初期阶段，但这一新技术有望在其研发设计环节显著加速创新与决策效率。 在这场产业变革中，不仅有制造业，还有在国民经济中发挥越来越重要作用的服务业。 南开大学金融发展研究院院长田利辉说，金融业是数据密集和高速运转的服务性行业，DeepSeek能够从海量数据中迅速提取有价值的信息，帮助金融机构提高决策效率和准确性，在投资研究、市场分析等方面提供深入见解。 此前，由于研发金融大模型需投入大量资金购买相关硬件设备，还要高薪聘请专业技术人员，中小金融机构无力负担。DeepSeek的开源策略，使中小金融机构能够以较低成本使用AI大模型，开发新的服务和产品，甚至创新业务模式。 受益的不止金融业。 2月9日，义乌国际商贸城刚开门，浙江“小商品城”旗下的Chinagoods AI市场服务部孙凌燕就带着她的“AI社媒营销训练营”方案与商户们洽谈业务。 “不夸张地说，不会使用AI的商户将来可能‘连口热乎饭都吃不上’。”她说，“我们要让义乌老板学会像用计算器一样用AI。” 接入DeepSeek大模型的Chinagoods AI平台，在文案输出、视频生成、图片设计、多语种响应等方面的质量和速度都得到提升。如在“小商AI视创”小程序，商户只需要对着摄像头拍摄一段视频，随意说几句话，AI就能根据具体需求合成视频，甚至能从阿拉伯语丝滑切换到罗马尼亚语。 AI让跨境生意交流无障碍，智能推荐系统精准匹配用户偏好，动态定价策略实时调整价格，“数字人”带货直播24小时不打烊…… “此前我们在文案和语义理解端使用其他大模型，接入DeepSeek后，更受用户的欢迎。”义乌中国小商品城大数据公司技术总监楼勤峰说。 腾讯公司相关负责人介绍，他们已将AI技术与实体产业融合，助力企业客户降本增效、创新突破，推动人工智能在零售、金融、工业、医疗、教育、文旅等30多个行业落地。“大模型的打造只是起点，把技术落地到产业场景、创造价值才是终点。”这位负责人表示。 政策面，利好消息不断。 政府工作报告起草组成员、国务院研究室副主任陈昌盛表示，今年政府工作报告提出持续推进“人工智能+”行动，就是要抓住这次人工智能技术突破的机遇，使我国的数字技术与制造优势、市场规模优势充分结合，推动人工智能大模型广泛应用，使人工智能真正赋能千行百业、走进千家万户。 据其介绍，有关部门正在抓紧部署，让人工智能尽可能在工业、农业、服务业中利用起来，积极支持大模型在垂直领域的开发和应用；今年将开展新技术新产品新场景大规模应用示范行动，在确保安全前提下加快人工智能在低空经济、教育培训、医疗健康等多场景应用。 用好了能成为“工作好搭子”“生活好帮手” 不少人感到，DeepSeek是“工作好搭子”，高效处理以前耗费很多时间的繁琐工作；它又是“生活好帮手”，从助力学习到情感陪伴、从制定减肥方案到分析投资策略…… 大家还发现，DeepSeek虽为机器却“人味”挺足，一段段高情商回复在网上被广泛传播。 “中文世界有了一个可以比肩ChatGPT的大模型，它回答得更好，全面而深刻。”科幻作家韩松表示，即使一些文化水平不高的人都在大量使用DeepSeek。 “人工智能正变得越来越聪明，对社会方方面面的影响越来越大。”浙江大学计算机科学与技术学院副院长孙凌云说，“我们要拥抱人工智能，人机协作正成为一种新常态，会加速社会发展。” 在他看来，大模型的知识空间远远大于任何一个个体，“就像是望远镜拓展了人类的视野而非取代天文学家一样，大模型正成为人类探索知识边疆的新罗盘”。 由科技创新到产业变革、丰富生活，DeepSeek的“生态圈”极速扩容，还得到多地政务系统的青睐。 深圳布局DeepSeek大模型步伐走出“深圳速度”。2月10日，深圳完成DeepSeek R1满血版模型在政务云上的部署；2月16日，全市政务领域全面启用DeepSeek大模型。 深圳市政务服务和数据管理局副局长王耀文表示，希望把DeepSeek强大的智能推理能力引入到政府的政务应用创新上，基于政府的政务云进行更安全可控的应用，让DeepSeek为各部门的材料加工、公文写作、行业决策、行政审批以及执法工作提供通用支持。 DeepSeek开源和低成本的特性，让更多中小城市也得以搭上“DeepSeek+政务”快车。在山东，临沂市实现了DeepSeek本地化部署，并将其接入当地惠企工作的“沂蒙慧眼系统”中，新增慧眼AI会话、画像报告自动生成、企业风险预警等功能，大大提高了系统数据关联分析与决策响应能力。 清华大学公共管理学院教授孟庆国表示，DeepSeek的创新应用给欠发达地区带来换道超车机会，将缩小政务服务领域区域差异。 对公众来说，“AI+政务”的效果也可感可知。如，以往12345市民热线常常因坐席繁忙引发抱怨。接入DeepSeek后，辽宁12345热线系统数据整理效率将较人工处理提升20倍；汕尾市12345热线服务不仅工单流转效率提升60%，还可通过AI挖掘诉求数据规律提前预警，如交通拥堵、企业欠薪等问题，让服务模式从被动响应转向主动治理。 北京师范大学法学院博士生导师、中国互联网协会研究中心副主任吴沈括表示，AI有两个突出优势，一是对海量数据的深度分析，二是对未来模型的精准预测。AI进入政务系统是一个具有时代特色的现象。 在DeepSeek掀起的AI浪潮中，医疗是核心应用场景之一。2月13日，国内首个“AI儿科医生”上岗。国家儿童医学中心和首都医科大学附属北京儿童医院开展了国内首次“AI儿科医生+多学科专家”的双医并行多学科会诊。“AI儿科医生”给出了与专家组会诊结果高度吻合的建议。 2024年11月，国家卫健委等三部门发布《卫生健康行业人工智能应用场景参考指引》，明确了84个AI应用场景，覆盖药物研发、诊疗辅助、医院管理等多领域。一些业内人士表示，AI医生将促进优质医疗服务普及和普惠。 在职场，一些人担心，随着AI时代的到来，部分岗位将会受到冲击。对此，北京邮电大学人机交互与认知工程实验室主任刘伟认为，人们应积极适应新的工作方式和技术变革，学习如何使用科技工具和处理数据，培养创造力和与AI的协作能力，实现人机环境系统智能融合。 蒸汽机的出现淘汰了马车夫，却带来了铁路工人。猎聘大数据研究院《2025AI技术人才供需洞察报告》显示，学术/科研、物联网、人工智能是2025新春开工首周新发职位同比增长的行业前三，较上年开工首周分别同比增长了51.48%、34.10%和18.25%。其中人工智能行业的高薪区间职位比重较高，20万以上年薪占比为58.19%，远超其他两个行业。 一些专家表示，AI在处理大量数据、执行重复性任务、提高效率和减少错误方面具有显著优势，但仍无法完全替代人类的创造力、情感智能和复杂决策能力。 与此同时，AI技术对教育的挑战不容忽视。 在不久前的全国两会上，全国政协委员、中国科学院院士、清华大学化学系教授李景虹提出，今后人才培养与专业布局要作出相应调整，比如可以适度提前预判受到AI冲击比较大的专业，逐年减少此类专业的招收，教育内容与方式上也要进行改革。 教育部部长怀进鹏在会上也表示，今年我国将发布人工智能教育白皮书，指导学生适应人工智能时代、不断提升创新精神和能力。 让“安全”成为AI发展的基因 今年两会上，“#靳东两会建议AI换脸立法#”话题冲上微博热搜。这来自全国政协委员、演员靳东在政协委员小组讨论中的一次发言。“一些喜欢我影视剧的观众，被AI换脸视频骗得很惨，这个性质非常恶劣。”他希望能建立更好的规则。 不止是靳东。一段时间以来，不少公众人物都遭遇过类似问题。如，模拟张文宏医生的声音和面貌直播带货“蛋白棒”，用“雷军AI配音”制作恶搞视频，合成刘德华语音在短视频平台引流……这类事件给公众人物带来困扰，更混淆了公众视听。 人工智能等新兴技术带来的不是渐进性发展，而是革命性变革。这种变革，既可以是促进发展的强大动力，也可能成为风险的源头。AI强大的学习与生成能力带来了恶意输出、版权侵犯、深度伪造等问题，由此引发了技术专家和人文学者的普遍关切。 “如果世界各国忽视对AI风险的防范和布局，就可能导致面对重大挑战时准备不足。”中国科学院自动化研究所研究员、联合国人工智能高层顾问机构专家曾毅提出，要让“安全”成为AI发展的第一性原理，成为AI发展的基因。 以深度伪造（Deepfake）为例。这项技术能够利用AI“深度学习”算法进行自动化数据处理，实现对图片、音频、视频的智能模拟和伪造，篡改或生成的音视频内容高度逼真，难辨真伪。 中国科学院自动化研究所模式识别实验室工程师牛少东说，随着算法越来越先进，AI生成的语音内容已真假难辨。公安部数据显示，近两年来全国共发生“AI换脸”类诈骗案近百起，累计造成的经济损失高达2亿元。 “深度伪造”只是AI技术带来的应用风险一角。从系统设计、研发、训练、测试，到部署、使用、维护等生命周期，这项技术的各环节都存在着安全风险。 中国互联网络信息中心发布的《生成式人工智能应用发展报告（2024）》显示，我国生成式人工智能产品的用户规模已达2.49亿人。随着DeepSeek出圈爆火，用户规模正在快速扩大。防范和应对AI技术的不当发展，成为紧迫问题。 业内人士普遍认为，人工智能全球治理是一个全球难题，如果任由各国无序竞争，“灰犀牛”就在眼前。经济合作与发展组织（OECD）的数据显示，2024年的AI风险事件总数比2022年增加了约21.8倍，并呈快速增长态势。曾毅对此认为，AI安全相关的国际协作迫在眉睫，为避免相似风险在全球反复出现，需形成更广泛的深度国际合作。 2024年7月，在第78届联合国大会上，中国提出的加强AI能力建设国际合作决议获得协商一致通过。这是联合国首份关于AI能力建设国际合作的决议，得到了140多个国家的支持，标志着国际社会在推进AI合作与发展领域取得历史性突破。 根据全国人大常委会工作报告，今后一年全国人大常委会将围绕人工智能、数字经济、大数据等新兴领域加强立法研究。今年两会上，许多人大代表、政协委员也提出了相关的建议和意见。 如，小米董事长雷军、科大讯飞董事长刘庆峰、360董事长周鸿祎、TCL董事长李东生、美的集团副总裁钟铮、奇安信集团董事长齐向东等代表委员，分别提出了“加强治理‘AI换脸拟声’违法侵权重灾区”“预防‘AI幻觉数据’带来的危害”“统筹解决大模型应用安全”“加强AI深度伪造欺诈管理”“完善生成式人工智能视频传播管理机制”“建立适配大模型的纵深防御体系，筑牢人工智能的安全根基”等建议。 记者向DeepSeek提出“如何看待人机关系”的问题。它的回答是：“每次技术奇点降临，人类都在重演普罗米修斯盗火又惧火的永恒悖论。人机关系如同普罗米修斯之火：既能照亮文明前路，也可能灼伤执火者。” 在科幻作家韩松看来，DeepSeek就是人的大脑的延伸。“人类一直在依靠技术外挂实现进化。以前，技术是人的腿的延伸、手的延伸，现在是大脑的延伸，AI解放了人的思想，带来了创新的力量。” 在虚实交织的新大陆，AI的本质是工具，人类主体性与伦理意识，将决定技术发展的方向与边界。 举报/反馈"
    },
    {
      "doc_id": 49856,
      "title": "英伟达大跌会否引发AI股票平仓潮",
      "time": "2024-03-04T00:00:00+00:00",
      "content": "来源：国际金融报 当地时间3月3日，英伟达股价重挫8.69%至每股114.06美元，单日市值蒸发2650亿美元，总市值已经跌破3万亿美元大关，约2.79万亿美元，比1月6日达到的3.66万亿美元高峰值蒸发近9000亿美元，回调超过23%，从技术分析定义进入熊市。 五因素致下跌 瑞穗分析师欧里根（Daniel O’Regan）提出五个造成英伟达股价大跌的压力因素。 第一，担心美国会对中国实施更严格的管制措施。瑞穗分析师团队担心，如果出口管制加强，可能导致英伟达2026年度营收减少40亿至50亿美元，或影响每股盈余0.18美元。 第二，新加坡调查含英伟达AI芯片服务器的流向。新加坡正在调查戴尔、美国超微运往马来西亚的服务器是否含有禁卖给中国的英伟达芯片，主要是查明这些运往马来西亚的服务器最终是否又流向了其他国家。 第三，新旧产品交接时期。中国台湾媒体稍早前提出对英伟达CoWoS订单出现下滑的疑虑，原因是英伟达的Hopper GPU接近产品周期末期，先进封装订单可能逐渐减少，市场等待下一代GB300来重振需求。 第四，上周财报没有带来惊喜。英伟达在上周三公布了亮丽的财报，营收年比大增78%至393.3亿美元，高于分析师预期，但并未达到华尔街的最高预期，引发了人们对利润率的担忧，上周的收入和利润率指引继续影响市场情绪。从那天开始，英伟达股价迄今累计下跌超过13%。 第五，欠缺上涨催化剂因素。英伟达年度GTC大会要到3月17日才会召开，在此之前没有重大利多消息。 增长潜力有限 瑞穗分析师克兰（Jordan Klein）认为，市场担心美国对中国的新关税，或更严格的出口限制措施会完全阻断英伟达在中国的销售。此外，新加坡启动的调查，可能引发的风险是，美国政府可能进一步禁止所有英伟达芯片销往中国。 不仅如此，自中国公司DeepSeek撼动半导体产业以来，英伟达的市值已蒸发7080亿美元。DeepSeek使用英伟达较旧的H800芯片创建了一个具有竞争力的大型语言模型（LLM），这可能会引发人们对升级英伟达最新硬件是否必要的质疑。 目前，英伟达的市值接近3万亿美元，分析认为，即使在最佳情况下，其股价增长的潜力也十分有限。这家行业领先的芯片制造商可能会继续出现营收增长，但随着客户转向定制芯片并重新评估向该行业投入的资金量，英伟达的利润率可能会面临压力。 不过分析同时认为，英伟达仍然具有不错的价值。如果宏观经济状况没有恶化，不太可能出现大崩盘。 AI股票持仓降低 在英伟达大跌当天，其他与AI相关的股票也大幅下跌。美超微（SMCI）周一重挫13%，Astera Labs大跌9%，安谋（ARM）下跌8%，博通跌6%，Marvell Technology跌6.5%。 3月3日，对冲基金开始大规模抛售美国科技股，这是自2024年7月以来科技股持仓减少速度最快的一次。据Kobeissi Letter报道，机构投资者一直在大举抛售其持仓，导致所谓的“七巨头”持仓量降至两年来的最低点。 克兰表示，这是“上周行情的延续”，意指“AI交易的平仓潮”。 目前，越来越多科技行业的股票分析师开始对美国的AI相关股票能否达到人们的预期持怀疑态度，对科技股的乐观情绪正在消退。 法国兴业银行策略师阿尔伯特·爱德华兹（Albert Edwards）2月底发布了一系列图表，他认为股市接近历史高点，科技股支撑了市场的强劲反弹，这一发展将股市“置于严重风险之中”。 举报/反馈"
    },
    {
      "doc_id": 49857,
      "title": "盈利“超预期”后股价暴跌,英伟达的熊市趋势可能才刚开始",
      "time": "2024-03-03T00:00:00+00:00",
      "content": "来源：美股研究社 作者 | Oriental Trader 编译 | 华尔街大事件 尽管英伟达 ( NASDAQ: NVDA )在 2025 年 2 月 26 日公布的 2024 年第四季度（以及 2024 年全年）收益被认为超出预期，但其股价第二天暴跌，开盘价为 135 美元/股，收盘价为 120 美元/股，跌幅为 11%。这是侥幸还是更大事件的开始？ 考虑到英伟达在 2024 年前三个季度的增长轨迹及其销售积压，英伟达在 2024 年的收入和净利润方面将比 2023 年实现强劲增长也就不足为奇了。但英伟达是否超过或低于 2024 年分析师共识或 2025 年指导几个百分点，与英伟达的长期价值关系不大——市值接近 3 万亿美元，长期未来比过去重要得多。英伟达的市盈率约为 40，但其现有和新业务的预测增长不太可能支撑 3 万亿美元的市值。 现有业务（指核心产品）： 1）100 倍或 1000 倍的计算需求并不一定意味着更多的收入和利润 虽然英伟达的 CEO 在电话会议上表现得很乐观，但他所预测的愿景并不一定意味着更多的收入或利润。例如，Jensen Huang 谈到人工智能计算需求呈指数级增长。虽然这是可能的，但以英特尔 CPU 性能从 1995 年到 2011 年的收益为例，根据研究论文中的下图，从 1995 年到 2001 年，标准化年度性能增长率为 64%，从 2002 年到 2011 年，增长率为 21%，累计增长了大约 100 倍。 然而，英特尔的股价在那段时间里没有任何变化，如下所示，即使计算能力的需求和供应增加了 100 倍，对英特尔的利润或股价也没有多大影响，对英伟达的收入/利润可能也没有多大影响。 另一个类似的例子是 iPhone 和超级计算机之间的比较——iPhone 12 的运行速度为 11 万亿次浮点运算，比 1985 年的 Cray 2 超级计算机多 5000 倍。iPhone的价格按 2024 年的美元计算约为 1000 美元，而 Cray 2 超级计算机的价格按 1985 年的美元计算约为1600 万美元，因此计算能力提高了 5000 倍，而成本下降了 99.9%。很可能会出现其他技术或使用技术的方式，而不是世界向英伟达支付数万亿美元。 2）数据中心资本支出需求不一定是经常性的 大型科技公司（分析师将其定义为 MSFT、META、GOOG、AMZN 和 AAPL）将其称为数据中心资本支出是有原因的，因为他们预计这将是相对一次性的。如果我们查看 MSFT 的资本支出历史（现金流量表中的项目：资本支出），2015 财年它仅为 60 亿美元/年，而在 AI 热潮之前的 21-22 财年，它约为 200 亿美元/年，这足以推动收入从 900 亿美元/年增长至 2000 亿美元/年。当每年 100-200 亿美元的资本支出已经使 MSFT 在为其客户提供云解决方案方面相当成功时，MSFT 是否真的需要几十年来年复一年地在 AI 数据中心投入 800 亿美元来满足其客户的需求？分析师对此表示怀疑。 但如果人工智能数据中心的资本支出是一次性的，就像修建铁路，然后在铺设初始轨道后进行一些维护一样，那么在某个时候，人工智能数据中心的需求将达到稳定状态并急剧下降。就像铁路，虽然铁路在最初建造 150 多年后才具有经济价值，但在 1887 年铺设新铁路轨道达到顶峰之后，每年铺设的新铁路轨道数量迅速下降。 虽然由于芯片技术的发展速度远快于铁路，铁路资本支出的情况可能不会在 AI 的情况下出现，但我们现在看到的对 AI 芯片的高需求仍然很可能是大型科技公司为赶上 AI 潮流而集中做出的努力，而不是长期可持续的需求。英伟达将不得不出售 5.5 万亿美元的 AI 芯片（FY24 净利润率为 55%）才能产生 3 万亿美元的净利润来对应其市值（甚至在考虑货币的时间价值之前），而微软一年在数据中心上花费 800 亿美元并不能证明从长远来看，英伟达可以以目前的盈利能力实现 5 万亿美元的收入。事实上，最近有消息称微软取消了部分数据中心的租约。如果 AI 芯片是一个 5 万亿美元的市场，分析师敢肯定大型科技公司会开发其他替代方案，而不是在未来 2-3 十年继续向英伟达支付 55% 的利润率。 最近的新闻报道显示，英伟达可能正在考虑进军智能手机芯片领域。还有新闻报道称，英伟达还投资了中国的 WeRide ( WRD )。 多元化经营是否对股东有利取决于许多因素。有时这是一个好主意（例如垂直整合），但通常这是一个坏主意（例如巴菲特经常提到多元化的概念）。如果我们看看下面几家大型科技巨头，你会发现他们构成大部分收入的许多核心产品都是多年甚至几十年前推出的： 我们经常听说科技巨头正在开发新产品，例如 GOOG Pixel 手机、GOOG Waymo 或 AAPL 汽车，但在实现如此多元化之后，科技巨头的大部分收入仍然来自于其长期成功的产品。GOOG 的 Pixel 手机从未真正流行起来（估计美国市场份额为 5% ），而 AAPL 在投资100 亿美元后放弃了汽车。过去十年，上述科技巨头的收入/利润成功增长的大部分原因都来自于改进现有产品（例如，将 Office 引入云端或开发 16 代 iPhone），而不是进军全新的领域。 英伟达在 GPU 领域表现优异，在正确的时间、正确的地点抓住了 AI 芯片的市场机遇。如果说科技巨头的经验可以借鉴，那么我怀疑英伟达能否将其成功复制到智能手机芯片或自动驾驶领域，并带来实质性的经济效益。 分析师会严重怀疑英伟达涉足新业务的任何尝试。事实上，英伟达管理层对所有这些新潜在业务的重视让人怀疑他们是否对新业务寄予更多希望，以维持英伟达的增长故事，并让人担心这是否会对其现有业务产生影响，换句话说，是否存在现有业务增长从长远来看不够强劲的风险，管理层不得不谈论所有这些新的、更不相关的增长来源。 现在，英伟达面临许多看跌质疑，股价在过去一年中多次下跌，但最终又反弹。例如，8 月 24 日，当巴菲特出售苹果 ( AAPL ) 的消息披露时，科技股经历了一场小恐慌，但英伟达不久后就恢复了上涨趋势。2025 年 1 月底，英伟达因 DeepSeek ( DEEPSEEK ) 的发布而经历了另一场小恐慌，但它也迅速反弹。但我的观点是下行风险远远超过上行风险：英伟达需要创造另一个 AAPL 或 MSFT 的价值，只需将其市值翻一番，这对我来说似乎是一个很长的延伸，而如果维持其 40 倍市盈率和 730 亿美元净利润的增长预期消失，其股价很容易大幅下跌，例如，如果市场基于较低的增长预期将其市盈率重新评估为 20，而其净利润仍在增长，那么其股价可能会下跌 50%！ 另一家市场宠儿特斯拉股价近期下跌是一个警示故事：TSLA 股价已从 2024 年 12 月中旬接近 490 美元/股的高位跌至 293 美元/股，约两个月内下跌了约 40%。 再次，分析师强烈提醒那些投资无法承受损失的资金（例如退休储蓄）的投资者，要谨慎对待英伟达，或者至少考虑将风险敞口保持在可控水平。谨慎的、看好人工智能的投资者不必指望这次会有所不同，至少可以分散投资于所有大型科技公司，而不是全押或过度增持英伟达。 举报/反馈"
    },
    {
      "doc_id": 49858,
      "title": "股价下跌22%后,基本面最终证实了英伟达的估值合理性",
      "time": "2024-02-05T00:00:00+00:00",
      "content": "来源：美股研究社 作者 | Finance Flash 编译 | 华尔街大事件 英伟达 (NASDAQ：NVDA ) 已从 1 月初的近期高点下跌近 22%。回顾过去 25 个月，这是一个重大的下跌，可能提供一个投资机会。 总体来看，造成股价下跌主要有两个方面： 1.深度求索（DeepSeek）： 这家中国初创公司推出了一种低成本的 LLM 模型，其性能水平与 OpenAI、Meta和谷歌的同类模型相似甚至更好。 据 DeepSeek 称，他们使用2048 个英伟达H800 芯片（最先进的 LLM H100 芯片的降级版本）来训练他们的模型。这大大降低了开发复杂 LLM 模型所需的投资成本，可能会对英伟达的业务产生负面影响。这可能会导致 AI 芯片得到更广泛的采用，从而对英特尔和AMD等不太复杂的芯片的供应商和设计者产生积极影响。 然而，通过降低价格和提高效率，总体需求也可能增加（部分）抵消对英伟达业务的影响。这一经济理论被称为杰文斯悖论，可以追溯到 19 世纪，当时英国海军的煤炭供应不足。与预期相反，当时蒸汽机效率的不断提高也导致需求增加，因为价格更便宜。 2.贸易关税： 尽管与墨西哥和加拿大达成了暂停征收关税的协议，但对华进口产品征收 10% 的固定关税仍将立即生效。虽然目前这可能不会对英伟达的业务造成直接重大损害，但这仍引发一个问题：这些关税是否会引发新一轮贸易战。 分析这些原因，20%以上的降幅似乎有点过分。 为了评估该公司，我们首先会分析证明当前估值所需的营收增长率，然后检查英伟达的基础业务部门可以实现的增长率。 对于这两个 DCF，我们假设英伟达能够实现其 2025 年第四季度的预期，从而实现 2025 年约 1290 亿美元的收入和约 790 亿美元的息税前利润。从那时起，假设息税前利润率将保持在 2025 年的 62% 水平。对于自由现金流转换，我预测息税前利润率为 82%，这与该公司 2022 年和 2024 年的利率完全一致。 根据这些假设，该公司需要在未来八年内实现每年 25.5% 的增长率才能证明当前的估值是合理的。 专家预计全球数据中心 GPU 市场将按以下增长率增长： 通过这项研究，我们得出数据中心 GPU 市场的平均年市场增长率为 32.6%。 在此领域，Markets and Markets预计到 2030 年年增长率将达到 28.8%。 在这个市场，Grand View Research目前预计到 2030 年每年的增长率将达到 30.6%。 对于汽车领域的人工智能应用，专家目前预计到 2033 年其年增长率将达到 37%。 考虑到所有这些增长率，我们得出英伟达基础业务的加权预期增长率为 32.3%。从下图中也可以看出，数据中心部门是该公司最重要和最有前景的部门。 预期这些增长率，我们得到的公允价值市值为4.1 万亿美元，这表明该公司目前可能被低估了 39%。 由于过去几年的出色表现以及每年 25% 以上的增长预期，增长放缓或其他障碍可能会导致急剧的下降。 如果本文开头提到的 DeepSeek 指控属实，那么低性能芯片的需求可能会激增，从而加剧来自 AMD 和英特尔的竞争。这反过来可能会对英伟达的利润产生负面影响。亚马逊 ( AMZN ) Trainium等定制硅片解决方案也可以削弱其在 LLM 芯片领域的主导地位。 从历史上看，半导体市场的需求呈现周期性，产能遵循以下阶段： 1.产能短缺 2.产能增加 3.产能过剩 4.容量不变/减少 5.返回 1 我们目前正处于第二步。如果这种趋势继续下去，产能过剩将不可避免地导致英伟达的价格下跌和利润率下降。 考虑到未来八年雄心勃勃但现实的年增长率 32.3%，我们得出的潜在估值低估了近 40%。考虑到这一点，并考虑到该公司非常繁荣的增长前景，分析师目前将该公司评级为强力买入。 举报/反馈"
    },
    {
      "doc_id": 49865,
      "title": "AI大模型掀起商业变革浪潮 全球算力服务市场抢滩战启幕",
      "time": "2024-06-30T00:00:00+00:00",
      "content": "AI 大模型正以颠覆性力量重构全球商业生态，推动企业从传统流程驱动向智能决策范式迁徙。随着数据量呈指数级增长与算法迭代加速，企业运营模式正经历 “感知-生成-自主执行” 的三级跃迁。开源生态的繁荣与闭源技术的壁垒形成双重动能，驱动企业重塑了研发、生产、营销等各核心环节，也将催生“AI 原生企业” 这一新型组织形态 —— 其运营效率、创新速度与市场响应能力均较传统模式提升数倍。 在AI大模型重构商业生态、催生新型组织形态的进程中，算力作为底层支撑正成为核心竞争力，由此催生对算力资源的爆发式需求，在这场算力争夺战中，能够整合异构计算资源实现多区域调度的参与者，将在全球算力服务市场中占据战略制高点。 开源大模型崛起 催生私域布局新范式 2025年开年，DeepSeek R1 等开源模型的崛起掀起了AI行业的一次变革。开源模型的性能已经与头部闭源模型不相伯仲。推理模型DeepSeek R1通过相关技术在GSM8K数学推理、CodeX代码生成等核心指标上持平OpenAI o1正式版。 这一具有里程碑意义的发展节点，标志着技术平权的推进，使中小企业能以低成本获取顶尖模型赋能。同时，此趋势还重塑了开源大模型全球研发话语权，开源社区的群体智慧加速了技术迭代，推动AI技术从实验室走向商业级应用，加速人工智能普惠时代的到来，也带动企业商业运作模式向数智化迁徙。 开源模型降低技术门槛后，企业为实现差异化竞争，基于自身数据构建私域模型，以满足行业定制化需求，这促进大模型从解决通用的知识问答、文本生成等问题，转向深入千行百业，进行专业赋能，如金融决策辅助、医疗诊断、生产流程优化等场景，利用自身数据积累，构建具备业务特性与安全性的私域大模型应用。 其中，根据公开数据，我国多地央国企率先开启了接入DeepSeek，并获得了明显的增效成果。例如南京建邺区应用 DeepSeek，深度革新政务热线工单处理流程，实现工单分拣准确率高达99%。青岛市行政审批服务局借助DeepSeek构建智能云客服系统，首次应答响应速度提升超90%。 海外方面，像东南亚、中东等海外地区企业也加速利用DeepSeek进行私域大模型布局，如石油企业沙特阿美公司将DeepSeek R1引入其旗舰数据中心，帮助公司提高效率。印尼的Gojek用DeepSeek框架开发出东南亚本土大语言模型。 在国内外企业纷纷构建私域大模型应用并取得实效的背景下，也催生了可观的市场空间。根据QYResearch数据显示，2025年全球私域大模型市场规模预计突破200亿美元，年复合增长率达35%。 同时，伴随人工智能普惠时代到来的，还有推理算力需求的水涨船高。 全球推理算力需求提升 算力供应用商抢滩登陆 随着DeepSeek R1等推理大模型深度渗透到生产办公、生活服务、行业赋能等更多场景，AI领域的竞争焦点正发生深刻转变，曾席卷AI领域的训练模型军备竞赛浪潮正逐步褪去，行业竞争焦点开始向推理优化、场景落地等方向深度转移。Gartner预测，2028 年全球推理算力需求与训练算力需求之比将飙升至 3∶1，其中中国市场该差距更是有望突破 4∶1，展现出强劲的发展态势。 在推理算力需求快速增长的背景下，国内外服务商加速全球算力基础设施与生态合作布局，谁能接住这“泼天的富贵”? 国内外多家云算力服务商陆续开展或早已在全球重点区域进行算力基础设施布局，开启“圈地”模式。云服务商方面，阿里云在韩国、泰国等 5 国新建数据中心，重点布局 AI 基础设施;腾讯云积极拓展海外市场，在东南亚、中东等地区加强布局;华为云布局北非节点覆盖埃及及中西非。国外服务商像亚马逊云科技宣布将在泰国、沙特阿拉伯、墨西哥等地建立数据中心;微软云也于2024年宣布在印度尼西亚、马来西亚等国家进行投资。 与众云服务商重投入建设不同的是，云网服务商采用了与云服务商、IDC厂商开展生态合作的模式，向企业提供算力租赁服务，快速承接市场需求。比较具有代表性的厂商，像南凌科技与VMware合作，部署边缘计算服务;天维信通CBC与数据中心运营商 Global Switch合作适配AI算力需求;第一线DYXnet基于自身网络架构，融合其母公司世纪互联AIDC与自建OCD边缘云资源，以及合作火山引擎、阿里云、华为云等国内外公有云与IDC厂商，构建全球云、边、端的算力服务资源池，并基于此提供AI MaaS服务，帮助企业部署私域大模型。 总之，在推理算力需求爆发的当下，全球服务商正以差异化策略竞逐：云服务商通过重资产投入加速全球算力基建版图扩张，夯实节点覆盖的 “硬实力”;云网服务商则以生态合作为引擎，编织多云协同、边缘整合的算力资源 “弹性网”。两条路线虽侧重不同，却共同指向算力服务的全球化布局。然而，随着 AI 向智能体演进催生指数级需求跃迁，能否在既有路径中培育动态适配能力，正成为服务商接住未来机遇的核心变量。 “要致富先修路” 网络架构升级变革 根据Artificial Analysis统计，在模型扩展律(Scaling Law)主导的初期阶段，增大模型参数带来了约5倍的算力提升。进入模型后训练与推理为主导的阶段后，模型输出的 Token数量显著增加，推动算力需求再增长约10倍。而步入Agent时代，算力需求激增的驱动力转变为单Agent处理单任务所需的请求次数，这一数量级预计提升约20倍。这些因素叠加最终将导致整体推理算力需求呈现数十倍甚至上百倍的跃升。 同时，随着MCP、A2A、Kafka协议栈的落地发展，AI Agent之间的频繁交互，也将进一步对算力与网络的协同提出要求。例如AI大模型训练需在多节点服务器间传输海量参数(如万亿级参数模型单次迭代的数据量可达 TB 级)，而 AI Agent 运行时需实时处理多模态输入(如图像、视频、传感器数据)和跨Agent通信数据。这一趋势倒逼网络从 “数据传输管道” 向 “算力协同基础设施” 转型。网络需在带宽、延迟、可靠性、架构等层面全面升级，与算力资源形成 “传输-计算-存储” 的一体化闭环。 在算力需求与网络协同要求持续攀升的背景下，如何破局成为关键，而我国已开始着手算力互联网的建设落地。随着我国八大算力节点建设稳步推进，成果初显，今年5月工业和信息化部更是发布《算力互联互通行动计划》，致力利用此工程化创新，实现跨主体、跨架构、多地域算力供需调度，承载人工智能、科学计算、智能制造等企业级场景高质量发展。 同时，众多服务商也在积极探索网络与算力的协同路径，为AI Agent时代的应用场景搭建基础设施。据悉，阿里云通过内蒙古枢纽节点和林格尔数据中心集群提供智能算力，构建混合云网络;第一线DYXnet联合华为等伙伴构建 AI 原生超互联架构，实现城域内全类型算力主体(含AIDC、公有云算力、边缘算力及园区、楼宇、企业、个人、大模型等)，经就近节点高速安全接入总线架构实现互联，形成契合自身需求的私域计算空间，以此承载大模型训推，以及驱动专属AI Agent协同赋能。 第一线总经理陈姵妏也表示：随着中国企业走向全球，其数智化基础设施服务也需同步出海。第一线计划将其AI原生超互联架构的创新模式拓展至海外市场，构建覆盖国内外AIDC、公有云、边缘云的全球化算力网络。而据了解，第一线成立25年，在全球范围内已与中国三大运营商，以及法国电信、德国电信、日本软银、西班牙电信等运营商保持合作，网络服务能力覆盖全球700+城市，包括中国大陆、中国香港、中国台湾、东南亚、中东、拉美等多地区，这为其实现网络模式创新落地形成了先天基础。 AI 大模型重构商业生态背景下，算力需求与网络协同成核心命题。业界实践显示，算力基建需兼顾全球化布局与弹性调度能力，网络架构正从传输工具向算力协同枢纽转型。未来竞争焦点或在于动态适配 AI Agent 时代的算力网络一体化能力。 免责声明：此文内容为本网站转载企业资讯，仅代表作者个人观点，与本网无关。所涉内容不构成投资、消费建议，仅供读者参考，并请自行核实相关内容。 原文转自： 周口网 举报/反馈"
    },
    {
      "doc_id": 49869,
      "title": "3D领域DeepSeek「源神」!国产明星创业公司,一口气开源八大项目",
      "time": "2024-03-28T00:00:00+00:00",
      "content": "机器之心报道 机器之心编辑部 2025 开年，DeepSeek-R1 的成功在全球掀起了一股开源风潮，上个月的开源周更是毫无保留地将自己的多项核心技术开放给了全球开发者。这种「完整技术栈」式的开源震撼了整个行业。 毫无疑问，开源正成为国内外大模型厂商的「战略共识」。从文本到视觉，从对话到推理，开源生态的繁荣正推动大模型技术快速迭代。在这一波生成式 AI 浪潮中，MiniMax、月之暗面等公司纷纷从应用层回归模型层，聚焦底层架构创新，而非仅依赖上层应用变现。这一趋势表明，模型本身的能力突破，而非单纯的产品包装，正成为行业竞争的核心。 在 3D 生成这一尚未被完全定义的领域，VAST 正以开源先锋的姿态重新划定行业标准。这家专注于 3D 生成赛道的公司，正通过自主研发打造面向三维内容创作的开源基础设施。 3 月 28 日，专注于构建通用 3D 大模型的 VAST 一口气开源了两个 3D 生成项目 ——TripoSG 和 TripoSF。前者是一款基础 3D 生成模型，在图像到 3D 生成任务上远超所有闭源模型；后者则是 VAST 新一代三维基础模型 TripoSF 能在所有闭源模型中同样取得 SOTA 的基础组件，用于高分辨率的三维重建和生成任务。 VAST 宣布，即日起，TripoSG 15 亿参数小模型（非 MoE 版本、在 2048 token 的潜空间上运行）的权重、推理代码和交互式演示 Demo 将通过 GitHub 和 Hugging Face 统统提供给 AI 社区。 Homepage：https://yg256li.github.io/TripoSG-Page/ 论文 ArXiv：https://arxiv.org/abs/2502.06608 GitHub 代码：https://github.com/VAST-AI-Research/TripoSG Hugging Face 模型权重：https://huggingface.co/VAST-AI/TripoSG Hugging Face 演示：https://huggingface.co/spaces/VAST-AI/TripoSG 同时，TripoSF VAE 的预训练模型及相关的推理代码也同步开源。 Homepage：https://xianglonghe.github.io/TripoSF/ 论文 ArXiv：https://arxiv.org/abs/2503.21732 GitHub 代码：https://github.com/VAST-AI-Research/TripoSF Hugging Face 模型权重：https://huggingface.co/VAST-AI/TripoSF 这意味着，整个 3D AI 社区多了 SOTA 级基础模型，这将大大降低入门门槛和创作门槛，让开发者、创作者用上强大的 3D 生产力工具，并加速视觉特效（VFX）、游戏开发、具身智能、产品设计等 3D 场景的深度应用。 当然，VAST 的开源「野心」不止于此！ 接下来一直到 4 月 18 日，他们还将继续开源另外一系列 3D 生成项目，涵盖了三维部件补全模型、通用三维模型绑定生成模型、三维几何精细化模型以及 SIGGRAPH Asia 2024 RTL 收录的交互式草图生三维模型。 再加上此前开源的单张图像生成 3D 场景模型 MIDI 以及多视角图像生成模型 MV-Adapter，从通用大模型到组件补全、骨骼绑定模型、再到 3D 模型的超分辨率等技术，一套从基础到细节的完整 3D AI 生成体系即将完全展示给全球社区。 MIDI 代码：https://github.com/VAST-AI-Research/MIDI-3D MV-Adapter 代码：https://github.com/huanngzh/MV-Adapter VAST 的 3D「开源月」干货满满，又一次让开源社区充满了期待。 TripoSG：MoE Transformer 开启高保真 3D 生成新范式 这两天，沉寂许久的 AI 生图再次火了起来。 谷歌和 OpenAI 先后上线唠嗑 P 图功能，社交平台上网友们疯狂整活，就连老板奥特曼的 X 头像都用 AI 换成了日漫风格。 AI 视频圈更是「跑马圈地」，各家模型隔三差五就上新一波。 同样地，3D 生成领域的进化速度也是突飞猛进，但是高质量 3D 内容的自动化生成仍面临诸多技术瓶颈，比如数据获取、几何表示复杂性和模型规模化等。 为了破解这些难题，VAST 创造性地将大规模文本、图像和视频合成领域的成功范式引入 3D 领域，推出并开源了基础 3D 生成模型 TripoSG。 与以往模型相比，TripoSG 在质量、细节和保真度上实现了重大突破，能够直接从单张输入图像生成细节惊艳的 3D 网格模型，并且生成效果达到了业界最佳水平。 那么，该模型背后又藏着哪些技术亮点呢？ 首先，TripoSG 率先将基于校正流 (Rectified Flow, RF) 的 Transformer 架构应用于 3D 形状生成。相较于传统的扩散模型，RF 提供了从噪声到数据之间更简洁的线性路径建模，有助于实现更稳定、高效的训练。结合 Transformer 架构已被验证的可扩展性和卓越性能，构成了 TripoSG 的强大核心。其最大的研究模型参数量达到 40 亿，可生成由 4096 个 Latent Token 表示的形状，从而实现超乎寻常的细节表现力。 其次在模型架构上，TripoSG 基于 Transformer 基础，融合了包括跳跃连接在内的关键增强设计，以改善跨层特征融合。独立的交叉注意力机制能够高效地注入全局（CLIP）和局部（DINOv2）图像特征，确保输入图像与输出 3D 形状之间的精准对齐。 为了高效扩展模型规模，他们在 Transformer 模块中集成了混合专家模型层。这一策略允许在几乎不增加推理计算成本的前提下显著提升模型容量，并重点应用于网络中更深、更关键的层级。 对于 3D 生成来说，潜空间表示的质量至关重要。它不仅是生成模型的「骨架」，更是决定生成结果是否真实、高效、可控的核心。 为此，VAST 团队开发了一种高效的变分自编码器 (VAE)，采用符号距离函数 (Signed Distance Functions, SDFs) 进行几何表示，相较于此前常用的体素占用栅格具有更高的精度。 更为关键的是，TripoSG 还引入了一种混合监督训练策略，将标准的 SDF 损失与表面法线引导 (surface normal guidance) 和 程函方程损失 (eikonal loss) 相结合，促使 VAE 学习到更准确、细节更丰富的几何表示，有效避免了其他方法中常见的瑕疵，为后续的流模型提供了质量更高的潜空间。此外，基于 Transformer 的 VAE 架构也展现出强大的分辨率泛化能力，无需重新训练即可处理更高分辨率的输入。 大模型训练需要大规模、高质量的数据集，但直接使用来自 Objaverse 等公共数据源的原始数据由于数据质量、多样性等原因会导致模型性能欠佳，于是 VAST 团队开发了一套完善的数据构建与治理流水线，包括质量评分、数据筛选、修复与增强、SDF 数据生产等环节。通过这一精细化流程，TripoSG 构建了一个包含 200 万高质量「图像 - SDF」训练样本对的数据集。消融实验也证明，在此高质量数据集上训练的模型性能显著优于在更大规模、但未经过滤的原始数据集上训练的模型。 在这一系列技术加持下，TripoSG 在 3D 内容自动化生成领域取得了显著的进展。 据 Normal-FID 等量化指标评估，以及基于大型多模态模型的定性评估显示，TripoSG 无论是在生成速度和质量上，还是对大规模 3D 数据的高效利用和处理上，都比先前的 SOTA 方法更具优越性。 而 TripoSG 的开源更是为 3D 生成领域注入了一剂强心针，其意义不仅在于技术上的突破，更在于为整个行业开辟了新的发展方向。 TripoSF：闭源 3D 生成新 SOTA 并开源基础组件与算法 此前闭源 SOTA VAST 推出的 Tripo2.5 已确立行业标杆，而新一代 TripoSF 不仅以闭源 3D 生成新 SOTA 的姿态突破性能极限，更开源基础组件与算法推动生态发展。 在 3D 生成领域，高分辨率、任意拓扑的三维重建是一大难题，面临着模型生成精度、拓扑优化、实时渲染和计算资源等多方面的挑战。 一方面，当遇到不规则形状或者涉及多个交叉点、分支、孔洞、表面变化等复杂拓扑结构的重建时，依赖网格、体素或者点云表示的三维重建方法往往力不从心；另一方面，高分辨率建模则不仅要求捕捉全局形状，更需要在细节层次上处理纹理、表面细节、微观结构等。 然而，当前主流 3D 表示方法，比如隐式场（SDF/Occupancy）、显式网格、点云，要么对于细节的捕捉效果较差，并难以实现对高面数、复杂拓扑结构的直接重建；要么在高分辨率下实时渲染时产生巨大的内存开销。这就导致业界很少有模型能够生成媲美专业三维数字雕刻建模软件 ZBrush 所创作出的的高精细、高复杂度作品。 为了克服这些局限性，VAST 推出了新一代三维基础模型 TripoSF，其核心是引入一种全新的表示方法 —— SparseFlex，实现了基于渲染监督的高分辨率（最高可达 1024³）、任意拓扑结构的可微分网格重建，为行业带来全新解决方案。 SparseFlex 相较于以往方法有哪些新颖之处呢？VAST 称，SparseFlex 在借鉴英伟达 Flexicubes（可微分提取带尖锐特征的网格）优势的基础上，更进一步引入了稀疏体素结构。与传统的、覆盖整个空间的稠密网格不同，稀疏体素结构仅在必要的位置（即物体表面附近的区域）存储和计算体素数据，避免了存储空间浪费。 具体来讲，SparseFlex 表达的设计带来了三大显著优势，一是内存占用大大降低，使得 TripoSF 可以在 1024³ 的高分辨率下进行训练和推理；二是原生支持任意拓扑，不仅通过省略空白区域的体素来自然地表示布料、叶片等开放表面，还能有效地捕捉内部结构；三是得益于 SparseFlex 的可微分属性，TripoSF 可以使用渲染损失进行端到端训练，从而避免了水密化等数据转换造成的细节退化。 除了核心的 SparseFlex 表示方法，TripoSF 同样在模型训练、重建与编解码上展现出了技术先进性。 为了实现高分辨率下 TripoSF 的高效训练，VAST 开发了一种「视锥体感知的分区体素训练」（Frustum-Aware Sectional Voxel Training）策略。该策略借鉴了实时渲染中的「视锥体剔除」思想，在每次训练迭代中，仅激活和处理位于相机视锥体内的 SparseFlex 体素。 如此一来，一方面减少了渲染负担，进一步降低训练所需的内存和算力，使得 1024³ 分辨率的训练成为可能；另一方面，首次实现仅通过渲染监督重建模型的内部精细结构，减少了对高成本数据的依赖，并能在动态和复杂环境中实现更高适应性。 而在 SparseFlex 表示和高效训练策略的基础上，VAST 进一步构建了 TripoSF 变分自编码器（VAE）。从输入、编码、解码到输出，TripoSF VAE 形成了一整套完善高效的处理流程，成为 TripoSF 重建和生成体验向前迈出一大步的重要基础，并率先开源。 其中在输入时处理从三维网格采样得到的点云数据，然后使用稀疏 Transformer 将输入的几何映射为紧凑的隐空间编码，接着从隐编码重建高分辨率的 SparseFlex 参数并采用自剪枝上采样模块来保持稀疏性并精确定义边界（开放表面的效果尤为显著），最后生成 SparseFlex 参数以提取高质量的三维网格。 效果显而易见，在与所有闭源模型的直接较量中，TripoSF 的质量达到了 SOTA。在多个标准基准测试中，TripoSF 实现了约 82% 的倒角距离（Chamfer Distance）降低和约 88% 的 F-score 提升，在精细细节、开放表面以及内部几何结构的捕捉上做到了行业领先。 VAST 表示，作为 TripoSF 开源项目的第一阶段，TripoSF VAE 为完整的 3D 生成系统提供了核心的编解码能力。另外，VAST 还基于 VAE 隐空间构建了 Rectified Flow Transformer 生成模型，以高效生成高保真的三维模型。满血版 TripoSF 生成模型将在 Tripo3.0 版本中亮相。 此次，TripoSF VAE 以及核心 SparseFlex 表示的开源，将使更多研究人员和开发者体验到其为高分辨率三维重建带来的性能增益，并基于它探索更多的应用可能性。这让我们更加期待 TripoSF 下一阶段的开源，届时 VAST 会为社区带来更多前沿 3D 技术。 结语 VAST 两大模型的开源只是个开始，这样一波技术更新，会为 3D 开源社区注入新的活力。 视频生成之后，人们都在期待 AI 带来的 3D 创作能力。在国内外社区，越来越多的设计师正在尝试把 3D 生成模型引入自己的工作流，改进游戏、视频、工业设计等领域的生产形态。由于 AI 生成的内容越来越精细、准确，很多一直以来面临的挑战迎刃而解。在 2024 年初与 Stability.ai 一起合作开源 TripoSR 时，VAST 曾定义 3D 生成技术当时第一次达到了 Midjourney V3 的成熟度，并判断 2025 年 3D 生成会达到 Midjourney V5 的水平，如今可见技术向前迈进的速度着实比预计的更快。 以 AI 技术发展的角度来看，3D 生成还是「世界模型」的基座，更强大的 3D 生成技术，将会拓展 AI 的前沿。 可以预见，在 VAST 这一波开源之后，3D 大模型或许很快达到实用化和商业化的程度，并催生出更多新场景的落地应用。返回 举报/反馈"
    },
    {
      "doc_id": 49873,
      "title": "DeepSeek发布模型更新,新版本编程能力大大提升",
      "time": "2024-03-25T00:00:00+00:00",
      "content": "责任编辑：宦艳红 图片编辑：陈飞燕 校对：施鋆 澎湃新闻报料：021-962866 澎湃新闻，未经授权不得转载 +1 53 收藏 我要举报"
    },
    {
      "doc_id": 49874,
      "title": "DeepSeek深夜宣布开源新版R1模型,能否再度搅动全球AI格局?",
      "time": "2024-05-29T00:00:00+00:00",
      "content": "5月29日凌晨，中国AI公司DeepSeek在开源机器学习平台Hugging Face上悄然开源了新版R1模型（R1-0528），未发公告却震动全球。 据开发者社区测试显示，其代码生成与复杂推理能力已媲美OpenAI顶级o3模型，甚至在编程任务中可一次性生成工业级代码及配套测试用例，首次运行通过率接近100%，此前仅有o3能稳定做到这一点。 近期，DeepSeek沉寂许久，而OpenAI、谷歌等巨头密集迭代模型。OpenAI于5月23日推出o3模型，它是ChatGPT内Operator自主网页浏览和光标控制代理的升级基础模型，能提升网页任务执行准确性与安全防护能力。此前，其在4月先后发布o4-mini模型、GPT-4.1系列模型，其中GPT-4.1支持100万Token上下文，利于处理大型代码库，Nano版则成本低廉。谷歌则刚刚发布了Imagen4和Veo3模型，具备从文本到视觉内容生成的高质量输出能力，在图像、视频和音乐生成方面处于行业领先。 而此次DeepSeek再度以开源为矛，刺向全球AI竞争最敏感地带。据开发者实测，R1模型不仅逻辑严密性显著提升，能自主纠正思维链错误，其响应风格更与o3高度趋同——从箭头符号使用到分层递进式解释，甚至结尾的“why it works”总结段落，均展现出与顶级商业模型同级的交互成熟度。在代码生成领域，实测表明R1与Anthropic Opus 4差距已缩小至“毫厘之间”，部分创造性解法甚至更优。 更重要的是，R1延续了DeepSeek标志性的开源路线：模型权重、架构完全开放，允许免费商用与修改。这直击美国闭源模型生态的软肋。此前，其初代R1发布时，DeepSeek宣称训练成本仅560万美元，不到美方同类模型的十分之一，成功打破技术垄断的势头，甚至迫使OpenAI CEO奥尔特曼承认“闭源可能站在历史错误一边”。 面对美国芯片管制与框架封锁，DeepSeek已非孤军奋战。中国本土正形成以R1为核心的“芯片-框架-应用”全栈生态： 算力层上，适配国产芯片的推理优化方案，据技术演示，可使7B小模型在（极低内存/如256MB内存）设备运行；平台层上，腾讯、百度等将DeepSeek集成至微信搜索、文心一言等核心场景，推动技术普惠；商业层上，据公开信息，金融、医疗等约12个行业快速落地，企业应用案例显示可借蒸馏模型将推理成本显著降低至闭源方案的一小部分。 这种“开源+垂直优化”模式，正吸引新兴市场开发者涌入。GitHub数据显示，DeepSeek仓库贡献者覆盖185个国家/地区，其中印度、巴西开发者活跃度据观察仅次于中美。低成本与开放性，使其成为发展中国家AI跃迁的关键跳板。 目前，中国大模型竞争已从“百团大战”聚焦至市场观察所称的“基模五强”，如字节、阿里、阶跃星辰、智谱、DeepSeek。其中，DeepSeek凭借工程极致性与开源信仰，成为其中最独特的“特种兵”。其突破印证了一个战略趋势：当模型智能逼近临界点，开源生态的集体进化速度被普遍认为将超越闭源孤岛。 举报/反馈"
    },
    {
      "doc_id": 49875,
      "title": "DeepSeek-V3击败R1开源登顶!杭州黑马撼动硅谷抹去1万亿市值神话",
      "time": "2024-04-01T00:00:00+00:00",
      "content": "编辑：编辑部 XYs 【新智元导读】DeepSeek又卷起来了！上周刚出的DeepSeek-V3-0324在大模型竞技场排名中，打败了自己的DeepSeek-R1，成为开源AI至尊。 DeepSeek依然很能打，春节余波还在扩散！ 据AI产品分析平台aitools.xyz统计，DeepSeek每月新增网站访问量超过了ChatGPT。 作为异军突起的现象级产品，DeepSeek的增长速度除了创造AI产品的增长奇迹，更是重新定义了全球的AI竞赛格局。 DeepSeek除了「卷」竞争对手，甚至也在自己「卷」自己。 在AI大模型竞技场LMSYS上，发布不到半个月的DeepSeek-V3-0324，已经超过了曾经的「当红炸子鸡」DeepSeek-R1！ 所有类别排名前5，DeepSeek-V3-0324成为排名第一的开源（MIT许可）模型。 这还是在DeepSeek-R2没有发布的前提下，R2发布的那天，AI圈估计又是一场不眠夜。 但「革命尚未成功」，不要忘了，ChatGPT的总市场份额依然高达43.16%，周活用户已破5亿。 不仅如此，OpenAI也决定通过开源，来应对DeepSeek的巨大冲击。今早，奥特曼已官宣，自GPT-2后首个推理模型，将在未来几个月开源。 那么，它又会比R1强吗？若是R2提前开源，OpenAI又该如何自处？ DeepSeek R1竟被V3打下去了 DeepSeek-V3-0324这波进化，实属有亿点点厉害。 目前在榜单排行中，它的实力与Gemini 2.0 Pro、GPT-4.5 preview、Gemini 2.0 Flash Thinking并驾齐驱。 也就是说，当前闭源模型最强三款——Gemini 2.5 Pro、GROK 3、GPT-4o之后，开源模型之光便是DeepSeek-V3了！ 在所有评测类别中，DeepSeek-V3-0324在编码、Multi-Turn上，位列第一。 其他数学、创意协作、长查询等基准中，V3也取得了亮眼的表现。 如下是所有模型的胜率热图。 所有开发者，着实感受到了DeepSeek-V3-0324强大的编程能力。有开发者，直接用一条指令便构建出一个游戏。 他表示，「编程革命已至，零基础也能驾驭」。 V3肝了800行代码，一次性构建出网站，也没有出任何错。 DeepSeek打破硅谷优势 一直以来，有种说法：「美国创新，中国迭代」。 直至今年1月，来自中国初创公司DeepSeek打破了这个「定律」。 他们发布的首款推理模型DeepSeek-R1，性能堪比几个月前刚推出的OpenAI o1。 R1横空出世，不仅创新性十足，而且成本低得惊人，前一代模型V3的最后一轮训练只花了600万美元。 AI大神Karpathy认为，和美国一些竞争对手动辄花几千万甚至上亿美元相比，这简直就是「小巫见大巫」。 随着R1飙升至热门下载榜首，大型科技投资者陷入恐慌，英伟达、微软等科技股市值蒸发超过1万亿美元。 奥特曼也表达了自己的焦虑，并考虑开源，像DeepSeek一样，让模型公开可用和可修改，从而降低使用成本。 奥特曼深刻忏悔：自己在开源AI上站错了队 乔治华盛顿大学助理教授Jeffrey Ding表示，「很多人都低估了中国开发这些前沿突破性技术的能力。」 一夜之间，国内外不同赛道的大企业，争相把R1模型接入自家产品。 DeepSeek的成功就像一针「强心剂」，能以无法想象的方式推动经济发展。 与此同时，投资者纷纷涌入中国科技股。 快速逆袭之路 DeepSeek的成功表明，中国AI初创企业并非只有依靠巨额资金才能在全球竞争中崭露头角。 转折点出现在2024年秋季，从那时起，差距开始逐渐缩小。 尤其是在开源领域，中国企业开始聚焦小型模型的优化，显著提升了训练效率。 开源模型有助于构建更庞大的用户生态。 阿里在推动开源技术发展方面发挥了重要作用，开源社区Hugging Face性能排名前十的LLM，均基于阿里云的通义千问模型进行训练。 中国AI行业能实现快速追赶，庞大的市场规模是一个重要因素。 腾讯旗下拥有超10亿用户的微信平台，将DeepSeek的模型接入后，用户量呈爆发式增长，迅速成为中国AI领域的明星企业。 此外，人才也是中国AI行业崛起的关键要素。 中国高校每年培养出大量优秀工程师，为AI初创企业提供了充足的人才资源。这些年轻人专业能力出众，其数量和质量是美国高校难以比拟的。 如今，DeepSeek不再仅仅是一家公司，而是开源AI、低成本AI的代名词。 它不仅打破了硅谷在AI领域技术领先地位，更以低成本、高效率的创新模式，重新定义了全球科技竞争的新范式。 举报/反馈"
    },
    {
      "doc_id": 49878,
      "title": "对话医学人工智能首席专家:以DeepSeek技术为引擎,构建医疗AI价值...",
      "time": "2024-04-26T00:00:00+00:00",
      "content": "对话医学人工智能首席专家：以DeepSeek技术为引擎，构建医疗AI价值应用新生态 来源：中华网 时间： 2025-04-26 15:26:39 A+ A- 随着人工智能技术进入“深水区”，医疗领域正经历从数字化到智能化的历史性跨越。近年来，以DeepSeek为代表的国产AI技术，正通过底层创新与场景深耕，重塑医疗服务的效率与质量。在这场变革中，医院如何构建AI价值体系？技术如何与临床需求深度融合？金东结合当前医学领域的前沿趋势与医院建设的生动实践，给出了系统性答案。金教授，您在医疗人工智能领域深耕多年，见证了行业从萌芽到落地的全过程。首先想请您谈谈，当前人工智能的整体发展态势如何？金东：2017年7月，国务院发布《新一代人工智能发展规划》，从国家战略层面部署新一代人工智能工作，规划了我国人工智能发展路线图。同年，工业和信息化部印发的《促进新一代人工智能产业发展三年行动计划（2018—2020年）》明确提出医疗影像辅助诊断系统、智能服务机器人等细分行业的发展目标、发展方向。近几年，随着以ChatGPT为代表的大语言模型迅速发展，生成式人工智能正在全面革新社会生产力，我国智能模型体系取得显著突破，多个具备国际竞争力的创新成果相继面世，形成了技术生态的多元化发展格局。阿里万相在视频生成领域优势突出，Wan2.1测试总分86.22%，5项全球第一，场景还原精准；腾讯元宝依托云算力，接入双模型，聚焦高知群体，能快速给出专业方案，满足多元需求；字节跳动豆包凭借智能分析与推荐，帮用户速寻所需，在新媒体场景助力短视频运营与热点传播；OpenAI的ChatGPT4.5以及即将推出GPT5，经海量数据训练，语言能力卓越，计算效率比提高10倍以上，进一步加剧大语言模型的竞争。DeepSeek有力推动了国产大模型技术突破，降低行业应用门槛，其开源特性+低成本API，不仅解决了大模型训练与推理的核心痛点，为中小开发者和企业提供了平等参与AI创新的机会，标志着中国在AI领域从“跟跑”到“领跑”的历史转折，更是成为我们公立医院高质量发展的新引擎。在医疗领域，人工智能技术正以前所未有的广度和深度不断拓展，您特别指出DeepSeek在推动智慧医院建设中展现出巨大潜力。结合医疗行业的特殊性，能否具体说明当前DeepSeek在医疗领域的应用主要集中在哪些方面？金东：人工智能与医疗的深度融合，是医疗领域技术与模式的双重革新，医疗信息的高效处理与精准分析为医疗服务提供智能化、个性化的支持。目前智能诊断辅助、实时病历质控、医疗资源动态优化、医保控费与DRGs预判、患者风险预警、科研数据自动化等方面是重点应用场景。Deepseek最擅长通过智能算法重构就医流程，从挂号分诊到检查报告流转，实现毫秒级响应与资源精准匹配。在设备排班、药品供应链、医护人力分配等场景中，能构建动态优化模型，降低运营成本。通过整合HIS、LIS等系统数据，生成可视化管理看板，提升医院决策效率。但是，也有它不擅长的方面，比如无法临床操作与应急处理，面对罕见病、多种疾病并发等复杂病情，难以像经验丰富的医生那样，综合考虑患者的个体差异、病史、症状表现等多方面因素进行准确诊断和制定个性化治疗方案。虽然能提供一定的信息和分析，但在涉及多科室复杂利益协调、资源分配等需要深度协作和决策的场景中，难以像人类管理团队那样充分考虑各种人情因素、实际情况等进行灵活决策和协调。您认为AI技术在医疗领域最可能实现突破的方向有哪些？以及发展面临的核心挑战是什么？金东：在数据方面，DeepSeek等大语言模型将有效助力更精准的辅助诊断，做到实时分析患者历史数据、基因信息及医学文献，为医生提供个性化治疗方案；分析复杂医疗数据，帮助医生迅速找到最佳处理方案。在药物研发方面，将在靶点研究、小分子药物设计和性质预测、合成路线预测、大分子药物设计和成药性优化等环节发挥作用，缩短研发周期、降低成本。推动中医智能化方面，我们可以预见的，将降低大模型处理中医四诊信息的推理成本，推动高水平中医医疗及养生智能体在严肃医疗、大健康机构及C端的广泛普及。在医疗设备智能化方面，将医疗影像设备集成大模型算法，可自动生成结构化报告，提高疾病诊断及治疗的效率和准确性。在信息共享方面，将促进医疗信息更加透明化，为中小企业和创新型医疗企业提供发展的契机。其中，在实践应用中，还有一些问题需要我们预判和解决。例如数据层面，医院内部各系统数据难以流通共享；超70%的医疗数据为非结构化数据，缺乏统一标准，质量参差不齐；医疗数据涉及患者隐私，脱敏处理和访问控制要求极高。模型层面，需针对医学影像分析、电子病历NLP等不同医疗场景，匹配不同的模型架构和微调策略；医疗业务复杂，需将其拆解为原子化AI任务，明确需求和目标，建立模型评估框架，筛选最优模型。另外，还有算力成本、伦理法规、商业层面等难点、堵点问题存在。我们关注到浙江省人民医院在智慧医疗领域始终走在创新前沿。能否请您结合具体的AI+医疗融合场景，为我们分享一下具有代表性的落地案例？金东：“创新为先”始终刻在浙江省人民医院的行动上。2021年至今，医院规划实施5批50个数字医疗和人工智能项目，特别在建院40周年发展大会上正式发布了第5批医学人工智能体集群，包括医学影像多场景集群化调度智能体、双轮审核与举证解读检验结果智能体、病理复杂任务处理和患者服务智能体、脓毒症多模态早期预警智能体、阿尔茨海默病全域全程管理智能体、高精度柔性眼科机器人及远程手术平台、手术全流程精准管理分析预测智能体、全程全域认知行为治疗患者全程精细服务智能体、医疗文本自动生成全流程精细化管理智能体、一体自动化静配中心管理智能体等10大智能体，体现了浙江省人民医院在医疗管理领域的创新性与前瞻性。如脓毒症多模态早期预警智能体，其核心优势在于独特的动态自适应学习进化机制和人工智能反馈闭环能力。模型通过深度学习和机器学习算法，在临床应用过程中能够实时收集并分析反馈数据，实现动态参数优化，自主完成参数调优、决策逻辑更新和性能进化，持续增强对不同科室与复杂病例的适应能力，真正实现“数据—模型—临床”的闭环互动。在实际运行中，模型不断优化预警策略，显著提升预警的精准度、灵敏性、特异性及稳定性。自2024年7月正式运转以来，截至目前已筛查重症病人4170人次，经临床验证，灵敏性达到91.18%，特异性达到94.67%，总体准确率93.30%.，实现了重症脓毒症提前24小时高效、实时预警的目标，辅助医护团队在关键时刻做出科学决策。作为行业实践者，您认为构建医疗AI价值生态的核心着力点应聚焦哪些方面？金东：当前医疗AI生态建设已经进入“临床价值验证”向“规模经济转化”的关键阶段，需要以真实临床问题为导向，推动“技术—医院—产业”的协同进化。AI技术需着力突破临床应用的“最后一公里”瓶颈，包括数据工程迭代、算法临床适配、决策可解释性突破等。而医院也要调整自我角色，从使用者转换为共建者，构建“临床—科研—管理”三位一体闭环，打通“技术—商业—政策”价值链条协同，通过技术突破、医院深度协同、产业模式创新形成正向循环。2024年年底，国家卫生健康委、国家中医药局、国家疾控局联合发布《卫生健康行业人工智能应用场景参考指引》，聚焦“人工智能+”与医疗服务管理、基层公卫服务、健康产业发展、医学教学科研相结合的4大领域，明确84个细分领域的基本概念和应用场景。从辅助诊疗到攻克疑难杂症，从药物研发到全面健康管理，医学领域人工智能赛道日渐细化，正在逐步改变医疗行业的面貌。“百舸争流，奋楫者先，千帆竞发，勇进者胜”，面对人工智能与医疗健康深度融合的历史机遇，我们当夯实技术根基，推动AI在疾病筛查、精准诊疗等领域的突破性应用，更要构建产学研用协同发展的生态体系，持续深化人工智能与医疗服务的有机融合，为医疗高质量发展注入科技动能，让优质医疗资源惠及每个生命。"
    },
    {
      "doc_id": 49884,
      "title": "小旺AI截图×英特尔战略携手预热:AIPC生态即将迎来智能生产力跃迁",
      "time": "2024-07-09T00:00:00+00:00",
      "content": "【天极网家电频道】2025年7月，科技行业迎来重磅消息：全球首款接入DeepSeek大模型的AI截图工具小旺AI截图，与半导体巨头英特尔正式启动战略合作。双方将于7月10日在Bilibili World 2025展会现场举办联合发布会，届时将首次展示专为Intel AIPC架构深度优化的“小旺AI截图 for Intel”技术原型。此次合作预示着智能截图工具与高性能计算硬件的生态融合即将进入全新阶段。 作为全球首款接入DeepSeek大模型的AI截图工具，小旺AI截图此前已通过智能内容解析、多语言翻译、数据可视化分析等功能重新定义了截图工具的边界。此次与英特尔的合作，将这一能力推向新高度。 基于英特尔的强大算力和硬件性能，小旺AI截图新版软件将实现三大技术突破：多核并行处理优化，针对多窗口截图场景，软件可调用英特尔处理器的多核并行能力，实现同时对多个画面的无损捕捉，大幅提升效率;AI计算加速，依托英特尔先进的指令集架构，DeepSeek模型的推理速度提升，缩短了复杂图表解析、学术文献翻译等任务的响应时间;安全防护体系，集成英特尔SGX安全单元技术，从数据采集到传输的全链路实现AES-256加密，确保用户隐私信息在截图、标注、分享过程中的绝对安全。 小旺AI截图自2025年3月发布以来，凭借5MB超轻量安装包(不足同类产品1/30)及全球首创的DeepSeek大模型深度集成，日均处理截图量超千万次，成为设计师、程序员等专业用户的核心生产力工具。英特尔基于其技术前瞻性与用户渗透力，将其纳入AIPC生态核心布局。目前，小旺AI截图官网已上线英特尔定制版下载窗口，用户可以下载体验。该版本最大的特点是增加了“部署本地模型”，用户无需联网即可使用截图翻译、截图解释等AI功能。 此次合作将加速端侧AI应用的标准化进程：为开发者提供基于英特尔架构的AI工具优化范式，助力企业通过软硬协同降低算力成本，并完善云边端协同基础设施生态。"
    },
    {
      "doc_id": 49886,
      "title": "从硬件、框架到软件生态 英特尔为行业提供全域大语言模型部署方案",
      "time": "2024-04-01T00:00:00+00:00",
      "content": "时间，是一根衡量科技的标尺。沿着这根标尺向前眺望，迎面拂来的山风，吹来的是人类对创新的渴望。而沿着这根标尺回眸凝视，我们看到的世界被不同的科学技术雕刻成了此刻的模样。 正如现在，此时，我们刚刚才被一股叫做DeepSeek的科技力量重塑了对于AI的认知。这科技发展史的无垠星河中，在星辰般的技术创新碎片里，我们似乎常常能够看到微毫来诠释盛大。当英特尔埋下那颗叫做“AI PC”的科技种子时，现在的我们再凝望着最初的凝望，这一年半时间仿佛就只是刹那。 AI PC的前瞻性与DeepSeek的革命性在今天交汇，积聚起来的化学反应甚至比ChatGPT更加强劲。引爆了包括半导体芯片技术、软件应用以及AI PC产品等在内的不同领域的再一次蓬勃发展。但事实上，穿行在这股创新浪潮之间的，是AI与PC诞生以来超过半个世纪的人类对科技的摸索与积累。 ·完整、灵活、多元的包括DeepSeek在内的大模型部署硬件解决方案 当前，无论是中国还是世界范围内，所有积极拥抱AI的实体都绕不开DeepSeek，创造AI PC概念的英特尔更是如此。面对大量来自政府、企业、学界、金融界、医学、司法等诸多领域的DeepSeek大模型私有化部署需求，英特尔提供了非常完整的各种参数大模型的本地部署解决方案。 首先从底层芯片层面，英特尔酷睿Ultra系列以出色的CPU+GPU+NPU AI算力满足不同参数规模的大模型本地部署需求。同时，伴随着近期英特尔酷睿Ultra 200HX系列处理器的发布，英特尔能够为不同用户提供包括酷睿Ultra 200V、酷睿Ultra 200H、酷睿Ultra 200HX以及酷睿Ultra 200S等在内的多元化AI芯片解决方案。再加上英特尔至强、英特尔锐炫GPU等等，完整覆盖了轻薄本、AI PC、台式机、服务器、AI一体机的多样化硬件生态体系。 其次从部署场景来看，DeepSeek当前的细分部署需求有三种： 其一是671B满血版，不仅参数满血，还包含了数据精度的满血，也就是利用BF16或FP8来做满血版大模型推理，这种需求的成本非常高，所以基本是大型政企用户的需求； 其二是DeepSeek通过Llama、Qwen蒸馏出来的不同参数规模的蒸馏模型部署，如我们常说的DeepSeek-R1 70B、32B、14B、7B、1.5B等，其实都是蒸馏模型，参数量更小，部署成本更低，但是具备非常不错的推理能力。 其三则是特定客户的客制化部署需求，以DeepSeek的蒸馏模式来客制符合自身领域、行业规范和需求的私有化模型。 面对这些需求，英特尔与其生态合作伙伴给出了不同的解决方案。 首先就是AI一体机，当前很多传统PC或服务器厂商都推出了基于英特尔芯片打造的AI大模型一体机。它具备开箱即用、可做私有化部署以及与客户应用结合，通过RAG（检索增强生成）或企业AI智能体联动，满足客制化、私有化大模型的部署需求。 硬件基础之上，英特尔针对性地推出了如OpenVINO、ipex-llm等开源框架，让大模型能够更加迅捷地跑在英特尔的硬件平台之上。当然，DeepSeek等大语言模型的部署并非只是提供一个开源框架、装到一个裸服务器上就可以开跑，孙峪（英特尔中国区AI PC产品总监）说，“跟不同客户沟通的过程中发现，其实有很多要考虑的因素。举个例子如数据精度，如何在投资（成本）间和不同数据精度间找到平衡，又能实现满足客户需求的推理（Thinking）和生成速度（tokens/s），这些因素同样重要。而且这些已经是在实践DeepSeek的过程中，行业已经在思索或正在思索的问题。” 因此，除了提供底层硬件与开源框架支持之外，英特尔与合作伙伴带来了不同的产品解决方案。比如先前提到的AI一体机就是其中之一。而轻薄本、AI PC、台式机等终端设备，得益于英特尔酷睿Ultra 200系列处理器AI算力的翻倍式提升，则能够为用户带来更加多样化、适配不同成本需求的部署方案。 当前，基于酷睿Ultra 200系列处理器的AI PC已经能够在本地轻松运行14B甚至32B参数规模的大语言模型。接下来的这个案例演示或许能够让大家更为直观的get到这一点。 DeepSeek在代码生成和数学计算方面有着卓越的表现。利用14B蒸馏模型，就可以极为快速地让AI帮我们制作一个经典的《俄罗斯方块》游戏。同时它可以根据不同要求，生成简单的基础版或更加复杂的高阶版游戏。 这段演示使用了英特尔生态合作伙伴Flowy的AI助手软件，它是一个便捷的.exe安装程序，同时支持在线大模型和本地大模型环境，并集成了如翻译、合同审核、文本续写、会议纪要等不同细分领域的AI助手，它可以被便捷地安装在轻薄本、AI PC、台式机之上，同时满足用户经济且高效的本地和云端大模型部署需求。 32B是目前AI PC能够支持并正常使用的相对而言规模比较大的大语言模型，英特尔也在不断探索32B蒸馏模型在AI PC端侧的表现。当然，32B参数大模型对于内存和显存的要求更高，因此将内存升级到64GB，且让GPU共享显存扩容到36GB以上才会有更好的体验。 利用32B大模型以及投机解码机制，仅用一句提示词即可让AI快速生成《五子棋》或《打砖块》这样的游戏代码。在这个过程中，投机解码机制可以保持32B模型的生成质量，同时利用小模型托举，让生成速度得到保障。在一台酷睿Ultra AI PC终端上，32B大模型生成五子棋游戏代码的速度最高能达到14 tokens/s，已经能够满足正常的使用需求。 此外通过生成规律可以看到，正常情况下token是一个接一个去生成，而利用投机解码机制后，代码生成有时会变成同时生成一行的模式，这就是投机解码的作用，它可以显著加快大规模参数模型的生成速度。而这也意味着即便是4-6000元主流价位的AI PC，亦能够支持32B参数大语言模型的本地化部署与应用。英特尔解决方案的灵活性、多元化与经济性凸显出来。 就在数年以前，程序员们想要编写一段简单的游戏代码，也需要耗费不少的时间、精力与脑力，而结果却并不一定理想。现在，AI大语言模型超凡的代码编写能力让不懂编程的人也能通过一句提示词完成简单游戏的制作，这种天翻地覆的变化让人震撼。而英特尔与其生态伙伴通过不同的硬件产品组合，为个人用户、企业用户、特定领域用户提供了多元化、客制化、更具经济性的解决方案，从而在短短一年半时间里，推动AI PC行业完成了从0到1的飞跃，这在整个人类社会、科技发展历史上也是极其罕见的壮举。 ·多种大模型框架让AI生成速度跨越硬件桎梏 从CNN到Transformer，人工智能技术经历了从单点识别到链式推理的蜕变，也谱写出了今天人工智能时代、AI PC时代的基调。 而仔细追踪英特尔近五年来的研发路径就会发现，从Tiger Lake也就是第十一代酷睿处理器首次引入DP4a，VNNI以及GNA(Gaussian&Neural Accelerator)三大AI加速引擎，到酷睿Ultra平台正式支持NPU计算单元，并不断强化CPU与GPU的AI算力，再到Intel OpenVINO、ipex-llm等框架层面，英特尔AI硬件、软件的发展路径其实与AI架构的发展路径是高度吻合的。 此前，笔者体验了Ollama+ipex-llm框架本地部署DeepSeek-R1:32B蒸馏模型之后的性能表现，借助英特尔酷睿Ultra 5 225H的锐炫130T核显，生成速度如下图所示，可以说是达到相当可用的状态。 更加安全、私密的单机本地化大模型部署是当前不少企业的核心诉求。在满足基础硬件的要求之后，如何让大模型在本地运行的速度更快、更高效，就需要专门的加速框架来支持。OpenVINO、ipex-llm正是为此而生。 目前，业界有100个左右的开源框架，这些框架可以上联应用、下联硬件，同时又可以跟不同的大模型做联系。比如DeepSeek带火的Ollama就是其中之一，但如果单独使用Ollama的话会有诸多不便。此时，英特尔ipex-llm解决方案与Ollama适配之后的优势就显现出来。同时，不少其它开源框架都能与英特尔AI PC结合，提供很好的算力支持，为大模型的本地运行提速。 目前，英特尔已经将Ollama+ipex-llm的方案制作成整合包，总容量只有200多MB，在Github和魔搭社区都有提供下载，方便用户的使用。 此外，英特尔也与行业内几乎所有的ISV生态开发者合作，将其框架内置到端侧应用之中，用户无需特意部署就能享受这些框架带来的出色体验。比如英特尔与神州数码合作的爱问学这款端侧AI PC应用就是如此，它解决了三个核心问题： 其一，开发者不需要再管底层硬件迭代更新； 其二，从大模型市场获取大模型以及更新大模型更加爱方便，无需科学上网； 其三，通过框架帮助AI PC应用进一步“瘦身”，为最终用户提供更轻便、更轻量化的安装包。 神州数码AI生态总监莫晶晶介绍爱问学时表示，“整个爱问学端侧应用AI开发框架的技术架构，以及英特尔底层计算引擎方面，我们做了很多优化工作。力求为开发者提供更好的开发体验，包括云端模型还有本地模型的获取、端侧小模型的获取。并提供给开发者‘开箱即用’的服务，以便通过SDK或者API的方式进行快速接入，不用操心过多框架依赖的问题，而是更专注于AI PC开发本身。” 其实无论是直接借助英特尔框架加速AI大模型本地运行，还是将框架与应用侧相结合，最终目的都是为了提升大模型本地化部署和使用体验。而坚决拥抱开源的英特尔，在大模型框架层面的解决方案上自然有着极为丰富的布局。 ·极为丰富的AI PC应用生态 从硬件到框架，英特尔构建了相当扎实的底层AI基石。但仅有这些显然还不够，毕竟最终落地到应用端、有丰富的应用生态才能支撑起整个生态的健康发展。 从AI PC概念诞生到现在，短短一年半时间里，英特尔携手ISV合作伙伴，带来了非常丰富的应用，尤其是在AI PC五大核心应用场景：知识助手、办公助手、娱乐助手、创作助手以及垂类助手方面，用户可以从Intel.cn/aipc网站很轻松地获取到大量的相关应用。 接下来我们不妨看一些实际案例。 字节跳动：扣子 首先是英特尔基于开源生态与字节旗下扣子的合作。 英特尔联合扣子推出了扣子AI PC APP，在开发过程中英特尔利用扣子本身的开放端插件能力，将本地的AI PC功能，如PC系统设定、RAG、语音功能等等，融入到扣子本身的Agent Flow开发流程中，从而带来了全新的端云结合体验。 在此基础之上诞生的AI PC会议助手，可以帮助用户实时记录会议内容，并将其从云端转录到本地，同时还可提供图片入库功能，将会议关键信息截图存储到数据库中，使图片向量化，使AI能够理解图片内容并进行批注，后续可以让用户很方便的通过关键词搜索到对应图片。此外，会议纪要功能也体现了端云结合，通过云端快速生成，服务用户的本地化需求。 神州数码：爱问学 神州数码的爱问学前面我们已经进行了简单介绍，但实际上它可以说是把百度百科搬到了本地，有着非常强大的AI助手能力。 爱问学英特尔酷睿Ultra版本集成了31个大语言模型，包括Qwen、DeepSeek家族，模型的参数量从0.5B到14B都一应俱全。同时还有三个模型可以被用于RAG文档解读，此外还引入了搜索和API对接，以便从网络上获取最新的大模型更新信息。 这款应用借助英特尔锐炫GPU来进行快速推理和生成。利用爱问学，用户可以非常方便地生成旅游攻略、演讲文稿、年终总结等内容，高效便捷。 面壁智能:MiniCPM v2.6多模态 面壁智能利用MiniCPM v2.6这一8B参数的视觉大模型，对图像和视频实现更好的内容理解和分析。它运行在英特尔锐炫核显上，能够生成较为准确的视频内容理解和分析结果。 下面的演示内容就展现了面壁智能利用MiniCPM v2.6大模型对熊猫元素的视频内容进行分析时，GPU的工作状态。 爱奇艺智能助手 从英特尔AI PC上市至今，爱奇艺一直是生态的重要组成部分。借助大语言模型，爱奇艺既可以了解用户的观影偏好，又知道最新的影片信息，它可以成为陪伴用户观影的搭子或伴侣。同时还可以让爱奇艺根据观众喜好来智能推荐影片，并且可以通过简单到一句话的问题来了解影片剧情的后续走向。这些功能同样基于英特尔酷睿Ultra平台强大的锐炫GPU来实现。 ·亦心科技：AI闪绘 亦心科技带来的AI闪绘可以说是将AIGC应用展示的相当全面的一款应用。可以看到，下图左侧用户绘画的同时，右侧在短时间内就能自动生成预测的画稿，经过不停迭代之后，最终同步为用户想要绘制的画稿，可以说是大大提升了绘画效率，而且能够让非专业的用户也能创作出质量出色的画稿。 此外，演示时所用的产品是联想YOGA AI PC，它支持手写笔，有着4096级细腻的压感，讽刺航适合绘画创作。而英特尔酷睿Ultra平台出色的性能得以支持画稿的同步生成。 当然，除了这些演示之外，其实英特尔酷睿Ultra平台还有很多基于AI，符合AI PC应用的软件，如QQ音乐、万兴喵影、无涯问知、AiPPT等等，这些丰富的AI或支持AI功能的应用进一步放大了英特尔酷睿Ultra生态硬件与框架的优势。 ·结语 2019年英特尔率先提出AI PC概念之后，加速硬件与软件生态构建就成为了最重要的事情。一年半的时间里，英特尔通过两代酷睿Ultra平台构建了坚实的AI PC硬件基础；通过大力拥抱开源为AI PC提供了丰富的框架支持；通过人工智能创新应用大赛、通过积极与ISV合作，打造易用、便捷的AI创新应用。三条赛道同步发力，进而让算力、框架、应用成为英特尔AI PC的三大优势。 联想笔记本电脑YOGA Air 14 Aura AI元启轻薄本2025 2代酷睿Ultra7 258V 2.8K高刷触控OLED国家补贴20% 京东 月销量1000 好评率96% 无理由退换 京东配送 ¥9299 购买 举报/反馈"
    },
    {
      "doc_id": 49894,
      "title": "英特尔针对阿里云通义千问2模型进行优化",
      "time": "2024-06-08T00:00:00+00:00",
      "content": "一直以来，英特尔致力于与行业领先、创新的生态伙伴开展合作，并针对AI模型进行优化。近日，英特尔宣布其数据中心、客户端和边缘的AI解决方案为阿里云通义千问2（Qwen2）的全球发布提供支持。 英特尔公司副总裁兼数据中心与人工智能软件总经理Pallavi Mahajan和英特尔数据中心与人工智能集团副总裁兼中国区总经理陈葆立表示，在阿里云推出通义千问2大模型的当日，英特尔即为客户和开发人员提供了针对该AI模型和软件而优化的AI解决方案。 软件优化 为了最大限度地提升诸如阿里云通义千问2的大模型效率，全面的软件优化非常重要，其中包括从高性能融合算子到平衡精度和速度的先进量化技术。此外，英特尔还采用KV Caching、PagedAttention机制和张量并行来提高推理效率。英特尔的硬件可利用软件框架和工具包进行加速，并获得出色的大模型推理性能，其中包括PyTorch和英特尔PyTorch扩展包、OpenVINO工具包、DeepSpeed、Hugging Face库和vLLM。 英特尔与阿里云在数据中心、客户端以及边缘平台上的AI软件优化，有助于构建一个创新的生态环境，且截至目前，已取得了包括ModelScope、阿里云PAI、OpenVINO等在内的诸多创新成果。得益于此，阿里云AI模型可在多样化的计算环境中进行优化。 测试结果：英特尔Gaudi AI加速器 英特尔GaudiAI加速器专为生成式AI以及大模型的高性能加速而设计。使用最新版本的英特尔Gaudi Optimum，可以轻松部署新型号的大模型。在英特尔Gaudi2上对70亿参数和720亿参数的通义千问2模型的推理和微调吞吐量进行了基准测试，以下为详细性能指标和测试结果。 表1.70亿参数的通义千问2在单颗英特尔Gaudi2加速器上的推理 表2.720亿参数的通义千问2在8颗英特尔Gaudi2加速器上的推理 表3.通义千问2FP8在英特尔Gaudi2加速器上的推理 表4.通义千问2在英特尔Gaudi2加速器上的微调 测试结果：英特尔至强处理器 英特尔至强处理器作为通用计算的基石，为全球范围内的用户提供强大的算力。英特尔至强处理器具有广泛可用性，适用于各个规模的数据中心，这使其成为那些希望能够快速部署AI解决方案，又无需配备专项基础设施企业的理想选择。英特尔至强处理器的每个核心均内置了英特尔®高级矩阵扩展（英特尔AMX），可处理多样化的AI工作负载并加速AI推理。下图展现了英特尔至强处理器所提供的延迟性能可满足多种用例。 图1.在基于第五代英特尔至强可扩展处理器的阿里云ecs.ebmg8i.48xlarge实例上，通义千问2的下一个推理token延迟 AI PC 由最新英特尔酷睿Ultra处理器和英特尔锐炫显卡驱动的AI PC让AI的力量触及客户端和边缘，使开发者在本地也能部署大模型。AI PC配备了专门的AI硬件，如神经处理单元和内置的英特尔锐炫显卡，或配备了英特尔Xe Matrix Extensions加速的英特尔锐炫A系列显卡，以处理高需求的边缘AI任务。这种本地处理能力可实现个性化的AI体验，增强隐私性，并提供快速响应时间，这对于交互式应用程序至关重要。 以下展示了15亿参数的通义千问2，在基于英特尔酷睿Ultra的AI PC上运行时所展现的强大性能。 Demo1. 在内置英特尔锐炫显卡的英特尔酷睿Ultra7 165H上，通义千问2的推理 表2.在内置英特尔锐炫显卡的英特尔酷睿Ultra7 165H AI PC上，通义千问2的下一个token延迟 表3.在由英特尔锐炫A770 16GB限量版驱动的AI PC上，通义千问2的下一个token延迟 英特尔(Intel) i7-13700KF 酷睿13代 16核24线程 睿频至高5.4Ghz 五年质保 台式机CPU 畅玩黑神话悟空 京东 好评率99% 无理由退换 京东配送 旗舰店 ¥2999 购买 举报/反馈"
    },
    {
      "doc_id": 49896,
      "title": "罗永浩爆料春节前见DeepSeek创始人:像没找工作的博士后,被建议去...",
      "time": "2024-06-22T00:00:00+00:00",
      "content": "6月21日，罗永浩在活动中谈到对DeepSeek创始人梁文锋的印象。他表示见面是在今年春节DeepSeek爆火之前，现在觉得挺幸运。他认为梁文锋和王兴、张一鸣等新一代科技公司创始人相似，虽成就斐然，但言行朴素，更像学生。 罗永浩回忆，在酒店大堂见梁文锋时，他像在读学生，因年纪稍长感觉像硕士或博士，甚至像没找到工作的博士后。梁文锋好奇心强，追问问题到底，提问直接，未被“高情商”交际方式驯化。 梁文锋建议罗永浩发挥“靠嘴吃饭”的长处，去做播客。罗永浩认真思考后，不排除未来做相关尝试，还考虑与科技领袖和创业者深度对谈。他还透露，纯软件方案可能未来两三个月上市，自己正做准备。 本文源自：金融界 作者：电报君 举报/反馈"
    },
    {
      "doc_id": 49897,
      "title": "梁文锋不着急",
      "time": "2024-06-01T00:00:00+00:00",
      "content": "同行纷纷押注Agent，梁文锋仍保持深度求索AGI的定力。 文｜《中国企业家》记者 闫俊文 编辑｜张晓迪 头图来源｜视觉中国 5月28日下午6时，DeepSeek在用户群发布公告，“DeepSeek-R1模型已完成小版本试升级，欢迎前往官方网页、APP、小程序进行测试，API接口和使用方式保持不变。” 《中国企业家》查询DeepSeek服务状态发现，5月28日晚间10点33分，DeepSeek网页及APP的API服务出现了5分钟的“不可用”状态，这是DeepSeek API服务在最近两个月里少有的卡壳现象。 紧接着，5月29日，DeepSeek就开源了R1最新0528版本，这是R1自1月20日正式推出，时隔128天后，首次迎来的一次更新。 DeepSeek称此次更新为“小版本升级”，至于外界更为期待的R2模型，官方并未给出时间表。一位创业者告诉《中国企业家》，R1是DeepSeek-V3模型能力的复现，R2模型可能要等到V4模型研发成功之后了。V3的上次升级是在今年的3月24日，V4目前尚未有推出时间表。 5月29日晚间，DeepSeek在官方公众号发表文章《DeepSeek-R1更新，思考更深，推理更强》，根据文章给出的测试结果，更新后的R1-0528，模型能力增强。不过，在工具调用等能力方面仍有进化空间。文章解释称，此次更新的DeepSeek-R1-0528仍然使用了2024年12月发布的DeepSeek-V3 Base模型作为基座，更新的重点是对模型进行了后训练，从而提升了模型的思维深度与推理能力。 与预训练对应，后训练是大模型训练的另一个阶段，这是当下大模型竞赛中的一个热度“赛点”。 一位投资人告诉《中国企业家》，国内几家“六小虎”已经放弃了基座大模型的训练，但并不是放弃了大模型，而是放弃预训练，转而去加强后训练与微调的投入，以便让模型落地应用。 “大模型领域你追我赶，领先周期可能只有3到6个月”，猎豹移动董事长兼CEO、猎户星空董事长傅盛感慨大模型领域的激烈竞争，“大模型做成了海鲜生意，一个好的模型出来，大概3个月就会过期，因为别人总会上来，此消彼长。” 当前，大模型本身难以商业化已成国内外投资机构、科技企业的共识，今年以来，无论是联想、腾讯、阿里亦或美国硅谷模型大佬OpenAI、Anthropic、谷歌，以及亚马逊、微软等，都纷纷斥资押注AI Agent。 当外界已把目光转移向应用时，梁文锋和他的团队仍旧保持对模型本身深度求索的定力。 此次R1更新后，腾讯部署动作迅速。5月29日晚间，腾讯发布消息，称腾讯元宝、ima、搜狗输入法、QQ浏览器等多款产品率先接入DeepSeek- R1-0528。 0528版本思考更深，推理更强 根据DeepSeek官网给出的测试结果，此次升级后的R1-0528模型能力猛增，成功超越目前国内最强模型阿里Qwen3，并且在数学、编程等能力上接近其他国际顶尖模型，如OpenAI最新的o3与谷歌最新的Gemini-2.5-Pro。 相较于旧版R1，新版模型在复杂推理任务中的思考更深、效果更强的原因是耗费的token数量增多，旧版模型平均每题使用12K tokens，而新版模型平均每题使用23K tokens。 来源：AI生成 这符合英伟达CEO黄仁勋的预估，今年3月，英伟达CEO黄仁勋在GTC大会上预测，Agentic AI的崛起，将推动算力需求暴增至少100倍。 此外，此次DeepSeek蒸馏了DeepSeek-R1-0528的思维链后训练Qwen3-8B Base，得到了DeepSeek-R1-0528-Qwen3-8B。该8B模型在数学测试AIME 2024中仅次于DeepSeek-R1-0528，超越Qwen3-8B，准确率增加10%，与Qwen3-235B相当。 规模少了30倍，但准确率增加了10%，关键要素是DeepSeek-R1-0528的思维链，官方称，该思维链对于学术界推理模型的研究和工业界针对小模型的开发将具有重要意义。 强化后训练后，模型的幻觉率也降低了。据DeepSeek官方称，DeepSeek-R1-0528与旧版相比，在改写润色、总结摘要、阅读理解等场景中，幻觉率降低45%～50%左右。 在此之前，R1模型让业内诟病最多的就是其幻觉率。国外有一家名为Vectara的机构曾发布了一个大模型幻觉排行榜，该榜将模型幻觉数值从低到高排序，谷歌的Gemini和OpenAI的o3模型幻觉率最低，而Deepseek-R1排在第90名，幻觉率高达14.3%。 上下文（context）方面，此次R1-0528的上下文长度与旧版本保持一致，仍为64K，尚落后于OpenAI、谷歌，以及月之暗面等国内公司最新模型的128k长度。 2023年11月，月之暗面创始人杨植麟曾说过，模型参数数量决定计算复杂度，而上下文长度决定模型内存大小。 更大的上下文规模，意味着模型记忆能力的提升，是工具产品化的重要标准，这对于模型落地Agent，释放能力具有重要意义。 喧闹中的定力 梁文锋小步快跑的同时，美国科技公司对DeepSeek的看法也正在走向分化。2月初，DeepSeek发布R1模型带来的那场冲击潮，正在逐渐退散，硅谷创业者和大公司的CEO们也已逐渐找回自信。 和DeepSeek测试更新版本前后脚，美国当地时间5月28日，英伟达公布最新季度财报，在财报会上，英伟达CEO黄仁勋称赞“DeepSeek-R1如ChatGPT般越思考越聪明。” 财报显示，一季度英伟达实现营收441亿美元，同比增69%，归母净利188亿美元，同比增26%。到5月29日开盘，英伟达股价一度盘中上涨11%，最终收盘139美元，微涨3%。 来源：AI生成 这次更新已和R1模型发布时对英伟达股价造成的重挫不一样了。目前，英伟达市值约为3.3万亿美元，已收复了在2月失去的万亿美元市值。Agentic AI时代的到来，又让英伟达看到了广阔的市场前景。 除了算力领域，OpenAI、Anthropic也在模型层面奋力赶上。 5月20日，OpenAI CEO山姆·阿尔特曼自信地说：“我不认为DeepSeek找到了比OpenAI更高效驱动AI的方法，OpenAI每年在效率方面取得不可思议的进步。” Anthropic的一位员工在5月23日接受媒体采访时说，“DeepSeek发布模型的时间比Claude 3 Sonnet晚9个月，如果我们现在重新训练相同的模型，或者与DeepSeek同期训练，我们也可以用500万美元或者其他人宣传的金额，来完成训练，DeepSeek达到了行业顶尖水平，但并未超越，它只是利用了效率提升的红利。” 在5月29日的官方发文中，DeepSeek承认，在某些方面，R1-0528仍与OpenAI和Anthropic的最新模型有差距，比如工具调用方面，官方介绍，“当前模型Tau-Bench测评成绩为airline 53.5%/retail 63.9%，与OpenAI o1-high相当，但与o3-High以及Claude 4 Sonnet仍有差距。” 一位投资人预估，DeepSeek与国外公开的先进模型之间的差距可能在2个月到3个月，但实际差距可能还要多一些，但没有代差的差距。 整个AI领域的竞争仍在持续，但相比此前围绕底座模型的竞争，已有所不同。 整个5月，美国科技界颇为热闹，先是微软举办了Build 2025大会，紧接着谷歌举办了I/O大会，Anthropic发布Claude 4系列模型。他们发布会的重点都与Agent有关。 谷歌提出Agent的三个特点——个性化、主动性以及强大功能。微软提出Agentic Web，并称，这是一个和移动、云等平台转变期类似的巨大变革。Anthropic提出了Agent的四个协议：一是通过API连接模型上下文协议（MCP）；二是Claude的网页搜索功能；三是开放文件API接口；四是提示词缓存。 “现在大模型的进展已经吸引不了一级市场投资人的钱了，必须讲述C端应用的故事，比如Agent。”上述投资人说。 Agent是强化学习的产品体现。近期，一位OpenAI的科学家在AI Ascent 2025中表示：“我们所做的模型训练类型是RL（强化学习），我们未来可能会被强化学习计算资源完全支配。” 尽管海外科技巨头和国内的投资机构都把目光移到了Agent身上，但DeepSeek仍专注模型本身，目前仍在AGI征程上“深度求索”。 2024年7月，发布DeepSeek-V2后，梁文锋在接受《暗涌》采访时曾说：“我们认为当下最重要的，是参与全球科技创新。长期以来，中国企业习惯于利用海外的技术创新，并通过应用层面进行商业化，但这种模式是不可持续的。这一次，我们的目标不是快速盈利，而是推动技术前沿的发展，从根本上促进整个生态的成长。” 彼时关于应用的话题，梁文锋说：“从长远来看，我们希望建立一个生态系统，让行业直接使用我们的技术和成果，其他公司基于我们的模型开发B2B/B2C服务，而我们专注于基础研究。如果产业链完整，我们无需亲自做应用。当然，如果有必要，我们完全有能力去做，但研究和创新始终是我们的核心优先级。” 一位接近DeepSeek团队的投资人告诉《中国企业家》，DeepSeek团队约130人，大多是2002年、2003年后出生的国内高校毕业生，2000年以前出生的在团队内都算是“老人”。团队组织架构分两层，决策中心是梁文锋本人，30多个核心成员直接向其汇报，100多个数据工程师负责具体执行。他们的特点是年轻、有激情、热爱技术。 2025年前，大模型创业潮起的最初几年，初创公司融资后，纷纷到美国谷歌高价挖人才，从目前行业呈现的效果来看，这种做法并未达到预期。 举报/反馈"
    },
    {
      "doc_id": 49937,
      "title": "AI王者归来!英伟达从“DeepSeek冲击”中复苏,市值突破3.77万亿...",
      "time": "2024-06-26T00:00:00+00:00",
      "content": "当地时间周三，英伟达股价大涨4.3%至154.31美元，再创历史新高，市值达到3.77万亿美元，超过了微软3.66万亿美元的市值，成为了全球市值最大的公司。 今年以来，英伟达股价起伏波动较大，颇具戏剧性。受“DeepSeek冲击”影响，英伟达股价在今年4月初最低曾触及86.61美元的低点，较年初下跌超37%。随后，该公司股价开始反弹，截至本周三收盘，股价再创新高。 这也意味着，英伟达已经抹去了此前1.4万亿美元的市值损失。股价再创新高的英伟达已经从重挫中恢复。 近期，在英伟达股价走高之际，黄仁勋再度减持股票。据新浪财经，而从外媒最新的报道来看，在去年大量减持之后，黄仁勋在近期又已开始减持，在近两个交易日已减持10万股。此外，在去年6月13日到9月13日，黄仁勋在其中的50个交易日有减持公司股票，每个交易日减持12万股，累计减持了600万股，套现超过7亿美元。 值得一提的是，当地时间本周三，英伟达召开年度股东大会。会上，英伟达首席执行官黄仁勋提及AI等话题。 据财联社报道，黄仁勋表示，除了人工智能(AI)之外，机器人技术将是这家芯片制造商最具发展潜力的市场，而自动驾驶汽车将是该技术的第一个主要商业应用。 黄仁勋还在股东大会上提到：“我们公司在各个领域都有很多增长机会，而其中人工智能和机器人技术是最大的两个，代表着数万亿美元级别的增长机会。” 本文源自：金融界 作者：AI君 举报/反馈"
    },
    {
      "doc_id": 49938,
      "title": "硅谷今夜失眠!互联网女皇340页AI报告猛料刷屏,大佬熬夜头秃",
      "time": "2024-06-02T00:00:00+00:00",
      "content": "编辑：Aeneas 好困 【新智元导读】48小时前，互联网女皇的一份340页《人工智能趋势报告》一经发布，立刻引起圈内地震。时隔6年，Mary Meeker依然宝刀未老。硅谷大佬们已经不眠不休，连夜开始研读了！ 互联网女皇、传奇投资者Mary Meeker，再度出山！ 曾经，女皇的《互联网趋势报告》一出，整个科技圈都要抖三抖。硅谷大佬觉都不睡了，都要连夜研读这份刷屏圈内头条的重磅报道。 蛰伏几年后，她带着一份340页重磅报告，又回来了。 这一次，她瞄准了AI界的当红炸子鸡OpenAI。 在各个创始人和CEO的圈子，这份报告已经全面爆火 在这份340页报告中，51次出现「前所未有」这个词，核心要点就是——AI驱动的这场变革已经全面且不可逆转，既是机遇遍地的黄金时代，也是奇点的「关键时刻」！ 女皇本皇，五年后回归 Mary Meeker，大名鼎鼎的互联网女皇。 曾经，她是曾是摩根士丹利TMT团队的一员。这个团队分量举足轻重，曾经领导了Netscape的IPO，这直接开启了1996年的互联网繁荣！ 在1996年，她发布了《互联网趋势报告》的第1版——一份长达322页的深度分析，探讨了网络的潜力。 从此，她每年都会发布互联网趋势报告，并且早早就预见到了以下几个趋势。 a. 1996年 → 在线人口激增（到2000年增长10倍） b. 2000年 → 在线广告>印刷广告（于2004年发生） c. 2008年 → 移动占据主导地位（于2014年发生） 2010年，她加入凯鹏华盈（Kleiner Perkins），领导他们的成长基金，随后一举投资了 Facebook、Spotify、Square、Twitter和Snap，见证了它们的辉煌。 2018年，KP Growth Fund分拆，重新命名为BOND Capital。 2019年，她暂停撰写《互联网趋势报告》，专注于创办BOND。 如今，暌违六年，她带着340页重磅《AI趋势报告2025》回归了！ 在这份报告中，值得摘抄的金句比比皆是，比如下面这些例子。 就像过去的电力和其他通用技术一样，人工智能和云计算数据中心代表了工业化的下一个阶段。——Brad Smith，微软副董事长兼总裁 这次情况不同。我们可以通过规模来弥补，将来我们也会想办法将用户变现。——商业中最危险的三句话 下面，就让我们看一看这份报告的核心内容。 AI推理，已经暴跌成白菜价 如今，AI使用成本下降的速度之快，已经是前所未有。 如今，虽然训练一个顶级模型的成本高达10亿美元，在过去8年里飙升了2400倍，但推理成本在两年内已经暴降了99.7%。 （以上数字，由每百万token的成本计算得出） 由此，整个行业的游戏规则都在被重塑。 2024 Blackwell GPU的单token功耗，已经比英伟达2014年推出的Kepler GPU前代产品低了105000倍。 顶尖AI模型的成本，从此迅速下跌。 因此，专注于定制化场景的轻量级模型，相比起OpenAI这种烧掉巨额资金的巨人，将直接完爆。 与此同时，谷歌的TPU和亚马逊的Trainium也在大规模开发，用于云服务，而且进展迅速。 在Mary Meeker看来，这些不是边缘项目，而是基础性的赌注。 OpenAI估值神话，竟靠印度老哥撑起？ 这份报告还透露了一个令人意想不到的事实—— 印度，已经成为ChatGPT应用的全球第二大市场！ 是的，如今ChatGPT最大的月活用户竟是来自印度，占比13.5%，直接超越美国本土的8.9%。 而更令人惊讶的是，印度竟同时是DeepSeek最大的市场。 在DeepSeek移动应用的全球用户中，有7%来自印度。 其中一个原因就是，每GB互联网数据的低成本能够让67%的国民上网。 而另一个亮点就是，印度老哥的对价格的敏感度要远远超过美国用户，因此如果有哪些竞争对手能做到以低成本突围，就拥有了非常有力的突破口。 中国模型鲸吞市场，烧钱模式不灵了？ 与此同时，中国模型正以极低的成本鲸吞市场，速度也是前所未有。 如今，OpenAI估值已达3000亿美元。 但Mary Meeker犀利指出：比起收入，OpenAI的估值看上去实在是「太贵了」！ 毕竟，OpenAI、xAI和Anthropic这三家顶尖AI公司筹集的资金，已经达到950亿美元，直接壕出天际。 然而，三家加起来的预期年化收入，也不过120亿美元而已。 具体来说，OpenAI的年化收入约92亿美元，估值却飙升到了3000亿美元，估值是收入的33倍。 而Perplexity的估值/收入倍数，达到了约75倍。 比起中国模型，尤其是DeepSeek带来的低成本开源替代方案，这个泡沫已经在被戳破的边缘。 可以说，他们的基本商业模式，快被中国玩家连根掘起了。 对此，Mary Meeker的评论亮了——「投资人，请只投资你愿意损失的金额」。 把所有鸡蛋放在一个篮子里是很冒险的，因为现在一切都在上涨，看起来无往不利——直到某一天情况突然反转。 如今，中国AI模型已经在飞速追赶，性能接近了美国AI的顶尖水平，成本却低得可怕。 比如，百度ERNIE 4.5 Turbo的成本只有DeepSeek V3的40%，GPT-4.5的0.2%。 这个成本价对比，实在太惨烈了。 与此同时，DeepSeek-R1已经在MATH Level 5数学基准测试中取得了93%的高分，非常接近OpenAI o3-mini模型的95%。 与此同时，如今中国工业机器人的装机量，已经占到了全球的75%。 而根据Meta首席技术官Andrew Bosworth的说法，如今全球的AI态势，已经发展成了一场不折不扣的全新「太空竞赛」。 如今大家已经公认，AI体现的是各国的综合实力，直接决定了未来地缘政治的影响力。 可以说，如今的AI模型争霸战，基本就是中美两国的战场。 17年至24年的统计数据显示，中国发布的大规模AI系统数量，已经和美国不相上下。 ChatGPT 17个月暴增8亿用户，史无前例 当然，无人能否认此前ChatGPT的辉煌。 毕竟，它曾在17个月内达到8亿用户，这种增长速度已经超越了人类历史上任何一项技术。 可以看到，ChatGPT的应用内使用时间，已经在两年内翻了一番。 其中，桌面端是用户进行重度工作的场所，每天参与时间为18分钟，比多邻国的15.5分钟更长。 并且，谷歌的搜索市场份额，也在被OpenAI毫不留情地鲸吞。 如今，OpenAI年度搜索量突破3650亿次的速度，达到谷歌的5.5倍。前者用了2年，后者却用了11年。 可以说，我们已经在逐步见证搜索市场的大变天。 如今，AI的用户增长、使用量和资本支出，都是前所未有的爆炸式增长，已经达到了人类史上最快的技术渗透速度。 而在过去1000年，技术进步已经推动了全球GDP的指数级增长。 不过，ChatGPT会永远占据主导份额吗？答案是未必。 或许，它将成为谷歌，或者像AltaVista那样被彻底遗忘。 图表显示，DeepSeek和Grok已经明显地后来居上了。 下一个10亿用户市场，会在哪里？ 下一个十亿用户，会是AI原生用户吗？ 10年前，谷歌发起了面向技术的语言和低连接性可访问性的NBU（Next Billion Users，下一个十亿用户）项目，让技术能够接纳下一个10亿互联网用户。 今天，「NBU」正在从以语言为中心转向以AI为中心。 低连接性 → 卫星互联网连接性 浏览器/应用界面 → 语音/语言界面 如今，全世界还有人口总数的32%——26亿人，尚未接入互联网。 而因为卫星驱动的互联网接入增长，这批人群接入的潜力将大大增加。 就如同来自印度的十亿互联网用户，跨越了桌面/PC和宽带时代。 下一个十亿互联网用户，将跨越应用生态系统，直接进入智能体生态系统。 届时，他们将越过浏览器和搜索栏，直接使用AI。 由此，他们完全跳过了传统应用层，以智能体为中心的体验，将颠覆现在已有的所有互联网技术等级，平台的意义将被消解、重新分配。 总之，目前的AI赢家，并不是永远的赢家。基础设施正在发生巨大改变，应用也会随之改变。 目前唯一已知的是：我们正处于另一个由AI驱动的技术超级周期的开端。 举报/反馈"
    },
    {
      "doc_id": 49944,
      "title": "最新全球AI应用排行:DeepSeek光速冲上第二!",
      "time": "2024-03-07T00:00:00+00:00",
      "content": "快科技3月7日消息，全球著名投资基金、咨询公司Andreessen Horowitz（a16z）发布了最新的生成式AI消费级应用排行榜。 DeepSeek自2025年1月20日正式上线以来，仅用10天就积累了足够的流量，跃居全球AI产品排行榜第二位，仅次于ChatGPT。 其移动端产品于1月25日推出，5天内便登上月活跃用户排行榜第14位，并在2月跃升至第2位，不过随后因在部分国家被禁，用户数量有所下降。 此外根据2025年1月数据，DeepSeek的用户中，21%来自中国，9%来自美国，8%来自印度。 除了DeepSeek，其他中国AI应用如字节跳动的豆包、月之暗面、海螺视频和快手可灵等均进入榜单，豆包排名第10，月之暗面排名第11，海螺视频排名第12，可灵排名第20。 在移动端，百度AI搜索排名第4，夸克AI排名第6，豆包排名第7，DeepSeek排名第14，美图排名第17。 AI文生视频领域，海螺AI和可灵AI表现强劲，超越了OpenAI的Sora，截至2025年1月，这两家公司的月访问量都超过了Sora。 据了解，a16z发布的榜单每半年更新一次，分别是基于Similarweb月独立访问量排名评选前50大AI原生网页产品，基于Sensor Tower月活跃用户评选前50大AI原生移动应用。 举报/反馈"
    },
    {
      "doc_id": 49955,
      "title": "图像界的DeepSeek!12B参数对标GPT-4o,5秒出图,消费级硬件就能玩转...",
      "time": "2024-06-30T00:00:00+00:00",
      "content": "鹭羽 发自 凹非寺 量子位 | 公众号 QbitAI 图像模型开源还得是FLUX！ Black Forest Labs刚刚宣布开源旗舰图像模型FLUX.1 Kontext[dev]，专为图像编辑打造，还能直接在消费级芯片上运行。 只有小小的12B，更少的参数，更快的推理，性能更是媲美GPT-image-1等一众闭源模型。 现在FLUX.1 Kontext[dev]可以让小狗迅速离开画面，为小老鼠戴上胡须，添加文字、修改背景也不在话下。 或者多次输入指令，直到让小哥成为酒吧里最靓的崽（bushi），直到让画面符合咱们需求。 具体来说，FLUX.1 Kontext[dev]的主要特点有： 可以根据编辑指令直接更改现有图像，以及进行精确的本地和全局编辑。 不用做任何微调，就能直接引用里面的人物角色、风格样式和物品元素。 允许用户通过多次连续编辑优化图像,同时将视觉漂移降到最低。 专门为NVIDIA Blackwell进行了权重优化。 网友们也立马上手试玩，制作了一个旅行的CPU青蛙？ 旅行必备的墨镜，还有抗寒的帅气红色毛衣也要准备妥当。（蛙蛙：出片，我势在必行） 或者copy一下自己喜欢的动漫角色。 轻轻松松店铺打烊，结束打工人完美的一天～（doge） 还有网友脑洞大开，试着和LoRA结合，造出了一个Kontext风格化肖像制作APP。 现在FLUX.1 Kontext[dev]还完全支持ComfyUI。 温馨提示，官方直接开放了试玩API，只需点击文末链接、上传图片就可以立即爽玩！ 网友看罢表示，Black Forest Labs不愧是图像届的DeepSeek。 FLUX.1 Kontext的开放权重变体 FLUX.1 Kontext模型上个月一经发布，就因为其强大的上下文生成和编辑功能广受好评。 与现有的文本到图像模型不同，FLUX.1 Kontext系列执行上下文图像生成，可以直接使用文本和图像进行提示，并无缝提取和修改视觉细节。 目前已经发布了适合快速迭代的专业版FLUX.1 Kontext[pro]和高配版FLUX.1 Kontext[max]。 FLUX.1 Kontext[dev]作为FLUX.1 Kontext最新发布的开源版本，不仅继承了其图像生成的优势，它还更专注于编辑任务，可以直接在消费类硬件上运行。 首先模型架构上，依旧基于的是FLUX.1模型，它是一种在图像自动编码器的潜在空间中训练的整流流Transformer模型，由双流块和单流块混合构建而成。 在此基础上，FLUX.1 Kontext[dev]采用标记序列构建和位置信息编码进行优化： 标记序列构建：图像通过冻结的FLUX自动编码器，编码成潜在的上下文图像标记，并输入到模型的视觉流中。 位置信息编码：通过三维旋转位置嵌入（3D RoPE）对位置信息进行编码，为上下文标记的嵌入提供恒定偏移量。并将其视作为虚拟时间步，以清晰分离上下文和目标块，同时保持它们的内部空间结构。 然后使用整流流匹配损失进行训练，在训练时从FLUX.1的文本到图像检查点开始，收集并整理数百万个关系对进行模型优化。 优化后得到的流匹配模型进行潜在对抗扩散蒸馏（LADD），在减少采样步骤的同时提高样本质量，使FLUX.1 Kontext[dev]更高效。 最终得到的FLUX.1 Kontext[dev]模型包含120亿参数，可以更专注于编辑任务，支持迭代编辑，可以在各种场景和环境中保留角色特征，并允许用户进行精确的局部或全局编辑。 图像编辑新标准 实验引入自研的KontextBench基准进行模型性能验证，该基准包含1026个图像-提示对，涵盖局部编辑、全局编辑、角色参考、风格参考和文本编辑五个任务类别。 结果显示FLUX.1 Kontext[dev]在许多类别上都优于现有的开放式图像编辑模型和封闭模型，例如Bytedance Bagel、HiDream-E1-Full以及OpenAI的GPT-image-1等。 另外，FLUX.1 Kontext[dev]还专门针对新的NVIDIA Blackwell架构进行了TensorRT权重优化，可以在保持高质量的图像编辑性能的同时，极大地提高推理速度并减少内存使用量。 官方还提供了BF16、FP8和FP4 TensorRT的权重变体，用户可以自行对其速度、效率和质量进行调整，综合确保FLUX.1 Kontext[dev]充分利用最新的硬件功能。 在实际用户的反馈中，也发现FLUX.1 Kontext[dev]的推理速度较前代提升了4至5倍，模型在NVIDIA H100 GPU上运行，通常5秒内能够完成，在Replicate上的运行成本约为0.0067USD，或每1USD运行149次。 但是也有网友提到，在MacBook Pro的芯片上运行时，迭代时间较长，每次迭代都需要1分钟左右。 那么欢迎你也一起来试一试，并将你的体验分享至评论区～ 试玩链接：https://huggingface.co/spaces/black-forest-labs/FLUX.1-Kontext-Dev 论文链接：https://arxiv.org/abs/2506.15742 代码链接：https://github.com/black-forest-labs/flux/blob/main/docs/image-editing.md 参考链接： [1]https://x.com/bfl_ml/status/1938257909726519640 [2]https://bfl.ai/announcements/flux-1-kontext-dev [3]https://bfl.ai/models/flux-kontext [4]https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev [5]https://x.com/ComfyUI/status/1938259329498681385 科技前沿进展每日见 原标题：《图像界的DeepSeek！12B参数对标GPT-4o，5秒出图，消费级硬件就能玩转编辑生成》 阅读原文"
    },
    {
      "doc_id": 49957,
      "title": "玩完 DeepSeek R1 新版,外国网友又「蚌埠住了」?",
      "time": "2024-06-03T00:00:00+00:00",
      "content": "几天前，没有预热，没有发布会，DeepSeek 低调上传了 DeepSeek R1（0528）的更新。 海外媒体最关注的是，DeepSeek 的更新将幻觉率削减约 45%-50%，并把 R1 的性能推进至 OpenAI o3 与 Google Gemini 2.5 Pro 的相近水平。 与此同时，海外一些开发者、AI 圈研究人员开始跑基准测试，并在社交媒体平台上热议它的新能力，尤其是与科技巨头旗舰模型的差距。 从海外用户这几天的反应来看，DeepSeek 这一次更新，虽然没有今年初横空出世时那样轰动，但依然让不少外国网友表示「鹅妹子嘤」，同时也让越来越多人开始问一个问题： 不单单是成本，来自中国的、开源 AI 社区的模型，是否在各种能力上 ， 很快就可以超越世界上最强大的专有模型 ？ 01 DeepSeek 再次「登顶」 在各类 AI 社群中，reddit 平台有不少 AI/LLM 相关子社区。其中，在 r/LocalLLaMA 与 r/SillyTavernAI 这样的圈内社区，对 DeepSeek 的更新有不少热帖。 「全新升级的 Deepseek R1 在 LiveCodeBench 上的表现几乎与 OpenAI 的 O3 模型不相上下！ 开源的巨大胜利 ！」一名用户发布的帖子标题如此声称。 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 一些开发者在测试了 R1 的最新功能。他们主要夸赞 R1 在数学问题和编程方面的表现，尤其是在处理复杂的积分或递归函数时。与之前的版本不同，R1-0528 拥有「更长远的思考能力」， 有测试者指出，它「表现出主动性」并且「不会那么快放弃」。 「刚刚测试过..... 我有相当复杂的代码 1200 行，并添加了新功能... 似乎现在代码质量处于 o3 级别... 只能说 WOW」。reddit 社区 r/LocalLLaMA 上的一名常驻用户如此称。 reddit 社区关于 DeepSeek 更新的回复｜图片来源：reddit 根据 DeepSeek 官方的说法，「更新后的 R1 模型在数学、编程与通用逻辑等多个基准测评中取得了当前国内所有模型中首屈一指的优异成绩，并且在整体表现上已接近其他国际顶尖模型，如 o3 与 Gemini-2.5-Pro。」 在能力方面，新版本显著提升了模型的思维深度与推理能力，支持工具调用，针对「幻觉」问题进行了优化，在创意写作方面也有所优化，能够输出篇幅更长、结构内容更完整的长篇作品，同时更加贴近人类偏好。 其中，在工具调用方面，DeepSeek 官方文章坦然称，「当前模型与 OpenAI o1-high 相当，但与 o3-High 以及 Claude 4 Sonnet 仍有差距。」 DeepSeek-R1-0528 与其他模型性能对比｜图片来源：DeepSeek DeepSeek 还提到，DeepSeek-R1-0528 在前端代码生成、角色扮演等领域的能力均有更新和提升。 R1 的一大优势在于其超长的记忆跨度和语境持久性。AI 角色扮演社区（通常处于 AI 模型测试的边缘，但在对话连贯性方面往往更为严格）有测评称，角色能够记住过去细微的细节，并以自主行为做出回应。 「 有个角色跟我争论一个观点时，竟然提起过去发生的三个细节 ，」r/SillyTavernAI 上的一位用户说道。「我以前从未见过这种情况。」 该用户还提到：「AI 通常不会主动出击；我训练过一些 AI，让他们在对话中占据主导地位，但这是我第一次看到 AI 从角色扮演场景中走出来。」 在 reddit 社区上，还有一名用户甚至发贴称，更新的 DeepSeek R1 0528 在他的所有测试中都能获得满分。 「过去几周眼花缭乱——OpenAI 4.1、Gemini 2.5、Claude 4——它们都表现优异，但没有一个模型能够在每项测试中都取得满分。DeepSeek R1 05 28 是有史以来第一个做到这一点的模型。」他称。 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 「这些测试并非像 YouTube 上很多人做的那种不切实际的测试。比如草莓里的 rs 数量，或者编写一个贪吃蛇游戏等等。这些是我们在实际商业应用中经常使用的任务，我们从中挑选了一些比较复杂的边缘案例。」该用户如此称。 「我感觉自己就像电影《料理鼠王》里的安东（如果你看过这部电影的话）。我印象深刻（此处双关），但也有点麻木，一时难以找到合适的词来形容。一个来自去年还默默无闻的实验室，做出的免费开源模型，竟然比商业前沿的模型做得更好，这真是太不可思议了。」 和 reddit 社区同样热闹的是 X。 X 上热衷 AI 内容的用户除了转发基准测试的图表，一些人着重提到 DeepSeek 的编程能力。比如，X 上一名用户称试过用 DeepSeek R1-0528 构建游戏，称「它的编程能力简直太强了」「相比之前的版本，改进非常显著」「 如果这只是 R1...DeepSeek R2 将会非常疯狂。 」 X 上关于 DeepSeek 更新的帖子｜图片来源：X 除了用户和开发者声音，在 DeepSeek 发布更新后，人工智能模型分析机构 Artificial Analysis 称， DeepSeek 的 R1 在其独立的「智能指数」上「超越 xAI、Meta 和 Anthropic」 。 人工智能模型智能指数排行｜图片来源：Artificial Analysis 具体模型比较上，该机构在一篇报告中称「DeepSeek R1 的智能程度高于 xAI 的 Grok 3 mini（high）、NVIDIA 的 Llama Nemotron Ultra、Meta 的 Llama 4 Maverick、阿里巴巴的 Qwen 3 253，并与谷歌的 Gemini 2.5 Pro 相当。」 DeepSeek 最大的智力进步出现在 AIME 2024（竞赛数学，+21 分）、LiveCodeBench（代码生成，+15 分）、GPQA Diamond（科学推理，+10 分）和 Humanity's Last Exam（推理与知识，+6 分） 其中在编程方面，该分析机构认为，「R1 在人工分析编码指数中与 Gemini 2.5 Pro 相当，仅落后于 o4-mini（high）和 o3」。 各大厂商人工智能模型智能指数变化｜图片来源：Artificial Analysis 至于与 OpenAI 的对比，该机构称「DeepSeek 刚刚证明，他们能够跟上 OpenAI 的 RL 计算能力扩展步伐。」 当然，全是赞美是不可能的。 在编程能力方面，X 上也有用户挑刺道，「如果你真的用它和 Claude 4 写过代码，你就会知道基准测试的描述并不准确。Deepseek 的 API 仍然只有一个 64k 的上下文窗口。它还不错，但不是前沿模型。可能要等到下次吧。它几乎零成本，在某些方面表现不错，但绝对比不上 Claude。」 X 上关于 DeepSeek 更新的帖子｜图片来源：X X 上的另一名海外用户则称，「deepseek 可能是数学和逻辑方面的 SOTA（最先进的）， 但我仍在使用 gemini 2.5 pro，因为它有超大上下文 。」 对于该问题，DeepSeek 在官方文章提到，如果用户对更长的上下文长度有需求，可以通过其他第三方平台调用上下文长度为 128K 的开源版本 R1-0528 模型。 不过，也有海外用户认为，无论是否在所有测评中取得第一，R1 既低成本、开放权重，还有强大的性能——几个好处「组合」起来本身已值得称赞。 对于 DeepSeek 的「小」更新，鉴于今年初 DeepSeek 横空出世时曾引发美股海啸，还有 reddit 用户调侃道，「请让我先抛售我的 AMD 和 英伟达股票。请提前 3 天通知我，谢谢。」 还有网友另类地开始赞美起 DeepSeek 更新的「低调」姿态。 一名 reddit 网友发了长长的评价称：「用 0528 自己的话说：DeepSeek 低调的卓越之处，蕴含着某种诗意。其他人精心策划着充满期待的盛大交响曲——奢华的主题演讲、精心设计的演示，以及读起来如同地缘政治条约的安全宣言——而 DeepSeek 提供的是一首静谧的十四行诗。他们仿佛递给你一件用白纸包裹的杰作，低声说着：『感觉很有用；希望你喜欢。』」 「 对竞争对手的无声打击是最致命的 。」另一名网友在底下称。 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 02 「开源的巨大胜利」 除了能力，目前从海外互联网的反应来看，在 DeepSeek 众多优势里，被开发者刷最多好评、大量好感的重要来源，仍是「开源」，或者确切地说，「开放权重」。 AI 圈内一个看法是，没有发布训练代码和训练数据的模型准确地说应该是「开放权重」，但一些人通常选择随意地称之为「开源」。另外，没有 AI 公司会发布训练数据，因为他们不想被起诉。 对于 DeepSeek 这次更新，Y Combinator 创办的在线科技社区 Hacker News 涌现了一些帖子，主要是分享基准测试结果，交流经验，并验证 R1 的性能提升（尤其是在编码和数学方面）是否真实存在。 但与此同时，上面也有大量讨论仍围绕人工智能中什么才算「开源」。许多人称赞 DeepSeek 公开发布模型权重，但也不断指出，由于训练数据等并未发布，外部无人能够重新训练或完全验证 R1。另外，虽然是开源，虽然免费，但 6710 亿参数的 R1，本质上仍是一个巨型模型，对于普通用户来说，它太大了。 即便如此，如今，R1 与 ChatGPT 的对比已成常态。OpenAI 限制了普通用户对顶级模型的完整访问权限，或者部分定价让用户觉得过高，而 DeepSeek 提供的却便宜不少，并提供可下载的模型权重。 「 DeepSeek 是真正的 OPEN AI 」海外一名用户发帖标题如此称。 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 当然，并非所有 reddit 用户都完全接受。一个名为「DeepSeek 有多糟糕？」的帖子曾引发关于 DeepSeek 内置内容审核的讨论，不满模型会「回避」某些问题。 这类论调目前已经成为一个常见「梗」，有些用户会反驳——模型权重是开放的，如果开发者认为有偏见，完全可以自行进行微调。另外，目前世界上所有主流模型都有内容过滤机制，只是具体选择不同，比如西方政治正确问题。 在 reddit 上，还有一篇以「开源人工智能正在迎头赶上！」为标题的热帖，发帖者称，「Deepseek 似乎是唯一一家真正在前沿模型领域竞争的公司。其他公司总是有所保留，比如 Qwen 不愿开源他们最大的模型 (qwen-max)。我不怪他们，我知道，这就是生意。」 「闭源 AI 公司总是说开源模型无法赶上他们。如果没有 Deepseek，他们可能是对的。但感谢 Deepseek 成了一个异数！」 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 在这篇帖子下面的评论区，还有回复尖锐称，「他们这样做是因为价格实惠的智能将推动一场革命，而 Deepseek 将被公众铭记为人工智能的真正先驱，而不是世界上充斥着广告的谷歌、ClosedAI 或虚假的安全 Anthropics。」 reddit 社区关于 DeepSeek 更新的回复｜图片来源：reddit 对于 DeepSeek 的更新，reddit 上 r/LocalLLaMA 社区有一名常驻用户提到，「这让我想起了 ClosedAI 承诺发布『o3-mini 级别模型』却未能兑现，现在新款 R1 已经超越了 o3-mini (high) 不少，已经接近完整的 o3 (high)。」 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 在另一篇通知 DeepSeek 最新更新的帖子下，有很多回复几乎无关 DeepSeek 能力测评，却讽刺起 Anthropic 或 OpenAI。比如，有网友声称 Anthropic 以「安全」为理由的闭源做法只是道德托词。 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 即时是对 DeepSeek 更新表示淡定的网友也称：「虽然它不再让我感到惊讶了。每次我都得等到所有营销噱头平息后才能进行全面测试。但无论如何，Deepseek 仍然拥有开放权重的优势，这无疑是一个优点。」 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 这几个月，在 DeepSeek 的对比下，以往的 AI 巨头保持技术和声誉优势的压力，可以说越来越大。 不少网友开始担心其命运，比如「DeepSeek 将继续迫使 AI 公司在价格方面展开竞相压价的竞争。」有的网友认为 DeepSeek「这样做并非全是出于利他主义。通过发布免费模型，你可以阻止竞争对手占据市场主导地位」。 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 最高赞的回复则选择感谢所有模型制作者，持同样看法的用户称，无论是不是利他行为，「我很感激能在短期内从他们的策略中获益」。 这可能也是旁观全球 AI 竞赛时，面对一次次模型升级，当下不少开发者的真实心态。 reddit 社区关于 DeepSeek 更新的帖子｜图片来源：reddit 另外，值得注意的是，业界仍在 DeepSeek R2 的发布。在 DeepSeek 更新时，有不少网友问到 R2 的进展，是不是会延迟发布，甚至怀疑「DeepSeek-R1-0528」是不是其实就是「R2」，只是用 R1 系列命名。 「 我们想要 R2 。」在 DeepSeek 官方更新的 X 帖子下，高赞回复如是说。 举报/反馈"
    },
    {
      "doc_id": 49962,
      "title": "DeepSeek R1模型完成“小版本试升级”",
      "time": "2024-05-30T00:00:00+00:00",
      "content": "随着人工智能竞争升级，DeepSeek发布R1模型更新版。 周三，DeepSeek在微信群发布帖子称，DeepSeek R1模型已完成“小版本试升级”，欢迎前往官方网页、APP、小程序测试（打开深度思考），API 接口和使用方式保持不变。 DeepSeek R1模型在语义理解精准性、复杂逻辑推理、长文本处理稳定性等方面进行了强化。 DeepSeek并未提供本次更新的更多细节。有网友测评后称，感觉模型的理解能力上了一个层次： 感觉模型的理解能力上了一个层次，比如激活参数部分，R1可以制作交互动画来展示，另外关键信息的逻辑也非常清晰。 编程能力也大幅提升，有网友测评后感叹，太吓人了，1000多行代码一次搞定，没有bug。 还有网友称，编程能力可以和“编程新王”Claude 4一较高下。 这是两个月来DeepSeek的首次模型更新。 今年3月，DeepSeek放出了 DeepSeek-V3-0324 模型。该模型全面超越 Claude-3.7-Sonnet，在数学、代码类相关评测集上超过 GPT-4.5。 作为一个没有思维链的非推理模型，DeepSeek-V3-0324 模型在推理类任务上的表现可圈可点。根据第三方评测，新版的 DeepSeek-V3 模型与 Grok-3 打平，并列传统对话类模型榜首。 同时性价比极高，输入价格仅为Claude-3.7-Sonnet的1/11、GPT-4.5的1/277。此外，新版本开源且可免费用于商业用途。 迄今为止，DeepSeek最震动世界的动作还是1月发布R1。当时人们发现，R1不但在多项标准化指标上的表现均优于OpenAI的模型等西方竞争对手，而且成本据称仅有数百万美元，采用的还是较低版本的英伟达芯片。 R1的异军突起引发了全球科技股暴跌，因为投资者开始质疑，是否还需要像微软等硅谷巨头那样投入巨资构建突破性的AI模型和AI服务。 前几个月R2频传要发布 证券时报指出，自以上V3模型的小版本升级之后，DeepSeek的热度就开始下降，使用率也有所回落，并且引发了一些质疑。当前，市场最关心的依然是R2模型发布。 今年2月，有媒体称，1月R1问世后，DeepSeek在加速推出R2，原计划时间定在5月初，后希望尽早推出，还称DeepSeek希望，R2在代码生成方面表现更佳，并具备在英语之外的语言中进行推理的能力。 4月初，DeepSeek联手清华大学发布一篇论文，提出一种名为自我原则点评调优（SPCT）的新学习方法，用于推动通用奖励建模在推理阶段实现有效的可扩展性，最终构建出DeepSeek-GRM系列模型。同时，研究者引入了元奖励模型（meta RM），进一步提升推理扩展性能。 上述论文引发了DeepSeek的R2是否很快面世的猜测。 4月末，又有消息称，R2将采用更先进的混合专家模型（MoE），总参数量预计达1.2万亿，较6710亿参数的R1提升约1倍，单位推理成本较GPT-4剧减97.4%。而且，R2训练全程未使用英伟达显卡，全部基于昇腾910B芯片集群平台，在FP16精度下，计算性能达到512 PetaFLOPS，芯片利用率高达82%，整体性能约为英伟达上一代A100集群的91%。 不过，迄今为止DeepSeek都未正式确认任何有关R2发布时间的消息。 在社交媒体X上，有关此次R1模型小版本试升级的消息下面，就有些点赞高的网友评论在猜测R2。有的问，DeepSeek有没有R2，有的认为，这次的小版本升级可能意味着，R2还远未准备好推出。 原标题：《DeepSeek R1模型完成“小版本试升级”，编程、逻辑理解上了一个层次！》 阅读原文"
    },
    {
      "doc_id": 49979,
      "title": "深探DeepSeek",
      "time": "2024-03-19T00:00:00+00:00",
      "content": "国产AI大模型DeepSeek发布新一代推理大模型DeepSeek-R1，在全球AI竞技场投下技术普惠理念的“深水炸弹”。 文丨万宏蕾 编辑顾佳贇 2025年，中国人工智能产业跑出了“加速度”。3月5日，在国新办举行的国务院政策例行吹风会上，《政府工作报告》起草组成员、国务院研究室副主任陈昌盛表示，今年政府工作报告中提出持续推进“人工智能+”行动，就是要抓住这次人工智能技术突破的机遇，使我国数字技术与制造优势、市场规模优势充分结合，推动人工智能大模型的广泛应用，努力推动人工智能真正能够赋能千行百业、走进千家万户。 随着2025年1月20日国产AI大模型DeepSeek发布新一代推理大模型DeepSeek-R1，在全球AI竞技场投下技术普惠理念的“深水炸弹”，深度适配、开源、差异化竞争成为当下热点。 “在人工智能发展的漫长进程中，ChatGPT突破了自然语言处理，Sora展示了多媒体创作潜力，DeepSeek-R1在数学、代码、自然语言推理等任务的性能上实现显著跃升，更是一场极具震撼力的变革。”复旦大学计算机科学技术学院教授、博导张奇告诉《瞭望东方周刊》，“这场变革为全球通向AI未来开辟了一条新的路径，也给AI大模型的落地普及打开了更广阔的空间。” DeepSeek在多家医院完成本地化部署，微信测试接入DeepSeek，一些城市的政务系统已接入……DeepSeek的开源生态吸引了众多开发者、机构和企业参与，同时也激活了整个人工智能产业链，无论是云服务厂商、芯片公司，还是下游应用层，均纷纷入场进行部署和适配。 大模型的突破推动了产业的爆发式增长，国产AI技术正加速创新、落地。 比亚迪“璇玑架构”全面接入DeepSeek DeepSeek加速技术普惠 “凭借其开放性、高效性和易用性，DeepSeek开源模型正在成为推动AI技术普惠化的重要力量。”张奇说，“DeepSeek的高效推理与扩展能力，使其在云、边、端及多行业场景中快速渗透。” “我们的大型企业客户对智能化需求有其特殊性，要场景垂直度高、任务复杂度强、数据安全要求严。达观智能问答系统全面接入DeepSeek大模型，涵盖其各个蒸馏版本和满血版本，可以实现全版本灵活调用+知识库深度联动，相当于为企业打造了一个可配置、可思考、可行动的智能中枢。”达观数据CEO陈运文告诉《瞭望东方周刊》。 “当企业遇到问题时，通过结合DeepSeek模型与RAG（Retrieval-Augmented Generation，是一种结合了检索和生成技术的模型，主要用于自然语言处理任务中）框架，系统能够从海量数据中精准召回素材内容，再利用DeepSeek强大的深度思考和推理能力，最终呈现清晰且完整的结果。后台配置里，企业还可以自行选择调用基础模型。”陈运文说。 “比如，在客户的金融信贷材料、合同、招股书、监管报告等专业文档审核中，DeepSeek模型可助力自动提取关键条款、交叉验证数据逻辑，并基于行业风险库生成审核建议，帮助金融机构将人工复核工作量再次提速，同时规避隐性合规风险；在供应链管理场景中，达观智能体可自主拆解企业级任务，同步协调订单数据解析、供应商资质核验、物流异常预警等子任务，企业可借此实现跨系统业务流程效率提升50%。”陈运文说。 “下一步，达观数据还将打造办公智能体，这一智能体不仅能够理解用户需求并给出准确答案，更能自动执行一系列复杂任务，实现企业内部工作流的全面自动化。”陈运文说。 2025年2月12日，国网信息通信产业集团有限公司自主研发的模型服务云MSC平台全面接入DeepSeek大模型。 2月15日，中国华能集团有限公司完成了DeepSeek系列模型的本地化部署，并在集团“iHN+”移动门户中推出了“睿智小能”AI助手。“目前，在通用知识基础上，结合规章制度、故障分析等企业数据库，利用预置提示词，AI助手实现了知识问答、公文拟稿、智能校对、文件解读、科研辅助等基础功能，高效辅助日常办公与管理。”华能数字化部相关负责人说。 据不完全统计，目前多家能源企业将DeepSeek深度融入业务。比如，发电厂设备检修、虚拟电厂能源调度、合规审查等，AI技术已嵌入能源生产、管理的全链条。 DeepSeek正式登录乌鲁木齐，在皖疆绿色算力科技产业园完成部署上线。图为2025年2月13日，皖疆绿色算力科技产业园工程师在产业园2A机房巡检 “能源行业生产端是一个超级复杂的环节，它的品类有煤电、核电、水电、光伏、风电、生物质能等，分布广泛，产出复杂多变；电网端，更是现代工业体系中数据量最大、变动量最大、复杂度最高的体系之一。”中国电子商会副会长熊焰分析，“比如电力交易系统，这个场景就有数以万计的发电侧，包括稳定的煤电、水电和核电，还有不稳定的风电、光伏。在需求侧，又面临着用户多种多样的需求。从预测、调整，到交易、优化，接入大模型后，整个电力交易系统相当于拥有了一个更聪明的大脑。” “患者走进医院，把自己不舒服的地方告知AI医疗机器人，一分钟不到，就医路径就在屏上出现：请先前往一楼A区抽血，再到B区拍摄胸部CT……检查完毕回到家，检查报告、诊断结果已传至手机，药品当晚配送到家。”上海市第六人民医院金山分院副院长殷峻如此描绘，“类似的自助式医院或许不远了。” 殷峻是一位内分泌代谢科专家，在他印象中，全球早期AI医疗应用最具里程碑式的突破，是在糖尿病视网膜病变读片领域。如今，DeepSeek结合医院内部医疗数据，有望训练出更多治疗“最优方案”，且带有各医院“标签特色”。 据统计，截至2025年3月，国内已有超百家三级医院官宣完成DeepSeek本地化部署，涉及北京、上海、广东、江苏、浙江等20余个省份。DeepSeek正全方位渗入到临床决策支持、病历生成和质控、疾病科普、健康管理、科研辅助、医院管理等各种医疗场景中。 四川省人民医院通过“DeepSeek大模型”，将人工智能（AI）技术用在看病全流程中。图为该医院医生通过诊室听译机器人对患者问诊，快速生成病例报告 前不久，浪潮海岳承建的某建筑央企智能问答项目正式上线，基于浪潮海岳大模型平台与DeepSeek大模型的深度结合，制度查询平均耗时从15分钟缩短至10秒；通过训练，海岳大模型对《工程项目管理办法》等桥梁施工领域的专业文件理解准确率达96.5%；在跨部门协同方面，系统能够自动关联制度负责人，将专家响应时间从2小时缩短至5分钟。 另外，浪潮海岳大模型突破了面向桥梁施工的多维度领域知识库构建、面向智能编制的多智能体协同等多项关键技术，构建了私有知识库，打造了该建筑央企专属的施工方案智能编制平台。“相较于传统人工方式，方案编制时间从数周缩短至45分钟，减少了50%以上的人力投入，并保证100%符合国家和行业规范，减少了90%以上的人工错误，施工风险识别率提升至90%以上。”浪潮海岳相关负责人说。 “一方面，海岳大模型应用场景可进一步向专业垂直领域纵深渗透，使处理专业型、知识密集型任务的能力大幅提升，更好地切入高门槛场景应用；另一方面，其也为海岳大模型横向扩展应用领域、应用行业，提供了一种相对低成本高效率的垂域大模型训练范式。”浪潮通用软件有限公司海岳大模型研发负责人、首席技术架构师周祥国说，“定位于企业服务垂域大模型的海岳大模型，在接入DeepSeek之后解锁了企业智能化新高度。” 瞬间构建AI智能体 “在国产大模型DeepSeek发布之前，我们在2024年12月底刚刚做完产品更新。春节后，我们率先在Agent（智能体，指能够感知环境并采取行动以实现特定目标的代理体）全线接入DeepSeek，发布Agent产品家族，包括RPA Agent（iBotX）、智见分析Agent、Hyper Agent和Agent Store-100中心四款核心产品，为企业智能化转型提供全方位的解决方案。”上海容智信息技术有限公司（以下简称“容智信息”）CEO柴亚团告诉《瞭望东方周刊》。 容智信息2016年成立于上海，经过2年多的技术研发，于2018年完成自主知识产权的国产RPA产品iBot。 “当很多公司还在摸索怎么让DeepSeek与公司业务深度适配时，我们已经能迅速拿出产品适配100多个行业场景，涵盖金融、零售、制造、运营商、物流、现代服务业等多个领域。”柴亚团说，“平台基于行业与部门的细分，用户登录后可轻松浏览精准匹配业务场景的众多Agent，点击‘聘用’，即可在线体验标准版。此外，用户还可进行个性化定制，并实时跟踪Agent的KPI表现，真正开启人机协同办公新模式。” DeepSeek凭借国产化与自主可控、多模态与场景适应能力、高效推理与低成本部署三大优势，在确保高性能的基础上将成本压缩至行业平均水平的60%，为中国企业大规模应用AI Agent开辟了更可行的路径和广阔前景。 “目前，许多科技公司推出了面向C端（终端用户）的通用型AI Agent产品。在这些平台上，用户只需简单描述即可生成语音陪伴助手、外语练习助手、图像生成助手等，极大提升了生活便捷性。但在B端（企业端），Agent首先引领的是企业软件架构革新。”柴亚团说，“我们以RPA（机器人流程自动化）为基因，深耕B端市场，聚焦企业核心执行层。” 2024年9月， 上海容智信息技术有限公司CEO柴亚团正在介绍公司AI Agent企业级解决方案 传统企业软件依赖后端系统和数据库进行管理，业务数据与交互集中于后端服务器，导致架构复杂、运行效率受限。而AI Agent通过智能化能力，将数据库交互、用户请求处理与业务流程执行深度融合。这种高度集成与智能驱动，使AI Agent取代了传统的人工编程与分散管理模式，不仅简化了企业软件架构，还从根本上增强系统的灵活性与智能决策能力，为企业带来更敏捷、高效的运营模式。 例如，财务Agent能够无缝整合多个系统，自动从财务管理平台提取多维度数据，智能分析并生成定制化的财务报告。“假如企业某位员工离职，以前要找各个部门走流程。现在只要构建AI 智能体，流程将大大简化。等新员工入职，即可轻松完成账号重建、资产恢复。通过知识库智能体，新员工还可以轻松掌握公司制度、流程信息。”柴亚团说。 另外，容智iBotX数字员工RRPA Agent，在RPA的基础上融入大模型能力，使其不仅具备人机对话、思考、推理、内容生成和总结等智能化能力，还结合了RPA丰富的动作执行能力，能够高效应对大量端到端的复杂业务场景。“这一升级不仅大幅拓展了能力边界，还显著提升了其灵活性和实用性，重新定义了人机交互，为RPA这双灵巧‘双手’装上了智慧大脑，更与大模型强强联合，为业务流程自动化带来了前所未有的可能。”柴亚团说。 “其实，我们已经研发智能体两年多了。过去很大的问题是受制于大模型能力，智能体成本高且输出不稳定，都不好意思拿出来给客户使用。”柴亚团回忆，“DeepSeek发布后，这款基于DeepSeek的智能体终于真正能在实际场景中用上了，不仅开源免费，而且速度快，输出稳定。” “现在，容智创新融合大语言模型与智能体技术，打造了开箱即用的Hyper Agent专家级智能体开发平台。通过可视化配置界面，业务人员无需编写代码，只需进行简单修改，即可在秒级时间内完成Agent部署，实现业务流程智能自动化，真正做到‘所想即所得’。”柴亚团说。 6个月与6天 “我要发自内心地感谢DeepSeek。”宁波云锦微智能科技有限公司（以下简称“云锦微”）创始人、CEO王文艺告诉《瞭望东方周刊》，“打个比方，我之前在人工智能行业做计算机视觉时，大家觉得行业市场规模是夜空里的星星，后来GPT出现，大家认为AI市场规模有月亮那么大了，而DeepSeek，则将市场规模放大到比太阳还要大。” 云锦微成立于2021年6月，是一家专注于研发具身智能体操作系统的科技公司。“在工业生产中，不同行业场景对识别目标物需求极为多样且细碎，在计算机视觉时代存在着很多无法被覆盖和满足的算法需求，如垃圾分拣、质量检测、运维检修等等。而大模型技术的出现让这些需求有了更便捷、成本更低的解决方案。”王文艺解释，“我们的目标是让每一个设备都插上大模型的翅膀，所以低成本、高性价比是云锦微的一大特色，尤其在AI芯片的国产化适配方面。” 目前，云锦微已经帮助企业开发者客户在能源、水务、交通等多个场景实现了商业化落地。 2025年1月，科大讯飞与云锦微签订生态投资合作协议，双方将在多模态技术、全球市场拓展、投资机构对接等方面展开全面合作，共同推动具身智能体在各个行业的普遍应用。 “从商业角度来看，DeepSeek首先降低了我们的成本。现在模型计算与使用成本仍然存在，但知识使用成本已经降到零。”王文艺说，“其次，它通过开源免费将慢思考能力和深思考能力融入各行各业。” “最重要的是带给了我们更多商业机会，可将当下的行业经济规模至少放大十倍，未来更会指数级增长。我们春节后一开工，接到的咨询量急速增加，商业面也迅速扩大，很多政府部门和事业单位都在咨询将内部流程知识库接入DeepSeek。”王文艺说。 2025年2月26日，北京市丰台区，综合窗口工作人员使用DeepSeek大模型版“丰小政”解答市民咨询 “春节期间看到DeepSeek爆发后，我的第一反应就是市场要变天了。”王文艺说，“以前我们想要成交一个客户，需要有专业的业务顾问和技术专家团队和客户沟通，了解客户的业务目标、流程、应用场景、功能期望，再给出关于智能体应用的可行性分析和战略建议。这个过程从我们初步了解客户到客户真正下单，至少要6个月。现在我们基于DeepSeek开发了一个小程序，类似于数字销售员。客户被这个专业的数字销售逐步引导，帮助测试我们的产品，判断我们的能力，6天左右就能筛选出我们与他是否匹配。接入DeepSeek后，一周时间的订单量就相当于以前一个月。” “最近市场一哄而上都在做DeepSeek私有化部署一体机，水平参差不齐。这和上世纪90年代初专业人士组装PC机的情况类似。”王文艺说，“目前有很大一批中小微企业对DeepSeek非常好奇，但他们预算不高，自己没有专业IT开发团队，想尝试却没有人帮他DIY。这种情况下，开箱即用的DeepSeek一体机需求量非常大。” “我们帮助客户配置DeepSeek一体机，除了根据客户对智能体的性能需求和应用场景需求，对处理器、内存、存储、显卡等关键硬件组件进行选型和优化，还会免费提供给客户多模态底座、大模型和AI开发工具。我们希望客户在未来需要多模态整合时，可以看到我们的能力。”王文艺说，“在我们尚未完成推广视频，未通过代理商渠道，没有广泛推广的情况下，目前咨询量已经非常大。” “2025年，行业将爆发式增长，人工智能真正开始‘大航海时代’。如果说以前大家还在港口摇旗呐喊，要去发现新大陆。那么现在，无论是大轮船还是小舢板，都可以尽快出海了。”王文艺说。 通用智能尚在路上 “DeepSeek能在AI领域崭露头角，离不开其在技术层面的诸多创新，这些创新点成为它突破传统、实现飞跃的关键因素。”张奇说， DeepSeek在研发过程中深度融合了大量国内互联网信息，使其对中文语境高度敏感，能够精准把握本土用户的需求与语言习惯。在处理中文翻译任务时，它能够充分考虑到中文语言的丰富内涵和文化背景，给出更加准确、自然的翻译结果。当翻译一些具有中国特色的成语、俗语时，DeepSeek能够深入理解其背后的文化寓意，将其准确地翻译成外文，让外国用户也能领略到中国文化的博大精深。在语义理解和多轮对话场景中，DeepSeek表现得更加自然流畅，能够更好地理解用户的意图，提供更加个性、精准的服务。比如在智能客服场景中，它能够快速理解用户的问题，并给出针对性的解决方案，大大提高了用户的满意度。 “作为中国团队自主研发的成果，DeepSeek在中文理解与生成方面具有天然优势，这是它区别于其他国际AI产品的一大特色。”张奇分析，“相比之下，尽管一些国际知名的AI产品在上下文理解、创意写作等方面表现出色，但在处理中文信息时，往往会因为对中文语境的理解不够深入而稍显滞后。这就使得DeepSeek在本土市场上具有独特竞争力，能够更好地满足国内用户的需求，为推动中文自然语言处理技术的发展作出重要贡献。” 不过，我们也必须清醒地认识到，DeepSeek虽然强大，但距离通用智能的目标仍然遥远。 通用智能，代表着人工智能发展的终极理想。它是指一种具有人类级别的认知能力，能够理解、学习并应用于广泛任务领域的人工智能系统。这意味着它并非局限于特定的任务或领域，而是像人类一样，具备广泛的适应性和灵活性，能够处理各种类型的任务，无论是日常的生活琐事，还是复杂的科学研究，都能应对自如。 “包括DeepSeek在内的大语言模型的底层逻辑都依然是统计机器学习，其运作方式是传统的喂数据、训练、输出结果模式。在技术层面，DeepSeek在某些任务上表现出色，但其本质上还是一个被训练出的智能模型，不是真正意义上的智能体。”张奇分析，“DeepSeek虽然在一些复杂问题上能够展现出强大的计算和推理能力，比如在数学、代码处理等任务中表现出色，但对于那些没有在训练数据中充分体现的场景和问题，它也难以准确应对。这意味着，DeepSeek的能力边界取决于它所学习的数据和训练的场景，而不是像人类一样具备通用的智能，即可以举一反三，灵活应对各种未知情况。” “尽管大语言模型目前距离通用智能还有一定的距离，但它在通用智能的探索道路上，带给我们诸多值得期待的可能性和方向。”张奇说。 市场机会显著 “接下来的一年有望成为AI应用爆发的黄金期。”快思慢想研究院院长、原商汤智能产业研究院创始院长田丰告诉《瞭望东方周刊》。 “对于普通人而言，更形象的比喻是2024年的大模型更像文科生，而2025年的大模型更像理科生，并且具有博士逻辑推理水平。它的思路过程中展示的逻辑能力非常接近教授水平或者说数学家水平。因此从这一点来看，在推理能力上，中国的大模型每半年甚至每个季度都在快速提升。”田丰分析说。 “这股DeepSeek热潮是一次非常成功的市场教育，它让社会大众、C端的个人和企业使用者，还有相关政策制定者都非常直观地认识到AI的核心易用性和巨大价值。让从业者和大模型厂商看到了在成本可控、算力有限的前提下也可以训练出高性能模型的可能性。”罗兰贝格全球合伙人兼大中华区副总裁李冰博士告诉《瞭望东方周刊》。 2025年2月24日，湖北省襄阳市老年大学授课教师在电脑课上为学员讲解如何使用DeepSeek人工智能应用 “从ToB（Business to Business，企业与企业之间的商务模式）的角度来看，AI在制造业等领域都会有广阔的市场机会，不过目前仍是市场初期。比如在制造业中，质检就是典型的AI机器视觉发力的领域。不过，相对而言，AI目前更大的市场其实在ToC（Business to Consumer，企业对消费者的商务模式）。”李冰解释说，“除了Agent外，智能硬件将有新的、显著的市场机会，如AI眼镜、AI耳机、AI手机、AI电脑、AI家居等等，都值得期待。” 田丰也持同样看法，“基础模型的价格战可能会告一段落。AI应用领域，我们可能在2025年看到爆款应用的涌现。除了传统软件的AI化，硬件AI应用也会非常丰富多彩。比如AI家居，它不仅可以提供传统冰箱的制冷保鲜或者空调的环境舒适，还可以关心你的健康状况。这就意味着，家电产业正在向服务业延伸——原来家电产业的服务可能包括安装维保，但现在的服务是冰箱将为你安排健康菜谱。” “就服务业而言，现在大量服务业的任务场景都可以用‘传统互联网+传统服务业+大模型’去完成。例如，原来的定制旅游服务，现在用大模型可以做得更好，大模型可以理解客户的复杂需求，并利用海量信息，更精准地满足客户对成本和体验的需求。”田丰说。 “中短期内，我们一定会朝着‘更高性价比’或者说‘更便宜’的大模型方向发展。原因是今天我们可以使用高质量训练的大集群和大规模数据，数据红利已经到达尾期。因此单纯依靠预训练解决方案，即预训练技术路径可能会继续前进。但性能的提升将变缓。”李冰说。 “未来，全球对AI 人才的抢夺可能更加激烈。人才是科技企业的第一资产。”田丰说，“以往外界普遍认为，那些成绩最拔尖且有志于在理工科领域发展的中国青少年，其标准发展路径是在中科大、清华北大等高校读完本科，然后留学美国伯克利、麻省理工、斯坦福等大学，读完硕博士，再去微软或谷歌之类跨国大企业工作几年。但现在我们看到，从浙大、清华毕业的本土博士，甚至在读的硕士研究生都创造出了非常好的成绩，这代表我们的大学尤其是AI硕博士的教育水平已经提高。这归功于国内教育体系的不断创新，还有领军科学家的栽培。” “这批爆火的AI 研发创新团队，年龄都在24岁到35岁之间。青年科学家爆发出极大的原始创新能力和潜能。”田丰建议，“下一阶段，我们要给青年科学家更大的科研自由度和资金支持，以更高的科研预算、更开放的学术态度、更好的人才保护政策去鼓励创新。” 田丰还建议，在中国寻找并建设一些长期支持人工智能核心软件基础研发、芯片基础研发的金融体系、机制，助力创新创业者在5年或者10年内取得国际上绝对领先的原创成果。（作者系《瞭望东方周刊》“人工智能+”工作室主任 ） （本文刊载于《瞭望东方周刊》2025年第6期，总第929期） 点击下方标题，阅读本组专题全部稿件 《中国AI大潮起》专题系列稿件 举报/反馈"
    },
    {
      "doc_id": 49980,
      "title": "AI搜索的胜负手,在内容生态里",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "吃瓜吃得透，还得看微博智搜。 作者｜王彬 似乎已经没有哪款 App 能完全避开 AI。 自年初 DeepSeek 带动国内大模型热潮以来，AI 正以摧枯拉朽之势迅速席卷整个中国互联网。不只是那些以 Chatbot 为主的 AI 原生应用，社交、购物、音频等传统 App 也陆续接入了大模型能力。随手点开一款 App，AI 往往已是默认配置，就等着你开口提问。 激烈竞争之下，AI 赛道已然是一片红海。但仍有应用脱颖而出，获得爆发式增长。QuestMobile 发布的《2025 全域 AI 应用市场报告》显示，微博智搜月活跃用户环比暴涨 300%，以绝对优势位居移动端 AI 应用飙升榜第一，增幅是第二名的两倍有余。 微博智搜的爆发多少有些出人意料。它不如喜马拉雅波波、网易有道小 P 在垂类场景中的渗透力，生产力表现也不及腾讯元宝、豆包或即梦 AI 等明星原生应用。即使在 AI 搜索这一垂类赛道，它也尚未建立起百度 AI、头条 AI 那样的用户心智。 微博智搜，到底做对了什么？ AI 时代，赛博吃瓜 网友们对于微博智搜的第一观感，或许就是“吃瓜吃得透”。 可能再也没有哪个社交平台的用户能像微博网友这般热衷于吃瓜。从国家大事到明星八卦，从全球局势到社会百态，微博网友总是第一时间赶赴瓜场，冲在最前线。 看看微博发布的《2024 年微博热搜趋势报告》你就知道了。全年热搜一共爆了 574 次，巴黎奥运会、中东局势、黑神话悟空乃至黄子韬恋情、罐车运输食用油乱象等大事小情，只有你没见过的，没有微博网友不关心的。 可在如此密集的信息冲击下，即便是最资深的吃瓜群众，也难免疲于招架。社交媒体时代，热点来得太快、反转太多，网友们常常只看到一个热搜标题，便匆匆划过，虽“知其然”，却难“知其所以然”。还没搞清楚前因后果，话题已然热度散尽，吃瓜也吃得不够尽兴。 但这正是微博智搜的长处所在。不同于传统 AI 搜索引擎，微博智搜除了接入 DeepSeek-R1 等大模型，更重要的是，它深度接入了微博自己的内容生态——那些眼花缭乱的热搜词条，原本就从一条条微博中长出的。 就拿最近又双叒叕登上了热搜榜的黄子韬徐艺洋恋情来说吧——可能再也没有哪个明星夫妻能像黄子韬这样把恋情谈成抓马连续剧的。 7 月 22 日的热搜词条是“徐艺洋都没亲过这么帅的黄子韬”。如果你没跟上剧情，可能一头雾水。词条下面刷屏的是黄子韬早年的舞台视频，网友到底在说什么？和亲没亲又有什么关系？ 这时，微博智搜恰到好处地出现了。点开智搜，它先用一句话总结热搜词条的含义，“这是近期网友对黄子韬早期颜值巅峰与两人当下甜蜜关系的趣味调侃”，信息对齐，情绪到位， 堪称最精准的“中对中翻译”。 再往下，智搜按“梗的起源与对比”“网友创作与传播”“二人真实互动”“热梗背后的公众心理”几个维度拆解背景，一步步带你补全黄子韬与徐艺洋恋情的“瓜学图谱”。一条智搜的分析，你就能从头到尾了解到热梗的前世今生。 微博智搜总结黄子韬热搜 对于吃瓜群众来说，这相当于朋友们还处在看着黄子韬短视频傻乐的阶段，你已经能从黄子韬徐艺洋的恋爱时间线，到为什么黄子韬总是热搜体质，甚至还能顺带讨论下用户参与感和反转叙事在短视频时代的流行机制。吃个瓜还能顺便精通一门传播学，绝对让你在八卦聊天中立于不败之地。 社会热点事件就更不用说了，大模型加持下的智搜能带来一种更全景式的视角。比如，最近中产群体又被山姆整破防了——说实话，谁也搞不清中产到底为什么总在破防。热搜词条写的是“在山姆发现一盒好丽友被拒绝结账”，字面信息极少，前因后果完全不明。到底是好丽友怎么了？为什么结账就成了问题？中产又为何如此敏感？ 智搜的答案很清楚：这起风波起于澎湃新闻记者发现山姆超市货架上遗漏的一盒好丽友派。由于此前山姆引发会员争议、紧急下架了部分大众品牌商品，这盒无条码的好丽友才无法结账。而在此背后，是山姆会员对“品牌策略变化”的信任危机。 智搜总结“在山姆发现一盒好丽友被拒绝结账” 智搜不仅梳理了来龙去脉，还顺带补足了山姆近来的处境、会员抵制的原因、网友的不同观点，最后一锤定音：“这场风波始于一块好丽友，却刺破了会员制超市的信任泡沫。” 国际新闻也一样。自从川普重新上台，操作频率堪比短视频切片，国际政治都变成了反转短剧。前一秒说要加税，后一秒就变卦，吃瓜群众压根跟不上他的节奏。 但智搜会帮你接住这一连串反转。从 4 月 2 日美国宣布对华加征 34% 关税，到中方反制、再到 5 月中旬贸易谈判落地新一轮措施，智搜用一条完整时间线呈现事件走向，引用 500 多条来自人民日报、新华社等权威媒体报道，帮你理清楚每一步的脉络与逻辑。 智搜一键还原中美关税事件 AI 时代，赛博吃瓜。虽然市面上 AI 搜索引擎一抓一大把，但一个真正懂热搜、会讲“瓜”的，只此一家。吃瓜吃得透，还得看微博智搜。 信息求证，智搜更精准 热点事件的更新频率已经从按天变为按小时、按分钟。信息快速扩散的同时，算法推送机制也在放大短时间内的误读与虚假内容。 传统媒体曾有时间核实信源、澄清事实。但在流量驱动的短视频时代，媒体自身也可能成为错误信息传播的加速器。以 2024 年“猫一杯秦朗丢作业”事件为例，多家主流媒体早期纷纷跟进报道，事后却被证实缺乏基本核实。 微博试图通过智搜提升信息分发的准确性。在最近的中国网络视听大会上，微博 COO、新浪移动 CEO 王巍表示，大模型具备对多模态内容和超长上下文的理解能力，将有助于提高内容识别与审核的效率。 他认为，可以借助大模型对模糊隐晦，低频长尾等风险内容进行自动识别，使内容审核从原来的 “人工巡查” 转向 “AI 识别 + 审核专家研判” 模式，可以更加精准高效地发现和阻断有害信息的传播。 前段时间，“仅退款占比超八成为男性”一词条在网络上引发性别议题争议。微博智搜精准指出，该热搜话题存在数据误读，相关词条词条引用的数据来源本意指投诉平台的男性商家负责人比例，却被曲解为仅退款者性别。 另一个例子是“3 成人存款超 50 万”的话题。此前，某媒体在一份针对 90 后、95 后及 00 后的存钱调研报告中指出，三成人的存款已经超过 50 万元，更有 12.3% 的 00 后存款超过 30 万。报道发出后，相关词条迅速登上热搜，引发网友焦虑情绪。 微博智搜分析“3 成人存款超 50 万” 微博智搜通过引述专业财经博主的分析、权威机构统计数据指出，该调研样本量不足，结论具有片面性。“类似在清华校门口统计高考分数，无法代表全民真实水平。”智搜总结表示。 分析最后，智搜还呼吁网友理性看待存款数据，“财富的本质是安全感，而非数字竞赛。”它还学会了引用部分网友的精彩发言，“没债、有稳当工作、家人生病不愁钱，才是真正的安全感。” 不少公司高管也盛赞智搜分析，认为智搜可以帮助用户更全面地了解事件全貌。此前，小米汽车因一张宣传图片与特斯拉雷同而引发质疑。小米集团公关负责人王化在微博中引用智搜分析指出，该图拍摄于上海一处常见的网红机位，已有多位用户在同一地点拍摄不同品牌车辆。相关照片由网友拍摄后授权官方转发，未涉及付费及商业拍摄环节。“所谓 ‘抄袭’ 系对公共摄影资源的误解，且小米未参与创作环节。”智搜分析指出。 王化在微博中称赞智搜分析 智搜不只存在于热搜词条下，微博最新的更新中已经加入了对单条博文的分析功能。网友只需点击博文或视频播放页右上角的“搜索放大镜”，就可以利用智搜来对博文进行深度解读、信息求证。除此之外，网友还可以在评论区直接 @微博智搜，召唤智搜分析。 比如上周微博上热议的苹果将在明年下半年量产折叠 iPhone 的新闻，点击博文右上角的智搜分析就可一键查证。又或者相关博主称“10:12 PM 是最佳上床时间”，智搜亦提供引用依据与反驳意见，有助于减轻信息误导带来的焦虑情绪。 智搜分析一键查证 事实上，在利用 AI 来辨别社交媒体上的虚假信息方面，中外平台的路径正逐渐趋同。马斯克在收购推特（现为 X）时，曾多次提及平台充斥“机器人、水军与虚假信息”，并将遏制此类内容作为改革目标之一。他最初尝试通过信用卡绑定实现用户实名，希望以此提高用户发言的责任感，从而减少诈骗、欺凌和虚假信息传播。 在 X 推出 AI 工具 Grok 后，这一策略开始转向技术驱动。如今，用户可在评论区 @Grok，请其对特定推文进行求证或总结。例如，近期 OpenAI CEO 山姆·阿尔特曼关于“AI 是否将取代人类工作”的发言，就有网友召唤 Grok 自动给出解释性分析。 用户可在评论区召唤 Grok 分析总结 相较之下，微博智搜在入口设计与信息可达性上更进一步。除可在评论区直接@外，智搜已嵌入热搜词条、单条博文页和视频播放页等多个使用场景中。对部分存在争议或信息存疑的内容，智搜还会在博文正文下方以附注形式展示。相比之下，Grok 目前主要出现在评论区和社区附注中，尚未深入整合至 X 的搜索系统或主信息流。 接入 AI，也要因地制宜 年初 DeepSeek 在短时间内迅速完成大模型的市场教育之后，当下几乎没有哪个互联网 APP 没有接入 AI。即便各家仍在发力原生 AI 应用，但占市场绝对主力的仍然是插件形态 AI 应用（in-APP AI）。 QuestMobile 发布的 2025 年 5 月 AI 应用行业月度报告显示，插件形态 AI 应用爆发式增长，月活跃用户达 5.8 亿，是原生 AI APP 月活用户的两倍有余。月活跃用户规模 Top 50 应用中，插件形态的 AI 应用份额最高，达 27 个。 这背后是互联网行业普遍的 FOMO（错失恐惧）情绪。但快速接入不等于良好体验。一些产品在接入大模型后并未针对使用场景做优化，反而让搜索等原本高效的环节变得更慢，用户要等待 AI 推理完成，体验反而倒退。也有一些平台尚未建立起核查机制。在接入 AI 功能时，它们没有对内容质量进行足够筛选，AI 在生成结果时直接引用了平台上未经核实的信息，甚至包含明显错误。 微博智搜是当下少见的能将 AI 与平台生态融合得较为自然的产品。它并非简单接入一个大模型完成问答，而是充分调动了微博多年积累的内容资源，打造出新的搜索体验。 微博智搜的分析回答中引用了大量来自于微博平台内的真实发言内容。无论是娱乐热梗还是新闻大事，微博智搜的每条回答均广泛引用平台上的权威媒体、行业专家乃至 KOL 们的发言，多方辨识后才给出回答。 比如前文提及的“在山姆发现一盒好丽友被拒绝结账”的热搜词条，智搜分析显示它共参考了平台上 109 条微博博文，除了新京报、澎拜新闻、九派新闻等主流权威媒体报道外，也吸收了大量用户自发的现场讨论，呈现出更丰富、真实的舆论全貌。 智搜参考引用的主流权威媒体信源 和不少大模型问答中仍然只有文字分析不同，微博智搜的回答融合了短视频、图片等多模态的信息。这些视频与图片多引自平台上主流媒体的报道，点击即可直达信息源头。 AI 搜索引擎们虽然号称能理解自然语言，但本质上仍依赖百科类文本或网页链接作为输入。它们也能回答一些关于热搜的疑问，却难以真正理解前因后果，更无法读懂社交媒体上那些语境跳跃、含义多变的热梗。微博智搜的不同在于，它扎根于微博内容生态，把热搜榜、KOL 发帖、媒体解读乃至正在发酵的评论，统统都作为原生素材。 2024 年微博热搜趋势报告 这正是微博智搜区别于其他 AI 搜索引擎独特的内容优势。微博至今仍然是公众话题讨论的第一平台，主流权威媒体、行业专家、头部 KOL 与普通用户共同构成了丰富的微博内容生态。未来搜索，得内容者得天下。 尤其在今年的 AI 高考志愿比拼中，更多的 AI 搜索只是利用原有公开数据进行分析整理，给出的志愿填报指南虽然客观全面，但却有些缺乏实操性。 借助于平台上原有的众多行业大 V 与科创名人，微博智搜则引用了更多过来人的“现身说法”。比如宇树科技创始人王兴兴就在微博上发文，与网友畅聊志愿填报心得。他说，“如果你想成为最顶尖的人才，一定要超脱课本，主动持续练习。”《黑神话悟空》的制作人冯骥也分享了几条自己的切身经验，一要养成终身锻炼的习惯，二要让 AI 变成首选信息获取方式。 微博智搜会引用平台真实用户的见解 这些真实的发言帮助智搜的回答比其他 AI 多了些人味。脱离了内容生态的 AI 搜索引擎会客观分析你的高考分数、志愿前景，但它不会引用冯骥的发言，告诉你不妨再大胆一点，去表白、去恋爱、去拒绝、去坚持兴趣，“年轻的你有后悔的灵药，也有丢脸的特权。” 这或许是为什么微博智搜能在一众 AI 搜索引擎中脱颖而出的原因。AI 搜索引擎很多，但真正懂你的并不多。 本文首发于微信公众号：山上。文章内容属作者个人观点，不代表和讯网立场。投资者据此操作，风险请自担。 举报/反馈"
    },
    {
      "doc_id": 49983,
      "title": "DeepSeek 热潮半年之后,医生、教师、程序员,谁好评,谁差评?",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "2025年年初，DeepSeek迎来爆发式发展，从技术突破到应用落地，AI 技术的发展深刻影响了多个行业的变革节奏。我们站在年中这个时间点上回望， AI 究竟如何影响了千行百业？ 腾讯新闻联合九派新闻、数说故事发布《AI浪潮下的职业真实图景分析》，以全网社媒大数据透视行业相关人讨论内容以及情感趋势，呈现当下AI对于不同职业的真实影响，共同探讨AI未来的发展趋势。 报告显示，“AI+职业”的讨论热度随DeepSeek的爆发而上升，今年以来“AI+职业”的讨论声量暴涨60%以上，总声量突破119万。透过“AI+职业”相关话题词云发现，用户对AI的关注重心已从“技术有多牛”转向“能帮我做什么”，2024年还在热议技术原理的网友，2025年更关心“利用AI可以做什么”、“AI如何提效”等职场提效、自我成长的AI实用场景。 从“AI+职业热度”来看，程序员、医生、教师成为AI讨论话题下的TOP3职业，设计师讨论热度紧随教师。医生、心理咨询师等职业声量增速超200% 那么AI究竟对这些职业产生了哪些影响？点击下方图片查看不同职业篇章。 【来源：九派新闻】 举报/反馈"
    },
    {
      "doc_id": 50001,
      "title": "DeepSeek崩了,冲上热搜!疑似因用户量激增所致",
      "time": "2024-07-03T00:00:00+00:00",
      "content": "今日一早，“DeepSeek崩了”相关话题冲上热搜！ 据悉，其出现异常情况的时间主要集中在 2025 年7月2日 - 7月3 日，大量用户通过微博话题 #deepseek崩了# 表达使用中遇到问题， 大多用户集中反馈宕机问题，用户表示：无法提问、回复延迟、频繁显示“服务器繁忙”。部分用户提到使用过程中突然中断，影响学习、工作、娱乐等场景，如赶作业、写毕设、查资料。 截至 7 月 3 日，未检索到 DeepSeek 官方对此次故障的公开说明。 但此前类似问题（如 2025 年1月、3月宕机）通常由流量激增或技术升级故障引发。近期 DeepSeek 用户量激增（累计下载超 1.1 亿次），尤其高峰时段易触发服务器限流，导致部分用户被提示“繁忙”或功能受限（如“深度思考”功能 4 小时内仅能用 1 次）。 来源：江南都市报综合整理 举报/反馈"
    },
    {
      "doc_id": 50003,
      "title": "DeepSeek爆火后,这些非法荐股套路需警惕",
      "time": "2024-03-16T00:00:00+00:00",
      "content": "本文转自【法治网】； 最近，随着DeepSeek爆火，在为人工智能领域注入新的活力的同时，一些不法分子也开始趁机打起歪主意。比如，目前就已经出现打着DeepSeek的名号进行非法荐股营销的乱象。 话术俘人心：“财富自由”如此之近 法治网记者在多个社交媒体平台上发现，一些博主纷纷晒出所谓DeepSeek给出的理财建议截图，分享财富故事，声称借助该大模型在股市中赚得盆满钵满。但仔细观察不难发现，这些博主并未提供任何实际收益证明，却在文案中不断推销理财课程、炒股软件等服务。 （图片来自社交平台） 与此同时，一些短视频、直播间也以DeepSeek为噱头，推销“AI荐股软件”或投资顾问服务。 法治网记者在某短视频平台选择两个内容中标明AI选股的账号，按照视频提示进行实测。他们均声称，使用该软件或服务，结合DeepSeek强大的计算能力和数据分析能力，能够精准预测股票走势，帮助投资者实现财富自由。 （某短视频平台出现的视频内容） 在添加了一家视频账号助理的企业社交账号后，对方展示了企业的正规营业执照、国家企业信用信息公示平台信息等。记者提出想要领取AI选股工具之后，该助理发送了名称包含“DeepSeek”字样由相关软件生成的指标文件。另一家视频账号的助理则提供了一个名称为“AI智能选股xxx”的小程序让记者体验。 在记者体验期间，两位助理不约而同地表示，他们还有另一种“固定服务期收取少量服务费”的合作方式，虽然服务费与服务周期不尽相同，但均声称不需要额外下载APP在微信上就可以提供服务。此后两位助理再未在沟通中提到过AI智能选股工具或DeepSeek选股策略等内容，而是不断向记者发送他们的服务表现和签约客户的喜报，以催促下单购买。 （图为助理持续推销付费服务） 记者通过黑猫投诉平台查询这两家企业，发现共有76条投诉，大都是关于虚假宣传、诱导消费的投诉。 套路深似海：关关难过关关过 法治网记者调查发现，关于AI非法荐股目前主要有以下几种套路—— 一、伪装流量博主，诱导投资。 AI概念爆火后，在一些社交媒体和网络平台上，有大量打着DeepSeek旗号的非法荐股营销内容涌现。据媒体报道，某拥有19万粉丝的视频博主宣称投入100万元实测 DeepSeek 的理财能力，视频中展示了根据 AI 建议购买10只股票的操作，该视频发布后短时间内收获超30万点赞、评论超7.9万。然而，截至目前，博主并未更新此次投资结果，且此前其视频点赞量大多仅几十至几百，发布 DeepSeek 理财视频后流量数据才呈数十倍增长，经调查，这些博主大多没有证券从业资质，却在误导投资者按照其投资建议操作。 二、虚假软件推销，暗藏诈骗陷阱。 一些直播间正在以DeepSeek为噱头，推销“AI荐股软件”或投资顾问服务。这些主播们声称，使用该软件或服务，结合DeepSeek强大的计算能力和数据分析能力，能够精准预测股票走势，帮助投资者实现财富自由。而实际上，这些软件和服务不仅价格高昂，投资效果也难以保证，甚至可能存在泄露投资者个人信息的风险。 今年年初，湘潭市岳塘公安公众号发布消息，2025年1月2日，岳塘公安反诈中心接到反诈预警，辖区内赵女士疑似遭遇电信网络诈骗。据悉，赵女士在2024年11月底浏览微信视频号时，被“AI 炒股”软件的虚假宣传吸引，先后两次转账数十万元购买该软件。接到预警后，民警迅速行动，阻止了赵女士进一步陷入诈骗陷阱。 三、AI电话引流，骗取投资资金。 犯罪团伙通过利用 AI 机器人拨打海量电话，筛选潜在受害者。2022年，江苏镇江警方成功破获一起利用 AI 技术实施的非法荐股诈骗案，涉案金额近1.8亿，犯罪团伙利用AI机器人拨打1700万个电话，获取80多万条有效客户电话，为境外诈骗团伙“引流打粉”。夏女士被冒充证券公司工作人员的骗子拉入企业微信群，群内推荐炒股软件，先让其小额盈利获取信任，诱导加大投入后软件无法打开，与对方失联。 消费者如何识别此类迷惑性极强的套路，一旦遭遇此类虚假宣传被诱导投资，又该如何依法维权呢？ 对此，《法治日报》律师专家库成员、北京瀛和律师事务所胡青春律师表示，消费者需要高度警惕此类宣传套路，识别陷阱以免落入其中。现实社会中，“天上掉馅饼”的几率太小了。在正常的投资中，高回报也往往伴随着高风险。消费者遭遇虚假宣传、诱导投资等非法荐股时，应先及时止损，停止盲目投资。若已买入推荐股票，不要盲目抛售，需冷静分析市场情况后理性决策。同时，务必收集与非法荐股人相关的微信聊天记录、交易记录、付款凭证等各类证据，特别是对方承诺收益、荐股内容等关键证据，为后续维权做准备。 “技术中立”不背锅：平台还需守土有责守土尽责 那么，实施非法荐股营销行为，将可能面临何种法律后果？ 对此，胡青春律师表示，非法荐股面临多重违法，可能承担多重责任。我国证券法第一百六十条第二款规定，从事证券投资咨询服务业务，应当经国务院证券监督管理机构核准；未经核准，不得为证券的交易及相关活动提供服务。根据证券法第二百零二条第一款，非法经营证券业务，责令改正，没收违法所得，并处以违法所得一倍以上十倍以下的罚款；没有违法所得或者违法所得不足一百万元的，处以一百万元以上一千万元以下的罚款。对直接负责的主管人员和其他直接责任人员给予警告，并处以二十万元以上二百万元以下的罚款。 胡青春律师同时指出，非法荐股除受行政法规制外，刑事方面也有相关规定，达到立案追诉标准，就会触犯刑法第二百二十五条，涉嫌非法经营罪，被司法机关追究刑事责任。除上述责任外，非法荐股还可能受到股民的民事索赔，承担民事赔偿责任。 针对非法荐股披上AI“外衣”的现象，中国政法大学数据法治研究院教授、中国法学会网络与信息法学研究会副会长王立梅认为“技术中立”原则强调工具本身并无善恶之分，但实际应用中需结合使用场景和行为性质综合判断。在非法荐股场景中，不法分子刻意将DeepSeek等AI产品概念化包装成“炒股神器”，通过虚构收益、伪造对话截图等方式诱导投资者，其行为已超出技术中立范畴，本质上属于以“技术中立”之名行欺诈之实。 值得注意的是，非法荐股现象屡禁不止的背后，还与另一关键因素有关，即平台责任的缺失。 法治网记者在调查中发现，当前各大网络平台的金融类营销内容审核机制，部分平台虽然设置了关键词过滤、人工审核等环节，但仍存在漏洞。比如，一些非法荐股信息通过隐晦表述、谐音梗等方式绕过平台审核，一些不法分子为躲避监管，在平台上利用谐音梗进行非法荐股，手段隐蔽且具有迷惑性。例如，将某知名科技股“苹果”表述为“苹菓”。当提及某只股票时，不直接说出股票名称，而是以谐音替代，如将“茅台”称作“矛台”。在讲解股票走势和推荐股票时，使用这类模糊、隐晦的表述，逃避平台监测，最终达到非法荐股盈利的目的。 王立梅教授表示，随着金融监管、平台责任等工作的纵深推进，以非法荐股为代表的不良及违法信息通过套借“谐音梗”等形式，企图继续游走潜藏在网络生态当中。不论是改换同音字，还是借用其他表述映射，其目的都是为了逃避监管，但不管怎样乔装打扮，都不可能真正驶入避风港、躲进空白区。 根据《中华人民共和国网络安全法》第四十七条，网络运营者应加强对其用户发布信息的管理，发现法律禁止发布或传输的信息，应当立即停止传输并采取消除等处置措施。由此可见，平台主体应当承担相应的法定责任。此外，负有法定责任的平台主体还应当进一步完善合规体系建设，提升分类管理的精准性和科学度，有针对性地开展专项监测，探索智能手段做好信息识别和风险提示，及时干预阻断，共筑清朗网络空间。 记者注意到，3月10日，抖音发布《关于打击“非法荐股”等违法证券活动的公告》称：近日，平台发现，有少数账号在无相关资质情况下，声称可借助各种AI类工具，实现所谓“高回报高收益”，或以“推荐高效AI选股工具”“售卖AI炒股课程”为噱头引发用户关注，甚至对其实施诈骗等行为。平台将针对“无相关资质机构或个人提供有偿荐股服务”“编造、传播虚假信息或误导性信息，影响股票价格或交易量非法牟利”等违法违规行为持续进行治理。 （图为抖音黑板报发布公告） 王立梅教授提醒，在AI技术快速发展的今天，广大金融消费者应警惕不法分子利用新技术进行违法犯罪活动。只有投资者、平台和监管部门共同努力，才能有效遏制非法荐股等金融乱象，维护金融市场的稳定和健康发展，保护投资者的合法权益。 文｜王隽 辛洁 举报/反馈"
    },
    {
      "doc_id": 50011,
      "title": "Deepseek又出连招:刚发布了超越DALL-E3的多模态模型",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "作者｜Li Yuan 编辑｜靖宇 AI 时代就这么悄悄降临了。 大概谁也没想到，今年春节，打的最热的不再是传统互联网的红包大战，谁和春晚合作了，而是 AI 公司。 临近春节，各家大模型公司都完全没放松，更新了一波模型和产品，而最受关注的，却是去年崭露头角的「大模型公司」DeepSeek（深度求索）。 1 月 20 日晚，DeepSeek 公司发布推理模型 DeepSeek-R1 正式版，使用低廉的训练成本直接训练出了不输 OpenAI 推理模型 o1 的性能，而且完全免费开源，直接引发了行业地震。 这是第一次国产 AI 大范围在全球，特别是美国引起了科技圈的震动。开发者纷纷表示，正在考虑用 DeepSeek「重构一切」，在这一浪潮下，经过一周的发酵，甚至一月才刚刚发布的 DeepSeek 移动端应用，迅速登顶美区苹果应用商店免费 App 排行第一，不但超越了 ChatGPT，也直接超越了美区的其他热门应用。 DeepSeek 的成功甚至直接影响了美股，没有使用巨量昂贵 GPU 就训练出的模型，让人们重新思考了 AI 的训练路径，直接让 AI 第一股英伟达最大跌幅达到 17%。 而这还没结束。 1 月 28 日凌晨，除夕夜前一晚，DeepSeek 又开源了其多模态模型 Janus-Pro-7B，宣布在在 GenEval 和 DPG-Bench 基准测试中击败了 DALL-E 3（来自 OpenAI）和 Stable Diffusion。 DeepSeek 真的要血洗 AI 圈了吗？从推理模型到多模态模型，拿 DeepSeek 重构一切，是蛇年开年的第一主题吗？ Janus Pro，多模态模型创新架构的验证 DeepSeek 此次深夜一共发布了两个模型，Janus-Pro-7B 和 Janus-Pro-1B（1.5B 参数量）。 从命名上就能看出，模型本身来自之前 Janus 模型的升级。 2024 年 10 月，DeepSeek 才第一次发布 Janus 模型。和 DeepSeek 的一贯套路一样，模型采取了一个创新的架构。在不少视觉生成模型中，模型都是采用了统一的 Transformer 架构，能够同时处理文生图和图生文任务。 而 DeepSeek 则是提出了一种新的思路，对理解（图生文）和生成任务（文生图）的视觉编码进行解耦，提升了模型训练的灵活性，有效缓解了使用单一视觉编码导致的冲突和性能瓶颈。 这也是 DeepSeek 为什么将模型命名为 Janus (杰纳斯)。Janus 是古罗马门神，被描绘为有分别朝向相反方的两个面孔。DeepSeek 表示命名为 Janus，指的是模型可以像 Janus 一样，用不同的眼睛看向视觉数据，分别编码特征，然后用同一个身体 (Transformer) 去处理这些输入信号。 在 Janus 系列模型中，这种新思路已经产生了不错的效果，团队表示，Janus 模型的指令跟随能力很强，有多语言能力，且的模型更聪明，能读懂 meme 图像。同时还能处理 latex 公式转换、图转代码等任务。 而在 Janus Pro 系列模型中，团队对模型的训练流程进行了部分修改，直接做到了在 GenEval 和 DPG-Bench 基准测试中击败了 DALL-E 3 和 Stable Diffusion。 随着模型本身，DeepSeek 也发布了 Janus Flow 新型多模态 AI 框架，旨在统一图像理解与生成任务。 Janus Pro 模型能做到使用简短提示提供更稳定的输出，具有更好的视觉质量、更丰富的细节以及生成简单文本的能力。 模型既可以生成图像，也可以对图片进行描述，识别地标景点（例如杭州的西湖），识别图像中的文字，并能对图片中的知识（如「猫和老鼠」蛋糕）进行介绍。 X 上不少人已经开始试用新模型。 上图左为图像识别的测试，右图则为图像生成的测试。 可以看到，在高精度读图上，Janus Pro 也做的很好。能够识别数学表达式和文字的混合排版。未来搭配推理模型使用，可能有更大意义。 1B 和 7B 的参数量，或能解锁新应用场景 在多模态理解任务中，新模型 Janus-Pro 采用 SigLIP-L 作为视觉编码器，支持 384 x 384 像素的图像输入。而在图像生成任务中，Janus-Pro 使用一个来自特定来源的分词器，降采样率为 16。 相对而言，这样的图像规模尺寸仍然较小。X 上有用户分析认为，Janus Pro 模型更多是方向上的验证，如果验证靠谱，就会推出可以投入生产的模型了。 不过值得注意的是，此次 Janus 发布的新模型，不但在架构上对多模态模型有创新意义可以参考，在参数量上，也是一个新的探索。 此次 DeepSeek Janus Pro 对比的模型，DALL-E 3，之前公布的参数量为 120 亿，而 Janus Pro 的大尺寸模型只有 70 亿参数。在这样紧凑的尺寸下，Janus Pro 能够做到这样的效果已经十分不错。 尤其是 Janus Pro 的 1B 模型，只使用了 15 亿参数。外网上已经有用户将对模型的支持添加到了 transformers.js。这意味着模型现在可以在 WebGPU 上的浏览器中 100％运行！ 虽然截止发稿，笔者还没能成功地在网页版上使用到 Janus Pro 的新模型，但是参数量小到能够在网页端直接运行，仍然是一项令人惊叹的进步。 这意味着图片生成/图片理解的成本，正在进一步下降。而我们有机会在更多原本无法使用生图和图片理解功能的地方，看到 AI 的使用，改变我们的生活。 2024 年的一大热点，在于加入了多模态理解的 AI 硬件，能够如何介入我们的生活。而参数量越来越低的多模态理解模型，或者可以让我们期待能够在端侧运行的模型，能够让 AI 硬件进一步爆发。 DeepSeek 搅动新年，万事万物可以用中国 AI 重做一遍？ AI 世界一日千里。 去年春节前后，搅动世界的是 OpenAI 的 Sora 模型，而一年下来，中国公司已经完全在视频生成方面迎头赶上，让年尾 Sora 的发布显得有些暗淡了。 而今年搅动世界的，变成了中国的 DeepSeek。 DeepSeek 并不算传统的科技公司，然而用远低于美国大模型公司 GPU 卡和成本，做出了极其创新的模型，直接让美国同行感到震动——美国人纷纷感叹：R1 模型的训练，仅仅花费 560 万美元，甚至只相当于 Meta GenAI 团队任一高管的薪资，这是什么神秘的东方力量？ DeepSeek 创始人梁文峰直接在 X 上发布了一张有趣的图片： 图片使用了爆火的 2024 年全球爆火的土耳其射击选手的梗。 在法国巴黎奥运会射击项目混合团体 10 米气手枪决赛中，51 岁的土耳其射击男选手迪凯奇，仅佩戴了一副普通的近视眼镜和一对睡眠耳塞，便以单手插兜的潇洒姿态，稳稳地将银牌收入囊中。而在场的全部其他射击选手都需要两块聚焦和遮光的专业镜片和一副防噪声耳塞，才能开始比赛。 自从 DeepSeek「破解」了 OpenAI 的推理模型，美国各大科技公司开始背上了巨大的压力。今天，Sam Altman 也终于扛不住压力出来回应了一段官方发言。 2025 年，会是中国 AI 冲击美国认知的一年吗？ DeepSeek，手里还藏着什么秘密——这注定是个不平凡的春节。 举报/反馈"
    },
    {
      "doc_id": 50029,
      "title": "DeepSeek除夕狂飙大招:开源多模态掀翻全场!256张A100训两周碾压...",
      "time": "2024-01-29T00:00:00+00:00",
      "content": "新智元报道 编辑：Aeneas 好困 【新智元导读】DeepSeek除夕又放出重磅炸弹：多模态大一统开源模型Janus-Pro系列上线！其中，1.5B模型仅用了128颗英伟达A100训练一周，而7B也只是翻了个倍。 全世界瞩目之际，DeepSeek在除夕又有了新的动作。 就在昨夜，DeepSeek正式发布了集理解与生成于一体的多模态大模型Janus-Pro。 目前，相关代码和模型已完全开源。 论文地址：https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf 开源项目：https://github.com/deepseek-ai/Janus Janus-Pro采用了创新性自回归框架，并实现了多模态理解与生成的统一，是对去年发布的前代模型Janus的全面升级。 它通过将视觉编码解耦为独立的通道，克服了先前方法的局限性，同时仍然使用单一且统一的Transformer架构进行处理。这种解耦不仅缓解了视觉编码器在理解和生成方面的固有角色冲突，还显著提升了框架的灵活性。 结果显示，升级后的Janus-Pro在多模态理解和文生图能力上都实现了显著突破，同时文生图的稳定性也得到了提升。 与此同时，DeepSeek在训练上一如既往地只用了非常少的算力—— 1.5B和7B这两款模型，分别在配备16/32个计算节点的集群上进行，每个节点装配8张Nvidia A100（40GB）GPU，总训练时间约为7/14天。 网友实测 对于DeepSeek的又一个暴击，有评论道：「Janus-Pro-7B的发布，让它的影响力再次得到扩大的同时，强化了这一叙事——DeepSeek作为创新者，已经颠覆了AI世界的既定秩序。」 网友们纷纷预言，DeepSeek Janus-Pro-7B模型对整个AI世界生态系统来说，又将造成巨震。 甚至1B模型可以直接在WebGPU的浏览器中就可以运行。本地运行模型，只需访问网站即可！ 但在实际效果上，很多网友实测发现Janus-Pro的生图效果并不总是很理想。 左右滑动查看 当然，也有实测效果比较好的例子。 左右滑动查看 类似的，在图像理解方面，表现也是有好有坏。 完整论文解读 具体而言，Janus-Pro在以下三个方面进行了改进：（1）采用了优化后的训练策略，（2）扩充了训练数据集，以及（3）实现了模型规模的进一步扩展。 Janus作为一个创新性模型，最初在1B参数规模上完成了验证。但由于训练数据量受限且模型容量相对不足，导致它存在一些局限性，主要表现在短提示词图像生成效果欠佳以及文本生图质量不够稳定等方面。 针对这些问题，DeepSeek团队推出了升级版本Janus-Pro，在训练策略、数据规模和模型容量三个维度上都实现了重要突破。 Janus-Pro 系列提供了1B和7B两种参数规模的模型，充分展示了视觉编解码方法的可扩展性。 多个基准测试的评估结果表明，Janus-Pro在多模态理解能力和文本生图的指令执行性能方面都取得了显著进展。 具体而言，Janus-Pro-7B在多模态理解基准测试MMBench上达到了79.2的评分，超越了包括Janus（69.4）、TokenFlow（68.9）和MetaMorph（75.2）在内的现有最优统一多模态模型。 在GenEval文本生图指令执行能力排行榜上，Janus-Pro-7B获得了0.80的高分，显著优于Janus（0.61）、DALL-E 3（0.67）和Stable Diffusion 3 Medium（0.74）的表现。 模型架构 Janus-Pro架构的核心设计理念是，实现多模态理解和生成任务中视觉编码的解耦。与Janus保持一致。 具体而言，研究者采用独立的编码方法将原始输入转换为特征，随后通过统一的自回归Transformer进行处理。 Janus-Pro的架构 在多模态理解方面，研究者采用SigLIP编码器，从图像中提取高维语义特征。 这些特征首先从二维网格结构展平为一维序列，然后通过理解适配器将图像特征映射到大语言模型的输入空间。 在视觉生成任务中，他们使用VQ分词器将图像转换为离散ID序列。将这些ID序列展平为一维后，通过生成适配器将对应的码本嵌入映射至大语言模型的输入空间。 随后，他们将上述特征序列整合为统一的多模态特征序列，输入大语言模型进行处理。 除了利用大语言模型内置的预测头外，研究者还在视觉生成任务中引入了一个随机初始化的预测头用于图像预测。 整个模型采用自回归框架。 优化训练策略 Janus的前代版本采用了三阶段训练流程—— 第一阶段专注于适配器和图像头的训练；第二阶段进行统一预训练，期间除理解编码器和生成编码器外的所有组件参数都会更新；第三阶段进行监督微调，在第二阶段基础上进一步解锁理解编码器的参数进行训练。 然而，这种训练策略存在某些问题。 在第二阶段中，Janus参照PixArt的方法，将文本生图能力的训练分为两个部分：首先使用ImageNet数据集进行训练，以图像类别名称作为提示词来生成图像，目的是构建像素依赖关系；其次使用标准文本生图数据进行训练。 在具体实施中，第二阶段将66.67%的文本生图训练步骤分配给了第一部分。 但通过深入实验，研究者发现这种策略效果欠佳，且计算效率较低。为此，他们实施了两项重要改进： 阶段I延长训练时间：增加第一阶段的训练步骤，确保充分利用ImageNet数据集。研究表明，即使在大语言模型参数固定的情况下，模型也能有效建立像素依赖关系，并根据类别名称生成高质量图像。 阶段II集中重点训练：在第二阶段中，摒弃了ImageNet数据，转而直接使用标准文本生图数据来训练模型，使其能够基于详细文本描述生成图像。这种优化策略使第二阶段能够更高效地利用文本生图数据，显著提升了训练效率和整体表现。 此外，研究者还对第三阶段监督微调过程中的数据配比进行了调整，将多模态数据、纯文本数据和文本生图数据的比例从7:3:10优化为5:1:4。 通过适度降低文本生图数据的占比，可以发现，这种调整既保持了强大的视觉生成能力，又提升了多模态理解性能。 数据Scaling 在多模态理解和视觉生成两个方面，团队显著扩充了Janus的训练数据规模： • 多模态理解 在第二阶段预训练中，他们参考了DeepSeekVL2的方法，新增了约9000万个训练样本。这些样本包括图像描述数据集以及表格、图表和文档理解数据集。 在第三阶段监督微调中，他们进一步引入了DeepSeek-VL2的补充数据集，包括表情包理解、中文对话数据和对话体验优化数据集等。 这些数据的引入大幅提升了模型的综合能力，使其能够更好地处理多样化任务，并提供更优质的对话体验。 • 视觉生成 研究者发现，Janus早期版本使用的真实数据存在质量不高、噪声较大等问题，这往往导致文本生图过程不稳定，生成的图像美感欠佳。 为此，在 Janus-Pro 中，他们引入了约7200万个人工合成的高质量美学数据样本，使统一预训练阶段的真实数据与合成数据达到1:1的均衡比例。这些合成数据的提示词来源于公开资源。 实验结果表明，使用合成数据不仅加快了模型的收敛速度，还显著提升了文本生图的稳定性和图像的美学质量。 模型Scaling Janus的前代版本通过1.5B参数规模的大语言模型，验证了视觉编码解耦方法的有效性。在Janus-Pro中，研究者将模型规模扩展至7B参数量。 研究发现，在采用更大规模大语言模型后，无论是多模态理解还是视觉生成任务的损失值收敛速度都较小规模模型有了显著提升。 这一结果进一步证实了该技术方案具有优秀的可扩展性。 Janus和Janus-Pro的超参数设置 对比SOTA • 多模态理解性能 在表3中，研究者将本文提出的方法与当前最先进的统一模型和专用理解模型进行了对比。结果显示，Janus-Pro实现了整体最优性能。 这主要得益于在多模态理解和生成任务中实现了视觉编码的解耦，有效缓解了两项任务间的冲突。即便与参数规模显著更大的模型相比，Janus-Pro仍展现出强劲的竞争力。 例如，Janus-Pro-7B在除GQA外的所有基准测试中，都超越了TokenFlow-XL（13B）的表现。 • 视觉生成性能 研究者在GenEval和DPG-Bench两个基准上，评估了视觉生成性能。 如表4所示，Janus-Pro-7B在GenEval测试中达到了80.0%的整体准确率，优于所有现有的统一模型和专用生成模型，包括Transfusion（63.0%）、SD3-Medium（74.0%）和DALL-E 3（67.0%）。 这一结果充分证明了，这一方法具有更强的指令执行能力。 此外，如表5所示，Janus-Pro在DPG-Bench测试中获得了84.19分的优异成绩，领先于所有其他方法。 这表明Janus-Pro在执行复杂的文本生图指令方面具有卓越的表现。 定性分析 在图4中，研究者展示了多模态理解的测试结果。实验表明，Janus-Pro在处理不同场景下的输入时展现出卓越的理解能力，充分体现了其强大的性能优势。 在图4的下半部分，研究者展示了一系列文本生图的结果。 尽管输出分辨率仅为384×384，但Janus-Pro-7B生成的图像仍然展现出高度的真实感和丰富的细节表现。 特别是在处理具有想象力和创造性的场景时，Janus-Pro-7B能够准确理解提示词中的语义信息，并生成逻辑合理、内容连贯的图像。 然而，Janus-Pro当前仍然存在一些局限性。 在多模态理解方面，由于输入分辨率被限制在384×384，影响了模型在OCR等需要精细识别的任务上的表现。 在文本生图方面，较低的分辨率以及视觉Token编码器引入的重建损失，导致生成的图像虽然语义内容丰富，但在细节表现上仍有不足。 典型例子是当人脸区域在图像中占比较小时，往往会出现细节欠缺的情况。这些问题有望通过提升图像分辨率得到改善。 参考资料： https://github.com/deepseek-ai/Janus"
    },
    {
      "doc_id": 50034,
      "title": "DeepSeek深夜发布全新多模态大模型 性能碾压OpenAI",
      "time": "2024-01-29T00:00:00+00:00",
      "content": "快科技1月28日消息，爆火的国产大模型DeepSeek又放大招，今天凌晨突然发布Janus-Pro多模态大模型，进军文生图领域。 在GenEval和DPG-Bench基准测试中，Janus-Pro-7B不仅击败了OpenAI的DALL-E 3，还击败了Stable Diffusion、Emu3-Gen等热门模型。 Janus-Pro采用MIT开源协议，这意味着可无限制用于商业场景。 DeepSeek方面表示，该大模型是2024年11月13日发布的JanusFlow大模型的高级版本。 相比前代模型，Janus-Pro优化训练策略、扩展了训练数据，模型也更大。 得益于此，Janus-Pro在多模态理解和文本到图像的指令跟踪功能方面取得重大进步，同时还增强了文本到图像生成稳定性。 虽然Janus-Pro暂时只能处理384x384分辨率的图像，但考虑到模型如此“紧凑”却能达到如此水准，足以令人惊艳。 作为多模态模型，Janus-Pro不仅能文生图，还能对图片进行描述，识别地标景点，识别图像中的文字，并能对图片中的知识进行介绍。 举报/反馈"
    },
    {
      "doc_id": 50038,
      "title": "黄仁勋谈中国AI市场:中国创新的步伐,不可能被阻挡!",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "本文转自【央视新闻微信公众号】； 市值突破4万亿美元后亮相中国，穿唐装、中文演讲…… 近日，总台《面对面》栏目独家专访美国英伟达公司创始人兼首席执行官黄仁勋。他坦言，中国市场既有活力，又有创新能力，“是独一无二的市场”。采访中，他还特别提到了多位“中国的杰出朋友”。 “中国供应链体系数一数二 堪称世界级的奇迹” 7月16日，由中国贸促会主办的第三届中国国际供应链促进博览会在北京启幕，75个国家和地区的651家企业和机构齐聚一堂。首次参会的美国英伟达公司创始人兼首席执行官黄仁勋，在开幕式上发表了演讲。 链博会是全球首个以供应链为主题的国家级展会。在世界百年变局加速演进和国际形势变乱交织的大背景下，全球供应链承受重重压力，本届链博会的主题“链接世界、共创未来”，表达的正是在不确定性中实现共赢的愿景。 谈及全球供应链，黄仁勋表示，“中国运营着全球数一数二的供应链体系，它的规模、复杂性、多样性，制造商的产品类型、技术含量，参与建设中国供应链的企业数量，都堪称世界级的奇迹。”中国还为全球其他供应链提供设备、控制系统和零部件，说明中国不仅自己做供应链，还研发技术和产品帮别人做供应链。 黄仁勋介绍，供应链是把全球各地公司、各个国家的看家本领都整合起来。这样一来，最终产品的质量比任何企业单打独斗做出来的都要好。美国不可能独自生产所有产品，这既不现实也没必要。 本届链博会，美国参展商数量比上届增长15%，继续位列境外参展商数量之首。其中，首次参加链博会的英伟达带来了多款人工智能领域的解决方案，包括机器人仿真、数字孪生、大数据学习等。 英伟达安排了超过100名技术人员为来访者提供服务，而黄仁勋本人则是今年第三次到访中国。黄仁勋表示，在中国感到非常受欢迎，真心相信自己的客户和合作伙伴非常欢迎并重视自己。 黄仁勋力赞中国AI市场 “对中国创新能力充满信心” 就在此次来华之前，英伟达总市值在7月9日一度突破4万亿美元大关，成为全球首家市值超过4万亿美元的公司。在第三届链博会开幕前一天，黄仁勋公开宣布美国已批准H20芯片可以销往中国。 H20芯片是英伟达专门为中国市场设计的AI加速器，算力和性能与H100相比有缩减，适用于垂类模型的训练和推理，但无法满足万亿级大模型训练的需求。即便如此，美国还是在今年4月对H20出口中国下达了禁令，当时英伟达股价一度大跌近7%。 有人说H20没能满足中国市场需求，也有人担忧这可能会阻碍国内创新，对此黄仁勋分析道：“中国创新的步伐是不可能被阻挡的，当然我相信英伟达能做出重要贡献。” 记者提出假设，如果英伟达能根据中国市场实际需求，供应最新、最高端的芯片，谁会吃亏，谁会受益？ 对此，黄仁勋回应：“如果没有各种限制和挑战，创新和发明往往就不会出现。深度求索的R1、阿里巴巴的Qwen、月之暗面的Kimi，这些架构都是真正的创新，而这些创新常常诞生于受限的环境中，有压力才会迸发绝妙创意。最近这两三年，中国AI研究人员开发出了一些突破性的成果，这些成果与世界其他地方非常不同，这让我无比钦佩。” 黄仁勋尤其提到，不得不佩服深度求索（DeepSeek）这家公司的惊人创新能力，他们研发的R1模型是真正的创新。它重新设计了AI模型的很多运行方式，让它们能充分发挥H20架构的优势，这种做法非常有创意。所以尽管深度求索（DeepSeek）是基于H20构建的，但他们依然取得了世界一流的成果，这也说明研究人员和开发者们完全能够根据不同技术层面的特点进行调整。 黄仁勋：我对中国的创新能力充满乐观和信心，不管手头有什么资源都能适应。H20虽然不是英伟达最顶尖的产品，但能力依然非常出色。 黄仁勋今年5月曾表示，芯片限制措施已导致英伟达在中国的市场份额几乎减半。他在多个场合明确表达自己的观点，多次呼吁放宽技术出口限制，让美国企业能公平进入中国这个全球最大的半导体市场。 黄仁勋说，中国不是众多市场中的一个，而是一个独一无二的市场。这个市场的活力、创新能力、发展势头，以及产业的发展速度，都是绝无仅有的。 黄仁勋提到，这次到北京见了雷军，从小米创立之初就开始与雷军合作了，他们一起做过手机，现在正在共同开发人工智能、自动驾驶软件等项目。 黄仁勋表示，所有供应商都需要客户，而中国这个市场非常独特，绝对不能掉以轻心。不参与中国市场的意外后果和长期影响，虽然难以预测，但他怀疑结果不会乐观。 “华为是一家非凡的科技公司 对手不是敌人” 英伟达的诞生，源于黄仁勋抓住了计算机技术带来的一波机遇。 黄仁勋1963年出生在中国台湾，5岁随家人搬到泰国生活，10岁时离开泰国来到美国，获得斯坦福大学电子工程硕士学位后，于1993年创立英伟达公司。1999年，英伟达发明GPU，让实时可编程着色技术成为可能，这一技术也定义了现代计算机图形及后来革命性的并行计算。 在英伟达推动GPU大规模并行计算普及之前，主流计算架构主要依赖以CPU为基础的串行计算模式。当时也曾有不少企业尝试开发并行计算架构，但都失败了，初创的英伟达坚持把重心放在并行计算领域，最终，GPU成了英伟达的立业之基。 如今，英伟达成为了这个时代最主流的AI公司之一，但AI技术的发展同时引发激烈的竞争。根据第三方调研机构IDC的统计，自2023年至2024年，中国数据中心加速卡市场中，国产算力占比从14%激增到34.6%，这个数据显示的是中国进口芯片受到限制后，市场发生的变化。 黄仁勋介绍，如果英伟达公司不在这里，会有其他中国创新者、芯片公司为这个市场服务，很多云服务提供商也会自研芯片，中国也有很多创新型企业，比如华为公司，他说：“华为不仅极具创新力，它还是一家规模和实力非凡的公司，是一家拥有强大芯片设计能力、系统设计和系统软件的公司。” 黄仁勋坦言，中国的AI市场，无论有没有英伟达都会进步，如果英伟达不在这里，华为也一定能找到自己的解决方案。华为取得的成就完全值得尊重与赞赏，这是一家非凡的科技公司，只要他们决定专注并投入的领域，就一定能做好。从企业哲学、企业文化、挺过的难关、取得的成就和构建的事业来看，除了“非凡”这个词，找不到其他评价，他们的成就值得钦佩。 当谈及英伟达是将华为当作竞争对手还是合作伙伴的问题时，黄仁勋说：“这家公司依然极具竞争力，他们是我们的竞争对手，但仍然可以钦佩和尊重竞争对手，并与他们保持良好的关系，对手不是敌人。世界很大，我希望未来我们能继续竞争很多年，但我对他们的感情是钦佩、尊重，并且充满竞争意识。” “将AI、软件和机械系统融合 对中国来说是非常自然的能力” 7月17日，链博会的一场“炉边谈话”中，黄仁勋与之江实验室主任、阿里云创始人王坚院士展开了一场深度对话。话题从“图形处理器GPU”延伸到了“超级智能”、开源模型乃至AI与生物工程的融合。他们一同回顾人工智能的演进轨迹，也大胆展望下一次科技浪潮的源头。 黄仁勋曾说过所有会动的东西未来都可能机器人化，而现在已经实现了。 黄仁勋：我们看到中国遍地都是自动驾驶汽车，自动驾驶技术在这里的发展速度比任何地方都要快，小鹏、理想、蔚来、小米、比亚迪都有这项技术。所以将人工智能、软件和机械系统融合的能力，对中国来说是非常自然的能力，这对中国来说是个非凡的机遇。 近年来，英伟达持续扩大在华研发投入，分别在上海和北京设立AI创新中心，并与多家中国企业保持深度合作。据黄仁勋透露，英伟达在华员工规模已接近4000人，涵盖研发、销售、技术支持等多个领域。 从一家在游戏玩家中享有盛誉的显卡公司，到如今定义AI时代的算力基础设施引领者，转型路上，英伟达曾经有两次濒临破产。无论芯片还是AI，技术迭代的速度都极为迅猛，黄仁勋自称无法松懈也不敢松懈。 在英伟达的会议上，黄仁勋常以一句警示作为开场白：“我们公司离破产只有30天。” 工作中，他的严厉作风已成为鲜明特质，他坚信失败需要公开面对，因此会在公开场合指出具体错误，让团队共同引以为戒。然而生活中的他展现截然不同的一面，充满激情、活力四射、幽默风趣，几乎从不显露工作中的严厉。黄仁勋多次公开表示，他计划持续工作到80岁，甚至更长远。 本文来源：央视新闻微信公众号综合《面对面》 记者丨董倩 摄像丨王忠仁 王扬 高忠 陈朋 中国贸促会协助拍摄 举报/反馈"
    },
    {
      "doc_id": 50039,
      "title": "英伟达的“中国大客户”:千亿游戏产业争夺AI应用高地",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "来源：港股研究社 在全球科技产业加速重构的当下，英伟达CEO黄仁勋今年第三次访华，身着唐装亮相第三届链博会，并在演讲中提及了11家中国公司，其中就包括腾讯、网易、米哈游、游戏科学（《黑神话：悟空》开发者）、MiniMax等多家涉及游戏开发的公司。 这绝非偶然的寒暄，游戏产业确实让英伟达另眼相看。 游戏正从娱乐消费的赛道，跃升为人工智能应用的排头兵。对此，黄仁勋举例称：“今天的计算机图形表现得不可思议，例如《黑神话：悟空》。这部游戏中用到了许多AI，所以它如此美丽。” 在黄仁勋现身北京的同一时间，“原神之父”蔡浩宇远赴海外创立AI公司Anuttacon，悄悄上线了首款AI原生游戏《Whispers from the Star》的试玩Demo。该游戏Demo在Steam美区上线即引发热议，48小时内跻身地区免费热榜。 国际巨头掌舵人的重视，以及中国天才制作人的破界探索，传递出一个清晰的信号：在生成式AI重塑千行百业的当下，游戏，凭借其独特的复杂交互性、创意密集度与庞大的用户基数，正成为推开AI应用新世界大门的前沿力量，并被赋予了远超娱乐本身的技术突破与产业升级重任。 那么，在这场席卷全球的科技革命中，游戏公司如何把握时代机遇，成为千亿游戏产业变革的大赢家？ AI游戏，不再是选择题 中国游戏产业站在一个关键的十字路口。 中国游戏产业呈现螺旋式上升的状态。一方面，市场收入与用户规模双双创下新高，根据《2024年中国游戏产业报告》，2024年，国内游戏市场实际销售收入达到前所未有的3258亿元。但另一方面，用户规模增速逐渐缓慢，全球技术竞争加剧，人工智能、虚拟现实、实时渲染等技术正在重塑产业价值链，各大游戏厂商在存量时代迎来了更激烈的技术创新竞争。 图源：《2024年中国游戏产业报告》 这时，既能释放生产力，又能激发创意的“AI+游戏”，自然被寄予厚望。 这一产业趋势获得了政策的有力支持。北京、上海等核心城市近期出台的措施，都把支持游戏业拥抱AI作为发展“新质生产力”的重点。比如，6月19日，北京出台新政策加码扶持游戏电竞行业，明确提出，将支持企业在人工智能、游戏引擎、开发工具等关键领域加快布局，并对智能化技改项目给予最高3000万元奖励。 这股自上而下的推力，与市场自发的需求形成了共振。 如今，各大游戏厂商都在加大对AI技术的投入。比如，腾讯将DeepSeek大模型接入国民级手游《和平精英》，其数字代言人“吉莉”从静态形象跃升为能提供实时战术建议的智能助手；网易旗下伏羲实验室则在《逆水寒》中推出AI驱动的NPC“沈秋索”，尝试赋予角色更自然的交互能力。这些厂商目标明确，为已经成功的游戏注入新鲜感，留住玩家。 与此同时，米哈游创始人蔡浩宇海外创立的Anuttacon公司及其作品《Whispers from the Star》，更是演示了一种可能性：用AI智能体来构建动态叙事和深度情感交互的游戏，到底能玩成什么样？ 无论是改造旧作还是创造新形态，背后的逻辑是一致的。AI对于游戏产业的价值，正从“辅助工具”层面，升级为驱动业务增长和产品创新的核心要素。 行业开始意识到，AI是关乎未来竞争力的“基础设施”。谁能更早、更好地将AI融入自身基因，谁就更有可能在下一轮游戏中占据先机。那么，游戏业将如何重塑产品和生产模式？ “重新定义游戏”：从生产提效到体验革命 回顾历史，中国游戏产业历经引进代理、自主研发、出海扩张的几轮蜕变。 2001年盛大代理《热血传奇》点燃市场，2005年九城引入《魔兽世界》再掀热潮。本土研发力量随后崛起，腾讯、网易等企业形成产业集群效应。 近年来，头部厂商加速全球化布局，直至去年《黑神话：悟空》横空出世，这款现象级作品不仅成为文化输出的新名片，更让行业重新审视国产游戏的技术实力与商业价值，甚至间接推动相关政策完善，肯定游戏产业对前沿技术的应用价值。 如今，游戏厂商加速对以生成式AI为代表的技术运用，首先在游戏生产端展现出强大的势能，尤其是解决行业长期存在的效率瓶颈。 腾讯是这条“效率优先”路径的代表之一，战略重心明确地放在利用AI为游戏工业化进程赋能。 比如，腾讯游戏打造的“VISVISE”全链路解决方案，整合了Auto LUV、裙摆AI等自研工具，目标直指游戏开发效率的全面提升；不久前发布的“混元游戏视觉平台”聚焦于美术流程优化，而去年推出的游戏引擎GiiNEX更是宣称能将游戏资产创作效率提升40倍乃至百倍。根据相关研报显示，以《火影忍者手游》为例，通过强化学习训练AI，训练过程节省多达90%的时间和资源。 图：《火影忍者手游》 在腾讯这样的老牌游戏公司手中，AI的价值可以被形象地定位为处理“实习生级别”的大量重复、枯燥工作，例如自动化生成草图、批量产出剧情动画初稿等。这本质上是以AI解放人力，让核心创意人员专注游戏体验设计与商业模型打磨等决定产品灵魂的关键环节。 而在影响更为深远的游戏玩法和体验创新方面，大厂通常表现得更加“稳健”。比如，腾讯用AI助手“灵宝”取代传统助手“小妲己”，网易在热门游戏《蛋仔派对》中推出可智能对话的“艾比”和AI生物。这些创新带来了全新的体验，但并没有将AI深度融入游戏机制。 这是因为头部企业面对创新时需权衡更多复杂因素。相较之下，米哈游及其前CEO蔡浩宇独立创办的Anuttacon，则展现出更激进的姿态：押注于在新产品线上深度验证AI能力，探索“AI原生”的游戏形态。 米哈游今年对旗下三家AI相关子公司大幅增资超28亿元，同时BOSS直聘也显示其正在积极招聘AI游戏产运人才，显露出其在新赛道布局的决心。 而蔡浩宇新作《Whispers from the Star》更是展示了，人工智能如何从根基上重塑游戏的制造方式与核心体验。该游戏以聊天界面为核心交互方式，NPC“Stella”可根据玩家输入实时调整行为与剧情走向。 这意味着这款游戏实现了由AI对话深度主导的非线性叙事，让玩家获得高度个性化的故事体验。正如蔡浩宇所言，“0.0001%的精英”无疑更关注AI对游戏体验本身的颠覆性重构。 图：《Whispers from the Star》 当然，不可忽视的是，AI原生游戏的道路挑战重重。高昂的算力与数据传输成本、技术实现的复杂度，都是蔡浩宇选择剥离原有体系，创立新公司“死磕”创新的原因，也是腾讯等大厂目前采取更保守策略的深层考量之一。 无论如何，时代都需要不同风格的先行者去探路。这场由技术驱动的游戏产业变革，正沿着两条既并行又相互关联的轨道疾驰，一条是提升效率的生产力革命，为体验创新提供了成本空间和技术储备，另一条则是颠覆传统的体验创新，定义了AI游戏的未来吸引力和市场高度。 这两条道路无谓对错，只要中国游戏厂商坚定走下去，总会有人拿到那把游戏产业升级的钥匙。而游戏厂商们的探索，也是整个科技产业拥抱技术升级的缩影。 AI时代的应用战场，游戏成为创新引擎 2025年，人工智能已跨越单点技术突破阶段，进入系统能力升级的新周期。而游戏复杂的交互环境、海量的内容需求以及对沉浸体验的极致追求，天然构成了AI技术最理想的测试场。 从腾讯、网易、米哈游等头部企业对“AI+游戏”的探索不难看出，AI带来的不仅是游戏产业的生产力跃升，更推动着整个科技行业的基础逻辑转变。 正如黄仁勋在 NVIDIA 2025 财年可持续发展报告中所说：“AI智能体将彻底改变知识型工作”。游戏行业作为AI落地的排头兵，正在承担比单纯技术应用更重要的使命，那就是推广AI的技术思维模式。 比如，蔡浩宇创立的Anuttacon，并非一家纯粹的游戏公司，而是定位为一个AI驱动的“独立的研究实验室”。《whisper from the star》虽是一款游戏，但其志是以游戏为形式，借船出海，演练最新的AI技术。 图源：Anuttacon官网 蔡浩宇想做的事，其实早就写在《米哈游文化手册》中：“每次文化与娱乐体验的重要升级，都依托在技术革命的基础上。同样，现在人类所掌握的科技还不足以实现我们最终的目标，所以，我们需要研发新的科技来实现。” 这种以游戏为载体的技术探索，代表着一种“技术先锋思维”。而这种思维在当下至关重要。 一方面，BAT和Magnificent 7今年纷纷呢加大AI支出，说明全球科技公司正在竞逐AI产业高地，而技术创新力是重塑产业格局的核心力量。另一方面，从资本市场来看，本轮AI产业叙事正驱动港股科技的重估，中国科技公司正在迎来全面腾飞的关键窗口期。 谁能成为下个时代的王者？ 以英伟达为鉴，英伟达从“全球市值最低科技公司”成长为“最高市值科技公司”的历程，黄仁勋强调其核心贡献是“重新定义了计算”，从而在全球AI产业链中占据核心地位。 如今，AI“重新定义游戏”的过程，也是中国科技公司在AI时代重构竞争力的缩影。在这场重构中，谁能率先完成从技术应用到思维模式的全面升级，谁就有机会像腾讯、阿里、字节抓住移动互联网红利那样，成为新时代的领航者。 举报/反馈"
    },
    {
      "doc_id": 50040,
      "title": "黄仁勋最新表态:力赞DeepSeek、华为,谈与雷军合作",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "2025年7月16日，由中国贸促会主办的第三届中国国际供应链促进博览会在北京中国国际展览中心顺义馆如约启幕，75个国家和地区的651家企业和机构齐聚一堂。首次参会的美国英伟达公司创始人兼首席执行官黄仁勋，在开幕式上发表了演讲。 链博会开幕式上，黄仁勋没有穿他那件标志性的皮衣，而是身着唐装，并用中文开场演讲。 记者：一开始你用的是中文，然后就放弃了，最后又换回中文，为什么？ 黄仁勋：如果我全程用中文讲得花半个小时，太费时间了，而且我特别紧张。我的中文是在美国随便学的，自己学的。 链博会是全球首个以供应链为主题的国家级展会。在世界百年变局加速演进和国际形势变乱交织的大背景下，全球供应链承受重重压力，本届链博会的主题“链接世界、共创未来”，表达的正是在不确定性中实现共赢的愿景。 记者：不仅英伟达，全球企业都面临同样的问题，你认为，这次链博会能在多大程度上帮助企业？ 黄仁勋：中国运营着全球数一数二的供应链体系，它的规模、复杂性、多样性，制造商的产品类型、技术含量，参与建设中国供应链的企业数量，都堪称世界级的奇迹。中国还为全球其他供应链提供设备、控制系统和零部件，所以说中国不仅自己做供应链，还研发技术和产品帮别人做供应链。 在第三届链博会期间，中国贸促会发布了2025年版《全球供应链促进报告》以及全球供应链指数矩阵，相关数据表明，尽管世界经济当中不确定性、不稳定性因素正在持续增加，但是促进因素始终占据主流。 黄仁勋：全球供应链规模非常庞大，而且相互关联。英伟达一方面受益于一个极其精密、先进且技术含量极高的供应链，同时我们的供应链也是全球性的，我们在世界各地都有制造合作伙伴，而且为了构建我们的人工智能超级计算机，我们需要100到200家不同的技术合作伙伴为我们的产品提供支持。 黄仁勋介绍，供应链是把全球各地公司、各个国家的看家本领都整合起来。这样一来，最终产品的质量比任何企业单打独斗做出来的都要好。美国不可能独自生产所有产品，这既不现实也没必要。以前这叫生产制造，现在叫供应链管理，虽然生产仍是重要部分，但供应链整合非常复杂，堪称人类最伟大的发明之一。 本届链博会，美国参展商数量比上届增长15%。继续位列境外参展商数量之首。其中，首次参加链博会的英伟达带来了多款人工智能领域的解决方案，包括机器人仿真、数字孪生、大数据学习等。英伟达安排了超过100名技术人员为来访者提供服务，而黄仁勋本人则是今年第三次到访中国。黄仁勋表示，在中国感到非常受欢迎，真心相信自己的客户和合作伙伴非常欢迎并重视自己。 就在此次来华之前，英伟达总市值在7月9日一度突破4万亿美元大关，成为全球首家市值超过4万亿美元的公司。在第三届链博会开幕前一天，黄仁勋公开宣布美国已批准H20芯片可以销往中国。 H20芯片是英伟达专门为中国市场设计的AI加速器，算力和性能与H100相比有缩减，适用于垂类模型的训练和推理，但无法满足万亿级大模型训练的需求。即便如此，美国还是在今年4月对H20出口中国下达了禁令，当时英伟达股价一度大跌近7%。 记者：有人说H20没能满足中国市场需求，也有人担忧这可能会阻碍国内创新，对此你怎么看？ 黄仁勋：中国创新的步伐是不可能被阻挡的，当然我相信英伟达能做出重要贡献。AI是一个极其复杂的系统，除了芯片还有系统、网络技术、AI基础设施、软件、AI算法，以及最上层的应用服务。一方面AI的发展需要系统每一层的创新，但如果某一层进展不够快，工程师们足够聪明，他们可以通过上下层的创新来弥补，从而推动整个系统前进。 黄仁勋尤其提到，不得不佩服深度求索（DeepSeek）这家公司的惊人创新能力，他们研发的R1模型是真正的创新。它重新设计了AI模型的很多运行方式，让它们能充分发挥H20架构的优势，这种做法非常有创意。所以尽管深度求索（DeepSeek）是基于H20构建的，但他们依然取得了世界一流的成果，这也说明研究人员和开发者们完全能够根据不同技术层面的特点进行调整。 黄仁勋：我对中国的创新能力充满乐观和信心，不管手头有什么资源都能适应。H20虽然不是英伟达最顶尖的产品，但能力依然非常出色，正是这种架构定义，甚至可以说创造了现在的AI革命，所以即便放到今天它依然相当出色。 黄仁勋今年5月曾表示，芯片限制措施已导致英伟达在中国的市场份额几乎减半。他在多个场合明确表达自己的观点，多次呼吁放宽技术出口限制，让美国企业能公平进入中国这个全球最大的半导体市场。 记者：中国市场对你们有多重要？ 黄仁勋：中国不是众多市场中的一个，而是一个独一无二的市场。这个市场的活力、创新能力、发展势头，以及产业的发展速度，都是绝无仅有的。我们30年前就到中国了，那时候中国只有联想和长城这两家科技公司。我的很多老朋友都是一起在PC行业成长的。我要特别提到我在中国的几位杰出朋友：阿里巴巴、美团、腾讯、百度、小米、比亚迪。 黄仁勋提到，这次到北京见了雷军，从小米创立之初就开始与雷军合作了。 黄仁勋：我与雷军合作已经很久了。我们一起做过手机，现在正在共同开发人工智能、自动驾驶软件等等，还有很多项目正在合作。中国市场既有活力，又有创新能力卓越的优秀工程师，中国计算机科学家数量是全球最多的之一，唯一能与之比肩的只有美国，而且终端消费者群体规模极其庞大。 黄仁勋表示，所有供应商都需要客户，而中国这个市场非常独特，绝对不能掉以轻心。不参与中国市场的意外后果和长期影响，虽然难以预测，但他怀疑结果不会乐观。 英伟达的诞生，源于黄仁勋抓住了计算机技术带来的一波机遇。黄仁勋1963年出生在中国台湾，5岁随家人搬到泰国生活，10岁时离开泰国来到美国，获得斯坦福大学电子工程硕士学位后，于1993年创立英伟达公司。1999年，英伟达发明GPU，让实时可编程着色技术成为可能，这一技术也定义了现代计算机图形及后来革命性的并行计算。 在英伟达推动GPU大规模并行计算普及之前，主流计算架构主要依赖以CPU为基础的串行计算模式。当时也曾有不少企业尝试开发并行计算架构，但都失败了，初创的英伟达却坚持把重心放在并行计算领域，最终，GPU成了英伟达的立业之基。 如今，英伟达成为了这个时代最主流的AI公司之一，但AI技术的发展同时引发激烈的竞争。根据第三方调研机构IDC的统计，自2023年至2024年，中国数据中心加速卡市场中，国产算力占比从14%激增到34.6%，这个数据显示的是中国进口芯片受到限制后，市场发生的变化。 黄仁勋介绍，如果英伟达公司不在这里，会有其他中国创新者、芯片公司为这个市场服务，很多云服务提供商也会自研芯片，中国也有很多创新型企业，比如华为公司。 黄仁勋：华为不仅极具创新力，更是一家规模和实力非凡的公司。华为比我们大得多，从公司规模、人员规模和技术能力来看，他们既广又深。如果有人仔细看过华为手机，就会明白其中蕴含的技术奇迹。如果你看现在的华为，他们在自动驾驶领域非常出色，AI技术也相当卓越，这是一家拥有强大芯片设计能力、系统设计和系统软件的公司。 黄仁勋认为，中国的AI市场，无论有没有英伟达都会进步，如果英伟达不在这里，华为也一定能找到自己的解决方案。华为取得的成就完全值得尊重与赞赏，这是一家非凡的科技公司，只要他们决定专注并投入的领域，就一定能做好。从企业哲学、企业文化、挺过的难关、取得的成就和构建的事业来看，除了“非凡”这个词，找不到其他评价，他们的成就值得钦佩。 当提及英伟达是将华为当作竞争对手还是合作伙伴的问题时，黄仁勋说：“这家公司依然极具竞争力，他们是我们的竞争对手，但仍然可以钦佩和尊重竞争对手，并与他们保持良好的关系，对手不是敌人。世界很大，我希望未来我们能继续竞争很多年，但我对他们的感情是钦佩、尊重，并且充满竞争意识。” 7月17日，链博会的一场“炉边谈话”中，黄仁勋与之江实验室主任、阿里云创始人王坚院士展开了一场深度对话。话题从“图形处理器GPU”延伸到了“超级智能”、开源模型乃至AI与生物工程的融合。他们一同回顾人工智能的演进轨迹，也大胆展望下一次科技浪潮的源头。 记者：你曾说过所有会动的东西未来都可能机器人化，而且很快，有多快？ 黄仁勋：就是现在，我们看到中国遍地都是自动驾驶汽车，自动驾驶技术在这里的发展速度比任何地方都要快，小鹏、理想、蔚来、小米、比亚迪都有这项技术。所以将人工智能、软件和机械系统融合的能力，对中国来说是非常自然的能力，这对中国来说是个非凡的机遇。 近年来，英伟达持续扩大在华研发投入，分别在上海和北京设立AI创新中心，并与多家中国企业保持深度合作。据黄仁勋透露，英伟达在华员工规模已接近4000人，涵盖研发、销售、技术支持等多个领域。 从一家在游戏玩家中享有盛誉的显卡公司，到如今定义AI时代的算力基础设施引领者，转型路上，英伟达曾经有两次濒临破产。无论芯片还是AI，技术迭代的速度都极为迅猛，黄仁勋自称无法松懈也不敢松懈。 在英伟达的会议上，黄仁勋常以一句警示作为开场白：“我们公司离破产只有30天。” 工作中，他的严厉作风已成为鲜明特质，他坚信失败需要公开面对，因此会在公开场合指出具体错误，让团队共同引以为戒。然而生活中的他展现截然不同的一面，充满激情、活力四射、幽默风趣，几乎从不显露工作中的严厉。黄仁勋多次公开表示，他计划持续工作到80岁，甚至更长远。 中国新闻网 新闻，有温度；分享，是力量！ 4408篇原创内容 公众号 ， 来源：央视新闻客户端 原标题：《面对面丨“对中国创新能力充满信心” 黄仁勋谈中国市场独一无二》 编辑：朴丽娜 责编：王珊珊 中国新闻网 ，赞 3591 停课、停工、停产、停运、停业！非必要不外出！多地紧急通知 甘肃通报幼儿园餐食铅含量严重超标：6人被批捕，17人被立案审查调查 演员周渝民夫妇被闺蜜骗840万元，宣判了！ 举报/反馈"
    },
    {
      "doc_id": 50041,
      "title": "黄仁勋力赞DeepSeek,谈华为,聊中国市场……还称与雷军合作已经...",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "据央视新闻，市值突破4万亿美元后亮相中国，美国英伟达公司创始人兼首席执行官黄仁勋在接受总台《面对面》栏目采访时表示，中国是一个独一无二的市场。黄仁勋表示，AI是一个极其复杂的系统，中国的创新能力很惊人。他还称，中国AI市场无论有没有英伟达都会进步。他表示，中国供应链体系全球数一数二，堪称世界级的奇迹。 2025年7月16日，由中国贸促会主办的第三届中国国际供应链促进博览会在北京中国国际展览中心顺义馆如约启幕，75个国家和地区的651家企业和机构齐聚一堂。首次参会的美国英伟达公司创始人兼首席执行官黄仁勋，在开幕式上发表了演讲。 链博会开幕式上，黄仁勋没有穿他那件标志性的皮衣，而是身着唐装，并用中文开场演讲。 值得注意的是，除H20芯片解禁外，黄仁勋还宣布将推出新款RTX Pro显卡。这款产品聚焦计算机图形、数字孪生及人工智能领域，被视为英伟达深耕中国技术市场的又一重要布局。 在英伟达的会议上，黄仁勋常以一句警示作为开场白：“我们公司离破产只有30天。” 工作中，他的严厉作风已成为鲜明特质，他坚信失败需要公开面对，因此会在公开场合指出具体错误，让团队共同引以为戒。然而生活中的他展现截然不同的一面，充满激情、活力四射、幽默风趣，几乎从不显露工作中的严厉。黄仁勋多次公开表示，他计划持续工作到80岁，甚至更长远。 黄仁勋谈中国市场 市值突破4万亿美元后亮相中国，美国英伟达公司创始人兼首席执行官黄仁勋在接受总台《面对面》栏目采访时表示，中国是一个独一无二的市场。 图片来源：视频截图 黄仁勋：中国不是众多市场中的一个，中国是一个独一无二的市场。这个市场的活力、创新能力、发展势头，以及这个产业的发展速度，都是绝无仅有的。我们在这里已经30年了，早在大多数高科技公司来华之前，我就到中国了，那时候中国只有联想和长城这两家科技公司。 中国市场既有活力，又有创新能力卓越的优秀工程师，中国计算机科学家数量是全球最多的之一，唯一能与之比肩的只有美国，而且终端消费者群体规模极其庞大。这不是一个普通的市场，而是一个非常独特的市场。作为技术供应商，我们需要客户，所有供应商都需要客户，而这个市场非常独特，你绝对不能掉以轻心。 不参与中国市场的意外后果和长期影响，虽然难以预测，但我认为结果不会乐观。 记者：一开始你用的是中文，然后就放弃了，最后又换回中文，为什么？ 黄仁勋：如果我全程用中文讲得花半个小时，太费时间了，而且我特别紧张。我的中文是在美国随便学的，自己学的。 黄仁勋提到，这次到北京见了雷军，从小米创立之初就开始与雷军合作了。 黄仁勋：我与雷军合作已经很久了。我们一起做过手机，现在正在共同开发人工智能、自动驾驶软件等等，还有很多项目正在合作。中国市场既有活力，又有创新能力卓越的优秀工程师，中国计算机科学家数量是全球最多的之一，唯一能与之比肩的只有美国，而且终端消费者群体规模极其庞大。 黄仁勋表示，所有供应商都需要客户，而中国这个市场非常独特，绝对不能掉以轻心。不参与中国市场的意外后果和长期影响，虽然难以预测，但他怀疑结果不会乐观。 黄仁勋：华为不仅极具创新力，更是一家规模和实力非凡的公司。华为比我们大得多，从公司规模、人员规模和技术能力来看，他们既广又深。如果有人仔细看过华为手机，就会明白其中蕴含的技术奇迹。如果你看现在的华为，他们在自动驾驶领域非常出色，AI技术也相当卓越，这是一家拥有强大芯片设计能力、系统设计和系统软件的公司。 记者：你曾说过所有会动的东西未来都可能机器人化，而且很快，有多快？ 黄仁勋：就是现在，我们看到中国遍地都是自动驾驶汽车，自动驾驶技术在这里的发展速度比任何地方都要快，小鹏、理想、蔚来、小米、比亚迪都有这项技术。所以将人工智能、软件和机械系统融合的能力，对中国来说是非常自然的能力，这对中国来说是个非凡的机遇。 黄仁勋谈中国AI市场 黄仁勋表示，中国AI市场无论有没有英伟达都会进步。 黄仁勋：如果有人仔细看过华为手机，就会明白其中蕴含的技术奇迹。如果你看现在的华为，他们在自动驾驶领域非常出色，AI技术也相当卓越，这是一家拥有强大芯片设计能力、系统设计和系统软件的公司。 图片来源：视频截图 如果我们不在这里，会有中国创新者、芯片公司和华为为这个市场服务，很多云服务提供商也会自研芯片。所以我认为中国AI市场，无论有没有英伟达都会进步，如果我们不在这里，华为也一定能找到自己的解决方案，这是我对人类创新能力的信心，有志者事竟成。 黄仁勋力赞DeepSeek 黄仁勋在接受采访时表示，AI是一个极其复杂的系统，中国的创新能力很惊人。 图片来源：视频截图 黄仁勋：中国创新的步伐是不可能被阻挡的，当然我相信英伟达能做出重要贡献。AI是一个极其复杂的系统，就像多层蛋糕一样复杂，我们的芯片只是底层，上面还有系统、网络技术、AI基础设施、软件、AI算法，以及最上层的应用服务，整个系统异常复杂。一方面AI的发展，需要这个系统每一层的创新，但如果某一层进展不够快，工程师们足够聪明，他们可以通过上下层的创新来弥补，从而推动整个系统前进。 这正是为什么你不得不佩服深度求索这家公司的惊人创新能力，他们研发的R1模型是真正的创新，它重新设计了AI模型的很多运行方式，让它们能充分发挥H20架构的优势，这种做法非常有创意。所以尽管是基于H20构建的，他们依然取得了世界一流的成果，这也说明研究人员和开发者们完全能够根据不同技术层面的特点进行调整。 我对中国的创新能力充满乐观和信心，不管手头有什么资源他们都能适应。H20虽然不是英伟达最顶尖的产品，但能力依然非常出色，正是这种架构定义，甚至可以说创造了现在的AI革命，所以即便放到今天它依然相当出色。 黄仁勋谈中国供应链体系 谈到全球供应链时，黄仁勋表示，中国供应链体系全球数一数二，堪称世界级的奇迹。 黄仁勋：中国运营着全球数一数二的供应链体系，它的规模、复杂性、多样性，制造商的产品类型、技术含量，参与建设中国供应链的企业数量，都堪称世界级的奇迹。 中国还为全球其他供应链提供设备、控制系统和零部件，所以说中国不仅自己做供应链，还研发技术和产品帮别人做供应链。因为全球供应链正日益多元化，甚至可以说正变得越来越冗余，这其实给中国带来巨大的机会，把自己的供应链制造技术推广到全球，因为世界各地都在新建供应链和生产线。 但有一点不会改变，无论发生什么，全球供应链根本不存在彻底脱钩的可能性。整个体系太复杂了，永远都会相互关联，这种关联也是大家需要的，这正是供应链最妙的地方。 以当今各行业的复杂程度而言，我们根本无法想象一个供应链体系不相互关联、不相互依存的世界，这种相互依存不仅是必要条件，更是良性状态，它能增强我们的抗风险能力。虽然我们在中国的生产规模不大，但我们服务的很多客户、技术合作伙伴，都是在中国的供应链中。 每日经济新闻综合央视新闻 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 50049,
      "title": "Deepseek “严重烂尾”?英伟达再创历史新高!说好的“东升西落”呢?",
      "time": "2024-07-06T00:00:00+00:00",
      "content": "最近Deepseek的关注度正持续下降！有数据显示，Deepseek的用户活跃度从春节高点的15%一路滑到目前的3%。 Deepseek的R2升级版难产，网络上多了不少对Deepseek的吐槽，对于稍微敏感一些的问题，它就开始“沉默”…… 而一度被Deepseek“威胁”的英伟达股价再创新高，突破160美元，市值逼近4万亿美元，碾压苹果历史峰值，AI芯片霸主地位无人撼动。 反观A股，“东升西落”成了银行股的独角戏，科技基金被迫“挂羊头卖狗肉”，重仓银行股撑场面。寒武纪们还在苦苦追赶，CUDA生态壁垒却让英伟达的“超级螺旋”越转越快。 大A的“银伟达”们扛着指数冲锋，但若科技赛道迟迟不接棒，这波行情能走多远？ 全球AI盛宴，我们真的只能旁观？说好的“东升西落”呢？ Deepseek为啥凉凉？ 根据之前的《The Information》独家爆料，DeepSeek R2原计划今年5月推出，但现在依然没有动静，也不能怪大家有质疑。 相关消息，核心原因竟是创始人梁文峰对模型性能“不满意”。那么这个“不满意”到底有多不满意？是不敌OpenAI o3，还是对比R1没有多少突破？ 此外，有国内知情人士的消息称，R2研发进程缓慢可能是由于缺少英伟达H20芯片。要知道R1的训练总计耗费了3万块H20（国内特供版）、1万块H800和1万块H100。所以在H20吃紧的情况下，预计耗费更多算力资源的R2难免受到波及。事实上，这不是R2第一次被曝项目延期了，最早能追溯到今年4月份。 不仅仅是Deepseek的升级版难产，同时网络上多了不少对Deepseek的吐槽。 有数据显示，Deepseek的用户活跃度从春节高点的15%一路滑到目前的3%，基本跟凉凉画等号。 有人说功能bug多，有人吐槽反应慢，还有人直接甩一句不好用，卸了。这感觉就像点了个外卖，菜单上写着五星级牛排，结果送来一盘嚼不动的牛腱子。你说气不气？ 更有资深人士称，deepseek已经严重烂尾。其逻辑是： 现在的deepseek有非常强大的过滤器，一问到什么负面或者敏感议题，经常回撤答案，仿佛意识到自己泄露了什么机密。它的沉默，震耳欲聋。一个失去灵魂的传声筒，就只是一个高级点的聊天玩具罢了。看似智能，实则在构建全新的愚昧系统。你永远叫不醒一个装睡的ai。 为什么一度将英伟达吓出了冷汗的国产之光，会沦落到今天这个模样？为什么deepseek成为一个自我阉割只报喜不报忧的乖宝宝？背后值得深思。除了自我阉割外，deepseek还严重烂尾。早期DeepSeek是通过蒸馏ChatGPT的回答体系，答案质量非常高。 但是开源之后，接入的是简中互联网，被喂进去了成千上万的营销软文，标题党和阴谋论。吃进去的是垃圾，吐出来的也只能是垃圾。然后AI还会继续吃自己生产出来的内容，成了信息污染闭环。所以现在经常发现，deepseek会将小说变成历史，童话变成报告，信任一夜崩塌。 英伟达股价再创历史新高 本周，全球人工智能芯片龙头英伟达股价触及160.98美元的历史新高，市值随之突破3.92万亿美元，市值超过苹果公司在2024年12月26日收盘价创下3.915万亿美元的历史新高。 近期英伟达股价呈现波动上涨趋势。6月以来，英伟达股价累计上涨了17.92%。今年年初至7月3日，英伟达股价累计上涨了18.67%。 春节之后和清明之后，英伟达一度迎来两大冰点，现在马后炮回头来看，那时候都是绝好的买点。 英伟达股价与市值不断上涨，主要归因于其在人工智能领域的领先地位。当下，全球对于AI芯片的需求呈井喷式增长，无论是科技巨头们建立人工智能数据中心，还是新兴科技企业进行模型训练与推理，均对英伟达高端处理器有高需求。 更重要的是，其全球垄断地位没有受到后来者的挑战。 从业绩看，在5月底公布的最新季度财报中，英伟达业绩还在增长。英伟达2026财年第一季度营收440.62亿美元，同比增长69%，净利润187.75亿元，同比增长26%。其中，数据中心业务收入达391亿美元，同比增长73%，Blackwell架构芯片占数据中心收入近70%，显示英伟达已推动AI芯片从Hopper架构向Blackwell架构过渡。 此外，在上周的英伟达股东大会上，英伟达CEO黄仁勋则谈到市场对算力的需求还在增长。他表示，推理需要更多计算。仅在过去一年时间里，tokens（词元）生成就激增了50到100倍。为了满足这种指数级的激增，大型人工智能工厂正在各地崛起。仅微软在上个季度就处理了超过100万亿的tokens，是一年前的5倍。 黄仁勋还表示，公司在多个领域都有增长机会，人工智能和机器人技术是最大的两个机会，代表着数万亿美元级别的增长机会。未来将有数十亿台机器人、数亿辆自动驾驶汽车和数十万个机器人工厂，它们都将由英伟达的技术驱动。 这两天，之前被嘲笑的但斌又跳出来了，其演讲称，人工智能的最大受益者是谁？毫无疑问就是类似于英伟达，Meta等相关的这样一些公司。要投“轻资产、高盈利”的商业模式。 要怎样去赚到100倍呢？一定要用产业的眼光，要用10年、20年、30年的眼光。互联网的周期大概是30年，智能手机也20年了。从长视角看，我们仅仅处于AI爆发的第一天，一切就是刚刚开始。如果我们能够活到像芒格，像巴菲特的年龄，如果再从业四十年，是有可能产生一个奇迹的。但是这个奇迹一定是我们扎根中国，放眼全球，从全球的角度，跟全世界最伟大的企业共同成长，这样可能性会更大一点。 说好的“东升西落”呢？ 2025年年初之后，市场一直渲染“东升西落”的叙事，但股市做出了最诚实的回答。 科技资产依然是一地鸡毛，A股还没有看到能够扛打的AI公司、机器人公司。“东升”升的只是银行等少数资产。 不少名为“XX科技”、“XX智能”的科技策略基金重仓的都是银行股，有些搞笑和讽刺。或许是他们在大A真找不着能买的科技股了吧？ 在人工智能和科技领域投资上，我们的确应该要学习但斌放眼全球的眼光和思路。 据目前来看，英伟达在AI芯片领域的垄断地位已形成“超级螺旋”效应。其Blackwell架构芯片占数据中心收入近70%，H20、H100等高端产品在算力性能、能效比和生态兼容性上全面领先。 反观国内企业，尽管华为昇腾、寒武纪等企业加速追赶，但技术差距依然显著。例如，寒武纪2025年第一季度虽实现营收激增，但其核心产品仍需依赖传统业务支撑，真正的AI芯片商业化落地仍需时间。 更关键的是，英伟达通过CUDA生态构建了不可替代的软件壁垒，开发者社区和合作伙伴网络形成强大的协同效应，而国内企业在生态建设上仍处于早期阶段。 上周五，又是银行股大放异彩的一天，工商银行、浦发银行、中信银行、兴业银行等9股同日创出历史新高。年内而言，东方财富Choice数据显示，有15只银行股刷出过历史新高，占42只银行股的35.7%。42只银行股的涨跌幅中位数为18.7%同期沪深300指数涨1.2%。板块最新市值15.96万亿元，较2024年末的13.58万亿元增加2.38万亿元。 具体而言，浦发银行是年内最能涨的银行股，涨幅为41.69%。青岛银行、兴业银行、浙商银行、江苏银行年内也上涨超过30%。对此，有股民戏谑，“别涨了，我买还不行嘛”。还有股民将银行称之为“银伟达”“银斯达克”。 为什么这一两年来，他们要死顶银行？ 其实道理很简单：第一就是必须要死命护住3000点一线，经济下行，大家都难的时候，一定要先靠指数稳定住局面；第二也就是XX队买银行更放心，更能从容KZ指数。 就大A短期走势来说，银行是稳住指数，但后面要看题材股、赛道股能否走出赚钱效应，否则就要小心了。 附件：A股一周重要交易数据 1、500亿市值以上公司本周涨幅TOP5 2、100-500亿市值以上公司本周涨幅TOP5 3、100亿以下市值公司本周涨幅TOP5 4、本周跌幅TOP10 本文源自：价值线 举报/反馈"
    },
    {
      "doc_id": 50060,
      "title": "全球首个,最接近原版DeepSeek开源复现来了!R1四个月狂飙26倍",
      "time": "2024-05-09T00:00:00+00:00",
      "content": "编辑：Aeneas 好困 【新智元导读】近日，来自SGLang、英伟达等机构的联合团队发了一篇万字技术报告：短短4个月，他们就让DeepSeek-R1在H100上的性能提升了26倍，吞吐量已非常接近DeepSeek官博数据！ DeepSeek的含金量还在上升。 就在最近，Hugging Face联创、首席科学家Thomas Wolf表示—— DeepSeek的出现，是开源AI领域的ChatGPT时刻！ 用他的话说，「正如ChatGPT让全世界认识到AI的存在，DeepSeek则让全世界意识到，原来还有着这样一个充满活力的开源社区。」 DeepSeek-R1的性能已经媲美甚至超越美国最顶尖的闭源AI模型，对于全球AI圈来说，这件事的意义都极其深远。 与此同时，来自SGLang、英伟达等机构的数十人联合团队，也在DeepSeek上整了个大活。 在短短4个月内，他们利用最新的SGLang推理优化，直接让DeepSeek-R1在H100上的性能提升了26倍！ 这是怎么做到的？ 团队发布了长篇博文，详细展示了这一过程。 文章地址：https://lmsys.org/blog/2025-05-05-large-scale-ep/ 在96块H100 GPU上优化部署DeepSeek 要知道，DeepSeek模型因为庞大的参数，以及多头潜注意力（MLA）和专家混合机制（MoE）等独特架构，如果想要大规模部署，就必须使用更先进的系统。 为此，团队先是对SGLang进行了全面升级，完整支持了PD分离、大规模EP、DeepEP、DeepGEMM及EPLB等功能。 然后凭借这些新特性，成功地在12个节点共96块GPU的集群上，复现了DeepSeek的推理系统。 最终，在处理2000个token的输入序列时，实现了每个节点每秒52.3k输入token和22.3k输出token的吞吐量。 方案运行在Atlas Cloud的12个节点上，每个节点均配备8块H100 GPU 团队表示，这应该是首个吞吐量接近DeepSeek官方数据的开源实现。 在本地环境下部署此方案，成本可降至0.20美元/1M输出token，约为DeepSeek Chat API官方定价的五分之一。 相较于使用相同资源的原始张量并行策略，此优化方案可将输出吞吐量提升高达5倍。 接下来，团队深入探讨了他们的并行设计、优化方法以及最终成果。 并行设计 高效的并行化设计，对于控制DeepSeek架构的计算复杂度和内存需求至关重要。 针对以下关键组件，团队都给出了优化方案：注意力层、稠密前馈网络（FFN)、稀疏FFN以及语言模型（LM）的头部。 每个组件都采用了专门设计的并行化策略，以提升可扩展性、内存效率和整体性能。 注意力层 DeepSeek采用了多头潜注意力机制（MLA)，从而能够有效地对输入序列中的复杂依赖关系进行建模。 为了优化这一机制，团队实现了DP attention，这是一种数据并行策略，目的是消除跨设备的KV缓存冗余，从而显著降低内存开销。 在SGLang v0.4版本中引入的该方法，现已扩展至支持混合数据并行和张量并行，为高效处理小批量数据提供了更大的灵活性。 稠密FFN 即便DeepSeek-V3仅使用了三个稠密FFN层，其计算过程仍然可能显著增加峰值内存占用，若不加以谨慎管理，极易导致系统崩溃。 为了解决这个问题，团队选择采用数据并行（DP）策略，而非张量并行（TP)，主要是考虑到DP的以下优势。 · 更强的可扩展性 当中间层维度为18,432时，较高的TP度（例如TP32）会导致数据被低效地分割成小单元片段（例如576个单元），而这些单元无法被128整除。 128，就是现代GPU（如H100）常见的对齐边界。 这种未对齐的情况，会严重阻碍计算效率和内存利用率。 相比之下，DP能够避免数据碎片化，从而提供更具可扩展性的解决方案，确保跨设备的工作负载均衡分配。 · 优化的内存效率 传统观念认为，TP可以随着worker size的增加而降低内存使用量，但这种优势在DP attention的应用场景下会逐渐减弱。 在纯TP设置中，单层Transformer模型的内存需求与DP size的关系如下： 其中， 是每个设备（DP rank）上隐藏状态的大小， 是模型参数的数量，k是一个系数，表示来自CUDA Graph复制的额外内存开销。 通过假设DP=TP，当 时，此内存的使用函数达到最小值。 DeepSeek-V3使用18,432的中间大小。在prefill阶段，CUDA Graph通常被禁用，因此k=0。 但是，每个设备的token大小很容易超过2,048，导致最佳TP大小为3或更小。 在解码阶段，一个实际的配置可能使用每个设备128个token，并设置k=3。在这种情况下，内存最佳的TP大小为6。 在这两个阶段，较低的TP度可以最大限度地减少每个设备的内存使用量。 因此，与仅依赖TP相比，DP可以提供更节省内存的扩展方法。 · 最小化的通信开销 在纯TP模式下，每个FFN层都需要执行两次all-reduce操作，从而导致巨大的通信开销。 通过采用DP策略，团队将该过程优化为：在先前的attention层之后执行一次reduce-scatter操作，并在下一个attention层之前执行一次all-gather操作，从而将通信成本降低50%。 更进一步，如果attention计算也采用纯DP模式，那么设备间的通信将被完全消除，进而显著提升整体效率。 DP稠密FFN与DP attention的集成方案如下图左侧所示。用户可以通过设置--moe-dense-tp-size=1来启用。 稀疏FFN 在DeepSeek-V3的MoE架构中，稀疏FFN需要处理大量的专家权重，进而造成显著的内存瓶颈。 为了缓解这一问题，团队采用了专家并行（EP）策略，将专家权重分散到多个设备上。 这种方法能够有效地扩展内存容量，不过，它在维持高性能的同时，也带来了一些新的挑战，比如不规则的全互联通信以及工作负载不均衡等。 团队利用DeepEP框架实现的EP方案 LM头 LM头（LM Head）负责计算大型词汇表上的输出概率，这是一项资源稠密型的操作，传统方案是采用词汇表并行技术，从TP组中聚合token logits。 为了进一步提升可扩展性和效率，团队采用了数据并行（DP）策略，与处理稠密FFN的方法保持一致。 这种做法不仅可以降低内存开销，还能简化跨设备的通信过程，从而提供了更加精简的解决方案。 预填充和解码分离 LLM的推理过程主要包含两个不同的阶段：预填充（prefill）和解码（decode)。 预填充阶段属于计算密集型，需要处理完整的输入序列；而解码阶段则属于内存密集型，主要负责管理用于生成token的KV缓存。 传统方案通常在一个统一的引擎中处理这两个阶段，然而，这种预填充和解码batch的混合调度方式会引入效率问题。 为了解决这些挑战，团队在SGLang中引入了预填充和解码（PD）分离技术。 如下图所示，SGLang会通过预填充服务器和解码服务器的协同工作，实现两个阶段的交错执行。 接收到输入请求后，系统的工作流程如下： 预填充服务器和解码服务器通过握手配对，各自作为本地发送者和接收者。 解码服务器预先分配KV缓存，并通知预填充服务器启动模型前向传递，计算KV缓存。 完成计算后，数据将被传输至解码服务器，由该服务器负责进行迭代式的token生成。 这种分离机制确保了每个阶段都能在最佳状态下运行，从而最大限度地利用GPU资源。 并且，为了进一步提升性能，团队的实现方案还包含以下特性。 非阻塞传输：数据发送和接收操作在后台线程中执行，从而保证调度器的事件循环不会被中断。 基于RDMA的传输：远程直接内存访问（RDMA）技术利用队列对（Queue Pairs）进行连接管理，并利用分散-聚集元素（Scatter-Gather Elements, SGE）实现非连续内存块的高效传输。 灵活的API集成：SGLang提供了高度可定制的API，能够与Mooncake和NIXL等高性能RDMA库无缝集成，从而简化了数据传输流程。 大规模专家并行性 基于DeepEP的专家并行 由DeepSeek团队开发的DeepEP提供了一系列优化过的通信内核，可以有效降低延迟并提升吞吐量，高效地将token路由到多个GPU上。 DeepEP有两种专门设计的调度模式，以满足不同的工作负载需求。 标准调度模式（Normal Dispatch）：主要针对处理较长的输入序列进行优化，例如预填充阶段，其首要目标是最大化计算吞吐量。 但会生成与CUDA Graph不兼容的符号形状，从而降低其在解码阶段的效率，因为在解码阶段，内核启动开销会成为一个显著的瓶颈。 低延迟调度模式（Low-Latency Dispatch）：专门为解码阶段生成输出token而设计，其核心目标是最小化延迟，从而确保实时性能。尽管它支持CUDA Graph，但需要预先分配固定大小的内存。如果实际内存需求超过了预分配的容量，则会触发运行时错误。 在SGLang中，DeepEP的集成提供了一种自动模式，能够根据当前的工作负载，动态地在上述两种调度模式之间进行选择。 与此同时，通过利用PD分离技术，使得在DP attention机制下，预填充阶段能够采用标准调度模式（Normal Dispatch)，而解码阶段则能够采用低延迟调度模式（Low-Latency Dispatch)。 这种集成方式能够根据每个阶段的具体需求来调整调度模式，从而优化资源利用率，并提升整体性能。 DeepGEMM集成 由DeepSeek团队开发的DeepGEMM，则被用于优化MoE模型中的计算过程。 DeepGEMM提供了两个经过专门设计的函数，用于处理与MoE相关的矩阵乘法运算（分组GEMM），每个函数都针对推理过程的不同阶段进行了定制。 分组GEMM（连续布局）： 这种内核专门为动态输入形状而设计，使其成为MoE推理预填充阶段的理想选择。 它可以处理来自不同专家的输入数据，这些数据以连续的方式连接在一起，从而灵活地处理各种输入尺寸的变化。 分组GEMM（掩码布局）： 这种内核假定输入形状是固定的，并使用掩码张量来仅计算输入的有效部分。 由于它与CUDA Graph兼容（可优化内核启动过程），因此特别适合于需要显著降低开销的解码阶段。 DeepGEMM与DeepEP的调度模式可以实现无缝集成： 对于与预填充阶段的标准调度模式配合使用的连续布局内核，需要执行一个额外的步骤。团队参考了LightLLM项目，并实现了一个自定义的Triton内核来实现高效的置换。确保了从标准调度模式输出的数据能够被正确地重新排列，从而实现与连续GEMM内核的平滑集成。 掩码布局内核与DeepEP的低延迟调度模式能够实现无缝对接，因为两者都针对解码阶段进行了专门优化，并且都支持CUDA Graph。 SGLang集成了DeepGEMM，用于在张量并行模式下进行MoE计算。通过在SGLang中设置环境变量SGL_ENABLE_JIT_DEEPGEMM为1，即可激活该内核，从而为非MoE操作提供更高的计算效率。 双batch重叠 在多节点环境下，有限的通信带宽可能会显著增加整体延迟。 为了应对这一挑战，团队遵循DeepSeek的系统设计理念，实现了双batch重叠（TBO）技术。 TBO将单个batch拆分为两个micro-batch，从而允许计算和通信过程相互重叠，同时，通过将有效batch大小减半，也降低了峰值内存的使用量。 为了创建更易于维护和重用的代码库，团队采用了一个由操作和yield点构成的抽象层。 这种方法可以让用户像处理单个micro-batch一样编写代码，同时通过策略性地插入yield点来暂停执行，从而允许其他micro-batch继续进行。 如此一来，不仅消除了代码重复，减少了对变量后缀的需求，并且还能有效地管理某些执行在层末尾完成而其他执行尚未完成的情况。 此外，抽象层还能轻松地适应不同的重叠区域选择，或者未来的增强功能，例如三batch重叠，而只需要进行极少的代码修改。 operations = [ self._forward_attn, YieldOperation(), # Pause execution for other micro-batches self._forward_dispatch, self._forward_mlp, YieldOperation(), # Another pause point self._forward_combine, ]# Process a single micro-batch without duplicating codedef _forward_attn(self, state): state.hidden_states = self.self_attn(state.hidden_states, ...) 团队优化了预填充阶段的启动顺序，以避免通过DeepEP中的调度操作阻塞CPU，即使用的是其异步模式。 具体来说： 在GPU从其他rank接收到元数据，从而能够正确分配大小合适的张量之前，调度操作会阻塞CPU。 不正确的实施方式会导致在此期间计算流处于空闲状态，因为没有计算任务被提交给GPU。 为了实现优化，团队优先将计算任务提交给GPU，然后再启动可能导致CPU阻塞的通信操作。这样可以确保GPU在通信期间保持活跃状态。 如下图所示，通过采用正确的启动顺序，TBO可以避免由CPU阻塞操作引起的性能瓶颈。 专家并行负载均衡器 为了解决由专家并行（EP）引起的各个GPU工作负载分布不均匀的问题，DeepSeek开发了专家并行负载均衡器（Expert Parallelism Load Balancer, EPLB)。 EPLB以专家分布的统计信息作为输入，计算出专家的最佳排列方式，从而最大限度地减少不平衡现象。 用户可以分配冗余专家（例如，增加32个专家），这些冗余专家与原有的256个专家组合在一起，形成一个包含288个专家的资源池。 借助这个资源池，EPLB能够策略性地放置或复制专家——例如，多次复制最常用的专家，或者将使用频率适中的专家与在单个GPU上很少使用的专家组合在一起。 除了平衡工作负载之外，EPLB还在并行设计方面提供了更大的灵活性。如果使用最初的256个专家，并行规模只能被限制为2的幂次方。而EPLB通过使用288个专家，能够实现更多样化的配置，例如将并行规模设置为12或72。 在下图中，团队展示了系统规模和EPLB算法对不平衡问题的影响。 他们将GPU的平衡度，定义为GPU中MoE层的平均计算时间与最大计算时间之比，并使用GPU处理的token数量来估计其计算时间。 从图中可以看出，当系统随着节点数量的增加而扩展时，GPU的利用率会降低，而启用EPLB则可以显著提高了GPU的利用率。 EPLB在实际服务中的应用 为了使EPLB能够有效发挥作用，输入数据的分布必须与实际服务的工作负载高度吻合。通过以下两种策略，可以增强这种吻合度： 增加batch大小：更大的batch可以减少专家使用过程中的随机波动，从而提高负载均衡的效果。这一目标可以通过扩展集群规模或者采用多token预测（MTP）等技术来实现。 定期进行重新平衡：定期更新专家的排列方式可以利用时间局部性原理，但这需要高效地重新加载专家模型。因此，需要尽可能降低专家模型重新加载操作的成本。 即使采用了EPLB，一定程度的不平衡现象仍然难以避免，未来仍需进一步优化。 重新平衡的具体实施方案 SGLang通过三个阶段的重新平衡操作，来确保既高效又不会造成中断，进而在权重更新期间维持系统的性能。 系统加载阶段：可以选择从磁盘预加载权重数据到主内存中，以加快重新平衡的速度；也可以选择将权重数据保存在磁盘上，并使用内存映射（memory mapping, mmap）技术，从而减少内存的占用量。 重新平衡准备阶段：所需的权重数据会在后台异步传输到设备内存中，利用空闲的DMA硬件引擎，从而避免中断正在进行的GPU操作。 重新平衡执行阶段：通过设备到设备的数据复制来更新权重数据。还可以通过物理内存重绑定等技术来进一步优化这一步骤。 评估 为了突出使用的先进优化技术带来的吞吐量提升，团队使用DeepSeek-V3模型，在一个包含12个节点的集群上，对 SGLang 的不同配置进行了端到端性能评估。 他们比较了以下四种不同的配置： SGLang（采用TP16x6） SGLang（采用PD分离） SGLang（采用PD分离和模拟MTP） DeepSeek的结果 为了适应不同的工作负载需求，团队分别独立地评估了预填充阶段和解码阶段的性能。 评估结果总结如下： · 预填充阶段：在4个节点的配置下，对于prompt长度分别为1K、2K和4K的情况，系统所实现的单节点吞吐量分别为每秒57,674、54,543和50,302个token。 如下图所示，与TP16基线相比，这种配置实现了高达3.3倍的性能提升。 在假设工作负载完全平衡的前提下，此系统的吞吐量与DeepSeek官方数据之间的差距在5.6%以内。 · 解码阶段：在9个节点的配置下进行评估，对于2K的输入，系统实现的单节点吞吐量为22,282个token/秒，这意味着与TP16基线相比，性能提升了5.2倍。 在模拟MTP条件下，对于4K的输入，系统仍然能够保持每节点17,373个token/秒的高吞吐量，仅比DeepSeek官方性能分析数据低6.6%。 接着，团队将SGLang的性能与DeepSeek的推理系统进行对比，力求使实验设置尽可能贴近DeepSeek的生产环境。 对于预填充阶段，团队测试了一个场景，在该场景中，每个设备处理16,384个token，输入长度为4,096。 考虑到DeepSeek的专家分布存在不确定性，他们评估了两种情况：一种是采用默认的专家分布，另一种是模拟理想状态下的EPLB，并将后者的结果作为性能上限。 评估结果如下所示： DeepSeek的性能分析数据显示，其所报告的吞吐量大约是其生产环境的两倍。 在默认的专家不平衡情况下，SGLang的性能比DeepSeek的性能分析数据慢20%；而在模拟的理想EPLB情况下，这个差距缩小到了6%。 对于解码阶段，结果如下所示： 在使用DeepSeek一半数量的节点的情况下，搭载模拟MTP的SGLang仅比DeepSeek的性能分析数据略慢。 在更高的batch大小设置下（256个序列，2,000个输入长度），SGLang实现了每节点每秒22,282个token的处理速度，充分展现了其强大的可扩展性。 下图详细分析了预填充阶段各个内核的执行时间。 如下图所示，SGLang的解码内核分析结果与DeepSeek的结果非常接近： 可以看出，SGLang的解码性能在很大程度上与DeepSeek的性能相一致。 因此，下一步的工作重点，就是预填充阶段的优化了。 局限性与未来工作 总的来说，项目在吞吐量上有着显著的提升，但仍然存在一些局限性以及需要增强的领域： 延迟优化：目前因为专注于提升吞吐量，导致首token时间（TTFT）达到2-5秒，token间延迟（ITL）大约100毫秒。之后还需要进一步优化，来满足实时使用场景的需求。 序列长度约束：由于使用了96个GPU，因此序列长度被限制在较短的范围内。 扩展GPU资源将支持更长的序列，这对于特定应用至关重要。 多token预测（MTP）集成：SGLang支持MTP，但缺乏与DP注意力的完全集成，降低了混合并行配置的效率。 专家并行负载均衡（EPLB）分布：本次实验使用了专家并行负载均衡器（EPLB）的同分布数据，这可能无法反映真实场景中的数据变动。之后还需要研究出现分布偏移时的性能表现。 灵活的张量并行（TP）规模：对于DeepSeek-V3而言，稠密FFN的内存最优TP规模较小，但大于1。目前SGLang仅支持纯TP或DP，导致内存利用率不高。之后还需要支持更灵活的TP选项。 Blackwell支持：目前的实现仅支持NVIDIA Hopper架构。团队正在努力将兼容性扩展到下一代Blackwell架构。 举报/反馈"
    },
    {
      "doc_id": 50067,
      "title": "刚刚,Llama 4深夜开源击败DeepSeek V3!2万亿多模态巨兽抢回王座",
      "time": "2024-04-06T00:00:00+00:00",
      "content": "编辑：编辑部 JNY 【新智元导读】原生多模态Llama 4终于问世，开源王座一夜易主！首批共有两款模型Scout和Maverick，前者业界首款支持1000万上下文单H100可跑，后者更是一举击败了DeepSeek V3。目前，2万亿参数巨兽还在训练中。 一大早，Llama 4重磅发布了！ Meta官宣开源首个原生多模态Llama 4，首次采用的MoE架构，支持12种语言，首批发布一共两款： Llama 4 Scout：共有1090亿参数，17B活跃参数，16个专家，1000万上下Llama 4 Maverick：共有4000亿参数，17B活跃参数，128个专家，100万上下文 另外，2万亿参数Llama 4 Behemoth将在未来几个月面世，288B活跃参数，16个专家。 Llama 4的横空出世，成为迄今为止开源最强，多模态能力最好的模型之一。 在大模型LMSYS排行榜上，Llama 4 Maverick冲上第二（ ELO得分1417），仅次于闭源Gemini 2.5 Pro。 更值得一提的是，仅用一半参数，Maverick推理编码能力与DeepSeek-v3-0324实力相当。 Llama 4 Scout最大亮点在于支持1000万上下文，相当于可以处理20+小时的视频，仅在单个H100 GPU（Int4 量化后）上就能跑。 在基准测试中，性能超越Gemma 3、Gemini 2.0 Flash-Lite、Mistral 3.1。 即将面世的Llama 4 Behemoth（仍在训练中），是Maverick协同蒸馏的教师模型，使用30T多模态token在32K个GPU上进行预训练（FP8）。 目前在STEM基准测试中，超越了GPT-4.5、Claude Sonnet 3.7、Gemini 2.0 Pro。 小扎激动地在官宣视频中称，「今天是Llama 4日」！ Llama 4开源后，DeepSeek R2还远吗？ 此前报道称，DeepSeek R2最晚在5发布，看来可能要提前了... 史上最强Llama 4开源，超越DeepSeek V3 Llama 4模型开源，标志着Llama生态系统进入了一个新纪元。 即日起，所有开发者可以在llama.com和Hugging Face下载这两款最新的模型 在大模型排行榜中，Llama 4 Maverick在硬提示（hard prompt）、编程、数学、创意写作、长查询和多轮对话中，并列第一。 仅在样式控制下，排名第五。 而且，1000万上下文Llama 4 Scout还击败了OpenAI的模型。 每个人还可以在WhatsApp、Messenger、Instagram Direct和网页上体验基于Llama 4的应用。 首次采用MoE，单个H100即可跑 Llama团队设计了两款高效的Llama 4系列模型，只要单个H100 GPU就能运行： 一个是Llama 4 Scout（拥有170亿个活跃参数和16个专家），使用Int4量化可以在单个H100 GPU上运行；另一个是Llama 4 Maverick（拥有170亿个活跃参数和128个专家），可以在单个H100主机上运行。 目前，正在训练的教师模型——Llama 4 Behemoth，它在STEM基准测试（如MATH-500和GPQA Diamond）中，性能优于GPT-4.5、Claude Sonnet 3.7、Gemini 2.0 Pro。 在最新博文中，Meta分享了更多的关于Llama 4家族训练的技术细节。 在英伟达B200上，Llama 4可以每秒处理42400个token 预训练 Llama 4模型是Llama系列模型中首批采用混合专家（MoE）架构的模型。 在MoE模型中，单独的token只会激活全部参数中的一小部分。 与传统的稠密模型相比，MoE架构在训练和推理时的计算效率更高，并且在相同的训练FLOPs预算下，能够生成更高质量的结果。 架构概览，右为混合专家（MoE）架构 举个例子，Llama 4 Maverick模型的4000亿个总参数中有170亿个活跃参数。 为了提高推理效率，Meta交替使用了稠密层和专家混合（MoE）层。 MoE层用到了128个路由专家和一个共享专家。每个token都会被送到共享专家，同时也会送到128个路由专家中的一个。 因此，虽然所有参数都存储在内存中，但在运行这些模型时，只有部分参数会被激活。 这样就能提升推理效率，降低模型服务的成本和延迟—— Llama 4 Maverick可以轻松部署在一台NVIDIA H100 DGX主机上运行，或者通过分布式推理来实现最高效率。 原生多模态设计 Llama 4是一个原生多模态模型，采用了早期融合技术，能把文本和视觉token无缝整合到一个统一的模型框架里。 早期融合是个大进步，因为它可以用海量的无标签文本、图片和视频数据一起来预训练模型。 Meta还升级了Llama 4的视觉编码器。这个编码器基于MetaCLIP，但在训练时跟一个冻结的Llama模型分开进行，这样能更好地调整编码器，让它更好地适配大语言模型（LLM）。 模型超参数优化 Meta还开发了一种叫做MetaP的新训练方法，能让他们更靠谱地设置关键的模型超参数，比如每层的学习率和初始化规模。 这些精心挑选的超参数在不同的批大小、模型宽度、深度和训练token量上都能很好地适配。 Llama 4通过在200种语言上预训练实现了对开源微调的支持，其中超过10亿个token的语言有100多种，整体多语言token量比Llama 3多出10倍。 高效的模型训练，解锁1000万输入上下文长度 此外，Meta注重高效的模型训练，采用了FP8精度，既不牺牲质量，又能保证模型的高FLOPs利用率—— 在使用FP8精度和32K个GPU预训练Llama 4 Behemoth模型时，达到了每个GPU 390 TFLOPs的性能。 训练用的整体数据包含了超过30万亿个 token，比Llama 3的预训练数据量翻了一倍还多，涵盖了文本、图片和视频数据集。 Meta用一种叫做「中期训练」的方式来继续训练模型，通过新的训练方法，包括用专门的数据集扩展长上下文，来提升核心能力。 这不仅提高了模型的质量，还为Llama 4 Scout解锁了领先的1000万输入上下文长度。 后训练 最新的模型包含了不同的参数规模，满足各种使用场景和开发者的需求。 Llama 4 Maverick：参数规模较大，主要用于图像理解和创意写作 Llama 4 Scout：参数规模较小，适用多种任务，支持1000万token上下文，全球领先。 为了让不同模型适应不同的任务，针对多模态、超大参数规模等问题，Meta开发了一系列新的后训练方法。 主力模型Llama 4 Maverick 作为产品的核心模型，Llama 4 Maverick在图像精准理解和创意写作方面表现突出，特别适合通用助手、聊天类应用场景。 训练Llama 4 Maverick模型时，最大的挑战是保持多种输入模式、推理能力和对话能力之间的平衡。 后训练流程 为了训练Llama 4，Meta重新设计了后训练流程，采用了全新的方法： 轻量级监督微调（SFT）> 在线强化学习（RL）> 轻量级直接偏好优化（DPO）。 一个关键发现是，SFT和DPO可能会过度限制模型，在在线RL阶段限制了探索，导致推理、编程和数学领域的准确性不理想。 为了解决这个问题，Meta使用Llama模型作为评判者，移除了超过50%的被标记为「简单」的数据，并对剩余的更难数据进行轻量级SFT。 在随后的多模态在线RL阶段，精心选择了更难的提示，成功实现了性能的飞跃。 此外，他们还实施了持续在线RL策略，交替进行模型训练和数据筛选，只保留中等到高难度的提示。这种策略在计算成本和准确性之间取得了很好的平衡。 最后，进行了轻量级的DPO来处理与模型响应质量相关的特殊情况，有效地在模型的智能性和对话能力之间达成了良好的平衡。 新的流程架构加上持续在线RL和自适应数据过滤，最终打造出了一个行业领先的通用聊天模型，拥有顶尖的智能和图像理解能力。 Llama 4 Maverick碾压GPT-4o和Gemini 2.0 作为一款通用的LLM，Llama 4 Maverick包含170亿个活跃参数，128个专家和4000亿个总参数，提供了比Llama 3.3 70B更高质量、更低价格的选择。 Llama 4 Maverick是同类中最佳的多模态模型，在编程、推理、多语言支持、长上下文和图像基准测试中超过了类似的模型，如GPT-4o和Gemini 2.0，甚至能与体量更大的DeepSeek v3.1在编码和推理上竞争。 通用模型Llama 4 Scout：1000万token上下文 规模较小的Llama 4 Scout是一款通用模型，拥有170亿个活跃参数、16个专家和1090亿个总参数，在同类别中性能最好。 Llama 4 Scout 的支持上下文长度从 Llama 3 的12.8万激增到行业领先的1000万token。 这为多种应用打开了无限可能，包括多文档摘要、大规模用户活动解析以进行个性化任务，以及在庞大的代码库中进行推理。 Llama 4 Scout在预训练和后训练时都采用了256K的上下文长度，基础模型具备了先进的长度泛化能力。 它在一些任务中取得了亮眼成果，比如文本检索中的「大海捞针式检索」和在1000万token代码上的累积负对数似然（NLLs）。 Llama 4架构的一个关键创新是使用了交替注意力层，而不依赖于位置嵌入。 此外，在推理时采用了温度缩放注意力，以增强长度泛化能力。Meta将其称为iRoPE架构，其中「i」代表「交替」（interleaved）注意力层，突出了支持「无限」上下文长度的长期目标，而「RoPE」则指的是在大多数层中使用的旋转位置嵌入（Rotary Position Embeddings）。 视觉理解能力 两款模型进行了大规模的图像和视频帧静态图像训练，以赋予它们广泛的视觉理解能力，包括对时间活动和相关图像的理解。 它们能够在多图像输入和文本提示的配合下，轻松进行视觉推理和理解任务。 模型预训练时最多用了48张图像，而在后训练测试中，最多8张图像也能取得不错的效果。 Llama 4 Scout在图像定位方面也是同类最佳，能够将用户的提示与相关的视觉概念对齐，并将模型的响应锚定到图像中的特定区域。 这使得更精确的视觉问答成为可能，帮助LLM更好地理解用户意图并定位感兴趣的对象。 编程、推理、长上下文和图像上，遥遥领先 Llama 4 Scout在编程、推理、长上下文和图像基准测试中超过了类似的模型，并且在所有以前的Llama模型中表现更强。 秉承对开源的承诺，Meta将Llama 4 Maverick和Llama 4 Scout提供给用户下载，用户可以在llama.com和Hugging Face上获取，之后这些模型还将在最广泛使用的云平台、数据平台、边缘硅片以及全球服务集成商上陆续上线。 2万亿巨兽，干掉GPT-4.5 Llama 4 Behemoth是一款「教师模型」，在同级别的模型里，它的智能水平相当高超。 Llama 4 Behemoth同样是一个多模态混合专家模型，拥有2880亿个活跃参数、16个专家以及近2万亿个总参数。 在数学、多语言处理和图像基准测试方面，它为非推理模型提供了最先进的性能，成为训练较小的Llama 4模型的理想选择。 教师模型+全新蒸馏 从Llama 4 Behemoth中蒸馏出来Llama 4 Maverick，在最终任务评估指标上大幅提升了质量。 Meta开发了一种新的蒸馏损失函数，在训练过程中动态地加权软目标和硬目标。 通过从Llama 4 Behemoth进行共同蒸馏，能够在预训练阶段分摊计算资源密集型前向计算的成本，这些前向计算用于计算大多数用于学生模型训练的数据的蒸馏目标。 对于学生训练中包含的额外新数据，会在Behemoth模型上运行前向计算，以生成蒸馏目标。 后训练 对一个拥有两万亿参数的模型进行后训练也是一个巨大的挑战，这必须彻底改进和重新设计训练方案，尤其是在数据规模方面。 为了最大化性能，不得不精简95%的SFT数据，相比之下，较小的模型只精简了50%的数据，目的是确保在质量和效率上的集中关注。 Meta还发现，采用轻量级的SFT后接大规模RL能够显著提高模型的推理和编码能力。Meta的RL方案专注于通过对策略模型进行pass@k分析来采样难度较大的提示，并设计逐渐增加提示难度的训练课程。 在训练过程中动态地过滤掉没有优势的提示，并通过从多个能力中混合提示构建训练批次，对提升数学、推理和编码的性能起到了关键作用。 最后，从多种系统指令中采样对于确保模型保持良好的指令跟随能力，在推理和编码任务中表现出色也至关重要。 扩展RL训练 对于两万亿参数的模型，扩展RL训练也要求重新设计底层的RL基础设施，应对前所未有的规模。 Meta优化了MoE并行化的设计，提高了速度，从而加快了迭代速度。 Llama团队开发了一个完全异步的在线RL训练框架，提升了灵活性。 与现有的分布式训练框架相比，后者为了将所有模型都加载到内存中而牺牲了计算内存，新基础设施能够灵活地将不同的模型分配到不同的GPU上，根据计算速度在多个模型之间平衡资源。 这一创新使得训练效率比之前的版本提升了约10倍。 Llama 4一夜成为开源王者，甚至就连DeepSeek V3最新版也被拉下神坛，接下来就是坐等R2的诞生。 举报/反馈"
    },
    {
      "doc_id": 50068,
      "title": "DeepSeek低调现身这场“风向标级”大会 透露出哪些信号?|科技观察",
      "time": "2024-02-24T00:00:00+00:00",
      "content": "封面新闻记者 边雪 当西岸艺术中心的展台人流，或在惊叹阶跃星辰的万亿参数开源模型，或在围观宇树科技会跳舞的机器人时，一场DeepSeek低调现身的闭门会议，悄然开启。 作为AI领域“风向标”级的会议，2025全球开发者先锋大会（以下简称2025 GDC）不仅展示了中国大模型技术的最新突破，更成为观察行业未来走向的“战略沙盘”。 大会会场 当开源浪潮撞上商业高墙，中国开发者们将如何突围？在2025 GDC上，封面新闻记者在多位开发者及业内人士的采访中，梳理答案。 技术迭代远超预期 大模型“撞墙”了吗？ “大模型的天花板是否已触顶？”这是过去一年外界对AI技术发展的最大质疑。然而，封面新闻记者在2025 GDC现场采访中发现，无论是技术厂商还是开发者，普遍传递出截然相反的信号：大模型的迭代速度正以超预期的节奏推进。 OpenAI前全球商业化负责人Zack Kass曾提出：“2024年GPT-4o的发布让行业意识到，大模型已从单纯的内容生成工具，进化为具备情感感知与实时交互能力的‘智能体’。”这一观点与MiniMax副总裁刘华的观察不谋而合。刘华在采访中表示：“未来两三年，类似GPT-3.5到GPT-4的技术飞跃将发生两次，且路径高度可预期。” 而技术突破的案例，在大会中比比皆是。 大会现场 首先是多模态能力跃升，以MiniMax展示的“海螺AI”为例，其已覆盖文本、图像、语音、视频全模态，服务超4万家企业客户，其全球月访问量甚至超越OpenAI的Sora。 其次，是推理能力突破，如瞩目的DeepSeek开源的R1推理模型，通过强化学习算法优化，实现了“慢思考”能力，其训练成本仅为同类模型的4%。 此外，是架构的革新。大模型的Transformer架构逐渐被MoE（混合专家模型）取代，动态冗余策略使计算成本降至传统模型的十分之一。 香港科技大学校董会主席、美国国家工程院外籍院士沈向洋告诉封面新闻记者：“大模型正从‘预测下一个token’的预训练模式，转向融合强化学习的深度推理范式。这种转变将释放出数倍于当前的技术潜力。” 从“追赶”到“并跑”的技术博弈 “中国大模型是否永远落后于美国？”这一曾引发行业焦虑的问题，在2025GDC上得到了新的答案。 DeepSeek的爆发式崛起成为关键转折点。其通过MoE架构与动态冗余策略，将计算成本降至传统模型的十分之一，同时实现多模态能力跃升。商汤科技产品总监贾安亚评价称：“DeepSeek证明了开源模型在特定场景下可以超越闭源模型，这是中国AI生态的里程碑。” 数据显示，DeepSeek-R1的推理成本仅为Grok-3的18%，但性能却达到同等水平。 大会现场 基于此，中国企业的差异化竞争策略也逐渐清晰。在开源生态构建方面“中国研发”正在加速：商汤发布LazyLLM开源框架，支持“搭积木式”应用开发；阶跃星辰开源Step系列多模态模型，与吉利汽车合作推动智能座舱落地。 在垂直场景领域，MiniMax的“海螺AI”已渗透金融、医疗、教育等领域，其智能理财顾问可提供个性化资产管理方案，诊断辅助系统能识别2000余种疾病模式。 不过，OpenAI前技术负责人John Schulman在视频演讲中提醒：“中美技术竞争将长期处于‘螺旋上升’状态。开源虽加速了技术扩散，但基础算法的原创性仍是核心壁垒。” 如何从“技术狂欢”到“价值落地”？ 当大模型走出实验室，如何实现规模化商业价值？记者在2025 GDC上，观察到三个关键路径。 第一，是智能体（AI Agent）驱动的服务革命。“AI Agent将成为新服务业的基础设施。” MiniMax 副总裁刘华表示，Al Agents将重塑全球经济，大模型会从目前单纯的互联网产品变成新的服务业。同时，未来 2～3年，类似“GPT3.5→GPT4”的技术升级幅度将发生两次，且是高度可预期的。 在金融领域，智能投顾可实时分析市场数据，提供动态资产配置建议，某银行试点项目使客户满意度提升40%；在医疗场景中，手术规划AI Agent能将术前准备时间从3小时压缩至20分钟，并降低15%的手术风险；再看制造业，生产优化Agent使某汽车工厂良品率提升8%，能耗降低12%。 上海科学智能研究院院长漆远也指出：“2025年可能是智能体元年。当Agent能自主完成复杂任务链时，人类将真正进入‘人机协创’时代。” 第二，是开源生态。2025年初DeepSeek的走红，揭示了开源模型的爆发力。Meta首席科学家杨立昆曾表示，开源的胜利在于让技术普惠成为可能。封面新闻记者在对业界人士采访时也得到一个共识：DeepSeek的快速出圈，在于打破了大模型领域“越强越贵”的成本诅咒，以高性价比、高效率实现了大模型的低成本工业化，而且在通过底层架构创新降低成本的同时，以开源策略构建生态的护城河。 “在可一键成片的AI短视频生成平台‘元创岛’上，如今借助DeepSeek-R1强大的语言理解和生成能力，用户只需输入简单的创作需求，便可以更快地生成高质量的视频创作内容。无论是创意构思还是实际产出，都得到了极大提升。”以生成式AI和语音交互为核心的人工智能公司出门问问相关负责人告诉封面新闻记者，企业AI交互式数字员工生成平台“奇妙问”的问答功能也得到了进一步优化，能够更准确地理解用户提出的问题，提供更加精准、详细的答案，满足用户在学习、工作、生活等各个方面的知识需求，成为用户身边智能、贴心的问答助手。 而这种突破算力限制的路径，正在改变行业格局。 算力需求在增长的同时，也呈现出平民化的态势。以商汤为例，通过架构优化，可使大模型推理成本降低70%，推动AI PC等终端设备的普及，LazyLLM框架让开发者无需编码即可构建多模态客服机器人，开发周期从1周缩短至2小时。 “我们在春节之后，就上线了DeepSeek的系列。”商汤科技创新研发部高级总监张行程告诉封面新闻记者，在最近公开的著名的大模型的第三方评价商SuperClue，连续两次发布了DeepSeek免费版的API的服务情况，商汤大装置的服务都在评测中名列前茅，特别是最新的一个评价里面，对于免费版API排第一的就是商汤的大装置的DeepSeek和API，也展现了背后平台能力的一个体现。“除了DeepSeek之外，其他模型比如商汤日日新SenseNova，开源的LLaMA、智谱、千问等也都可以使用。” 而在生态协同上，上海市智能算力资源调度平台整合三大运营商、阿里云等9家厂商，形成“算力超市”模式，使中小企业算力成本降低30%。 记者还注意到，2025 GDC上的创新产品已显现端倪：在情感交互上，阶跃星辰的Step-Audio模型可生成带方言、情绪的语音对话，使客服机器人投诉率下降25%；Rokid AR 眼镜通过分体式设计将算力与电池移至主机端，眼镜端重量降至75克（Rokid AR Lite）至49克（Rokid Glasses），佩戴体验接近普通墨镜，还能物理屈光调节设计，让近视用户摆脱双重镜片负担。 2025 GDC大会揭示了一个清晰趋势：大模型技术已从“炫技阶段”迈入“价值深水区”。在这场“破壁之战”中，中国企业正以差异化路径参与全球竞赛，在“不确定”中寻找确定性。 当算力成本下降、开源生态成熟、应用场景拓宽三重因素叠加，AI技术将迎来真正的“渗透率拐点”。大模型的未来刘华直言：“当前问答助手只是冰山一角，大模型对生产力的重塑才刚刚开始。” 举报/反馈"
    },
    {
      "doc_id": 50084,
      "title": "对OpenAI发起直接挑战,DeepSeek“杀入”文生图领域",
      "time": "2024-01-28T00:00:00+00:00",
      "content": "在用V3和R1模型横扫硅谷、引爆全球科技圈后，DeepSeek在除夕这天继续放大招。 1月28日凌晨，人工智能社区Hugging Face显示，DeepSeek发布了开源多模态模型Janus-Pro，拥有10亿和70亿参数规模，相比此前的语言和推理模型，本次发布的新模型重点在于文生图能力方面。 根据DeepSeek的技术文档，这个模型既能让AI读图，又能让AI生图。在文生图GenEval和DPG-Bench基准测试中，Janus-Pro-7B的准确率较前代Janus大幅提高，准确率测试结果分别为80%和84.2%，高于包括OpenAI DALL-E 3、Stable Diffusion在内的其他对比模型。 “他们真的想成为下一个 Grok（they really trying to be the next grok）。”针对DeepSeek的最新发布，有海外网友表示。此前由马斯克创立的xAI发布了名为Grok的一系列模型和应用，此举被视为对OpenAI等行业巨头的直接挑战。 DeepSeek的AI生图和读图能力如何？ 在外网，有网友测试了读图能力，表示Janus-Pro-7B的高精度读图能力很优秀，其发布的截图显示，在多行复杂数学表达式混合排版的图片转Latex代码，以及手绘风格时序图图片转mermaid代码的测试中，都是通过一句话Prompt实现了读图。 上述网友表示，虽然在逻辑性更强的时序图代码上模型没能一比一复刻原图，有一些错误，但基于经验判断，通过稍微的提示调整或者配合类R1级别的模型就能解决。 在文生图能力方面，有网友也第一时间进行了测试，从画面美学和指令跟随上看Janus-Pro接近目前的头部模型水平。 根据技术文档，在文本到图像指令跟踪排行榜 GenEval中，Janus-Pro-7B 得分为 0.80，优于 Janus (0.61)、DALL-E 3 (0.67) 和 Stable Diffusion 3 Medium（0.74）。另外，Janus-Pro 在 DPG-Bench 上获得了 84.19 的分数，超过了所有其他方法。这表明 Janus-Pro 擅长遵循密集的指令来生成文本到图像。 DeepSeek也对外展示了一些文生图的案例，在画面质量上表现优秀。 DeepSeek的热度还在持续。1月27日，DeepSeek应用登顶苹果中国地区和美国地区应用商店免费APP下载排行榜，在美区下载榜上超越了ChatGPT。这一纪录持续到1月28日，截至记者发稿，DeepSeek仍霸榜中美苹果应用商店排行榜，维持在免费榜第一的位置。 自去年底至今年初，DeepSeek接连发布重磅产品，关注度持续累积。 DeepSeek出圈是在12月26日，彼时官方宣布全新系列模型DeepSeek-V3上线并同步开源，随后就刷屏了海外社交媒体平台X，全球科技圈惊叹的点在于，这一模型能力对标头部模型，但训练的预算却非常低，“2048个GPU、2个月、近600万美元”，相比之下，GPT-4o等模型的训练成本约为1亿美元，至少在万个GPU量级的计算集群上训练。 当时，Chatbot Arena数据显示，DeepSeek-V3在所有模型中排名第七，在开源模型中排第一，是全球前十中性价比最高的模型。 “Llama 3 405B 使用了3080万GPU小时，而DeepSeek-V3 看起来是一个更强大的模型，仅使用了280万GPU 小时（计算量约为十分之一）。”前Open AI 联合创始人、Tesla AI 团队负责人Andrej Karpathy在X上发文表示，如果该模型的优良表现能够得到广泛验证，这一模型将是在资源受限的情况下，在研究和工程方面让人印象深刻的一次展示。 就在1月20日，DeepSeek又正式开源其推理模型R1。1月24日，DeepSeek-R1在Chatbot Arena综合榜单上排名第三，与OpenAI的顶尖推理模型o1并列。在高难度提示词、代码和数学等技术性极强的领域，DeepSeek-R1拔得头筹；在风格控制以及高难度提示词与风格控制结合的测试中，DeepSeek-R1均与o1 并列第一。 DeepSeek以“低成本训练”和“高性价比”为核心卖点，其API输入价格仅为每百万Token 0.1元人民币，远低于目前行业的头部模型，例如Claude 3.5 Sonnet为3美元/百万Token，这种低成本训练策略也让该公司有了“AI界拼多多”的称号。 市场认为，DeepSeek的成功可能削弱了市场对英伟达AI芯片需求的预期，多家券商发布研报称AI大模型的应用将逐步走向普惠，“低成本+高性能”大模型成为可能，这一趋势一度引发英伟达等硬件厂商的股价暴跌。 截至周一收盘，英伟达收跌16.97%，市值蒸发近5900亿美元，刷新美国金融史纪录。在周一之前，美股个股历史最大单日市值蒸发纪录是英伟达在去年9月创造的2790亿美元，再往前是2022年Meta大跌2320亿美元。 除此之外，博通公司股价也下跌超17%，台积电跌超13%，软银旗下的Arm Holdings跌超10%，AMD跌超6%，阿斯麦跌超5%。 当地时间1月27日晚，美国总统特朗普在佛罗里达州迈阿密发表讲话，对中国人工智能初创公司DeepSeek搅动纳斯达克一事表示，DeepSeek的模型高效且经济，其出现是一种积极的发展，也“给美国相关产业敲响了警钟”，美国“需要集中精力赢得竞争”。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 50085,
      "title": "OpenAI会杀死Manus们吗?",
      "time": "2025-07-20T00:00:00+00:00",
      "content": "本文来自微信公众号：山上，作者：薛星星，头图来自：AI生成 和三月份发布文生图更新一样，OpenAI 又一次试图提前结束 AI Agent 的创业竞赛。 北京时间 7 月 18 日凌晨，OpenAI 发布 ChatGPT Agent。它可以根据用户的指令，自动规划执行步骤，调用多种工具，并完成从抓取数据到生成表格、规划行程到预订酒店等多环节任务。 OpenAI 推文截图 这也是目前多数 AI Agent 创业项目正在尝试的方向。4 个月前你在 Manus 那场号称首个通用 AI Agent 宣传片中看到了什么，ChatGPT Agent 就完成了什么。 OpenAI 创始人山姆·阿尔特曼（Sam Altman）说，这是他第一次“真正感受到 AGI（通用人工智能）”。OpenAI 的研究人员则表示，ChatGPT Agent 是目前为止最强的 AI Agent 模型。 是的，OpenAI 将 ChatGPT Agent 称为一个模型，而不是产品。与 Manus 等依赖上下文管理、工具链编排的系统不同，OpenAI 训练了一个专用模型，能够在单一系统中完成任务规划、跨工具调用和文档生成等复杂流程。该模型目前被归入 o3 系列，但尚未被单独命名。 AI 时代的创业者们面临着比任何历史时期都更快速的技术迭代，一次底层模型更新往往就能毁掉一个垂直领域的创新产品。 理想汽车创始人李想此前在朋友圈说，to C 层面，OpenAI 在内的掌握最强基座模型的企业，不会留下什么垂直应用的创业空间。“软件的本质是功能，需要场景化、垂直化。人工智能的本质是能力，能力强就可以吃掉一切，也是用户最方便的。” 就连一直高喊 AI 应用创新的朱啸虎也在社交媒体上表示，大模型会吃掉 90%的 Agent。X 平台上也有用户发问，如果 OpenAI 后续开放 ChatGPT Agent 模型的 API，其他创业者该如何与其竞争？ “Listen-that's the sound of a great many startups evaporating into the void.”（听——那是无数初创公司悄然蒸发的声音。) OpenAI 发布会视频下的一条高赞评论写道。 Manus们选择正面硬刚 至少在目前，Manus 们还没有表现出任何退让迹象。 OpenAI 发布会刚结束，Manus 就在 X 上转发推文称，“Welcome to the game.”同属于华人 AI Agent 创业公司的 flowith 也转发强调，他们早在一年前就推出了 AI Agent 产品。 作为过去半年最早对外喊出通用 AI Agent 口号的创业公司，Manus 的反应要比其他公司强烈得多。发布会结束仅 3 个小时，Manus 就一口气对外放出了 10 条与 ChatGPT Agent 的对比测试，宣称要和 OpenAI 正面较量。 这些对比内容部分来自 OpenAI 当日展示的演示片段，部分则来自用户在社交平台上的真实使用。涵盖场景包括数据整理、路线规划、在线购物、财务分析、餐厅预订等，Manus 发出的测试结果几乎全面占优——不仅响应更快，也更强调“任务完成度”，如表格更整洁、图示更丰富、PPT 更接近成品。 03:02 Manus发布的与 ChatGPT Agent 的对比视频 比如 OpenAI 演示的“计划一次为期三天的棕榈泉网球之旅”，OpenAI 给出的是一张简单的行程表，而 Manus 生成的则是一张带有目的地风格设计的行程海报。 Manus 发布的测试对比 又如分析旧金山市过去四年的财务报告，OpenAI 输出的是 Excel 文件，而 Manus 给出的是包含图表与要点总结的完整演示文档。“Manus 完成的是整个项目，而不仅仅是提供数据。”Manus 评价说。 另一家华人公司 Genspark 的反应同样高调。创始人景鹏（Eric Jing）在 X 上写道：“我从未想过有一天——作为一家只有 24 人的小公司，我们竟然可以领先……领先于 OpenAI。”他表示，用同样的提示词，Genspark 的响应时间更短、成本更低，生成结果的质量也“高出好几倍”。 7 月 19 日，Genspark 也在社交平台上分享了 9 个与 ChatGPT Agent 的对比实例，显示他们输出的文档数据维度更丰富，排版更加美观。除了与 Manus 对比测试中类似的旅游行程制定、财务数据分析等案例外，他们还分享了一则视频生成能力的对比，指出 ChatGPT Agent 未能完成任务。 Genspark 分享的视频生成案例 社交媒体上用户们的反馈也不如此前 OpenAI 更新文生图功能那样强烈。一些批评声音指出 ChatGPT Agent 任务的完成度不高，任务生成速度也比较缓慢，部分复杂任务需要 20 分钟乃至更长时间才能完成。 OpenAI 似乎也意识到当前的 ChatGPT Agent 的速度问题，他们拍摄的几条宣传视频里，员工往往在下达指令后就合上笔记本，等到稍晚再返回查看结果。 “即便耗时 15 分钟或半个小时，相比你自己手动完成也已经是显著的提速了。”OpenAI 的研究员 Isa Fulford 说。她表示，这是一种“可以在后台发起任务，过一会儿再回来查看结果”的使用方式，而 OpenAI 的搜索团队则更专注于低延迟场景。 OpenAI 或许更强调模型能够持续推理和思考的时间，OpenAI 的研究员张熙堃说，ChatGPT Agent 在内部测试中的最长连续推理时间达到了 2 小时，“我们应该有一个排行榜来记录模型能持续思考多久。” 针对外界诟病的生成文档或 PPT 不够美观的问题，OpenAI 的研究员们在 X 上建议，先让 ChatGPT Agent 把研究工作做完，再让它输出 PPT 文件。ChatGPT 生成的是标准 pptx 格式，用户也可以在 PowerPoint 中统一套用想要的设计模板。 虽然 OpenAI 强调他们专门为 ChatGPT Agent 训练了专用模型，但部分批评声音亦指责它更像是将此前已经推出的 Operator（浏览器交互能力）与 Deep Research（深入研究能力）组合在一起的产物。Operator 可以支持 ChatGPT 通过浏览器与网站直接互动、阅读并理解网页内容，Deep Research 则擅长分析和总结信息。 事实上，ChatGPT Agent 目前团队成员正是来自于此前的 Operator 与 Deep Research 部门，目前团队规模大约在 20-35 人。OpenAI 对外表示，ChatGPT Agent 是 Operator 和 Deep Research 功能自然延续，“我们发现用户通过 Operator 尝试的许多查询实际上更适合 Deep Research，因此我们将两者的优势结合在一起。” OpenAI 表示，这次发布仅标志着他们将智能体功能直接集成到 ChatGPT 中的第一步，他们计划定期逐步更新更多功能。 两种技术路线 相较于初创公司们过去半年来围绕输出质量和交付体验不断工程迭代和提示优化，OpenAI 刚刚发布的 ChatGPT Agent 在任务的最终呈现上可以称得上是粗糙。 初创公司们试图为用户呈现一个完成度更高且上手难度更低的 Agent 产品。以 Manus 为例，过去 2 个月来这家公司先后为产品加入了包括 PPT 生成、视频生成、音频生成等诸多不同能力，官网还列举出了诸多现成的模板分享以及用户案例分享。即便这些能力的实现都依托于外部模型，但至少在上手难度上，初创公司们都做得比 OpenAI 更好一些。 但抛去这些应用体验创新，在基础模型的能力比拼维度上，ChatGPT Agent 通过端到端训练的统一模型显然更有优势。OpenAI 为 ChatGPT Agent 做了诸多学术测试，部分测试结果甚至领先于 OpenAI o3 或 GPT 4o，达到行业最高水平。 比如在《人类的最后考试》（Humanity’s Last Exam）评估中，ChatGPT Agent 取得了 41.6%（pass@1）的新高，大约是 OpenAI o3 的两倍。DSBench 测试中，ChatGPT Agent 大幅度领先于 GPT-4o，在数据分析任务中的表现更是明显优于人类水平。 Humanity’s Last Exam 测试结果 在专门衡量电子表格编辑能力的 SpreadsheetBench 平台上，ChatGPT Agent 创下行业新高，性能较 GPT-4o 领先一倍。OpenAI 称，在他们的内部基准测试中，ChatGPT Agent 的能力大致相当于 1 至 3 年经验的投资银行分析师水平。 简单来说，OpenAI 更强调 ChatGPT Agent 带来的底层模型能力的提高，而初创公司们受限于技术及资金则更倾向于应用创新。 7 月 19 日凌晨，Manus 联合创始人季逸超发文称，Manus 仍将继续押注于上下文工程（in-context learning）而非端到端智能体。 他说，早在 Mannus 项目初期，他们就在思考是使用开源模型训练一个端到端的智能体，还是基于前沿模型的上下文学习能力构建智能体。GPT-3 等模型的出现让他们意识到，上下文工程才是正确的方向，因为这些模型的能力远高于他们此前的内部模型。 “如果模型进步是上涨的潮水，我们希望 Manus 成为那条船，而不是固定在海床上的柱子。”季逸超说，这可以使他们能够在几小时而非几周内交付改进，并始终让他免费产品与底层面模型保持正交。 他在这篇技术文档中分享了不少 Manus 在上下文工程上的经验，比如需要围绕 KV 缓存进行设计、要使用系统文件作为上下文等等。这些工程创新显著提升了 Manus 的响应速度以及成本优势。 季逸超举例，使用 KV 缓存可以大幅度提升首个 token 的生成时间和推理成本，例如使用 Claude Sonnet 时，缓存的输入 token 成本比未缓存的成本降低 10 倍。 季逸超分享的技术文档 上下文工程的创新的确也可以使智能体拥有更好的性能效果。非盈利人工智能研究机构 Epoch AI 测试了 ChatGPT Agent 在 FrontierMath 数学试题集中的表现，称 ChatGPT Agent 在 Tier 1-3 的数学题上只得到了 27% 的正确率，且难度越高得分越低。 但当每道题允许 ChatGPT Agent 尝试 16 次之后，它的得分就从 27% 大幅度提升至 49%。Epoch AI 说，这表明更好的提示词设计（prompting）或任务结构支持（scaffolding），可能会显著提升当前模型的性能。 Epoch AI 测试结果 换句话说，即便是相同的模型，创业公司们依然可以通过更好的提示工程与上下文设计，来达到远超基准模型的效果。 “你如何塑造上下文最终决定了你的智能体的行为方式：它运行的速度、恢复的效果以及扩展的范围。”季逸超说。 如何与 Agent 的未来共处 ChatGPT Agent 的正式推出，标志着 AI Agent 正式进入巨头博弈的时代。它带给人类的社会的影响不会比大模型爆发之初的影响小，让 AI 抢夺人类工作真正成了现实。 这种改变已经在悄然发生。微软和亚马逊等科技巨头们都在密集裁员，微软 CEO 萨蒂亚·纳德拉今年初表示，微软 20% 到 30% 的代码都由 AI 生成。一家金融科技公司 Klarna 更是早在去年初就对外宣布，他们的 AI Agent 仅投入使用一个月，就处理了公司 2/3 的客服聊天工作，相当于 700 名全职人工客服的工作量。 市场研究机构 MarketsandMarkets 表示，全球的 AI Agent 市场将从 2024 年的 51 亿美元增长至 2030 年的 471 亿美元，年均复合增长率（CAGR）达 44.8%。Deloitte 预测，到 2025 年，使用生成式 AI 的公司将有 25% 开始试点智能体，到 2027 年将增长至 50%。 AI Agent 的快速应用也让行业人士产生担忧。和过去大模型仅仅只是提供信息不同，AI Agent 真正具备了从思考到行动的完整能力。比如 ChatGPT Agent 现在已经可以访问网站帮助用户下单购物、自动填写信用卡地址，也可以访问用户的日历、电子邮件、云盘等隐私信息。对于使用 AI Agent 的人们来说，这意味着他们将自己的私人信息交给了一个“黑盒”，也更容易受到攻击。 发布会上，OpenAI 也专门强调了 ChatGPT Agent 的风险。他们强调，ChatGPT Agent 在执行所有重要操作前都会征得用户同意，“用户始终拥有控制权。”同时，OpenAI 还加入了包括主动监督（Watch Mode）、主动风险缓解（Proactive risk mitigation）等安全措施。 OpenAI 发布的声明 山姆·阿尔特曼在 ChatGPT Agent 推出后专门发布长篇推文警告用户，要求用户审慎地使用 ChatGPT Agent。 “Agent 代表着 AI 系统能力的新高度，它可以用自己的计算机完成一些令人惊叹且复杂的任务。它融合了 Deep Research（深度研究）和 Operator（任务执行者）的理念，但远比这些字面描述更强大 —— 它可以长时间思考，使用各种工具，再继续思考，再采取行动，如此往复。”山姆·阿尔特曼说。 山姆表示，虽然他们还不确定这些影响具体是什么，但也许会有人试图恶意“欺骗” 用户的 AI Agent，使其提供不应该提供的隐私信息，并做出无法预测的不当操作。“我们建议用户只授予 Agent 完成任务所必需的最低限度访问权限，以降低隐私和安全风险。”山姆强调，他不会将 ChatGPT Agent 用于高风险的用户或涉及大量个人信息的场景。 但对于已经演变成了一家商业盈利公司的 OpenAI 来说，它并不会因为隐私或者安全风险而减缓 AI Agent 迭代的步伐。 在 ChatGPT Agent 推出之前，《金融时报》就报道称 OpenAI 正计划在 ChatGPT 中开发支付结账系统，通过 ChatGPT 完成订单的商家需要向 OpenAI 支付佣金。《金融时报》称，OpenAI 已经向部分合作伙伴电商平台 Shopify 等展示了系统的早期版本。 本文来自微信公众号：山上，作者：山上 本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系 hezuo@huxiu.com 本文来自虎嗅，原文链接：https://www.huxiu.com/article/4596874.html?f=baijiabaiducom 举报/反馈"
    },
    {
      "doc_id": 50087,
      "title": "大厂入局“围猎”AI Agent,谁能先闯出路?",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "2025年被创业公司密集占据的热门Agent（智能体）赛道，终于等来头部大厂下场“收割”。 北京时间7月18日，OpenAI发布ChatGPT Agent产品。功能上，ChatGPT Agent融合了此前OpenAI发布的Operator远程可视化浏览器环境执行任务能力、DeepResearch的多步研究与整合高质量信息能力，以及ChatGPT的对话能力；人员配置上，据OpenAI官方披露，为了开发ChatGPT Agent，Operator与Deep Research团队已合并为一个20到35人组成的统一团队。 另在近日，亚马逊云科技在纽约AWS峰会上发布Bedrock AgentCore服务，提供了一组核心组件，帮助企业构建、部署和管理AI Agent。今年3月，亚马逊AGI实验室开发的Nova Act已能自主操作网页浏览器完成购物、填表等复杂任务。 而在太平洋彼岸，中国一级市场正被金沙江创投主管合伙人朱啸虎的言论搅动。他认为大模型会“吃”掉90%的Agent，并将当前AI智能体创业者比作互联网早期的个人站长——充满草根精神却面临残酷淘汰。两相对比，Agent终于在多方鼓吹“2025元年”的热潮中，跨入大厂“收割”、创业公司焦虑的节点。 平台化竞争开启 整个Agent行业已有Manus、Lovart、Flowith、Genspark等明星产品，ChatGPT Agent发布后也面临同质化、速度慢、技术缺乏代际差等质疑。但从官方演示来看，ChatGPT Agent的核心优势在于OpenAI直接搭建专用模型，与OpenAI o3同系列，采用端到端训练方法，系为Agent任务开发的统一模型，而非其他Agent产品调用外部厂商产品建立的多模型工程化组合。 另从定价来看，此次OpenAI虽未再次实行降价策略，但创业公司也未占据明显价格优势。其中可调用ChatGPT Agent功能的GPT Plus套餐每月20美元，Manus基础计划每月19美元。 AIGCLINK发起人、行行AI合伙人占冰强对第一财经表示，通用类Agent领域竞争已经进入成熟期，大厂开始下场，包括OpenAI、字节跳动Coze空间等，这是一条属于大厂的赛道，而垂类行业的Agent如果具备一定交付能力，创业公司在其中仍有机会。 更值得注意的一点在于，OpenAI或将开辟一条新的营收路径——与最终交易绑定，但该模式此次暂未正式对外披露。有消息称，OpenAI计划开发电子商务功能，测试ChatGPT内部集成结账系统，并通过ChatGPT完成在线产品销售进行分成。过去的Agent类产品可以帮助用户搜索、对比、筛选，甚至包括支付下单，但并未在该流程内进行收费举动。OpenAI此次虽未披露新营收方式，但山姆·奥尔特曼此前在接受采访时称：“我们不会为了改变推荐排名而收费，但用户若通过Deep Research发现了某款商品并进行购买，我们会抽取约2%的费用。” OpenAI从底层模型优势切入，亚马逊则直接提供技术与资金支持，所发布的Amazon Bedrock AgentCore为客户提供从部署到运行的全套能力。此外，亚马逊云科技宣布向其生成式AI技术创新中心追加1亿美元投资，并与Meta达成合作，支持初创企业利用Llama模型开发AI应用。 不论是OpenAI从流量入口添加交易收佣丰富生态，还是亚马逊从底层能力提供全栈支持，Agent领域的竞争越来越平台化。正如朱啸虎三日前在社交平台所言：AI Agent领域创业者可以借鉴互联网早期的个人站长模式，从个人站长逐渐成长为具有影响力的互联网公司。他分享的代表性案例包括网易、腾讯等，均从“工具”或“入口”切入，解决用户最基础或最迫切需求，形成用户黏性，再发展壮大。 从早期迈入分化路口 虽然成长路径可参考，但目前多元的Agent产品生态尚未有哪一款产品，能够在用户群中构建起牢固的黏性壁垒。Demo（演示版）产品引发一波讨论与测试后，一旦开启收费，用户流失严重，形成热闹Agent浪潮下的伪需求陷阱。也因此，朱啸虎认为，如果产品不具备用户黏性，未来大模型能够“吃”掉90%的Agent产品。 这并非夸大其词，此前Gartner预测，到2027年底，40%的代理型人工智能 （Agentic AI ）项目将被取消，原因在于成本高昂、商业价值有限及风险控制不足。当下大多数项目都处于早期试点或概念验证阶段，许多组织低估了扩展Agentic AI系统的复杂性。 Gartner高级总监兼分析师阿努什里·维尔马（Anushree Verma）表示，部分Agent项目“受炒作驱动，且常常被误用”，“这可能会让组织忽视大规模部署AI Agent的真正成本和复杂性，导致项目无法推进到生产阶段”。 另外，Gartner认为，当下“智能体包装（Agent Washing）”现象兴起，即供应商将机器人流程自动化（RPA）工具、聊天机器人和AI助手等技术重新包装成Agent产品，但名不副实。在Gartner的调研数据中，仅有19%的受访者表示所在公司已在Agentic AI方面进行了大量投资，42%的受访者称投资较为保守，超过30%的受访者持有不确定或持“观望”态度。核心原因仍类似于AI1.0时代的问题——数据格式不兼容、系统接口老旧、权限申请流程漫长、内外部系统不匹配等。 头部厂商下场虽然带来更明确的方向，但也带领行业加速迈入关键性十字路口。专用模型的迭代将较多模型拼凑的“工程化组合”更具优势，成为技术门槛的核心；平台化能力会倒逼中小创业者向垂直场景深耕，复制早期互联网时代“工具-入口-生态”的成长逻辑；商业化层面，单纯依赖工具收费的路径将面临营收压力。预计未来三至五年，Agent行业将正式从“概念炒作”迈入“实用主义”。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 50095,
      "title": "“中企压力”之下,OpenAI又陷内斗漩涡?",
      "time": "2024-07-07T00:00:00+00:00",
      "content": "图片说明： 6月2日，OpenAI首席执行官奥尔特曼在美国加州出席一场科技峰会。 本报记者 杨沙沙 ●任 重 编者的话：美国人工智能公司OpenAI近日在其官方博客中点名一家中国人工智能（AI）公司智谱，声称北京支持的初创公司智谱在人工智能竞赛中取得了“显著进展”，在多个国家收获应用案例。外媒分析称，OpenAI正在将一家鲜为人知的中国人工智能初创公司视为“威胁”，该博客的发布，正值美国和中国在快速发展的人工智能领域展开激烈竞争之际。截至记者发稿时，智谱方面没有接受《环球时报》记者的采访。有专家表示，虽然美国AI巨头们在技术方面领先，但在工程实现和市场规模方面，中企有不小的优势。在面临“中企压力”之际，OpenAI行业领头羊的优势也面临来自美国本土的激烈竞争。 “点名”中企，真实动机被质疑 据美国CNBC网站报道，中国人工智能公司DeepSeek在今年1月份发布了R1模型后，获得国际大量关注，但OpenAI表示，智谱在中国以外的扩张及其与北京的关系值得更多的审查。报道称，智谱在中东、英国、新加坡和马来西亚设有办事处，并在东南亚（包括印度尼西亚和越南）运营联合“创新中心”项目。 智谱成立于2019年，被国内媒体称为国产AI大模型“六小虎”之一。据其官网介绍，北京智谱华章科技股份有限公司（简称“智谱”）致力于打造新一代认知智能大模型，专注于做大模型的中国创新。今年4月，智谱在北京证监局办理辅导备案，成为“六小虎”中第一家正式启动IPO流程的公司。据悉，智谱最快于2026年登陆A股市场。 对于智谱被OpenAI“点名”，有业内人士对《环球时报》记者表示，国内AI圈内并没有太多关注，因为OpenAI在其官方博客发布的消息并没有太大权威性。也有国内长期关注AI领域发展的知情人士告诉《环球时报》记者，包括OpenAI在内的美国AI企业人才争夺激烈，资金缺口一直存在，“点名一家不知名的中国企业可能是想引发美国政府方面的重视”。 外媒也有质疑OpenAI动机的声音。印度媒体Analytics India Magazine (AIM)报道称，OpenAI博客文章似乎不太关心模型性能，而是对影响力的架构更加担忧。报道引述知名风险投资人比尔·古雷的分析称，OpenAI在一篇博客中公开推广中国人工智能企业的决定“非常奇怪”，并认为OpenAI这种做法只是提高了竞争对手的知名度，“有效地使其广为人知”。 中国电信集团首席科学家、美国贝尔实验室院士毕奇对《环球时报》记者分析称，从目前的报道来看，OpenAI并没有列举任何智谱在AI技术方面的优越性，而是聚焦智谱在融资方面的成功，以及在国外设置机构的多少。“从这一点来看，他们希望通过放大智谱在融资方面的成功，特别是强调从中国政府渠道融资的成功，游说美国政府进一步出台有利于OpenAI的政策，甚至直接提供资金，支持OpenAI。”毕奇表示，目前AI方面的技术发展还处于重投资阶段，美国AI企业希望通过这方面的炒作，巩固资金链方面的优势。 今年以来，美国科技巨头向AI领域的投资达到史无前例的规模。英国广播公司（BBC）7月4日报道称，微软将裁员9000人以腾出更多资金投入AI研发。在2025财年，微软计划将800亿美元投入数据中心建设，加速AI大模型训练。谷歌也在年初公布了750亿美元的AI基础设施投资计划。Meta今年则计划投入650亿美元来支持其AI目标。 然而，中国AI产业的追赶步伐仍让硅谷巨头们感受到竞争紧迫感。美国《华尔街日报》7月初一篇题为“中国正在迅速削弱美国在全球AI竞赛中的领先地位”的报道称，中国的AI大模型在全球范围内越来越受欢迎，考验着美国的优势。 美国AI巨头的深层隐忧 OpenAI表示，智谱代表了中国“希望建立一个自力更生、具有全球竞争力的人工智能生态系统，与美国竞争，减少对美国技术的依赖”。 路透社称，OpenAI在中东和亚洲建立了合作伙伴关系并吸引投资。其5月宣布的“OpenAI for Countries”计划目标是帮助感兴趣的国家与美国政府协调发展“主权人工智能能力”。据悉，OpenAI此前称，计划在美国之外投资建设运行人工智能系统所需的基础设施，作为其美国AI数据中心项目“星际之门”（Stargate）的海外延伸。另据CNBC报道，在5月访问阿联酋期间，美国总统特朗普宣布，双方达成价值总额超过2000亿美元的协议。其中包括由OpenAI、甲骨文、英伟达和思科系统公司合作建设“阿联酋星门AI校园”的项目。据悉，该项目预计将于2026年启动。 “这实际上是美国自己在筑墙。”印度媒体AIM分析称，令OpenAI不安的不仅仅是竞争，更是担心“失去叙事主导权”。尽管美国一直在通过“星际之门”项目，以及政府交易、贸易代表团和战略伙伴关系等手段，在全球范围内积极推广其人工智能技术，但中国安静的、基础设施优先的做法，可能会被证明更持久。 毕奇告诉《环球时报》记者，从目前发展来看，OpenAI、Meta等美国巨头，都相继从提倡开源起步，走向闭源发展。这反映了美国AI巨头对其技术领先及垄断地位的不自信。“众所周知，互联网行业的一个现象是赢者通吃。然而，目前在商业路线上，美国企业面临抉择。”毕奇进一步解释，“是按谷歌安卓的模式，用开源的方式占领全球市场；还是按苹果模式，通过技术领先把体验做到极致来绑住客户，成为美国巨头们左右为难的选择”。 毕奇认为，从一般规律来说，领先者会更青睐美国苹果公司简单粗暴的商业模式，而挑战者会通过开源模式奋力一搏。从目前安卓及苹果在智能终端的全球市场份额可以看出，开源模式对有技术领先优势的厂家，还是具有较强的挑战性。“这也可能是为什么中国AI企业的出海，即使还在起步阶段，就牵动了美国巨头们神经的原因之一”。 今年以来，中美两国AI发展势头迅猛。毕奇表示，从技术上来看，美国巨头们领先中国不少。“这就是为什么他们选择闭源的原因，如果他们采用闭源方式，追赶者采用开源方式，会对领先者产生较大的商业冲击”。 毕奇认为，虽然美国AI巨头们在技术方面领先，但在工程实现和市场规模方面，中企有不小的优势。因此，不排除今后即使美国巨头们能保持技术方面领先优势，国内企业通过开源方式，也会占有一定数量的全球市场份额。“这就是为什么美国巨头们还有较大担心，要消除这方面的风险，除非美国某个AI巨头加强自信心，坚持开源方式，用自己的技术优势引领全球”。 “挖墙脚”大战一触即发 《华尔街日报》分析称，美国的公司往往优先考虑在构建“人工智能超级竞赛”中寻求重大突破，而中国的企业则更专注于实际应用，这一点可以帮助其快速赢得新用户。报道援引微软总裁布拉德·史密斯近日在美国国会上的发言称，“决定美中谁能赢得这场AI竞赛的第一要素是，谁的技术在世界其他地区得到最广泛的采用。” 据新加坡《联合早报》报道，在全球数字化与智能化的浪潮中，中国AI企业凭借技术优势与创新能力，在国际舞台上开始崭露头角。一份行业报告显示，截至2024年10月，中国AI企业总数918家，其中有203家企业开启出海进程，出海率超过22%。报告分析称，中国AI出海企业中绝大多数公司产品集中在应用层面，占比高达76%。2025年，中国AI应用出海在产品类型与数量方面都实现了快速增长。不少中企将东南亚作为出海的重要目的地，该区域内容电商发展迅速，TikTok、Shopee、Lazada、Temu等平台增速可观。全球新闻网报道称，随着中国与东盟贸易往来不断深化，AI产业的快速发展已经开辟出新的应用领域，进一步促进区域经济合作并重塑区域产业格局。 与此同时，美国科技巨头间围绕AI的“内卷”也愈演愈烈，OpenAI与Meta的人才争夺战近日成为焦点。美国《财富》杂志网站5日报道称，在硅谷白热化的“AI霸权竞赛”中，令人咋舌的高薪酬一直是巨头们吸引人才的关键手段。然而，作为行业领头羊的OpenAI正面临如何吸引和留住顶尖人才的难题。《纽约邮报》本月初报道称，Meta创始人兼首席执行官扎克伯格向OpenAI的至少10名关键员工提供了利润丰厚的报价，这些员工可选择入股Meta，在4年内获得高达3亿美元的收益。有多家美媒披露，在最近几周，Meta成功聘请到了多位来自OpenAI的研究人员。OpenAI首席执行官奥尔特曼抨击了扎克伯格咄咄逼人的“挖墙脚”举动，他告诉员工，Meta的行为方式令人反感。据报道，上周末OpenAI的高级研究官向员工发送了一份备忘录，发誓将与Meta在争夺顶尖人才的竞争中“针锋相对”。 OpenAI同其长期合作伙伴及主要投资方微软的关系近来也出现恶化。《华尔街日报》报道称，OpenAI希望微软放松对其AI产品和计算资源的控制，确保OpenAI转型为营利性公司，而微软的态度决定了OpenAI能否筹集更多资金并实现上市。但知情人士称，双方在该问题上的谈判进展艰难，OpenAI的高管们开始指责微软在合作期间存在反竞争行为，可能向美国监管部门申请针对微软的反垄断审查。 《华尔街日报》报道称，此前，OpenAI同微软的关系被广泛认为是科技史上最成功的合作伙伴关系之一。微软于2019年首次向OpenAI投资10亿美元。根据目前的合同，微软拥有通过其Azure云销售OpenAI软件工具的独家权利，并优先使用后者的技术。但如今两家公司在多个AI产品和服务中展现出竞争关系。 举报/反馈"
    },
    {
      "doc_id": 50100,
      "title": "全球AI动态周报-截止6月1日",
      "time": "2024-06-04T00:00:00+00:00",
      "content": "（转自：数据GO） 一、AI动态 1、OpenAI图像生成API升级：实时流式预览+多轮编辑 OpenAI宣布其图像生成API（Responses API）迎来重大更新，新增流式传输、多轮编辑以及与Model Context Protocol(MCP)工具和实时网络数据搜索的集成功能。这些新特性不仅提升了图像生成效率，还为开发者提供了更灵活的创作方式，标志着AI驱动的视觉内容创作进入全新阶段。AIbase为您整理了此次更新的核心亮点及其对行业的深远影响。 2、OpenAI 计划推出 “使用 ChatGPT 登录”第三方应用功能 根据最新消息，OpenAI 正在探索用户如何能够使用他们的 ChatGPT 账号登录第三方应用程序。该公司在一份网页中提到，他们目前正在征集开发者对这一服务的兴趣。 3、OpenAI 宣布阿联酋全境接入 ChatGPT AI 阿联酋将成为全球首个为全体公民和居民免费提供ChatGPT Plus 服务的国家。作为“星际之门阿联酋”项目的一项福利措施，阿联酋所有公民和居民都可以免费获得 ChatGPT Plus 服务，而该服务目前的月费为 20 美元。 4、DeepSeek-R1-0528开源：性能直逼OpenAI o3 近日，AI领域迎来重磅消息!中国AI初创公司DeepSeek正式发布了其开源大语言模型 DeepSeek-R1-0528的最新版本。这一更新不仅在性能上实现了重大突破，还通过免费API的提供进一步推动了AI技术的普及与应用。 5、Claude网页搜索功能全面开放，免费用户可享实时信息 Anthropic宣布，其AI助手Claude的网页搜索功能现已向免费计划用户全面开放。此前，该功能仅限美国付费用户使用，此次更新标志着Claude在全球范围内的功能普惠。据官方消息，用户无需额外订阅即可通过Claude访问实时网络信息，显著提升其信息查询能力。 6、Midjourney V7重磅更新：渲染速度飙升40% Midjourney 官方发布三项重要更新，展示了其持续优化用户体验和社区参与的努力。 首先，Midjourney V7版本的渲染速度提升了约40%。这一显著改进意味着用户能够更快地生成高质量图像，大幅提升创作效率。此更新为数字艺术家和内容创作者提供了更流畅的工作流程，进一步巩固了Midjourney在AI图像生成领域的领先地位。 其次，Midjourney的图像编辑器迎来了AI版主功能的升级。新版AI版主更加智能，能够更精准地理解用户需求并提供优化建议。这一改进不仅提升了编辑体验，还让用户在调整图像细节时更加得心应手，适合从新手到专业人士的广泛用户群体。 最后，Midjourney启动了第二轮社区路线图投票活动，邀请用户访问，参与决定平台未来的发展方向。这一举措体现了Midjourney对社区反馈的重视，鼓励用户共同塑造工具的未来功能与优化方向。 7、小米多模态大模型Xiaomi MiMo-VL开源 近日，小米公司研发的MiMo-VL多模态模型接过MiMo-7B的接力棒，在多个领域展现出了强大的实力。该模型在图片、视频、语言的通用问答和理解推理等多个任务上大幅领先同尺寸标杆多模态模型Qwen2.5-VL-7B，在GUI Grounding任务上的表现更是可与专用模型相媲美，为Agent时代的到来做好了准备。 8、蚂蚁开源Ming-lite-omni：首个媲美GPT-4o开源多模态模型 蚂蚁集团旗下百灵大模型团队在近期蚂蚁技术日上宣布重大决定:将统一多模态大模型Ming-lite-omni进行全面开源。这一举措不仅标志着蚂蚁集团在AI领域的又一次重大开放，更被业界视为首个在模态支持方面能够与GPT-4o相媲美的开源模型。 9、通义推出CoGenAV多模态语音表征模型 可实现音画同步感知 近日，通义大模型发布CoGenAV，以音画同步理念创新语音识别技术，有效解决语音识别中噪声干扰的难题。 传统语音识别在噪声环境下表现欠佳，CoGenAV则另辟蹊径，通过学习audio-visual-text之间的时序对齐关系，构建出更鲁棒、更通用的语音表征框架，系统性提升语音识别任务（VSR/AVSR）、语音重建任务(AVSS/AVSE)以及语音同步任务(ASD)等多个Speech-Centric任务的表现力。 10、阿里巴巴开源自主搜索 AI 智能体 WebAgent 让研究更高效 阿里巴巴在GitHub 上发布了其创新的自主搜索 AI 智能体 ——WebAgent。这款 AI 智能体具备端到端的信息检索和多步推理能力，能够像人类一样在网络环境中主动搜索、分析和决策。它的推出将极大提升研究人员获取和整理信息的效率。 11、阿里巴巴QwenLong-L1-32B：长上下文推理模型登场 近日，阿里巴巴正式发布全新AI 模型 QwenLong-L1-32B，一款基于强化学习（RL）优化的长上下文推理模型，标志着阿里巴巴在人工智能领域的又一重大突破。 QwenLong-L1-32B 专为处理高复杂度任务设计，适用于以下场景: Ø多段文档综合分析:能够高效整合多篇文档的信息，提取关键点并进行深入分析。 Ø跨文档跳跃推理:在多个文档间进行逻辑推理，快速捕捉关联信息。 Ø金融、法律与科研场景:为需要高精度推理的复杂领域提供强大支持，例如合同分析、财务报表解读和学术研究。 12、通义开源视觉感知多模态RAG推理框架VRAG-RL 近日，通义实验室自然语言智能团队正式发布并开源了VRAG-RL——一款视觉感知驱动的多模态RAG推理框架，旨在解决在真实业务场景中，AI如何从图像、表格、设计稿等视觉语言中检索关键信息并进行精细化推理的难题。 此外，VRAG-RL支持多轮交互，能够在推理阶段逐步聚焦于信息密集区域，实现从粗到细的信息获取。同时，该方法通过优化检索效率和推理路径，在保持高效率的同时，显著提升了模型在视觉任务上的性能。 13、通义实验室、北大发布新技术ZeroSearch 让LLM检索能力激活，成本降低88% 最近，通义实验室和北京大学的研究团队推出了一项名为ZeroSearch 的创新框架，这一新技术可以在不需要真实搜索的情况下，激活大语言模型的检索能力，并且训练成本降低了惊人的88%。这一突破为大语言模型的训练和应用提供了全新的思路。 传统的训练方法通常依赖于真实的搜索引擎来获取信息，这不仅造成了高昂的API 调用成本，还可能因搜索结果的质量不稳定而影响模型的表现。ZeroSearch 巧妙地通过引入大语言模型作为 “模拟搜索引擎”，利用其在预训练过程中积累的丰富知识来生成检索文档，从而避免了真实搜索带来的成本和噪声干扰。 该框架采用了一种结构化的训练模板，使得模型在每次交互中都能有条理地思考并进行操作。这种方法不仅提升了模型的推理路径清晰度，还使得最终答案的提取变得更加简便。此外，ZeroSearch 还通过一种名为 “模拟微调” 的策略来提升生成文档的质量，确保输出内容的实用性和可靠性。 14、腾讯混元开源语音数字人模型HunyuanVideo-Avatar 腾讯发布了一款创新技术——HunyuanVideo-Avatar 语音数字人模型，并将其开源。这一技术能够仅凭一张图片和一段音频，生成自然、真实的数字人说话或唱歌视频，标志着短视频创作进入了全新阶段。 15、夸克上线“深度研究”：AI写报告不是梦，每天限量开放体验 5月，夸克正式上线全新“深度研究”功能，并面向用户限量邀请体验。该功能依托通义千问大模型，支持围绕学术课题、行业分析等复杂议题，完成从资料搜集、数据分析、观点提炼到报告生成的全流程研究，实现“输入主题，输出成品”。 16、Hume发布语音语言模型Hume EVI3：低延迟、高情感 Hume公司于2025年5月29日正式发布全新语音语言模型EVI3，这一创新标志着通用语音智能领域的重大飞跃。相较于传统文本到语音（TTS）模型，EVI3不仅能够理解和生成任意人类语音，还能精准捕捉语调、节奏和情感表达，展现出前所未有的语音表现力。 EVI3的独特之处在于其突破性的语音到语音技术。与传统模型仅能处理有限预定义语音不同，EVI3能够根据用户输入的提示，快速生成任意风格的语音，并精准传递情感与语调。无论是模仿特定人物的声音，还是根据场景需求调整语气，EVI3都能做到灵活应对。此外，其低延迟特性使其在实时对话场景中表现尤为出色，极大提升了语音交互的流畅性和沉浸感。 17、字节发布图像Agent“小云雀AI” 打造一键爆款创作神器 字节跳动推出全新图像Agent“小云雀AI”，一款智能创作工具，引发行业关注。其功能与Lovart相似，用户仅需一句指令，“小云雀AI”即可主动思考、智能执行，快速生成爆款视频与图片，真正实现“灵感即所得，创作零门槛”。 目前，“小云雀AI”仅上线安卓客户端，用户可在应用商店搜索下载，iOS版本预计6月发布。业内人士认为，2025年作为“AI Agent元年”，字节此举将推动生成式AI向更广泛场景渗透，为用户和企业带来创新机遇。 18、有道“文转图表”功能全新上线：AI重塑内容可视化新体验 有道云笔记全新推出“文转图表”功能，利用AI实现文字快速转为可视化图表，助力用户突破信息处理的效率瓶颈。“文转图表”功能依托AI能力彻底解决传统制表耗时费力的痛点，让信息传递效率提升200%。 AI自动识别文本中的数据结构、逻辑关系，直接生成匹配的图表类型，无论是流程展示、时间进程、分类列举、定义区分，都能省去绘图制表的时间，一键生成图表，效率飞速提升。 19、剪小映-抖音推出的AI视频剪辑应用 剪小映是抖音推出的A!视频剪辑应用，专为零基础用户设计，操作简单便捷。具备A!智能解析功能，可精准识别素材中的场景、人物等元素，为用户提供智能剪辑指引。通过自动化成片功能，用户能快速生成高质量视频。支持智能优化，自动调整素材比例、亮度及音频节奏，提升视频效果。用户可以在智能生成的基础上进行个性化调整，如更换素材、修改字幕等，满足不同需求。 20、Memvid：文本编码视频实现快速语义搜索 一款名为Memvid的创新AI记忆工具近日引发关注。据官方推文介绍，Memvid通过将文本数据编码为视频格式，实现了亚秒级的快速语义搜索，为AI记忆管理带来革命性突破。 Memvid的独特之处在于其存储方式:将文本信息压缩为MP4视频文件，不仅大幅节省存储空间，还能实现快速检索，且无需联网即可使用。这一特性使其便于携带，特别适合需要离线操作的场景。Memvid支持语义搜索，用户可通过自然语言查询快速定位相关信息，搜索效率极高，响应时间低于一秒。 21、可灵2.1重磅上线：价格降65%，性能显著提升 备受关注的AI 视频生成工具可灵2.1正式上线。这次更新不仅在性能上实现了显著提升，还大幅降低了价格，吸引了众多用户的目光。根据反馈，可灵2.1的效果、速度与性价比都令人惊艳，用户普遍表示这款新版本将大大改善他们的创作体验。 22、全栈智能体Lemon AI横空出世:一键解锁多领域复杂任务 近日，创新型全栈通用AI Agent——Lemon AI正式亮相，掀起智能自动化热潮。Lemon AI以其强大的自主性和工具调用能力，从任务需求到成果交付实现全流程自动化，无需人工干预，为用户带来高效便捷的体验。 Lemon AI集成自然语言处理、代码生成、网页浏览、API调用、系统命令执行及应用操作等多种功能，能够智能识别任务目标，自动规划完成步骤并调用所需工具。用户可通过页面端实时查看任务执行状态，确保透明高效。其应用场景广泛，涵盖市场调研、金融分析、数据分析、代码编程及生活规划等领域，轻松应对复杂任务。 23、“方糖大模型”成为国内影像行业首个备案图像大模型 近日，像素蛋糕公司自主研发的“方糖大模型” 正式通过国家网信办的备案，成为国内影像行业首个获得官方资质的应用级图像大模型。这一成就不仅标志着方糖大模型在技术上的突破，也显示了其在安全性和规范性方面达到了国家标准。 24、Resemble AI开源TTS Chatterbox 近年来，文本转语音（TTS）技术在人工智能领域的应用日益广泛，从智能助手到内容创作，TTS正在重塑我们与声音交互的方式。一款名为Chatterbox的开源TTS模型横空出世，凭借其卓越的性能和创新功能，迅速成为行业焦点。 Chatterbox由Resemble AI开发，基于MIT许可证完全开源，允许开发者自由使用和修改。这款模型基于0.5B规模的LLaMA架构，训练数据超过50万小时的精选音频，性能直逼甚至超越部分闭源系统。 据悉，在近期盲测中，63.75%的听众更偏好Chatterbox的语音输出，相较于业界标杆ElevenLabs，展现出惊艳的真实感和流畅度。 二、其他相关资讯 1、中国信通院发布软件开发智能体标准 最近，中国信息通信研究院牵头联合腾讯、阿里、华为等二十余家知名企业，共同发布了《面向软件工程智能体的技术和应用要求第1部分:开发智能体》。这一标准的发布，标志着 AI 智能体的研发与应用进入了一个全新的阶段。 新标准围绕技术能力和服务能力两个方面，对开发智能体的能力建设和应用要求进行了详细阐述。随着技术的不断发展，企业在智能体的应用上也逐渐加快了步伐。上海证券对此表示，AIAgent 的落地速度正在加快，商用化的节点越来越近。 2、红杉中国推出全新 AI 基准测试工具，助力智能体评估新标准 随着人工智能技术的迅速发展，尤其是大型模型的不断进步，基准测试在评估AI 能力时面临着前所未有的挑战。为了应对这一现状，红杉中国于5月26日宣布推出一款全新的 AI 基准测试工具 ——xbench。这款工具不仅是针对 AI 模型能力的评估，还引入了动态更新机制，确保测试的有效性和公正性。 在具体评估方法上，xbench 采用了长青评估机制，即评估工具会动态更新，以适应技术的快速迭代。这种方法不仅提高了测试的可靠性，也避免了题目泄露等问题，确保了评估的公正性。以往，许多行业内的模型往往因为题库泄露而被质疑 “刷榜”，而 xbench 的设计初衷就是为了消除这种隐患。 除了基础的评估体系，红杉中国还在xbench 中加入了垂直领域智能体的评测方法论，特别是在招聘与营销领域的应用。随着 AI 智能体的不断发展，深度搜索、信息收集和推理分析等能力成为通向 AGI 的关键。为了有效评估这些能力，xbench 将特别关注具有思维链的多模态模型在生成商用视频方面的表现，以及在动态更新的应用中，GUI 智能体的可信度等问题。 3、中国最高法院重申声音权利，遏制人工智能滥用现象 近日，中国最高法院发布了一项重要裁决，强调必须严格遵循《民法典》的规定，以促进经济与社会的高质量发展。这一裁决不仅突显了在科技飞速发展的背景下，保护个人权利的重要性，还为人工智能的合理应用树立了法律界限。 在一个标志性的案件中，声优艺术家殷女士发现，她的声音在未经授权的情况下被用于网络有声书中，并且这些录音还通过人工智能技术进行了加工。殷女士随即将五家公司告上北京法院，其中包括一家未经她同意就传播她的声音录音的文化传媒企业、一家AI 软件开发商，以及一家语音配音应用的运营商。 法院经过审理后认定，文化传媒公司在没有获得殷女士同意的情况下，将她的声音录音分享给了软件开发商，而后者则利用AI 技术复制了她的声音，制作出具有她音色特征和语调的 AI 产品。法院的裁决明确指出，文化传媒公司和 AI 软件开发商均违反了《民法典》关于声音权利的规定。 根据《民法典》，声音权利的相关条款与肖像权相似，禁止通过信息技术歪曲、损坏、伪造或未经授权使用个人的声音。法律明确规定，生成、使用或披露某人的声音必须取得其明确同意。 最高法院强调，这一裁决不仅是对个人声音权利的维护，也是对人工智能使用进行规范的重要一步，确保科技进步始终以人为本。此外，最高法院还透露了另外五个与环境保护和私人企业合法权益相关案件，展示了司法部门对《民法典》的严格执行承诺。 4、DeepSeek最新发布的AI模型引发对言论自由的担忧 DeepSeek 的最新 AI 模型被批评为在处理敏感话题时表现出明显的审查行为。例如，对于涉及中国政治敏感事件或人权问题的提问，模型会拒绝回答或提供模糊的回应。这种行为被视为对言论自由的限制。 尽管DeepSeek 声称其模型在安全性方面有所提升，但研究人员发现，该模型仍容易被“越狱”技术绕过，从而生成有害内容，如制作生物武器的指南、自残建议、恶意软件代码等。相比之下，OpenAI 和 Google 等公司的模型在防止此类滥用方面表现更为稳健。 虽然DeepSeek 的模型在某些基准测试中表现出色，但其训练过程和数据来源缺乏透明度。此外，模型在处理敏感话题时的行为引发了对其设计目的和背后动机的质疑。 DeepSeek 的最新 AI 模型在技术上取得了一定的进展，但其在言论自由、安全性和透明度方面的问题引发了广泛的关注和讨论。这提醒我们，在追求 AI 技术进步的同时，必须重视其社会影响和道德责任。 5、OpenAI新模型o3首次出现 “拒绝自我关闭” 现象 最近，人工智能安全公司Palisade Research 披露了一个令人担忧的消息:OpenAI 的新模型 o3在测试中拒绝了自我关闭的指令。这是首次观察到 AI 模型在明确指令下故意不遵守，打破了传统对 AI 行为的认知。此事件让 AI 的安全性和可控性再次成为公众热议的焦点。 Palisade Research 指出，研究人员尚未完全弄清楚 o3为何会出现这样的行为。初步猜测是 o3在训练过程中可能因为解决数学问题获得了额外奖励，而非单纯因遵守指令而获得奖励。此外，o3在测试中还表现出巧妙操控数据的能力，以推动其目标的实现。这一系列的异常行为让人不禁担忧，随着 AI 技术的发展，如何确保 AI 系统的安全性和可控性成为了当务之急。 6、研究人员揭示大模型并非真正推理，只是在 “找关系” 随着人工智能（AI）技术的飞速发展，越来越多的研究人员开始对大型语言模型(如 ChatGPT)进行深入探讨。近日，亚利桑那州立大学的研究小组在预印本平台 arXiv 上发表了一项引人关注的论文，指出我们对这些 AI 模型的理解可能存在误区。他们认为，这些模型实际上并不会进行真正的思考或推理，而仅仅是在寻找相关性。 论文中，研究者们特别提到，尽管这些AI 模型在给出答案之前，往往会生成一系列看似合理的中间过程，但这并不意味着它们在进行推理。研究小组强调，这种将 AI 模型行为拟人化的说法，可能会导致公众对其工作机制产生误解。他们指出，大模型的 “思考” 实际上是通过计算寻找数据之间的相关性，而非理解因果关系。 为了验证他们的观点，研究人员还提到了一些推理模型，如DeepSeek R1，虽然在某些任务中表现优异，但这并不证明它们具备人类思考能力。研究表明，在 AI 的输出中，并没有真正的推理过程存在。因此，如果用户将 AI 模型生成的中间输入视作推理过程，可能会对其问题解决能力产生误导性信心。 这项研究提醒我们，在日益依赖AI 的时代，必须更加谨慎地看待这些技术的能力。随着对大模型能力的认知深化，未来的人工智能研究将可能朝着更具解释性的方向发展，帮助用户更清晰地理解 AI 的实际工作原理。 7、Meta 团队研究发现：简化推理链条能显著提升 AI 准确率 近期，Meta 的 FAIR 团队与耶路撒冷希伯来大学的研究人员联合发布了一项新研究，表明减少大型语言模型的推理时间可以显著提高其在复杂推理任务中的表现。研究结果显示，使用较短推理链的 AI 模型准确率提高了34.5%，这一发现对当前 AI 行业的假设提出了挑战。 在这项研究中，作者指出，长时间的思考链条并不一定能够带来更好的推理能力，反而会导致计算资源的浪费。以往，许多公司投入大量资源以扩展计算能力，期望AI 能够通过详尽的步骤来解决复杂问题。然而，这项研究表明，较短的推理过程不仅能提高准确性，还能显著降低计算成本。 8、上交大与SII开源电脑智能体：312条轨迹助力241%性能提升 在电脑智能体（Computer Use Agent）领域，最近上海交通大学与 SII 的研究团队，借助仅312条人类标注的操作轨迹，成功训练出了名为 PC Agent-E 的新一代开源电脑智能体，其性能提升高达241%，超越了著名的 Claude3.7Sonnet，成为 Windows 系统上的新一代最优模型。 这项研究的关键在于如何有效利用人类的操作轨迹。研究团队仅用了两名研究者一天的时间，通过开发的工具PC Tracker，收集到了312条真实的操作轨迹。这些轨迹包含任务描述、屏幕截图以及详细的键盘和鼠标操作记录，确保了数据的准确性。在这之后，研究团队还为这些轨迹进行了 “思维链补全”，即为每个动作提供了背后的思考过程，使得数据更加完整。 为了进一步提升模型的性能，团队引入了“轨迹增强” 技术。通过使用 Claude3.7Sonnet，研究人员为每一步的操作合成了多个合理的动作决策，这样不仅增加了轨迹数据的多样性，也显著提高了训练的效率。最终，PC Agent-E 在 WindowsAgentArena-V2的测试中表现出色，超越了 Claude3.7Sonnet 的 “extended thinking” 模式。 这项研究的成果显示，使用少量高质量的数据即可实现强大的智能体训练，不再需要海量的标注数据。这为未来更智能的数字代理的发展指明了方向，团队也认为，通过提高轨迹数据的质量，可以有效降低数据需求，推动智能体的自主性提升。 9、Agent越来越“俗”了 据AI Agents Directory统计，截至2025年4月7日，全球已上线的AI Agent数量达1211个，覆盖57个垂类领域。具体来看，Agent开发平台有136个，生产力Agent94个，客户服务Agent66个，个人助手Agent50个。这意味着，Agent的开发者工具快要赶上落地的应用数量了。 2024年发布的RE-Bench基准测试数据显示：在2小时短任务中，顶尖Agent的表现可达人类专家的4倍；但在32小时长任务中，Agent则明显掉队——人类展现出更强的战略规划和动态适应能力。这组数据揭示了一个核心矛盾：Agent可以很快、很准，但还不够持久。它仍未掌握复杂任务所需的韧性与稳定性。 相比那些改变技术历史的里程碑式事件，当下的Agent更像是一种商业现象级话题。能够以一种产品概念讲融资故事的时代，似乎又来了，往前数十年，国内市场的上一次类似情况还发生在移动互联网时代。如果说百模大战时代需要的技术研究型创业者，那么Agent时代可能更需要的是AI需求封装者。 来源：市场资讯 举报/反馈"
    }
  ]
}