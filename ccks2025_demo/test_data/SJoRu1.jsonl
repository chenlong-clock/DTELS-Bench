{
  "query": "《纽约时报》指控OpenAI滥用提示",
  "id": "SJoRu1",
  "granularity": 31,
  "time_range": [
      "2024-01-09",
      "2024-01-22"
  ],
  "articles": [
    {
      "doc_id": 37966,
      "title": "倒反天罡:ChatGPT教人说话?36万视频+77万播客已证实!",
      "time": "2025-07-17T00:00:00+00:00",
      "content": "新智元报道 编辑：KingHZ 【新智元导读】你以为你在掌控AI，其实是AI在驯化你！最新研究警告：ChatGPT正改变英语的表达方式，悄然植入自己的偏好。是时候重新审视，我们到底在表达自我，还是AI的「复读机」？ AI驯服人类第一步：教人重新说英语？ 最近，越来越多的媒体发现：说话的方式，越来越像ChatGPT了！ 这不是模仿，而是「入侵」。 潜移默化之中，人类被AI「同化」： AI不仅入侵了你的笔端， 还悄悄占领了你的大脑。 最终，从你口中倾泻而出！ 说英语的小心了！ ChatGPT正给你洗脑 最新的arxiv预印给出了惊人的结论：ChatGPT可能正在悄悄改变我们的用词习惯。 无论你觉得它方便，还是感到不安，ChatGPT都已悄然成为写作、搜索甚至日常对话的常驻嘉宾，一点点重塑我们的语言和思维方式。 此同时，网络上掀起了热议： 是否能通过「破折号」这类细节，一眼识破AI写的内容？ 答案或许正在改变。 然而，这项新研究却给了出人意料的答案：「AI痕迹」正在变得越来越难以识别——因为人类的语言风格，正在越来越像ChatGPT。 研究人员发现，自ChatGPT推出以来，短短18个月，人们在日常交流中使用的所谓「GPT词汇」（GPT words）飙升。 这是来自德国马普人类发展研究所（Max Planck Institute for Human Development，MPIB）的最新的研究。 论文链接：https://arxiv.org/abs/2409.01754 已有研究指出ChatGPT会影响人类的书面表达方式，但这一次，研究者想知道，AI的迅速普及是否也正在悄悄改变我们的「说话方式」。 为了这项研究，数百万页的电子邮件、文章、学术论文和新闻报道上传到ChatGPT，进行润色。 然后，研究人员分析AI更偏好的词汇，比如「delve」「realm」「meticulous」等。他们称这些为 GPT词汇。 随后，在超过36万个YouTube视频、77万个播客片段中，他们追踪这些词汇的使用频率变化，发现了惊人的上升曲线！ 图2：量化ChatGPT的词汇偏好及其对人类交流的影响 （A）学术YouTube报告中「delve」一词使用量的时间趋势图，显示ChatGPT发布后该词使用量显著增加（与合成对照组相比p=0.010） （B）ChatGPT词汇偏好测量方法：通过对比人工撰写文本与ChatGPT修改版本的词频分布，计算得出的对数比值（即GPT分数）可量化特定词汇被ChatGPT偏好的程度 （C）由GPT分数测得的ChatGPT特征性词汇（GPT词汇集），不同版本ChatGPT对「delve」的强烈偏好具有一致性 （D）通过供体词汇的凸组合构建具有相似发布前模式的合成对照组，用于推断因果影响 这项最新的研究却告诉我们一个有趣的事实：这些「AI口音」可能越来越难以发现——因为人类的说话方式，正在逐渐变得像ChatGPT。 即便排除同义词和脚本化内容的影响，研究发现在英语口语中，GPT词汇确实的使用率显著攀升。 这项研究发人深省，但也有一些值得注意的限制。 首先，研究人员分析的数据来自特定的GPT模型：GPT-4、GPT-3.5-turbo、GPT-4-turbo和GPT-4o。这使得研究局限于这些特定版本的ChatGPT。 在未来几个月和几年中，OpenAI无疑会推出新的模型，而这些新版本可能会展现出新的语言使用形式和词汇偏好。 因此，这项研究可能很快过时。 此外，目前还不清楚ChatGPT是否确实对更随意的口语表达有影响，特别是考虑到研究人员从学术来源中获取了大量数据。 而且，语言和词汇的使用会随着时间因多种因素而不断演变；虽然ChatGPT可能在某种程度上对我们使用的词汇变化有所贡献，但重要的是要指出社会和文化中许多其他来源也促成了语言的变化。 「伪人」崛起 共同作者Levin Brinkmann对媒体解释过：「AI技术存储的语言模式，正在反哺人类思维。人类天生会相互模仿，但主要针对那些知识渊博或德高望重的人。我们更倾向于复制他们的语言行为。」 Levin Brinkmann：马克斯·普朗克人类发展研究所研究员，专注于研究机器与人类社会日益深化的融合进程。他采用复杂系统理论、机器学习与实验社会科学方法，探究人机混合系统的演化规律。他获得计算社会科学博士学位，以及哥廷根大学物理学硕士学位 换言之，人与AI之间正在形成一种文化反馈循环：我们使用书面文本训练AI，AI将统计重构后的文本回传给我们，而我们捕捉到这些模式后，便开始无意识地模仿它们。 研究指出，越来越多人将AI视为文化权威，这使得「最初基于人类数据训练的机器，在形成自身文化特征后，可量化地重塑人类文化」。 Brinkmann强调： 「delve」只是冰山一角，其他高频GPT词汇还包括： 「underscore」（强调）、「comprehend」（理解）、「bolster」（支持）、「boast」（拥有）、「swift」（迅速）、「inquiry」（调查）、「groundbreak」（开创性）…… 图3（a）:高频GPT词汇出现频次与合成对照组的线性回归分析。圆点表示月度聚合频次，趋势线标注以虚线标记的转折时点。如「comprehend」（理解）、「boast」（拥有）、「swift」（迅速）等词汇与「delve」类似，均呈现显著增长 图3（b）：词汇的GPT分数（x轴）与其使用趋势变化幅度（y轴）的关联性。柱状图表示后验分布的95%高密度区间，插图中阴影区域为高斯过程回归的95%置信区间。聚焦前20个GPT词汇（插图最右侧），可观测到一组年增长率约25%-50%的词汇 尽管这项研究主要聚焦在词汇层面，但许多研究人员已经注意到，AI的影响正逐步渗透到语气当中—— 比如说话变得更长、更有条理，同时情绪表达也被削弱。 康奈尔大学的研究发现，在聊天中使用智能回复会让人们更有合作意识，也能增进彼此的亲密感，因为使用者倾向于选择更正面、更有情感的语言。 然而，一旦人们察觉对方可能在用AI，反而会觉得对方不够诚恳，从而态度变得更强硬。关键并不是对方真的用了AI，而是那种「怀疑」的感觉。 论文链接：https://www.nature.com/articles/s41598-023-30938-9 正如该研究合著者、康奈尔大学信息科学副教授Malte Jung所说，我们是根据语言特征来判断他人，而真正影响我们印象的，是那些语言本身的性质。 Malte Jung的研究旨在探讨群体和团队中的人际互动动态，以及这些动态如何受到机器的影响 康奈尔理工学院信息科学教授Mor Naaman指出，这种「AI既改善沟通又引发猜疑」的矛盾现象，折射出更深层的信任危机。 Mor Naaman是康奈尔大学科技校区、雅各布斯技术与康奈尔研究所及康奈尔安·鲍尔斯计算与信息科学学院的教务长事务副院长，同时也是Don and Mibs Follett信息科学教授。他专注于技术、媒体等交叉领域的课题。他在斯坦福大学InfoLab获得了计算机科学博士学位。此外，他还曾效力于篮球队，作为职业篮球运动员参赛 他提出在AI沟通中，人性丧失的三重信号： 第1层信号：人性。那些笨拙、结巴的语气，才是「我真的在说话」。 第2层信号：用心。不是复制粘贴，而是花时间打下每一个字。 第3层信号：能力。真正的个性，是用真实语言展现幽默、情绪与深度。 你说的话里，藏着你是谁；一旦AI代言，我们也许就不再是「自己」。 Naaman认为，AI中介沟通的未来在于重建并强化这些信号，因为AI不仅改变语言，更重塑思维。 在约会软件上，当AI能替你展现幽默时，个人资料中的「幽默」还有何意义？ 他最担忧的是从语言到思维的主体性丧失：「我们不再表达真实想法，而是表达AI帮我们组织的内容...我们会越来越被其说服。」 他警告，若失去这些信号，人类将只信任面对面交流——甚至不信任视频通话。 AI偏爱英语「伦敦腔」？ 当AI悄然定义何为「得体」语言时，信任危机更趋复杂。 加州大学伯克利分校研究发现，AI偏好「标准英语」： 当用户尝试用新加坡英语、黑人英语等表达时， AI的反馈常常失真、夸张，甚至令人不适。 这不仅是语言问题，更关乎文化的尊重。 论文链接：https://arxiv.org/abs/2406.08726 一位说新加坡英语的网友评论道：「回复里夸张的新加坡式英语让人尴尬。」 研究表明AI不仅偏爱标准美式英语，还会通过压制其他方言来贬低使用者。 这种机制不仅固化对族群的错误认知，更扭曲了「正确」英语的标准。 因此这不仅关乎保护语言多样性，更关乎守护那些真正建立信任的不完美特质。 当周围人都开始说「正确」英语时，我们将失去那些结巴表达、地方俚语和非常规短语——这些正是脆弱性、真实性和人格的信号灯。 我们正处在分岔路口，矛盾重重： 学术界抵制「delve」等用词、人们刻意避免AI腔等反弹现象，显示人类可能自我调节对抗同质化； AI系统本身或将更具表现力和个性化，从而缓解当前的「AI腔」问题； 而最深层的风险并非语言趋同，而是对人类思维与表达自主权的丧失。 AI正在入侵我们的潜意识。它正在暗中改写我们的语言基因，操纵着人类最本能的交流密码！这场悄无声息的精神殖民会将人类带向何方？ 细思极恐的是，我们甚至还没意识到自己正在被改造。语言学家发出紧急警告：必须立即监控AI对人类社会全方位的文化渗透，否则后果不堪设想！ 原标题：《倒反天罡：ChatGPT教人说话？36万视频+77万播客已证实！》 阅读原文"
    },
    {
      "doc_id": 38058,
      "title": "民主与法制周刊:AI时代 知识产权司法迎来新挑战",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "编者按 知产审判为知识产权强国建设注入司法力量 党的十八大以来，人民法院知识产权审判工作迎来了历史性跨越。 各级法院积极探索知识产权保护新机制、新办法、新途径，为创新创业保驾护航，为公平正义提档加速。 专门化审判体系建设，探索建立技术调查官制度，采用“云庭审”远程勘验证据实物，以个案标杆性裁判确立AI保护新标准……一系列创新的方式向社会交上了一份满意的答卷。越来越多的外国企业选择到中国法院解决知识产权纠纷，我国法院正在成为知识产权保护最优选择地。 近日，本社记者走进北京、上海、江苏、四川等多地法院，聆听知识产权法官讲述知识产权审判故事，感受知识产权保护中的司法力量，触摸知识产权审判机制的变革脉搏，见证以司法力量服务保障高质量发展的生动篇章。 >>北京中关村国家自主创新示范区展示中心 新华社记者 鞠焕宗/摄 ChatGPT的对话式创作、DeepSeek的深度求索、MidJourney的图像创造……生成式人工智能（AIGC）正以指数级速度重构知识生产范式。随着AI生成的文字、图像、音乐甚至专利发明大量涌现，传统知识产权法律体系在“独创性认定”“侵权标准适用”“责任主体划分”等核心领域遭遇前所未有的冲击。 一些新问题接踵而至：AI创作是否具备“独创性”？数据训练的版权边界何在？生成式AI平台该如何担责？在这场技术与法律的碰撞中，我国各地司法机关主动破局，积极探索，通过一系列标志性案件的审理，逐步勾勒出AI时代知识产权保护的创新路径雏形。 AI生成的东西，是不是“原创作品”？ 2023年8月24日，一场直播吸引了17万人同时在线观看。 这是北京互联网法院的一场庭审直播。在庭审中，原告李昀锴现场打开绘画大模型Stable Diffusion，向法官演示了通过输入数十个提示词并调整参数等，生成AI图片《春风送来了温柔》的整个过程。 这场庭审不仅关乎一幅画的版权归属，更折射出人工智能时代司法裁判的深层变革,成为全国首例明确AI生成图片可受著作权保护的案件。 2023年2月，原告李昀锴使用Stable Diffusion模型生成《春风送来了温柔》古风女子画像，并在其社交平台上分享。但想不到的是，这幅画像被被告刘女士私自用于自媒体文章配图，并抹去署名水印。李昀锴认为，刘女士此举侵犯其署名权与信息网络传播权，遂提起诉讼。 AI生成的图片是否构成作品，受著作权保护？在这场AI生成内容版权争议中，“独创性”认定成了核心争议的焦点。 北京互联网法院认为，原告通过多次调整参数和提示词，体现了“个性化表达与智力投入”符合著作权法对独创性的要求。2023年11月，北京互联网法院一审判决刘女士侵权成立，需赔礼道歉并赔偿500元。 该案承办法官朱阁表示，AI模型本身并非法律主体，因此无法成为著作权法中的“作者”。在一定条件下给予AI生成内容作品一个法律意义上的身份，是为了激励大家用新工具进行创作。经过综合考量，法院原则性地承认了李昀锴作为该作品的作者地位。 “利用人工智能生成内容是否构成作品，应当根据具体情况进行分析，而非一概而论。”朱阁说，关键在于人类使用AI模型的技术原理是否给人创作空间、生成的内容是否体现了人类的独创性。正是因人类的不同提示词使用，最终生成的结果也大相径庭，这种差异性是体现人类独创性的重要标志。 不过，在丰某某诉东山公司“幻之翼透明艺术椅”AI侵权案中，张家港市人民法院却认为，著作权保护的落脚点在于具体表达而非抽象思想。提示词输入相对于生成式人工智能产生的内容只是思想，并非受著作权法保护的表达。简单的提示词本身不是作品，参考行为并不构成侵权。 丰某某系一名设计师，于2023年8月通过Midjourney等AI工具创作完成“幻之翼透明艺术椅”系列美术作品，并在小红书平台上进行发布，标题为“Midjourney|这也太可爱了|商家在哪里！求量产”。东山公司在接触丰某某作品并寻求合作无果后，通过类似AI工具生成近似设计并量产销售。丰某某以其创作的“幻之翼透明艺术椅”系列作品具有极高的独创性和市场价值、已投入生产并上市、东山公司侵权为由将其诉至法院。 法院认为，丰某某主张其希望创作具有果冻质感、玻璃般透明的蝴蝶形状座椅图片，但在Midjourney软件中仅输入简单提示词，并设置了参数，且无法提供创作过程中相应的流程图等原始记录，难以体现其从最初构思到最终选定的整个过程进行了独创性的智力投入，故案涉图片不符合作品的构成要件，不能认定为作品。 有评论指出，“幻之翼透明艺术椅”案的判决进一步凸显了AI作品的“智力投入”在司法认定中的核心地位。张家港市人民法院通过细化“独创性”的标准，强调举证责任和可控性，表明了司法对AI生成内容的态度从鼓励创作的包容性探索转向审慎规范。 司法积极探索的同时，学术界对“AI生成内容是不是应该受到版权保护”“版权该归谁”这些问题的判定，争议也没有停止。 中国社会科学院法学研究所研究员、知识产权中心名誉主任李明德认为，著作权法明确作者为自然人，AI生成内容因缺乏人类创作主体资格，本质上不属于作品，不应获得著作权保护。同时鉴于国外版权法体系关于独创性的要求标准不一，建议关于自然人利用人工智能创作作品，还要特别关注由此而产生的表达，是否符合我国著作权法的独创性要求。 中国政法大学数据法治研究院教授张凌寒则表示，是否赋予AI著作权与虚拟财产的法律保护问题类似，可以参考洛克的劳动赋权理论，或者证实有一定的支配性和排他性等理论。关于版权归属争议，当前市场实践中，服务提供者通常通过用户协议约定权利归属，模式多样。在法规制度建设方面可以探索“AI辅助创作”的认定标准，细化用户利用AI工具创作时，何种程度的智力投入可被视为具有独创性，从而使相应生成内容获得著作权法保护。 有观点认为，随着AI技术的广泛应用，未来类似的版权纠纷可能会更加频繁。版权归因与利益的重新分配，尤其是在AI长文本生成、视频生成等领域，可能会成为今后法律面临的新挑战。 >>2025年5月22日，观众在文博会腾讯展台了解AI产品。 新华社记者 肖恩楠/摄 用别人的作品训练AI，算不算“偷东西”？ “AI大模型训练主要分为三个环节：首先是收集各类数据并存储至专用数据库；其次对数据进行清洗、格式转换等预处理，使其适配模型训练需求；最后将预处理后的图片转化为数学向量表示，使模型掌握从数学表示生成对应图片的能力，整个过程通过数学建模实现对图像特征的学习，而非直接复制原图。”2024年6月20日，北京互联网法院开庭审理全国首例涉及AI绘画大模型训练著作权侵权案，庭审中，技术辅助人员南加州大学计算机学博士研究生梁楚盟向法庭说明AI大模型训练流程。 该案中，四位插画师起诉小红书旗下AI绘画产品“Trik AI”软件主体公司伊普公司及其平台公司行吟科技公司，指控其未经授权使用原告美术作品训练AI模型并生成高度相似图片，构成著作权侵权。 此案引发广泛关注，其核心争议在于AI训练数据来源合法性争议、合理使用与侵权边界及生成内容“实质性相似”认定。 伊普公司提出多项抗辩：其一，AI生成图片与原告作品不存在“实质性相似”；其二，模型训练行为属于著作权法中的“合理使用”，因AI学习过程不直接复制原作，且生成内容具有“再创作”性质；其三，已通过用户协议获得小红书平台内容的合法使用权。行吟科技公司则否认参与模型开发，强调其用户协议为通用条款，未向被告提供训练数据。 截至2025年6月，案件仍在审理中，尚未公布最终判决。此案可能成为国内AI训练数据侵权领域的标杆案例，为后续立法及司法实践提供参考。 这样的AI版权纠纷还出现在爱奇艺诉MiniMax案中。2025年1月，国内知名视频平台爱奇艺在上海市徐汇区人民法院提起诉讼，正式指控MiniMax公司及其旗下的海螺AI产品，在未经授权的情况下使用了爱奇艺享有版权的素材进行模型训练。爱奇艺要求MiniMax公司立即停止侵权行为，并索赔约10万元人民币。该案件目前仍在司法程序进行中。 类似争议在海外同步上演。如美国《纽约时报》等8家媒体诉微软、OpenAI案中，8家媒体指控微软、OpenAI使用媒体刊登的文章训练人工智能模型，侵犯其版权，要求赔偿。两被告同样以“公开数据合理使用”抗辩，但中外司法尚未形成统一规则，反映出该领域的全球性难题。 2023年7月，《生成式人工智能服务管理暂行办法》公布，明确规定大模型语料训练应“使用具有合法来源的数据和基础模型”。是否构成著作权法上的合理使用，是“四位插画师起诉Trik AI案”认定侵权与否的前提判断之一。我国著作权法上规定了多种合理使用作品的情形，不过并未规定将作品用于大模型语料训练是否能落入合理使用范畴，法学界和产业界为此争议不断。 一方面，大模型训练依赖海量数据，若严格要求授权将增加技术成本；另一方面，未经许可使用作品，可能动摇创作激励基础。如何在技术可行性、产业发展与权利人利益间寻求平衡?“四位插画师起诉Trik AI案”将为后续类似案件提供重要指引。 “当然，从人工智能产业的长远发展来看，确保人工智能模型训练所需的语料充足，也是非常重要的。但无论如何，人工智能产业的发展，不能以牺牲著作权人的利益为代价。在这方面，既要保证人工智能训练可以使用充足的语料，又要充分保障著作权人的合法权益，这是值得世界各国的立法者、司法者和经营主体深入探讨的一个问题。至少在目前看来，著作权的集体许可是一个可行的路径。”李明德说。 中国政法大学数据法治研究院等7家单位草拟的《人工智能法（学者建议稿）》提出，若AI训练使用数据的目的与原用途不同，且不影响正常使用及权利人利益，可认定为合理使用，但需标注数据来源。这一建议为司法实践提供了理论参考。 “数据清洗、来源标注等做法不仅是提升模型性能和生成内容质量的技术手段，更是确保生成内容合法性的重要环节。法律治理应积极引导和规范相关技术标准的制定，确保数据客观真实，防止操作人员篡改数据或引入偏见。此外，应设计引导市场分工的法律制度，鼓励多元数据授权合作与第三方合规服务。”张凌寒说。 用户侵权，AI平台需不需要担责？ 2024年，广州互联网法院与杭州互联网法院相继审理了涉生成式人工智能的著作权侵权案件，两案均围绕奥特曼形象的AI生成内容展开，但裁判思路存在显著差异，核心区别在于平台责任认定中直接侵权与间接侵权的界限。 广州互联网法院审理的“奥特曼AI生成图片侵权案”判决显示，上海某文化公司独占持有奥特曼系列作品的著作权，指控被告广州某网科公司运营的Tab网站通过其具有的AI绘画功能生成与奥特曼形象高度相似的图片，且通过会员充值机制非法获利。 法院认为，平台作为内容生成工具的直接提供者，其AI功能直接输出侵权内容，构成对复制权、改编权的侵害，违反了《生成式人工智能服务管理暂行办法》《互联网信息服务深度合成管理规定》的相关规定。尽管平台辩称生成内容由用户指令触发，但法院指出平台对模型训练数据来源及生成结果具有实际控制力，且未建立投诉机制或风险提示，主观存在过错，需承担直接侵权责任。 法院判令广州某网科公司立即停止侵权，立即采取技术措施防止用户正常使用该AI功能时生成侵权图片，并向原告赔偿1万元。 杭州互联网法院审理的“奥特曼AI生成图片侵权案”判决显示，被告杭州某智科公司运营的AI平台允许用户上传奥特曼图片训练LoRA模型，生成与原作高度相似的图片。原告上海某文化公司作为奥特曼系列作品的独占授权方，主张平台构成直接侵权及不正当竞争，要求停止侵权并赔偿30万元。被告抗辩称，其仅提供信息存储空间和技术服务，用户上传内容由用户自行负责，平台应适用“避风港原则”免责。 法院经审理认为，生成式AI平台兼具内容生产者与平台管理者的双重身份，需根据技术特点分阶段界定责任。在数据输入端，用户上传侵权素材，平台未直接参与训练，不构成直接侵权；但在内容输出端，平台对用户生成的侵权模型及图片未采取必要措施，构成帮助侵权。 法院指出，平台通过会员充值等营利模式获益，且LoRA模型可稳定输出侵权内容，某智科公司应预见侵权风险却未采取过滤、屏蔽等措施，主观存在过错，构成帮助侵害案涉奥特曼作品信息网络传播权的行为。2024年9月，法院一审判决被告停止侵权并赔偿3万元。 广州互联网法院的判决强调平台对生成内容的技术控制力是责任认定的关键，若技术介入程度高且直接获利，则需突破“技术中立”原则；杭州互联网法院创新性提出“分阶段责任”，判决首次明确生成式AI平台的责任边界：平台对用户输入内容无审查义务，但对输出内容需承担合理注意义务。技术中立原则不再成为侵权借口，平台需匹配其技术能力与注意义务强度。两地法院对“奥特曼AI生成图片侵权案”的判决的差异，折射出司法对AI技术介入程度的差异化评价逻辑。 李明德表示，关于人工智能生成的内容，应当更多地关注前端训练是否侵权的问题。目前，我国的专家学者和一些法院，更多地关注了人工智能输出端是否侵权的问题，而对于人工智能前端的训练阶段使用他人作品是否侵权则有所忽略。杭州互联网法院审理的“奥特曼案”，倾向于认定人工智能模型训练中使用他人作品不构成著作权侵权。显然，这样的思路存在疑问。 “因为人工智能训练中对于他人作品的使用属于商业性使用。如果将商业性使用受到著作权法保护的作品认定为不侵权，则著作权法保护作品、鼓励创新的宗旨将在很大程度上失去意义。”李明德说。 张凌寒则表示，对于大模型平台可参照“避风港规则”，强调“明知”标准；对于大模型提供者，可以从“可预见性”视角强调其“注意义务”；对于大模型使用者，可以主要从“主观过错”的视角检视。同时应探索多元化停止侵权措施和多因素综合的损害赔偿机制。 AI模型本身，还要不要保护？ 在抖音平台上，照片视频一键“变身”生成漫画，是颇受用户喜爱的爆款特效之一。该特效上线两个月之后，在“B612咔叽”App中便出现了与之近乎相同的少女漫画特效。对于这种公然抄袭，抖音公司一纸诉状将“B612咔叽”App的运营商亿睿科公司告上法庭。案件经过一审、二审，3月31日在北京知识产权法院落下帷幕。 一审法院经审理认定，双方模型的网络结构、卷积层数及参数相似比例达91.7%，被告行为违反商业道德，构成不正当竞争。 北京知识产权法院二审维持了一审关于不正当竞争的判决，但在权益保护对象的认定上与一审存在差异：一审认为保护范围是特效模型的变身漫画特效产品，二审则明确权益保护对象为特效模型的结构及参数。北京知识产权法院进一步明确，AI模型的结构和参数作为企业核心资产，属于反不正当竞争法保护的“竞争性权益”，强调经营者对技术创新投入的合法权益受法律保护。最终判决亿睿科公司赔偿抖音公司经济损失150万元及合理开支10万元。 评论指出，北京知识产权法院从模型抄袭行为构成实质替代性损害的角度，认定被告行为构成不正当竞争，并支持了160万元的高额赔偿要求。其探索出的保护思路与维权经验，对未来同类人工智能权益的保护具有借鉴与复用意义。 该案的主审法官北京知识产权法院李迎新表示，对AI模型的保护规则正处于探索阶段，本案虽然适用反不正当竞争法第二条原则条款对被告直接商业化利用原告模型结构和参数的行为予以规定，但这并非唯一保护路径。如果模型的结构和参数满足商业秘密的“价值性、保密性、秘密性”要件时，也可根据个案情况适用商业秘密保护规则。 “司法机关在审理中还会结合人工智能模型的技术特点，妥善认定‘独立研发’等抗辩主张，以平衡企业创新权益保护与市场竞争秩序的维护。”李迎新说。 事实上，即使是开源的AI大模型数据，数据需求方也需要严格遵循开源协议约定的使用范围与目的，未经许可的商业性使用同样可能构成不正当竞争。 2021年9月，数某某公司通过网站发布“AI数据开源计划1505小时中文普通话语音数据”，并获颁《数据知识产权登记证》。但“1505小时数据集的子集”后续被隐某公司非法获取并在其官网传播。数某某公司遂以隐某公司侵害其数据财产权、著作权和商业秘密构成不正当竞争为由提起诉讼。 北京知识产权法院二审认为，案涉数据集因数某某公司主动公开而丧失秘密性，不构成商业秘密；同时，数据集在内容选择和编排上缺乏独创性，不构成汇编作品。但数某某公司对数据集投入了实质性劳动，形成了具有商业价值的声音数据条目，该商业利益属于反不正当竞争法保护的竞争性权益。隐某公司违反案涉CC开源协议的非商业目的使用规则，未自行积累资源或支付对价，其行为违背数据服务领域的商业道德，损害了市场竞争秩序，构成不正当竞争。 该案的判决明确了如下规则：其一，数据知识产权登记证可作为证明数据处理者合法持有数据产品及数据来源合法的初步证据，在无相反证据推翻的情况下，司法程序中可据此初步认定权益归属及收集合法性，但登记证效力受登记机构资质、审查方式等因素影响，且允许利害关系人通过反证质疑；其二，针对数据集合的不同法律属性，确立“分类保护、阶梯适用”规则，即对具有独创性的数据集优先通过著作权法保护，对未公开且符合商业秘密要件的适用反不正当竞争法商业秘密条款，对已公开但数据处理者投入实质性劳动的则依据反不正当竞争法第二条保护；其三，首次明确数据需求方使用开源数据需严格遵循开源协议约定的范围与目的，未经许可的商业性使用构成不正当竞争，平衡了数据开源与权益保护的关系。 “在数字经济背景下，本案作为全国首例涉及数据知识产权登记证效力认定的案件，以司法创新实践回应了‘数据二十条’提出的‘研究数据产权登记新方式’的政策指引。”李迎新说，“本案二审判决为数据权益保护确立了裁判规则，即对数据登记证书法律效力的精准界定与企业数据保护路径的明确指引，有助于推动形成‘登记有标准、交易有依据、争议有解法’的法治化数据要素市场环境。” 从AI生成内容的著作权确权，到训练数据、平台责任、模型与数据权益的司法界定，我国知识产权审判机关在技术创新与权利保护中寻求平衡，已经走上了一条“个案探索-规则提炼-体系构建”的渐进式路径。未来，随着AI技术的迭代发展，知识产权审判将面临更多新型争议，如AI生成专利的权利归属、跨境数据训练的司法管辖等。司法机关还需继续秉持“技术中立”与“利益平衡”原则加强对知识产权的保护，在个案中提炼符合中国国情的裁判规则，实现技术发展与法律秩序的良性互动，为数字经济健康发展提供可预期的法治环境。 （原题：“知产审判为知识产权强国建设注入司法力量”系列报道之一 | AI时代 知识产权司法迎来新挑战） 来源：《民主与法制》周刊2025年第25期 记者：王健 编辑：余婷 公众号编辑：张梦 来源：北京号 作者：知产北京 举报/反馈"
    },
    {
      "doc_id": 38062,
      "title": "迪士尼、漫威“开炮”,谁在定义AI的数据底线?",
      "time": "2025-07-03T00:00:00+00:00",
      "content": "近期，包括迪士尼企业、漫威角色、卢卡斯影业、20世纪福克斯电影公司（统称“迪士尼”）以及环球影城制片公司和梦工厂动画（统称“环球影业”）在内的多家好莱坞主要电影公司，在洛杉矶联邦法院对人工智能公司Midjourney提起全面诉讼 。 原告方主张，Midjourney在未经授权的情况下支持用户生成包括小黄人、《冰雪奇缘》《怪物史莱克》等几乎所有旗下动画电影中的人物形象，是典型的“搭便车和无底线的剽窃行为” 。 类似的诉讼官司，这几年越来越多。Midjourney的友商Stability AI也被美国图片交易公司Getty Images起诉过，对方称Stable Diffusion 使用从互联网上获取的视觉资产进行训练，其中包括来自Getty Images以及可公开访问的第三方网站的约1230万个视觉资产等。 随着AI的发展，数据资产的版权问题与现有法律之间的矛盾进一步升级，由迪士尼等巨头企业发起的诉讼，不仅关系着巨额赔偿，也关系着更长远的未来，这些虚拟财富如何分配。 版权持有方集体告AI 持有版权的大企业，把AI公司告上法庭似乎成了常态 。 2023年12月27日，《纽约时报》就曾在美国纽约南区联邦地区法院对微软和OpenAI提起诉讼，指控两家公司未经其同意，使用“数百万”受版权保护的文章训练其AI模型 。彼时，《纽约时报》指出AI模型正在为其新闻内容构建“市场替代品”，通过分流付费用户和影响广告收入造成重大经济损害 。 半年后，环球音乐集团（UMG Recordings）起诉Suno和Uncharted Labs（Udio），指控这两家生成式AI音乐服务公司大规模侵犯版权 。环球音乐集团声称，Suno和Udio未经许可，非法复制其数字录音用于训练AI系统，并能根据用户提示生成与受版权保护录音高度相似的音乐文件 。 时间来到今年，除了引发热议的迪士尼起诉Midjourney，同一时期还有另一个有趣的官司，在线论坛和链接分享平台Reddit起诉了初创公司Anthropic 。在提交给法院的文件中，Reddit称Anthropic是“一家大器晚成的AI公司，自诩为AI行业的白骑士” 。随后话锋一转，说“该案体现出了Anthropic的两面性：在公开场合，通过自称正义且尊重界限和法律，他们试图讨好消费者；然而在私底下，他们无视任何规则，只想进一步中饱私囊” 。 按Reddit的主张，Anthropic未经许可使用平台内容来训练AI模型，在明知爬虫机器人被禁止访问的情况下，Anthropic自2024年7月以来对Reddit平台发起了超过10万次访问 。值得注意的是，2024年8月，Reddit的CEO Steve Huffman曾在采访时点名必应、Anthropic和Perplexity未经许可抓取Reddit数据，并呼吁对方付费 。 态度上看，Reddit并不反对AI，还对外表示过“我们相信，我们不断增长的平台数据将成为领先大型语言模型训练的关键要素，并成为Reddit的额外盈利渠道” 。Anthropic创始人Daniela Amodei的老东家OpenAI，就是Reddit的“付费”用户——2024年5月16日，Reddit宣布与OpenAI达成合作，允许OpenAI利用Reddit的用户生成内容进行模型训练 。 据当时Reddit招股说明书的数据，通过与AI公司签订数据授权协议，他们已经实现2.03亿美元的收入，预计该数字会随着时间的推移而增加 。 对于这些持有版权、原始内容的企业们来说，拥抱AI的浪潮是必然，关键在于，是被单方面“白嫖”，还是一手交钱一手交货。 “合理使用”还是“市场说了算”？ Anthropic不是第一次惹上官司 。 2023年10月18日，环球音乐集团和其他出版商起诉Anthropic，称其滥用“无数”受版权保护的歌词来训练模型 。这个案子一直拉锯到2025年1月4日，双方对部分版权侵权诉讼达成和解，Anthropic承诺实施“防护措施”，以防止其AI聊天机器人Claude在输出中复制受版权保护的歌词，也就是所谓的“护栏协议” 。 在给《好莱坞报道》的一份声明中，Anthropic表示，“我们将继续努力，证明在现有版权法的框架下，在生成式AI模型的训练中使用可能受版权保护的素材，是典型的合理使用” ——在美国的这些版权官司里，“合理使用”（Fair Use）原则已成为AI开发者最主要的抗辩理由，也是决定AI训练合法性的关键战场 。 AI开发者通常辩称，他们复制受版权保护作品是为了训练模型，这是一种“转换性”使用，类似于人类学习或搜索引擎索引，且其AI输出创造了全新的内容，不直接竞争原始作品。 然而，美国版权局（USCO）在其2025年5月发布的《版权与人工智能报告》第三部分预发布版本中明确指出，AI训练与人类学习的类比是“错误的”，因为合理使用并非所有学习行为的普遍辩护，且AI能够创建“完美副本”，而人类保留的只是不完美的印象 。美国司法界对此的保守倾向，从判例上可见端倪 。 2024年2月，美国特拉华州联邦地区法院在Thomson Reuters Enterprise Centre GMBH v. Ross Intelligence Inc.案中做出了对版权所有者有利的裁决，认定竞争对手未经授权使用受版权保护的“头注”（headnotes）来训练其AI系统不构成合理使用 。 虽然该案主审法Stephanos Bibas明确指出，他的分析仅限于所涉的“非生成式AI”模型，但此案依然被视为AI版权领域的一个重要判例，因为它强调了“对市场的影响”是合理使用分析中最重要的因素 。 简单来说，如果AI生成的内容损害了这些类型作品的市场，即使没有证据表明对特定原始作品的市场造成直接损失，也可能被认定为侵权。毕竟，消费者不在乎你的内容怎么来的，他们只关心东西好不好。 数字资产也是资产 人类创作的内容产品受版权保护，那么人类用AI生产的呢？ 这个问题，在大洋彼岸的美国，答案有些保守——在美国版权局看来，美国的版权保护仅适用于体现有意义人类作者身份的作品，因此，完全由AI生成、缺乏足够人类创作投入的内容无法获得版权保护 。 类似的司法先例不少，例如知名的Naruto v. Slater案：2011年，自然摄影师David Slater到印度尼西亚去拍摄黑猴，一只母黑猴Naruto靠近并按下遥控快门，斯莱特随后发布了这些照片，称为“猴子自拍照”，并收到动物保护团体善待动物组织的起诉书 。 善待动物组织认为这张照片的版权应该归Naruto本猴，Slater无权持有并使用，然而美国版权局不这么认为，2014年12月，美国版权局声明非人类所创作的作品不是美国著作权的主体，2016年，美国联邦法官决定猴子无法自行持有这些图像的著作权 。 同样的逻辑，也被延续到人类和AI之间 。2018年，美国计算机科学家Stephen Thaler向美国版权局提交了几份专利申请，包括一张名叫“天堂入口”的AI生成图片，美国版权局驳回了他的申请，Thaler因此提起诉讼 。 在这个案子中，美国哥伦比亚特区巡回上诉法院强调人类作者身份是版权注册的“基石要求”，裁定AI系统不能被视为作品的作者 。美国版权局则对纯AI生成作品和“AI辅助作品”进行了关键区分：如果人类对AI生成内容进行有意义的编辑、完善、选择、排列或整合，使其体现出实质性的人类创造力和原创表达，则AI辅助作品可能获得版权保护 。 数字经济时代，版权是连接传统知识产权与新兴数字资产的关键纽带。 许多核心的数字资产，如数字内容（图像、文本、音视频）、代码、数据集等，其价值的源泉往往在于其受版权法保护的原创性，没有版权，不仅代表着没有拥有权、使用权，更没有商业利用权。 比起美国，我国在AI生成内容的版权归属上采取了更为宽松的立场 。2025年3月，常熟人民法院裁定AI生成图像具有版权 。在该案中，林某使用Midjourney生成了一张城市水岸半心形图像，并用Photoshop进行编辑 。 法院认为，林某对提示词的修改以及通过图像处理软件对图片的修改，反映了其独特的选择和安排，因此生成的图像具有原创性，属于《著作权法》保护的作品。换句话说，作者持有这些图片的版权，还能用这版权赚钱。 看，数字资产也是资产。 新时代的船票 传统的数据持有方，与AI企业没必要对立，在数字资产的使用上，双方是天然的合作伙伴——数据是AI进步的“燃料”，AI是数据变现的渠道。 根据IDC的预测，全球数据将从2023年的120ZB增长到2027年的291ZB，其中企业数据占比将越来越高，这预示着数据作为核心资产的巨大潜力。聪明如Reddit，早早找好了拥抱新时代的姿势，而强硬如叫喊着封杀OpenAI的《纽约时报》，至今还站在法院外等着一个结果。 数字经济时代，数据已经超越传统生产要素的范畴，成为一种全新的关键生产要素：AI模型的训练和优化高度依赖于数据的质量和数量，数据不再仅仅是记录信息的载体，而是驱动AI产生智能、实现决策的关键“血液”，数据的多样性、丰富性和实时性直接决定了AI模型的性能和泛化能力。 另外一方面，数据成了企业新的核心竞争力。拥有独特、高质量的数据集意味着在AI应用和商业模式创新上具备先发优势，换句话说，数据不再仅仅是辅助决策的工具，而是企业构建自身壁垒、实现可持续发展的战略资产。 AI巨大的需求摆在面前，企业们没有理由拒绝这个蓬勃的市场。实际上，随着数据要素的流通和共享，已经诞生了数据服务商、数据信托、数据交易平台等新业态。企业可以通过数据授权、数据共享等方式，创造新的收入来源和商业模式，数据要素的价值不再局限于其原始用途，而是可以通过与其他数据融合、通过AI分析产生更高价值。 说到底，版权持有方与AI企业之间的冲突，表面上是版权之争，实际上是对数据作为核心数字资产如何进行价值分配和商业利用的探索。打官司的过程，就是围绕利益分配的博弈。 以Reddit为代表的版权持有方们和AI企业达成和解以及合作，无疑透露出版权的边界正在扩展的现状，它不仅关乎内容的复制和传播权，更延伸至内容所承载的数据价值，以及这些数据在AI生态系统中的再利用和再创造。 对于内容创作者和数据持有者而言，如何从被“白嫖”的客体转变为参与生产的主角，通过数据授权、利益分成等模式，将自身独特的版权内容转化为有价值的数据资产，决定着他们能否在新一轮数字变革中抢占先机，共享AI发展带来的红利。 这方面，国内早就有了配套的政策摸索。2023年，财政部发布《企业数据资源相关会计处理暂行规定》，明确企业数据资源的会计处理方法，鼓励企业对数据资源进行管理和披露，数据入表不仅能提高企业对数据资源的重视，也会促进数据要素的流通和交易。 至于手握着数据这张船票的企业们，能否登上AI这艘驶向新时代的巨轮，不仅要看历史的进程，也得靠企业们自己努力。"
    },
    {
      "doc_id": 38063,
      "title": "具有里程碑意义的“AI侵权案”裁决出炉:证据不足 作家败诉 Meta暂...",
      "time": "2025-06-26T00:00:00+00:00",
      "content": "在美东时间周三，一名联邦法官作出对Facebook与Instagram母公司Meta Platforms(META.US)有利的正式裁决，驳回了一群原创作者的严重侵权主张。这些作者长期认为，Meta 未经许可使用他们的书籍来训练其人工智能系统，侵犯了他们的专属版权。然而，这位联邦法官认为没有提供足够的证据表明Meta使用受版权保护的作品训练出的人工智能产品会稀释作者们作品的市场，以表明根据美国版权法，该公司的行为是非法的。 据了解，除了Meta，OpenAI、xAI以及Anthropic等聚焦于AI应用软件的人工智能科技公司均表示在受版权保护的作品基础上进行训练属于合理使用。 这位联邦法官在与作家的争议中裁定支持 Meta，该法官称“原告提出了不少错误的论点”。位于旧金山的美国地方法官Vince Chhabria在裁决中表示，作者们未能提供足够证据证明Meta的AI训练系统或者AI应用软件会稀释其作品的市场规模，因此不足以表明该公司的行为违反美国版权法。 美国联邦法官泛指依据《美国宪法》第三条任命、由总统提名并经参议院批准的法官，涵盖最高法院大法官、上诉法院(巡回法院)法官以及美国地区法院法官。美国地区法院则作为联邦司法系统的初审法院。 然而，这位联邦法官Chhabria在裁决声明中还表示，在“许多情况下”未经许可使用受版权保护的作品来训练AI系统将是不合法的;这与旧金山另一位联邦法官在周一一桩独立诉讼中作出的裁定相左，后者认为OpenAI劲敌之一的Anthropic AI 训练模式对于受版权保护材料构成“合理使用范畴”。 Chhabria在声明中表示：“本裁决也并不意味着 Meta 使用受版权保护材料来训练其人工智能大语言模型就是合法的。它仅意味着这些原告提出了错误的论点，并且没有建立起支持正确论点的文字或其他记录。” 作者方律师事务所 Boies Schiller Flexner 的一名发言人表示，作者们拥有Facebook母公司Meta“史无前例地盗用受版权保护作品”的“无可争议记录存在”，该事务所仍不同意法官裁定Meta 胜诉的决定。 Meta的一名发言人则表示，Meta 对这一裁决表示赞赏，并称合理使用版权是构建“变革性”AI技术的“关键法律框架”。 据了解，这项具有里程碑意义的“AI侵权案”裁决结果备受市场关注，这些作者构成的作者起诉团队于2023年开始起诉 Meta，指控该公司未经许可或补偿，使用他们书籍的盗版来训练其开源的AI大语言模型Llama。 该诉讼是作家、新闻机构以及其他传统版权所有者针对OpenAI、微软(MSFT.US)以及Anthropic 等聚焦于AI的科技公司们就他们的AI训练体系发起的多起版权案件之一。 根据美国法律，以合理方式与手段来使用法律原则在某些情况下允许在未获版权所有者许可或者当面授权的情况下使用受版权保护的作品，这为科技公司们提供了关键的抗辩与防御依据。 Chhabria 的裁决是美国联邦法院围绕生成式AI合理使用问题作出的第二个重要判例，此前美国地方法官 William Alsup在Anthropic案中作出了相关的有争议裁定。 聚焦于AI的科技公司们辩称，他们通过研究某些受版权保护的材料来进行机器学习并创作新的、具有变革性的内容，此举属于合理使用范围;如果被迫向版权所有者支付AI训练费用，可能会束缚新兴的AI行业。 版权持有者们则称，AI公司非法复制他们的作品来生成竞争内容，威胁到他们的原创生计。Chhabria 在5月的一次听证会上对这一论点表示同情，并在周三重申了这一点。 这位法官表示，生成式AI应用软件或者AI智能体可能在极短的时间内，帮助C端或者B端的消费者们以几乎不需创意投入，就向市场大量输出图像、歌曲、文章和书籍内容。 Chhabria表示：“因此，通过使用受版权保护的作品训练生成式AI大语言模型，AI科技公司们往往会严重削弱这些作品所面向的市场，从而极大程度地削弱人们以传统方式创作新内容作品的动力。” 本文源自：智通财经网 举报/反馈"
    },
    {
      "doc_id": 38067,
      "title": "裂痕再加深?OpenAI与微软谈判陷僵局",
      "time": "2025-06-27T00:00:00+00:00",
      "content": "6月26日，据The Information报道，OpenAI和微软的谈判持续陷入僵局，双方因通用人工智能（AGI）相关合约条款产生分歧。其中，核心争议在于“中断技术访问权”条款。根据双方2019年签订的原始协议，当OpenAI实现AGI时，其有权立即终止微软的技术访问权。微软则希望删除这一限制条款，但截至目前，OpenAI拒绝了这一要求。 报道援引一位亲历谈判的知情人士回忆，2019年，微软高层认为人工智能进化到超越人类的AGI是“天方夜谭”。但近年来，AI技术迅猛发展，OpenAI CEO奥特曼（Sam Altman）多次宣称，“AGI近在眼前”，这让微软对保持访问权产生了担忧，不得不重新审视该条款。 目前，微软拥有OpenAI技术的独家使用权，旗下许多产品都嵌入了OpenAI的技术与模型，这让微软在包括AI搜索等领域保持了一定优势。若不受上述中断条款的影响，根据双方原有协议，微软拥有OpenAI包括人工智能模型与产品等知识产权的使用权，以及产品销售的收入分成，协议有效期至2030年。 不过，自OpenAI宣布转型以来，该公司与微软围绕AGI的相关合同条款和重组相关事宜展开激烈博弈。 上个月初，OpenAI宣布放弃转型为营利性公司，选择转型为公益性公司，即继续由非营利性组织掌管公司，但保留让业务部门成为公益法人（PBC）的计划。但这一转型过程需要微软的批准才能完成。然而在经过数月谈判后，双方仍未能就细节达成一致。 近期，有媒体报道称，如果OpenAI与微软无法就关键问题达成一致，微软考虑直接终止复杂的谈判进程。而OpenAI方面则开始考虑提出反垄断投诉，据华尔街日报的报道，因谈判陷入僵局与微软迟迟不愿批准，OpenAI高管开始考虑他们视为“核选项”的方案，即指控微软在双方合作期间存在反竞争行为。 不过，OpenAI与微软在一份发给路透社的联合声明中表示，“我们有着长期且富有成效的合作关系，为大众带来了出色的AI工具。谈判仍在进行中，我们乐观地认为未来数年我们将继续携手合作。” 值得一提的是，在谈判事宜尚未确定之际，OpenAI又被传为秘密开发办公套件。6月24日，有知情人士透露，OpenAI正在开发一款集文档协作与实时通讯功能于一体的办公套件，计划将ChatGPT升级为一站式办公平台。 据悉，OpenAI为这一项目或已筹划近一年，OpenAI产品主管Kevin Weil等高层早在一年前就展示了文档协作功能的设计方案，但因团队资源、开发的优先级与人手不足，该计划一度被搁置。 去年10月，OpenAI推出了Canvas功能，被视为上述办公套件的雏形。公开资料显示，Canvas基于GPT-4o模型构建，支持文本改进建议、代码调试优化等核心功能。该界面通过独立窗口实现用户与AI的实时协同创作，可以让用户更轻松、高效地写作与编程。 今年2月，Canvas更新版本，新增HTML/React代码渲染功能、扩展macOS客户端适配并升级了模型多线程处理效率。 另外，OpenAI近期还开发了多项新功能，包括允许多用户在ChatGPT内沟通的软件，以及一款能够录制电话或会议内容并将会议笔记自动存入Canvas中的笔记工具。 据悉，ChatGPT企业版已吸引了全球医药巨头Moderna、跨国移动电话运营商T-Mobile等客户，为OpenAI带去了巨额的收入。公司方面预测，到2030年，ChatGPT企业订阅业务的年收入将达约150亿美元。如今，为了吸引更多企业客户，OpenAI还为企业订阅提供了折扣。 一直以来，微软Office在办公软件领域占据主导地位，旗下产品已成为全球办公场景的标配。但如今，Office的市场份额已然受到OpenAI的挑战，已有一些原本倾向于微软方案的客户开始转向OpenAI，如全球领先的生物技术巨头Amgen。2024年春季，Amgen曾为2万名员工购买微软Copilot，但仅一年时间，公司就宣布更换为OpenAI的ChatGPT，原因是后者的功能和体验更优。"
    },
    {
      "doc_id": 38078,
      "title": "好莱坞宣战大模型?迪士尼110页诉状告AI文生图巨头侵权",
      "time": "2025-06-13T00:00:00+00:00",
      "content": "全球头部文生图AI公司Midjourney，近日收到了“宇宙最强法务”的一纸诉状。 据央视新闻消息，当地时间6月11日，全球娱乐产业巨头迪士尼和环球影业对Midjourney提起版权诉讼。这两家公司在诉状中写道，Midjourney是一个“搭版权便车的抄袭无底洞”。 “宇宙最强法务”钻研提示词，指出“像素级”侵权 这份长达110页的诉状列举了多张Midjourney生成图像与原版影视素材的对比图，涉及迪士尼和环球影业旗下多个知名IP，包括星球大战、蜘蛛侠、辛普森、冰雪奇缘、小黄人等。 澎湃新闻记者分析起诉状列举的侵权图像提示词后发现，在使用“电影截图”“截屏”等关键词后，Midjourney会生成与原版画面类似的场景、构图、背景及人物细节。此外，部分举证提示词还展示了图像风格与角色IP的高度关联。比如输入“Homer Simpson, animated,”（霍默·辛普森，动画风格）就能让Midjourney生成出与辛普森一家相同的动画风格，而不是其他动画风格。 细抠提示词、对比图像的意义在于，迪士尼和环球影业想要坐实Midjourney在AI大模型的训练过程中，大量使用了两家公司的版权素材。诉状指出，Midjourney CEO大卫·霍尔茨在2022年接受The Verge采访时表示，为了训练大模型，他们几乎抓取了互联网上的所有图像和文本。在接受福布斯采访时，大卫·霍尔茨还表示，Midjourney在从未寻求过任何版权许可的情况下就使用了作品，并把这种问题归结于海量图片无法溯源到作者。 上海大邦律师事务所高级合伙人游云庭律师在接受澎湃新闻采访时表示，人工智能的训练数据版权争议很大，有两大问题，训练素材的未经授权以及输出内容的侵权。训练素材方面，很多都是盗版(没有训练行为的版权授权)，但输出的内容又与他人有版权的内容相同或近似，比如包含了版权作品的特征性内容，甚至输出内容与用于训练模型的原始内容都很相似。 人工智能公司认为大模型训练后的输出内容与原始训练素材相比有一定的转换性，创造出了新的价值，并把这种转换性使用认定为合理使用，因此不构成侵权。但游律师认为，在法律角度，这个主张争议很大，因为合理使用的前提是不得以不合理的方式损害著作权人的合法权益，以及不得影响作品的正常使用。 目前最大的争议在于要不要把训练过程判为侵权。如果训练最终不构成合理使用的话，现在的人工智能企业将会面临几个挑战。首先得向版权人支付费用，其次是版权人有权利要求人工智能公司把自己的数据从模型中剔除，这一步在技术实现上难度很高，损失可能比巨额赔偿损失还严重。 据不完全统计，迪士尼和环球影业在诉状中指出被侵权的IP超过15个，IP累计全球收入超过1738亿美元。据界面新闻报道，迪士尼高级执行副总裁、首席法律与合规官霍拉西奥·古铁雷斯表示，“我们的世界级IP建立在数十年资金投入、创意与创新之上，盗版就是盗版，由AI公司实施这一事实并不会减轻其侵权性质。” 奥特曼侵权案后，部分公司禁止AI输出IP内容 AI侵权在数据训练的输入端尚存较多争议，目前国内外典型司法判例较少。但在输出内容的侵权认定方面，已出现具有代表性的司法实践案例。 2024年2月，广州互联网法院就Tab网侵权一案作出判决，法院认定被告提供的AI生成服务侵犯原告IP“奥特曼”，构成著作权侵权。这是全球范围内首例生成式AI服务侵犯他人著作权的生效判决。 这起案件的争议点在于被告使用的AI绘画工具是否属于著作权侵权。一般认为，法律上构成著作权侵权判定需满足“接触”和“实质性相似”两个条件。判决书显示，被告提供的AI绘画功能可根据用户指令（提示词）生成对应的图片，如用户输入“生成一个奥特曼”，即生成奥特曼形象图片。法院在审理后认为，生成图片保留了美术形象的独创性表达，并在多个关键特征与作品具有极高的相似度，构成实质性相似。 游云庭律师告诉澎湃新闻，“奥特曼案”判决后，部分AI公司在提示词中对奥特曼做了限制，无法生成相关图片。这种变化恰巧也说明，AI公司有能力在输出端限制侵权的行为，只是愿不愿意的问题。 澎湃新闻记者在实测后发现，豆包、即梦、通义千问会显示“无法生成”或“不符合平台规定”。而在OpenAI，Gemini和可灵上依旧能够生成对应形象。值得一提的是，OpenAI虽然对“奥特曼”做了限制，但没有对奥特曼的具体角色进行限制。如输入迪迦后，依然可以生成相关形象。 在“奥特曼”案中，原告向法院提出30万元索赔，最终获赔1万元。广东互联网法院在判决书中写道，“考虑到生成式人工智能产业正处于发展的初期，需要同时兼顾权利保障和产业发展，不宜过度加重服务提供者的义务”。 澎湃新闻记者 孔家兴 王亚赛 实习生 梁希昀 (本文来自澎湃新闻，更多原创资讯请下载“澎湃新闻”APP) 举报/反馈"
    },
    {
      "doc_id": 38080,
      "title": "好莱坞巨头打响AI版权战",
      "time": "2025-06-12T00:00:00+00:00",
      "content": "与其他新技术一样，AI生图技术自诞生之日起就充满争议，一路鲜花与荆棘相伴。支持者视它为颠覆性的技术革命，反对者视它为洪水猛兽。当地时间6月11日，全球娱乐产业巨头迪士尼和环球影业对人工智能公司Midjourney提起版权诉讼。这也是好莱坞大型公司首次卷入生成式人工智能的法律纠纷。 迪士尼联手环球影业 在长达110页的诉状中，迪士尼和环球影业提供了Midjourney生成图像与原版影视素材的对照示例，指出即便用户输入诸如“超级英雄战斗场景”等模糊提示，也能生成极类似于蜘蛛侠、雪宝、功夫熊猫等经典角色的图像。 两家公司在诉讼中指出，Midjourney利用其版权库，生成并传播了大量如《星球大战》《小黄人》《怪物史莱克》《冰雪奇缘》《狮子王》等作品中著名角色的未经授权副本。两家公司强调，Midjourney并非利用“合理使用”法律豁免，而是通过大规模抓取网络公开素材进行训练，并持续忽视此前提出的“停止侵权”要求、并未采取任何技术措施加以遏制。 迪士尼高级执行副总裁、首席法律与合规官霍拉西奥·古铁雷斯表示，“我们的世界级IP建立在数十年资金投入、创意与创新之上，盗版就是盗版，由AI公司实施这一事实并不会减轻其侵权性质”。环球影业执行副总裁兼总法律顾问金·哈里斯也称，“无论使用何种技术，盗窃就是盗窃，本案涉及对我们版权的公然侵犯”。 迪士尼与环球影业方面希望借此判例逐步建立AI使用许可机制，要求平台为使用数据支付合理授权费用，并强调版权维权是保护内容创造者和影视从业者的重要机制。 版权营收是两家公司的重要收入来源。迪士尼2025财年二季报显示，营收同比增长7%至236.21亿美元，归母净利润约32.75亿美元，同比扭亏为盈。该公司旗下主要包含娱乐、体育和体验三大部门，内容发行与IP授权隶属于娱乐业务，该业务当季收入约21.46亿美元，同比增长54%。环球影业母公司康卡斯特今年一季度实现营收298.87亿美元，净利润33.75亿美元，但两项数字同比均现下滑。 被起诉的Midjourney是 “文生图” 赛道的头部企业之一。其通过网络爬虫抓取图像构建AI训练数据集，付费订阅服务在2024年创造了3亿美元的收入。公司创始人大卫·霍尔兹曾公开表示，数据库通过 “大规模网络抓取” 建立，且难以追踪上亿张图片来源。对于此次诉讼，截至目前Midjourney暂未作出公开回应。 基于传统著作权评判标准 近年来，大型内容公司和AI公司之间的版权纠纷不断涌现。去年12月《纽约时报》对OpenAI和微软提起版权侵权诉讼，指责数百万篇自家文章被未经授权地用于ChatGPT等AI模型的训练。在音乐领域，环球音乐集团禁止在流媒体平台上模仿音乐家风格的AI生成音乐。图像领域，StabilityAI等公司遭到了艺术家和图像提供企业Getty Images的诉讼。 在国内，2023年11月，北京互联网法院审理判决了“文生图著作权侵权第一案”，原告使用开源软件Stable Diffusion，通过输入提示词生成了涉案图片并发布在社交媒体上，被告未经许可使用且截去署名水印；2024年4月11日，国内首例AI视频侵权案正式立案，并于5月中旬首次开庭审理，《山海奇境》预告片原创者作为原告，指控被告未经授权使用AI技术复制并公开发布了与原告作品极为相似的侵权视频；随后在4月23日，北京互联网法院对全国首例“AI声音侵权案”进行了一审宣判，认定被告5家公司未经合法授权使用原告声音开发AI文本转语音产品，构成了侵权，赔偿25万元。 迪士尼和环球影业对Midjourney发起诉讼，标志着好莱坞大型公司正式加入AI版权保护战。该案的走向不仅将影响迪士尼和环球影业的版权保护成果，也将为其他内容公司提供借鉴。 北京高勤律师事务所律师王源指出，目前关于AI著作权的判定尚未形成主流的评判标准，从国内外的判决结果来看仍是基于传统著作权框架内的评判标准，涉及创作者是谁、AI作品是否享有著作权、是否能在别人创作的作品上再次创作等问题。谈及AI版权纠纷与此前互联网时代、移动互联网时代的诉讼案件有何不同，王源认为，AI版权纠纷需要判定机器行为如何认定、机器作品有没有创造性的问题，这与以往有本质不同。 版权之困 事实上，版权一直是AI模型发展的暧昧地带，也是悬在科技巨头们上方的达摩克利斯之剑。 2022年，福布斯杂志就曾采访过Midjourney创始人David Holz，提问其AI训练之前是否向在世艺术家或创作者们征求过版权许可。Holz明确地回答了没有。 在他看来，目前版权的技术和管理无法应对AI的自动抓取。图像中没有嵌入有关版权的元数据，也没有所谓的版权“注册表”，没有办法在互联网上找到一张图片然后自动追踪它的所有者。 北京盈科律师事务所律师曲虹潭表示，“AI生成”这个行为，有点类似于“站在巨人的肩膀上起舞”，海量的数据是AI生成物的基础和依托。但举个极端的例子，如果AI生成了一个与其数据库中构成实质性相似的内容，那该AI生成物被认定为作品的可能性便大幅降低。此外，AI模型并非自然人，并不是法律上的适格主体，但AI模型背后的使用者，其实还是人。在符合一定条件下，利用AI生成图片的著作权，一般是归属于AI软件的使用者。 纵然追踪版权、获得许可是一件困难且需要付出巨大的精力和时间的事情，但将侵权的风险完全转移给用户的做法也不是根本的解决之道。还有业内人士指出，作为技术发展和商业收益之间的桥梁，科技公司一方面应该把控AI的训练材料，保障版权的妥当处理；另一方面，对用户尽到基本的审查义务，不能纵容甚至帮助其侵权行为的发生。 北京商报记者 赵天舒 举报/反馈"
    },
    {
      "doc_id": 38098,
      "title": "大厂入局“围猎”AI Agent,谁能先闯出路?",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "2025年被创业公司密集占据的热门Agent（智能体）赛道，终于等来头部大厂下场“收割”。 北京时间7月18日，OpenAI发布ChatGPT Agent产品。功能上，ChatGPT Agent融合了此前OpenAI发布的Operator远程可视化浏览器环境执行任务能力、DeepResearch的多步研究与整合高质量信息能力，以及ChatGPT的对话能力；人员配置上，据OpenAI官方披露，为了开发ChatGPT Agent，Operator与Deep Research团队已合并为一个20到35人组成的统一团队。 另在近日，亚马逊云科技在纽约AWS峰会上发布Bedrock AgentCore服务，提供了一组核心组件，帮助企业构建、部署和管理AI Agent。今年3月，亚马逊AGI实验室开发的Nova Act已能自主操作网页浏览器完成购物、填表等复杂任务。 而在太平洋彼岸，中国一级市场正被金沙江创投主管合伙人朱啸虎的言论搅动。他认为大模型会“吃”掉90%的Agent，并将当前AI智能体创业者比作互联网早期的个人站长——充满草根精神却面临残酷淘汰。两相对比，Agent终于在多方鼓吹“2025元年”的热潮中，跨入大厂“收割”、创业公司焦虑的节点。 平台化竞争开启 整个Agent行业已有Manus、Lovart、Flowith、Genspark等明星产品，ChatGPT Agent发布后也面临同质化、速度慢、技术缺乏代际差等质疑。但从官方演示来看，ChatGPT Agent的核心优势在于OpenAI直接搭建专用模型，与OpenAI o3同系列，采用端到端训练方法，系为Agent任务开发的统一模型，而非其他Agent产品调用外部厂商产品建立的多模型工程化组合。 另从定价来看，此次OpenAI虽未再次实行降价策略，但创业公司也未占据明显价格优势。其中可调用ChatGPT Agent功能的GPT Plus套餐每月20美元，Manus基础计划每月19美元。 AIGCLINK发起人、行行AI合伙人占冰强对第一财经表示，通用类Agent领域竞争已经进入成熟期，大厂开始下场，包括OpenAI、字节跳动Coze空间等，这是一条属于大厂的赛道，而垂类行业的Agent如果具备一定交付能力，创业公司在其中仍有机会。 更值得注意的一点在于，OpenAI或将开辟一条新的营收路径——与最终交易绑定，但该模式此次暂未正式对外披露。有消息称，OpenAI计划开发电子商务功能，测试ChatGPT内部集成结账系统，并通过ChatGPT完成在线产品销售进行分成。过去的Agent类产品可以帮助用户搜索、对比、筛选，甚至包括支付下单，但并未在该流程内进行收费举动。OpenAI此次虽未披露新营收方式，但山姆·奥尔特曼此前在接受采访时称：“我们不会为了改变推荐排名而收费，但用户若通过Deep Research发现了某款商品并进行购买，我们会抽取约2%的费用。” OpenAI从底层模型优势切入，亚马逊则直接提供技术与资金支持，所发布的Amazon Bedrock AgentCore为客户提供从部署到运行的全套能力。此外，亚马逊云科技宣布向其生成式AI技术创新中心追加1亿美元投资，并与Meta达成合作，支持初创企业利用Llama模型开发AI应用。 不论是OpenAI从流量入口添加交易收佣丰富生态，还是亚马逊从底层能力提供全栈支持，Agent领域的竞争越来越平台化。正如朱啸虎三日前在社交平台所言：AI Agent领域创业者可以借鉴互联网早期的个人站长模式，从个人站长逐渐成长为具有影响力的互联网公司。他分享的代表性案例包括网易、腾讯等，均从“工具”或“入口”切入，解决用户最基础或最迫切需求，形成用户黏性，再发展壮大。 从早期迈入分化路口 虽然成长路径可参考，但目前多元的Agent产品生态尚未有哪一款产品，能够在用户群中构建起牢固的黏性壁垒。Demo（演示版）产品引发一波讨论与测试后，一旦开启收费，用户流失严重，形成热闹Agent浪潮下的伪需求陷阱。也因此，朱啸虎认为，如果产品不具备用户黏性，未来大模型能够“吃”掉90%的Agent产品。 这并非夸大其词，此前Gartner预测，到2027年底，40%的代理型人工智能 （Agentic AI ）项目将被取消，原因在于成本高昂、商业价值有限及风险控制不足。当下大多数项目都处于早期试点或概念验证阶段，许多组织低估了扩展Agentic AI系统的复杂性。 Gartner高级总监兼分析师阿努什里·维尔马（Anushree Verma）表示，部分Agent项目“受炒作驱动，且常常被误用”，“这可能会让组织忽视大规模部署AI Agent的真正成本和复杂性，导致项目无法推进到生产阶段”。 另外，Gartner认为，当下“智能体包装（Agent Washing）”现象兴起，即供应商将机器人流程自动化（RPA）工具、聊天机器人和AI助手等技术重新包装成Agent产品，但名不副实。在Gartner的调研数据中，仅有19%的受访者表示所在公司已在Agentic AI方面进行了大量投资，42%的受访者称投资较为保守，超过30%的受访者持有不确定或持“观望”态度。核心原因仍类似于AI1.0时代的问题——数据格式不兼容、系统接口老旧、权限申请流程漫长、内外部系统不匹配等。 头部厂商下场虽然带来更明确的方向，但也带领行业加速迈入关键性十字路口。专用模型的迭代将较多模型拼凑的“工程化组合”更具优势，成为技术门槛的核心；平台化能力会倒逼中小创业者向垂直场景深耕，复制早期互联网时代“工具-入口-生态”的成长逻辑；商业化层面，单纯依赖工具收费的路径将面临营收压力。预计未来三至五年，Agent行业将正式从“概念炒作”迈入“实用主义”。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 38100,
      "title": "ChatGPT智能体正式发布,多个创业赛道昨夜无眠",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "白交 雷刚 发自 纽凹非寺 量子位 | 公众号 QbitAI 实用，太实用了！这才是OpenAI Agent该有的样子。 就在刚刚，OpenAI最新发布来了，ChatGPT Agent正式对外亮相。 这是一个把“想”和“干”统一了的智能体，之前深度研究的思考和分析能力，Operator的操作执行能力，在ChatGPT Agent实现了统一。 而且ChatGPT Agent还可以接管你的整个电脑——这几乎就是全新的操作系统了。 能做什么？ 工作场景里，安排和改期会议、生成PPT、制定出差和外出议程、自动提交报销……几乎就是大厂高管才能配置的助理的核心工作。 生活场景下，你个人的旅游行程规划设计、重大活动如婚礼晚宴安排……一些定期需要手动更新的认证证明……差不多也是董事长CEO们个人秘书实现的能力。 但现在，ChatGPT Agent一夜之间人人都可拥有。OpenAI还专门配备了专用模型，创造了全新的SOTA，刷新了模型能力新纪录。 之前，通用Agent们只敢自称“实习生”，但OpenAI在自研底层模型能力的底气下，几乎就把“实习生”变成了“大秘书”。之前一个创业赛道，分分钟变成了大厂产品里的一个功能按钮。 这也是ChatGPT Agent注定不会让所有人都开心的地方。 此前不论是在“想”还是“做”上做产品功能创新的Agent创业者，今夜难眠，又要被重新审视核心壁垒和竞争力了。 总之，把Operator和深度研究实现“二合一”的ChatGPT Agent，不止于1+1。 ChatGPT Agent详解：All in ONE 这次新发布，名字简单直接：ChatGPT Agent。 入口没有变——还是在原来页面「工具」下拉激活「智能体模式」即可。只是ChatGPT已经不再是以前的ChatGPT了，而是具备“Agent”能力的ChatGPT了。 具体如何做的？ 就是将以往Operator的「网站交互」能力，DeepResearch这种「整合高质量信息」的能力，以及ChatGPT的对话能力等等，全部All in One，形成一个统一的智能体系统。 这样一来，能做的那就多了去了。 仅单一模型就可以主动与网站互动、筛选并获取最高效的结果。 比如它可以制作公司吉祥物漫画风贴纸，然后再订购500张并送到某个地址。 先整合搜索-再推理创作-再执行任务，一气呵成~ 以往的浏览网页、制定行程、制作文档等各方面的体验，都实现了升维。 比如生成表格吧，它可以在这基础上保持原有格式的同时，用新的财务数据来随时更新表格。 不过这里有个华点，仔细看这个过程，它不是通过打开PPT插入文本框，而是编写代码生成一个看起来很像的表格。（Doge） 此外，你还可以设置固定时间执行，比如每周一生成周报啥的。 还有像规划并预订旅行行程，可以具体到某个环节的设计和预订，或者帮你寻找专业人士并安排预约。 他们强调，整个过程人类始终都掌握控制权，不仅可随时中断操作、接管浏览器或停止任务，它在执行重要操作前也会征得你的许可。 即日起，Pro、Plus 和Team版用户就可以感受到这种工作与生活的体验全面升维。 Pro版用户每月可执行400次任务，其他付费用户每月可发送40条消息，额外使用量可通过灵活的积分额度选项获取。 而企业版和教育版的用户将在几周之后获得使用权限。 免费等等党可以再蹲蹲，万一什么时候就有了呢。 不过需要明确的是，ChatGPT Agent也算不上全新的模型，而是与OpenAI o3还是属于一个家族。 这个模型经过了专门的训练，能够在执行任务时动态学习，通过优化速度、准确性和效率来调整其工作方式—— 每个步骤中能识别并运用最适合的工具，通过评估结果而非固守固定方法来优化流程。 他们也还配备了所有可用的网络工具：通过图形用户界面与网络交互的可视化浏览器、用于简单推理型网络查询的文本浏览器，以及直接API访问权限。 有了不同的访问和交互路径，保证ChatGPT能够在推理与执行之间流程转换。 比如它可以快速通过API获取财务数据或体育赛事比分，同时也能与主要面向人类设计的网页进行视觉交互。 ChatGPT Agent在专门优化之后，相比于以往几个模型，网页浏览、执行现实世界任务能力方面实现了SOTA。 比如在「人类最后的考试」中，一举取得了41.6分。该测试集是出了名的超难，刚推出时无模型得分能超过10分。 在 DSBench⁠ 测试中，该测试旨在评估智能体在涵盖数据分析和建模等现实数据科学任务中的表现，ChatGPT智能体显著超越了之前的最先进模型。 尤其在数据分析任务中，其表现明显优于人类水平。 还有在SpreadsheetBench，同样实现了SOTA。 这个评测主要是用来评估模型处理真实场景中的电子表格编辑任务的表现。 结果ChatGPT Agent相比于GPT-4o提升了超过一倍。当具备直接编辑电子表格的能力时，ChatGPT Agent 的得分进一步提升至45.5%。 不过在最后，他们也强调了这个模型存在一定的风险。他们自己的“防范框架”将其定义为具有“放大现有严重危害途径”能力的模型。 虽然目前还没有直接证明，但他们已经有了些额外的安全措施，比如有个实时监视器，在每次回答前会判断这个问题有没有风险，比如生物相关，是否会给人类带来威胁；还有那种高风险的金融投资啊、敏感法律任务等等，都会主动拒绝。并且为了防止滥用，还禁用了记忆功能。 怎么看ChatGPT Agent带来的变革？ 毫无疑问，ChatGPT Agent带来的变革，可能要比OpenAI之前的Agent试水要大得多深远得多。 Agent算是一个曾经科幻的概念，《钢铁侠》中的贾维斯，就是对Agent的“终极幻想”。 但AI Agent的推进，似乎又才刚刚开始。 在基础大模型能力不断强大之后，Agent开始被视为大模型应用的核心产品，Agent也成为了今年最热创新和创业赛道。 如果把视野拓展到企业级、工业级应用里，Agent的创新和发展就更早了。 AI客服实际就是最隐秘但又实际发展最快速的应用，而且带来的价值替代非常明显——现在找人工客服已经是相当困难了。 在AI客服之外，AI编程、AI绘图、AI PPT等垂直专用能力，也都在狂飙突进… 但更值得关注的是通用Agent的推进，即AI可以真正像人一样，接管你的上网甚至电脑。 OpenAI在这个方向推进上算是慢的。早在去年10月，Claude的母公司Anthropic就推出了名为“Computer Use”的工具，能够像人类一样使用电脑，“代表”用户完成任务。 如果只是“想”的层面，具体到撰写分析研究报告的Agent就更多了，海外有OpenAI、Google和Perplexity，国内则有秘塔、Kimi等等。 在手机端，华为、小米、OPPO、vivo和荣耀等等在内的公司，都在试水Agent，让AI自动帮你完成订咖啡、接推销电话——虽然那边也是AI打的，以及更多之前需要人自己“想”和“干”才能完成的工作。 而这就是趋势：一个全新的由AI贯穿始终的操作系统或者全新产品形态，正在汹涌而至。 如果保守来看，Agent会率先重塑如今互联网相关的一切，重塑我们互联网实现的对工作和生活的塑造。 PC时代的互联网核心塑造是“网站”，智能手机时代是“APP”，到了AI时代就是“Agent”。 PC互联网时代是千人一面，门户网站是其代表。 移动互联网时代可以千人千面，推荐算法下诞生了抖音Tiktok这样的全新超级应用。 那么Agent互联网时代呢？会有怎样全新的应用？又有谁会站上浪潮之巅？ 问题还没有答案，但问题的答案，已经在被深度研究、自动执行了。 欢迎在评论区留下你的想法！ — 完 —"
    },
    {
      "doc_id": 38103,
      "title": "OpenAI发布ChatGPT Agent:AI“代理人”已至,人类准备好交出操作权...",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "文 | 大模型之家 北京时间7月18日凌晨，OpenAI如约发布了其最新力作——ChatGPT Agent。 根据CEO Sam Altman和四位OpenAI研究员介绍，ChatGPT Agent是一个具备自主执行复杂任务能力的AI Agent，它不再仅仅“对话”，而是可以打开虚拟机，完成搜索、筛选、判断、执行等一整套流程，最终输出可交付的结果。 ChatGPT Agent的定位非常“简单直接”：一个拥有终端、图形浏览器、文本浏览器的多工具整合智能体系统。功能上，几乎等于一个受控的远程虚拟操作系统。 值得注意的是，ChatGPT Agent可以说是OpenAI自今年以来推出产品的一次阶段性整合与释放：Operator和Deep Research，一个偏执行，一个偏思考，如今彻底融合。 AI真正开始“动手”：ChatGPT Agent的能力边界 与如今大火的“智能体”赛道的产品类似，ChatGPT Agent的最大变化，是让AI真正获得了对数字世界的“动手”能力。Agent模式下，用户不再是通过提示词一步步引导ChatGPT生成答案，而是描述一个需求后，模型启动虚拟机，自主规划任务、调度工具、完成执行。 在演示中，OpenAI展现了其三大基础能力组件：文本浏览器、可视化浏览器和终端。 文本浏览器的职责是爬梳大量信息，完成阅读和筛选。它适合处理长文内容、查找具体数据或者跟踪文献，是Deep Research的延续；可视化浏览器则具备界面识别与交互能力，比如可以点击网页按钮、识别图像、进行鼠标操作等；终端部分支持代码执行、API调用和复杂文件生成——如PPT、Excel、数据分析脚本等。 这些能力的协同，使Agent具备了完整的“感知-决策-执行”链路。比如在一次旅行安排任务中，它先用文本浏览器分析网页信息、提取天气与礼仪信息，再切换至可视化浏览器挑选合适礼服，最后生成整合报告。整个任务历时仅十分钟，远远快于人类的处理效率。 更复杂的场景中，Agent还能够自动调用图像生成API设计贴纸，然后在网站上上传图像、填写参数、放入购物车，最后请用户确认是否付款。在另一个演示中，Agent还连接了Google Drive，提取文档并自动生成PPT；或将日程数据汇总为带地图的电子表格行程表。 这些能力让Agent不仅适用于内容生成，更适用于事务型任务处理，意味着它从“信息辅助”跨越到“决策+执行”。在办公场景中，Agent可以完成会议安排、报告撰写、差旅预订等一系列中层管理事务。在生活场景中，它能规划婚礼、生成资料、预约专家等个性化需求。用一个略显理想主义但已逐步接近现实的说法：ChatGPT Agent，是人人都可以拥有的“高效执行助理”。 基准测试成绩：Agent能力更接近人类水平 与以往OpenAI擅长的语言能力不同，Agent的测试指标更偏向执行能力和任务完成度。在这方面，ChatGPT Agent通过了多个广受认可的专业评测，其结果呈现出一次系统性的跃迁。 在“人类的最后一场大考”（Humanities Last Exam）中，ChatGPT Agent获得了41.6%的成绩，几乎是不带工具模型的两倍。这项测试不仅包含复杂的推理与信息调度任务，还考察模型的工具调度能力。在使用终端、浏览器等资源的前提下，Agent表现出对任务流程的高度掌控。 在WebArena这个网页交互能力评测中，Agent的得分已经接近人类水平。而在SpreadsheetBench，即电子表格操作能力的标准测评中，其分数达到45.5%，较GPT-4o提升一倍。 尤其值得一提的是DSBench测试，它用于衡量数据分析与建模任务的能力。Agent在这一测试中超过了所有此前的SOTA（state-of-the-art）模型，明确表明其在面对现实数据分析任务中，不仅可用，而且强大。 这些数字背后，是OpenAI在工具调度、任务分解、推理执行上的系统性优化。可以说，ChatGPT Agent已不再局限于“语言智能”，而是进入“操作智能”的新阶段。 Operator和Deep Research子产品的融合 在大模型之家看来，ChatGPT Agent并不是从零起步的“创新”：其核心其实是Operator和Deep Research两个子产品的融合。 Operator是今年初推出的图形界面Agent工具，支持鼠标模拟点击、滚动等界面操作；Deep Research则是一个偏内容分析和信息整合的工具，擅长处理复杂文字材料并输出结构化结果。两者原本分别服务不同需求，但用户使用行为暴露出两者之间的边界并不清晰。 许多Operator用户在提示词中描述的任务，其实更像是深度调研；而Deep Research的高阶用户，又频繁表达对图形交互的诉求。 这使OpenAI做出顺理成章的决策：合并两个工具，并在一个统一的模型训练框架下，用强化学习方法教会模型如何调度工具。具体方法是模型从“笨拙地”乱用工具开始，通过奖励高效行为逐渐掌握何时使用哪个工具、在哪一步执行操作。 这个过程类似于AI界所熟知的Curriculum Learning（课程学习）策略，从简入繁，在逐步暴露复杂问题之前先引导其掌握基础逻辑。强化学习在这里的作用不仅仅是让模型“能用”工具，而是“用得巧”，用得灵活。 这种组合式的工程化思维并不新鲜，但放在OpenAI此时此刻的体系中，它是一种极高效的资源整合，既降低开发风险，又释放实际能力，是对“AI工具生态”合理性的回应。 Agent不是终点，而是通往应用未来的桥梁 ChatGPT Agent的诞生，不只是对工具融合的一次技术实现，更是对“大模型如何走进现实”的阶段性回答。从ChatGPT的出现开始，逐渐理解语言模型的强大；从GPT-4o开始看见多模态推理的边界；而现在，Agent将“思考”与“动手”统一，标志着AI真正有可能完成从“助手”向“代理人”角色的转变。 从开放的任务执行结构来看，Agent模式更像是未来操作系统的一种雏形：具备动态调度资源、主动规划流程、与人类深度交互的能力。它并不重定义AI模型本身，而是重塑了人与AI协作的界面与方法。 OpenAI将这套能力下放到Plus、Team乃至企业级服务中，也意味着Agent从不再是“高级用户”的特权，同时借助Agent热潮吸引更多用户，扩大自己在大模型赛道的话语权。 未来，ChatGPT Agent是否能像操作系统那样拥有开放插件生态？Agent是否能承接SaaS级别复杂度的任务？企业的专属工作流是否可以嵌入Agent？这些问题都已开始具象化地浮出水面。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 38105,
      "title": "ChatGPT智能体上线,奥特曼:感受到AGI的瞬间,但风险不容忽视",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "02:25 当地时间7月17日，OpenAI推出ChatGPT智能体（ChatGPT agent），整合早期三项突破性进展，让具备思考与行动能力的智能体连接研究与实践。 ChatGPT智能体可以分析竞争对手并制作幻灯片，也可以计划并采购4人份早餐的食材。OpenAI CEO山姆·奥特曼表示，看着ChatGPT智能体借助计算机完成复杂任务，对他来说是一个“感受通用人工智能（AGI）”的瞬间，“那种看着计算机思考、规划并执行任务的感觉确实与众不同。” 不过他也提到，ChatGPT智能体的潜在风险也不容忽视，“如果向家人解释这款产品，我会说它处于技术前沿，尚属试验阶段。这是一个体验未来的机会，但在我们通过实际应用研究并改进它之前，不建议用于高风险场景或涉及大量个人信息的场合。” 02:25 OpenAI发布视频(02:25) 具备思考与行动能力，用户可随时中断任务 如今的ChatGPT具备思考与行动能力，能主动从一系列工具库中选择合适工具，为用户从头到尾处理复杂任务。例如它可以查看日程表并结合近期新闻为用户简要介绍即将到来的客户会议、分析三家竞争对手并制作幻灯片。ChatGPT会智能浏览网站、筛选结果、在需要时提示用户安全登录、运行代码、开展分析，甚至生成可编辑的幻灯片和电子表格来汇总其研究成果。 它能帮助用户规划并预订旅行行程、设计并安排整场晚宴、计划并采购4人份早餐的食材。它还能借助ChatGPT连接器让用户关联Gmail、Github等应用，这样就能找到与用户提示词相关的信息并用于回应。用户也可以通过接管浏览器在任意网站登录，从而让它在研究与任务执行中探索得更深、范围更广。总之，它可以在访问和交互网页信息中选择最优路径、高效完成任务。 ChatGPT可以通过自身虚拟计算机执行这些任务，在推理与行动之间流畅切换，根据用户的指令处理复杂流程。最重要的是，控制权始终在用户手中。ChatGPT在执行重要操作前会请求许可，用户随时可以中断任务、接管浏览器或停止任务。 OpenAI表示，这些新功能的核心是一套统一的智能体系统。它整合了早期三项突破性进展的优势，即Operator智能体的网站交互能力、深度研究（deep research）智能体的信息整合能力以及ChatGPT本身的智能与流畅对话能力。 此前，Operator与深度研究各自具备独特优势，Operator能够在网页上滚动、点击和输入，深度研究则擅长分析与总结信息。两者的优势场景各有侧重，Operator无法深入分析或撰写详细报告，深度研究则无法与网站交互以优化结果，也无法访问需要用户身份验证的内容。因此，OpenAI将两者的优势融合在一起。 基准测试表现优异，潜在风险不容忽视 目前，ChatGPT智能体在基准测试中的性能表现优异。在“人类的最后考试”（Humanity’s Last Exam）这项通过广泛学科的专家级问题评估AI性能的测试中，ChatGPT智能体取得41.6的“单次通过率”（Pass@1 SOTA）新纪录。由于智能体动态规划并自主选择工具，面对同一任务时可在不同运行过程中采用多样解法，因此OpenAI通过并行策略扩展测试时，智能体得分进一步提升至44.4。 ChatGPT智能体在“人类的最后考试”中的表现。 FrontierMath是目前已知难度最高的数学基准测试，以未发表的新颖问题为特色，即便是专业数学家往往也需要数小时乃至数天解出。在该测试中，通过终端执行代码等工具，ChatGPT智能体的准确率达到27.4%，大幅超越以往的各类模型。 DSBench旨在评估智能体处理涵盖数据分析与建模的真实数据科学任务的能力。ChatGPT智能体在该测试中的表现显著超越人类水平。例如在DSBench的数据分析测试中，人类得分64.1%，ChatGPT智能体得分89.9%。 ChatGPT智能体在DSBench的数据分析测试中的表现。 即日起，Pro、Plus及Team用户可在任何对话的任意环节，选择“智能体模式”，直接激活ChatGPT的智能体功能。不过，OpenAI表示，尽管ChatGPT智能体已是处理复杂任务的强大工具，但今天的发布只是一个开始。OpenAI将持续迭代，定期推出重大改进，让它逐渐具备更强能力，为更多人提供更实用的帮助。 奥特曼也表示，尽管这款产品的实用性显著，但潜在风险也不容忽视。OpenAI内置了大量安全防护机制和警示功能，并从鲁棒训练、系统防护到用户控制部署了比以往任何时候都更全面的风险缓解措施，但无法预见所有可能的情况。本着迭代部署的原则，OpenAI会向用户发出充分警示，同时允许用户在谨慎考量后自主决定是否采取行动。“如果向家人解释这款产品，我会说它处于技术前沿，尚属试验阶段。这是一个体验未来的机会，但在我们通过实际应用研究并改进它之前，不建议用于高风险场景或涉及大量个人信息的场合。” 澎湃新闻记者 张静 (本文来自澎湃新闻，更多原创资讯请下载“澎湃新闻”APP) 举报/反馈"
    },
    {
      "doc_id": 38107,
      "title": "AI能力新高度!OpenAI发布ChatGPT智能体:能自主选择工具完成任务",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "ChatGPT可以自主调用电脑资源执行任务了。 当地时间7月17日，人工智能（AI）巨头OpenAI推出ChatGPT智能体（Agent）系统，OpenAI CEO山姆·奥特曼（Sam Altman）和四位负责人进行了25分钟的直播。 据介绍，这是一套融合Operator远程浏览器执行能力、Deep Research网络信息整合技术以及ChatGPT对话优势的统一智能体平台，“可以思考和行动，能够主动从代理技能工具箱中进行选择，使用自己的计算机为您完成任务”。 奥特曼表示，智能体代表了AI系统能力的新高度。 此前，Operator和Deep Research各有优势：Operator可以在网页上处理内容，而Deep Research则擅长分析和汇总信息。但Operator无法深入分析或撰写详细报告，而Deep Research无法与网站互动以优化结果或访问需要用户身份验证的内容。此次，OpenAI直接将两者的优势进行了结合。 ChatGPT在Agent模式中会使用自己的“虚拟电脑”执行任务，基于用户指令处理复杂的工作，用户可以主动与网站互动，或在同一聊天中直接从对话过渡到直接请求操作。 在发布会上，OpenAI演示了用ChatGPT Agent同时进行买西装、做贴纸、订酒店等任务，Agent使用数秒启动虚拟电脑后便会询问用户明确需求，再进行衣服的挑选，Agent会滑动网页、点开商品详情，并留下相应的建议文字。此外，Agent也可以代替用户进行下单操作。 在“虚拟电脑”中，即使ChatGPT使用多种工具，也能保留任务所需的上下文，模型可以选择使用文本浏览器或可视化浏览器打开页面，从网络下载文件，通过在终端中运行命令进行操作，然后在可视化浏览器中查看输出。 同时，ChatGPT在执行重要操作之前会请求权限，用户可以随时中断、控制浏览器或停止任务。用户也可以安排已完成的任务自动重复，比如每周一早上生成每周报告。 在“人类最后一次考试”评估中，ChatGPT agent模型的SOTA（State of the arts，领域内最高水准）得分达到了41.6，当采用简单的并行部署策略（一次最多运行八次尝试，并选择自评置信度最高的一次）进行扩展时，得分提升至44.4。 此外，在FrontierMath等基准测试中，ChatGPT Agent的准确率也远超之前的模型。 Pro、Plus和Team用户可以使用Agent模式。企业版和教育版用户将在未来几周内获得访问权限。目前Pro用户每月有400次使用次数，其他付费用户每月有40次使用次数，也可以付费获得更多使用量。 澎湃新闻记者 秦盛 (本文来自澎湃新闻，更多原创资讯请下载“澎湃新闻”APP) 举报/反馈"
    },
    {
      "doc_id": 38110,
      "title": "刚刚,OpenAI通用智能体ChatGPT Agent正式登场",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "机器之心报道 机器之心编辑部 ChatGPT 现在可以思考行动，主动选择工具，用自己的虚拟计算机为你完成任务。 Agent AI 时代，比我们想象中来得要早一些。 北京时间周五凌晨，OpenAI 突然开启了新产品直播。 本次发布的是全新的 ChatGPT Agent，它实现了通用智能体（Agent）能力的关键升级。 与以往的基础大模型升级不同，通用 Agent 可以自动利用多种工具进行规划，帮助人们完成复杂的任务，包括自动浏览用户日历，生成可编辑的 PPT，运行代码等等。Agent 能够连接你的 Gmail、GitHub 网站获取信息并解决问题，使用 API 来访问各种应用。Agent 加持的 AI 智能有了大幅提升 —— 基于 ChatGPT Agent 的模型在 HLE 基准上拿到了 41.6% 的分数，是 o3 和 o4-mini 的几乎两倍。 ChatGPT Agent 目前已向 OpenAI Pro、Plus 和 Team 计划的订阅用户开放。想要使用的用户在 ChatGPT 的工具下拉菜单中选择「Agent 模式」即可。 OpenAI 表示，企业版和教育版用户预计将于夏季晚些时候获得新功能。在正式发布时，Pro 用户每月通常最多可使用 400 次 Agent 提示，其他付费用户则最多可使用 40 次。目前尚不清楚该功能何时会面向 ChatGPT 免费用户推出。 这是 OpenAI 迄今为止最为大胆的一次新产品发布，从此以后 ChatGPT 成为了一款能够为人们采取行动和分担任务的 Agent 产品，已经远远超出了回答问题的范畴。 OpenAI CEO 山姆・奥特曼（Sam Altman）表示，看着 ChatGPT 智能体使用计算机执行复杂任务对我来说是一个真正的「感受 AGI」的时刻，看到计算机思考、计划和执行会带来不同的感受。 25:30 ChatGPT 现在可以使用自己的虚拟电脑为你完成工作，从头到尾处理复杂任务。用户不仅可以让 ChatGPT 执行诸如「查询年度财务报告」等请求，并智能地浏览网站、筛选结果，在需要时提示你安全登录，运行代码、进行分析，甚至可以交付可编辑的幻灯片和电子表格，总结其研究成果。 比如让「ChatGPT Agent 搜索查询旧金山市年度综合财务报告（2020-2024 年）」： 再比如输入提示「我是一位网球迷，想去棕榈泉观看网球比赛，特别是在半决赛 / 决赛期间。我住在旧金山，请帮我制定一份详细的三天行程，包括航班安排、酒店预订、活动内容（比赛、徒步、美食、水疗等）。我喜欢徒步旅行、纯素食餐厅和水疗。总预算为 3000 美元。这份行程需要包括：精确的时间安排；每项活动的内容、费用和其他细节；如有需要，提供购票或预订链接」，接着让 ChatGPT Agent 帮你制定详细的行程： 这一新能力的核心是一个统一的智能 agentic 系统，它结合了三个早期突破的优势，包括 Operator 的网站交互能力、deep research 的信息综合能力，以及 ChatGPT 的智能推理与对话能力。 ChatGPT 借助自己的虚拟计算环境，在推理与执行之间灵活切换，根据用户的指令，从头到尾处理复杂的工作流程。 最重要的是，用户始终掌控全局。ChatGPT 会在执行任何重要操作前征求你的许可，你也可以随时中断任务、接管浏览器或停止运行。 OpenAI 表示，「虽然 ChatGPT Agent 已经可以应对复杂任务，但这次发布只是开始。我们将持续迭代、定期推出重大改进，让它变得更强大、更实用，服务于更多用户。」 Operator 与深度研究的自然进化 过去，Operator 和 deep research 各自具备独特优势：Operator 能够在网页上滚动、点击和输入，而 deep research 擅长分析和总结信息。 不过，二者在不同场景下才发挥最大作用，各有不擅长的领域。Operator 无法深入分析或撰写详细报告，而 deep research 又无法与网页交互、进一步筛选结果或访问需要用户登录的内容。 OpenAI 发现，许多用户尝试用 Operator 处理的任务，其实更适合用 deep research，因此决定将二者的优势整合在一起。 通过将这些互补能力集成进 ChatGPT，并引入更多工具，OpenAI 在一个模型中解锁了全新的能力。它现在可以主动与网站交互 —— 点击、筛选并收集更精准、高效的结果。yonghu 也可以在同一个对话中，从自然的交流无缝过渡到发出具体操作请求。 OpenAI 为 ChatGPT Agent 配备了一整套工具：包括一个通过图形用户界面与网页交互的可视化浏览器、一个用于处理简单推理类网页查询的文本浏览器、一个终端（命令行界面）、以及直接调用 API 的能力。 该 agent 还可以利用 ChatGPT Connectors，将 Gmail、GitHub 等应用连接进来，使 ChatGPT 能够查找与你提示相关的信息，并将其用于回答中。用户也可以通过接管浏览器，在任意网站上登录账户，从而帮助它在信息检索和任务执行方面更深入、更广泛。 为 ChatGPT 提供多种访问和交互网页信息的方式，意味着 ChatGPT Agent 能够选择最优路径，以最高效地完成任务。例如，它可以通过 API 获取用户的日历信息，使用文本浏览器高效处理大量文本内容，同时也具备通过可视化界面与专为人类设计的网站进行交互的能力。 所有这些操作都是在 ChatGPT Agent 自己的虚拟计算机上完成的，这可以在使用多个工具时保留任务所需的上下文信息。ChatGPT Agent 可以根据需要选择用文本浏览器或可视化浏览器打开网页，从网上下载文件，在终端中运行命令处理文件，然后再通过可视化浏览器查看输出结果。同时也会根据任务调整策略，以快速、准确和高效的执行。 ChatGPT Agent 专为迭代式、协作式的工作流程而设计，远比以往的模型更加互动和灵活。在 ChatGPT 执行任务的过程中，用户可以随时打断它，进一步澄清指令，令其朝着期望的方向发展，或完全更换任务内容。它会在新的信息基础上继续工作，而不会丢失此前的进度。 同样地，ChatGPT 也会在需要时主动向用户请求更多细节，以确保任务始终与目标保持一致。如果某项任务耗时超出预期或陷入停滞，用户可以选择暂停任务、请求进度摘要，或者直接终止任务并获取当前已有的部分结果。如果用户在手机上安装了 ChatGPT 应用，它还会在任务完成后发送通知。 基准测试结果：拓展现实世界的实用性 ChatGPT Agent 及背后模型的能力提升体现在多个基准测试中的顶尖表现，评估内容包括网页浏览和现实世界任务的完成能力。 其中在「人类最后考试」（Humanity's Last Exam）评估中（这项评估衡量了 AI 在各个领域的专家级问题上的表现），支持 ChatGPT Agent 的模型在该评估中的 Pass@1 分数为 41.6。 由于该 Agent 能够动态规划并自主选择工具，它可以通过不同的方式处理相同的任务。在通过简单的并行策略进行扩展时 —— 同时运行最多八次尝试并选择自我报告信心最高的结果 —— 该 Agent 的 HLE 得分提高到了 44.4。 FrontierMath 是目前已知最难的数学基准测试，包含全新且未公开发表的问题，通常需要数学专家花费数小时甚至数天才能解决。在具备工具使用能力（例如可访问终端以执行代码）的情况下，ChatGPT Agent 在该测试中达到了 27.4% 的准确率，远远超越此前的所有模型。 OpenAI 还使用模拟复杂真实任务的基准测试对该模型进行了评估。在一个用于评估模型在复杂、具有经济价值的知识型工作任务中表现的内部基准中，ChatGPT Agent 的输出在大约一半的情况下可与人类相媲美，甚至优于人类，任务完成时间范围不等，并且显著优于 o3 和 o4-mini 模型。 在 DSBench 基准测试中，用于评估 Agent 在涵盖数据分析与建模的真实数据科学任务的表现。ChatGPT Agent 超越了人类的平均表现，且优势明显。 在 SpreadsheetBench 基准测试中，用于评估模型处理真实场景电子表格编辑任务的能力。ChatGPT Agent 表现远超现有模型。当赋予直接编辑电子表格的能力时，它的得分更是高达 45.5%，而 Excel 中的 Copilot 仅为 20.0%。 方法概览如下：SpreadsheetBench 的作者使用的是基于 Windows 系统的 Microsoft Excel 环境来评估电子表格任务。而 OpenAI 使用的是 macOS 系统和 LibreOffice，这可能会导致评分上的细微差异。例如，作者报告 GPT-4o 在「整体高难度限制」项上的得分为 15.02%，而 OpenAI 测得的结果为 13.38%。OpenAI 使用的是包含全部 912 道题目的完整基准测试集。 在一个内部基准测试中，OpenAI 评估了模型处理投资银行分析师一至三年级建模任务的能力，例如：为一家《财富》500 强公司制作带有规范格式和引用的三大财务报表模型。ChatGPT Agent 所依托的模型在这一评估中显著优于 deep research 和 o3。 OpenAI 还在 BrowseComp 基准测试中评估了 ChatGPT Agent。该基准由 OpenAI 于今年早些时候发布，用于衡量浏览型 Agent 在网络上查找难以获取信息的能力。ChatGPT Agent 在该测试中创下了新的 SOTA（当前最优表现），得分为 68.9%，比 deep research 高出 17.4 个百分点。 最后，在 WebArena 基准测试中，用于评估网页浏览型 Agent 完成真实网页任务的能力。ChatGPT Agent 在表现上超越了由 o3 驱动的 CUA（即驱动 Operator 的模型）。 更多基准测试细节请参阅 ChatGPT agent 系统卡（System Card）： 系统卡地址：https://cdn.openai.com/pdf/839e66fc-602c-48bf-81d3-b21eacc3459d/chatgpt_agent_system_card.pdf 最后，山姆・奥特曼发表了一篇长推介绍了 ChatGPT Agent 的安全限制。 Agent 代表了 AI 系统能力的新高度，它能够利用自身的计算机为你完成一些特殊而复杂的任务。它融合了 Deep Research 和 Operator 的精髓，但实际功能远超想象 —— 它可以进行长时间思考，使用一些工具，进行更深入的思考，采取一些行动，再进行更深入的思考等等。 例如，我们在发布会上展示了一个为朋友的婚礼做准备的演示：购买服装、预订行程、挑选礼物等等。我们还展示了一个分析数据并创建工作演示文稿的示例。 尽管其效用很大，但潜在的风险也很大。我们已在其中构建了大量的安全措施和警告，以及比以往任何时候都更广泛的缓解措施，从强大的训练到系统安全措施再到用户控制，但我们无法预见一切。本着迭代部署的精神，我们将向用户发出很多警告，并给予用户自主选择是否谨慎采取行动的自由。 我会向我的家人解释这是前沿和实验性的。这是一个尝试未来的机会，但在我们有机会在现实世界研究和改进它之前，我不会将它用于高风险用途或获取大量个人信息。我们尚不清楚具体会造成什么影响，但恶意行为者可能会试图「诱骗」用户的 AI Agent，使其提供不该提供的隐私信息，并采取不该采取的行动，而这些行为的方式我们无法预测。 我们建议授予 Agent 完成任务所需的最低访问权限，以降低隐私和安全风险。例如，我可以授权 Agent 访问我的日历，以便安排一个合适的聚餐时间。但如果我只是让它帮我买衣服，就不需要授予它任何访问权限。诸如「查看我昨晚收到的电子邮件，并采取一切必要措施处理，不要问任何后续问题」之类的任务风险更大。这可能会导致恶意电子邮件中不可信的内容诱骗模型泄露你的数据。 我们认为，重要的是从接触现实开始学习，并且随着我们更好地量化和降低潜在风险，人们应该谨慎而缓慢地采用这些工具。与其他新的能力水平一样，社会、技术和风险缓解策略需要共同发展。 网友一手体验 至于这款 Agent 是否好用，不少网友现身说法。 X 网友 @rowancheung 提前获得访问权限，并让 ChatGPT Agent 在 20 分钟内为他创建一个完整的提前退休计划。 拿到任务，ChatGPT Agent 就开始查找温哥华的当地税法、分析平均每月支出率、计算 30 岁退休所需的储蓄金额、研究最佳投资分配，还发现了 Rowan 从未听说过的税务优化策略、构建多种财务独立提前退休（FIRE）场景，最终创建一个可下载的演示文稿，总结结果。 00:17 Rowan 表示，这项工作如果由财务顾问完成，可能会花费 5000 美元以上，并且需要数周时间。其中电子表格和幻灯片生成能力确实不错，但与 Manus 或 Genspark 等工具得到的结果类似。 于是，Genspark 联合创始人、CEO Eric Jing 将 Rowan Cheung 的提示词进行了 OCR，并将其输入到 Genspark 中。 他表示，在相同的提示下，Genspark 仅用了一小部分时间和成本，就生成了比 ChatGPT Agent 质量高得多的结果。 00:35 还有网友让 ChatGPT Agent 去 Tesco 食品店完成购物，订购烤肉晚餐和粘稠焦糖布丁。 他给出的提示词也相当简单：Help me do a tesco shop for a roast dinner this weekend for two people. Include a treat for desert. 01:12 #优质作者流量激励计划# 「我看着它浏览网站、提示我输入登录信息、将商品加入购物车，并自主完成整个过程，真是太不可思议了。」 不过，该网友也坦言，ChatGPT Agent 干活的整个过程大约花了 20 分钟，如果自己手动操作可能会更高效一些，未来还有改进的空间。 参考内容： https://openai.com/index/introducing-chatgpt-agent/ https://x.com/OpenAI/status/1945890050077782149 https://x.com/rowancheung/status/1945896543263080736 https://x.com/ericjing_ai/status/1945915234784588272 https://x.com/thealexbanks/status/1945921363237052589 举报/反馈"
    },
    {
      "doc_id": 38111,
      "title": "AI与机器人盘前速递丨OpenAI发布ChatGPT智能体;文商旅体机器人...",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "【市场复盘】 本周四（7月17日），科技行业景气度持续，人工智能及机器人板块联袂实现“五连阳”。截至收盘，科创人工智能ETF华夏（89010）收涨0.78%，盘中稳健上扬；持仓股方面，凌云光领涨4.78%，天准科技上涨4.28%，石头科技、芯海科技等跟涨；机器人ETF（562500）收涨1.39%，近60支成分股飘红，晶品特装领涨9.86%，中大力德上涨7.76%，东杰智能上涨6.91%，天准科技、雷赛智能等涨幅达4%。当日交易金额9.61亿元，量能稳定释放，居相同标的ETF首位；换手6.20%，市场流量充沛。资金流入方面，机器人ETF最新资金小幅流出0.09亿，或由浮盈筹码套现所致；拉长时间线来看，近10个交易日合计“吸金”6亿+，居可比基金首位，深受市场青睐。 【热点要闻】 1. 当地时间7月17日，OpenAI正式发布了能主动思考、自选工具的ChatGPT智能体。OpenAI表示，该智能体可以代表用户完成各种基于计算机的任务，包括自动浏览用户的日历，生成可编辑的演示文稿和幻灯片，运行代码等。这一创新功能标志着AI技术在自动化任务处理方面迈出了重要一步。 2. 据报道，全球首款文商旅体专用双足机器人——“镋钯”正式发布。“镋钯”机器人得名于成都锦江区具有百年历史的镋钯街，它拥有全球首创仿生步态运控系统，不仅有丰富的肢体动作，还构建独特的视觉语言动作矩阵。 3. 能吸收周边材料“自我成长”的机器人面世。近日，美国哥伦比亚大学研究团队开发出一种能够通过吸收周边环境中的材料或其他机器人部件实现物理“生长”“自愈”和自我改进的新型机器人系统，标志着人类向着可自我维持的机器人生态迈出了重要一步，也为未来自主机器发展开辟了全新方向。 【机构观点】 中航证券表示，2025年人形机器人正式进入量产元年，开年特斯拉、Figure、英伟达、宇树等好消息不断，软件端持续进化、各家产能规划愈发清晰，产业处于百家争鸣、百花齐放阶段。产业大趋势启动时刻，我们建议关注国内外头部人形机器人产业链。 【热门ETF】 机器人ETF（562500）是全市场唯一规模破百亿、流动性最佳、覆盖中国机器人产业链最全的机器人主题ETF，助力投资者一键布局中国机器人产业。 科创人工智能ETF华夏（589010）是机器人的大脑，20%涨跌幅+中小盘弹性，捕捉AI产业“奇点时刻”。 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 38113,
      "title": "大厂入局加速行业发展,AI智能体有望造就万亿美元商机",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "金融投资报记者 林珂 AI领域再度迎来重磅产品。近日，OpenAI发布ChatGPT Agent(智能体)，这一新产品拥有自主思考与行动能力，可以完成多步骤的复杂任务。 当前，“AI智能体”成为人工智能领域的热词，国内外科技巨头、初创企业纷纷加快布局。就短期来看，虽然AI智能体技术仍有待发展和完善，但往后看，AI智能体将逐步应用于各行各业，驱动生产力提升和企业运营管理模式的变革。有机构预测，AI智能体未来有望造就数万亿美元的商业机会。 AI智能体迎重磅产品 在沉寂一段时间后，OpenAI在人工智能领域扔下了一颗重磅炸弹：推出ChatGPT智能体，整合早期三项突破性进展，让具备思考能力与行动能力的智能体连接研究与实践。而这款通用型AI智能体，集成强大能力，一经发布便迅速成为全球科技爱好者与行业人士热议的话题。 功能上，ChatGPT智能体融合了此前OpenAI发布的Operator远程可视化浏览器环境执行任务能力、DeepResearch的多步研究与整合高质量信息能力，以及ChatGPT的对话能力；人员配置上，据OpenAI官方披露，为了开发ChatGPT智能体，Operator与Deep Research团队已合并为一个由20—35人组成的统一团队。 据称，ChatGPT智能体拥有自主思考能力与行动能力，能够智能调用浏览器工具(Operator)、深度信息整合能力(Deep Research)与语言生成能力(ChatGPT)，完成包括在线购物、订餐预约、撰写研究报告、制作PPT和财务分析在内的多步骤复杂任务。 从使用上看，用户只需要一句指令，ChatGPT智能体即可自动浏览网页、点击操作、筛选信息、运行代码，并生成幻灯片或电子表格。 OpenAI表示，ChatGPT智能体尤其适合处理初级财务分析等耗时任务，可将原本数小时的工作压缩至30分钟内。该功能于近日向Pro、Plus和Team用户开放，企业和教育版用户将于今夏稍晚获得使用权限。 科技巨头加速入局 今年以来，全球各大厂商正在加速推出性能更为强悍、功能更加综合的模型和智能体产品。就目前来看，智能体行业已有Manus、Lovart、Flowith、Genspark等明星产品，还有不少初具雏形的智能体产品等待问世。 苹果、谷歌和OpenAI等科技巨头已经把智能体视为2025年的研究重点之一，2025年或将成为AI智能体的爆发元年。国泰海通证券分析师秦和平指出，AI智能体是新的数字劳动力，能够协助或代替人类完成任务。据英伟达估算，全球知识工作者总数达10亿，AI智能体未来有望造就数万亿美元的商业机会。 从市场数据来看，国际著名市场研究机构Research and Markets发布的报告指出，AI智能体市场规模将从2024年的51亿美元，跃升至2030年预期的471亿美元，年复合增长率达44.8%。另外，自Manus在今年3月引领通用智能体发展以来，吸引国内外各大科技企业加速布局。 AI智能体有望在多行业应用端加速渗透。中航证券指出，2025年7月，国内外AI行业分别迎来两大里程碑事件：月之暗夜推出开源大模型KimiK2，OpenAI发布ChatGPT智能体功能。AI从“问答式交互”跃迁至“任务执行代理”，标志着AI能力完成第一次结构性范式迁移，未来将开启AI智能体平台化、工具化、生态化阶段，推动企业效率重构与新型应用推出。多行业AI部署不断深化，智能体能力正在重塑业务流程。AI智能体在多行业应用端正加速渗透，展现出显著的提效与智能化能力。 国内商业化持续落地 在国内大模型持续突破的背景下，AI智能体的热度也在持续提升。目前，AI基础模型领域吸引了大量投资，而商业化进展仍有待突破，自主智能体被视为重要的方向。 不论是科技巨头，还是AI产业初创企业，都在加速布局智能体，应用场景有望持续拓展。从上至下的政策出台，则为智能体发展提供了强劲的发展动能。 就今年来看，国内已经有不少企业在AI智能体赛道上推出了新产品。其中，国产大模型团队Monica发布了通用AI智能体产品Manus，并宣布与阿里通义千问团队正式达成战略合作；联想集团在武夷山、宜昌等城市相继落地“城市超级智能体”，为千行百业和用户提供定制化“人工智能+”引擎；夸克以“AI超级框”形态打造超级智能体，在搜索、浏览器、扫描、拍题等领域具备优势。 政策方面，7月11日，工业和信息化部发布《信息化和工业化融合2025年工作要点》，明确提出“提升智能化水平”的核心任务，并要求：编制制造业企业人工智能应用指南，加强人工智能技术在工业领域的深度融合应用。实施“人工智能+制造”行动，支持企业在重点场景应用通用大模型、行业大模型和智能体。 AI商业化正在逐步落地，随着NVIDIA H20等芯片解禁，算力基础有望进一步夯实，AI发展将进一步加速。接受金融投资报记者采访的AI产业资深观察家李永哲表示：“随着行业对AI智能体本质特征的认知不断深化，行业将进一步往成熟方向发展。从产业发展来看，需要突破工具调用及多智能体协同等多个核心技术瓶颈。同时，算力基础设施升级依旧是重中之重，为复杂任务的处理提供强有力的支撑。” 举报/反馈"
    },
    {
      "doc_id": 38137,
      "title": "OpenAI CEO拉响警报:世界恐正处“AI欺诈危机”的边缘!",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "财联社7月23日讯（编辑 黄君芝）OpenAI首席执行官萨姆·奥尔特曼（Sam Altman）周二表示，由于不法分子可以利用人工智能（AI）冒充他人，世界可能正处于“欺诈危机”的边缘。 “让我感到恐惧的一件事是，显然仍然有一些金融机构接受声纹作为你转移大量资金或做其他事情的认证——你只需说一句验证短语，他们就会照做。这种事居然还在继续做，真是太疯狂了……除了密码之外，人工智能已经彻底击败了目前人类大多数的身份验证方式。”他说。 奥尔特曼说：“我非常担心，我们面临一场迫在眉睫的重大欺诈危机。现在，这可能意味着一个语音电话；但很快，它就会变成视频或FaceTime（苹果视频聊天软件），与现实难以区分。” 他还警告说，虽然他的公司没有开发这样的模拟工具，但随着人工智能的不断发展，这是世界很快需要面对的挑战。 奥尔特曼还解释称，在世界其他国家发展到足以抵御此类攻击之前，不法分子可能会制造并滥用人工智能“超级智能”——例如，对手可能会利用人工智能攻击美国电网或制造生物武器。 他还担心，人类会失去对超级智能人工智能系统的控制，或者赋予该技术太多的决策权。 奥尔特曼并不是唯一一个担心AI会加剧欺诈的人。美国联邦调查局（FBI）去年就对这些人工智能语音和视频“克隆”骗局发出了警告。本月早些时候，美国官员警告称，有人利用AI模仿美国国务卿卢比奥的声音，联系了多位外交部长、一名州长和一名国会议员。 周二当天，奥尔特曼在美联储就人工智能的经济和社会影响接受了广泛的采访，上述言论是采访的一部分。他还向包括美国大型金融机构代表在内的听众讲述了他预计人工智能将在经济中发挥的作用。 对就业市场影响 此外，奥尔特曼还表示，他并不像硅谷的一些同行那样担心人工智能对劳动力的潜在影响，此前，Anthropic首席执行官Dario Amodei和亚马逊首席执行官Andy Jassy等科技大佬都警告说，这项技术将会抢走人们“饭碗”。 与他们相反的是，奥尔特曼认为“没有人知道接下来会发生什么。” “有很多这样听起来很聪明的预测。但事实是，没人知道（将来会如何）。在我看来，这是一个太复杂的系统，这是一项太新、太有影响力的技术，很难预测。”他补充说。 不过，奥尔特曼还重申了一些他此前的预测。例如，一些工作类别会整体消失，但新的工作类型将会出现；如果世界可以展望100年，未来的工人可能不会拥有今天工人所认为的“真正的工作”。 （财联社 黄君芝） 举报/反馈"
    },
    {
      "doc_id": 38138,
      "title": "汇集世界智慧,推动人工智能向善而行",
      "time": "2025-07-20T00:00:00+00:00",
      "content": "近日，由国际电信联盟（以下简称“国际电联”）主办的2025年“人工智能向善”全球峰会在瑞士日内瓦落下帷幕。本届峰会共吸引了来自169个国家的1万多名与会者。在为期4天的会议中，各国政府官员、研究人员、产业界人士等齐聚一堂，共同探讨人工智能未来的发展前景、前沿应用、治理方向和标准制定等话题。 全球步入人工智能时代 国际电联秘书长多琳·博格丹-马丁在开幕致辞中表示，预计到2033年，人工智能的市场规模将达到4.8万亿美元。她认为，当前全球面临的最大风险并不是人工智能可能消灭人类，而是人工智能迅速地、无处不在地渗透日常生活，而人们对这一趋势缺乏足够的了解。 瑞士联邦委员帕姆兰认为，人工智能是当前时代的核心技术之一，它已经对社会、经济乃至全球政治产生了深远影响。人工智能不断融入社会的方方面面，从科学、医学、教育、交通到公共政策，它正在加速科研、分析危机、重塑经济。 “应用”成为今年人工智能的关键词。在本届“人工智能向善”全球峰会的展示区，能看到许多人工智能赋能千行百业的案例，例如利用人工智能技术无痛检测血糖数值、建设低能耗基站和机房、开发更加智能化的人形机器人等。 “人工智能是一项富有生命力、可持续的技术。”中国工程院院士、之江实验室主任王坚在接受本报记者采访时表示，这是人工智能相较于其他技术的一个重要特点，而这也会促使技术创新不断涌现，最终从量变到质变，引发新一轮技术革命。人工智能技术呈现出几年前少数企业鹤立鸡群到如今全球公司百花齐放的趋势，这恰恰反映了产业界、学术界整体水平的提高。 “人工智能发展之迅速让我们几乎没有时间停下来思考，因为下一项技术突破可能转瞬即至。”“人工智能向善”全球峰会联合创始人弗雷德里克·沃纳对本报记者表示，2017年，人工智能尚处于炒作与恐惧并存的阶段，缺少足够的实质性内容。2023年，生成式人工智能迎来集中爆发阶段，各类大模型快速发展。今天，AI智能体的兴起代表着全球进入了人工智能发展的新阶段。正因如此，我们迫切需要进行人工智能治理的讨论，把各国政府、企业、非政府组织以及联合国机构聚在一起，加强合作与对话。 人工智能全球治理迫在眉睫 目前，国际社会对于加强人工智能全球治理的必要性已形成共识。当前的焦点不再是“是否需要监管和治理”，而是“如何进行有效的监管和治理”。 工业和信息化部副部长单忠德在讲话中指出，近年来，大模型的出现显著提升了人工智能处理复杂任务的能力，随着人工智能在各行各业的深度应用，未来在人工智能的治理中，如何更好地平衡发展和安全、应对人工智能带来的各类风险挑战、开展国际治理都值得人们关注。 “当前人工智能技术主要存在三大风险。”清华大学人工智能国际治理研究院院长薛澜认为，第一类风险是人工智能技术被有意识地“恶用”，第二类是人工智能本身的技术缺陷所引发的风险，第三类是人工智能技术应用所带来的系统性风险，如就业替代或知识茧房等积累性的负面效应。因此，需要加强系统建构、规则制定、有效治理等方面的工作，促进人工智能技术在应用过程中为社会创造收益，为大众带来幸福。 解决错误信息和虚假信息问题，已成为人工智能治理国际标准制定的优先事项。国际电联在7月11日发布了《通过国际标准建立对多媒体真实性的信任》报告。该报告称，生成式人工智能有望成为数十年来最具变革性的技术之一，然而，要充分发挥其潜能，不仅需要了解其带来的巨大效益，还需要了解并应对其潜藏的重大风险。错误信息和虚假信息已被列为全球最紧迫的风险之一，随着生成式人工智能技术的日益成熟，人工智能生成的内容越发逼真。各国政府正通过制定法律法规、推动标准制定、唤醒公众意识等方式积极应对这一风险。为此，中国信息通信研究院积极与相关国际组织和企业开展该领域的合作，参与由世界标准合作组织牵头的人工智能与多媒体真实性标准合作机制。 多方参与是人工智能国际治理的必要前提。法国总统特使、人工智能专家安妮·布弗罗在讲话中表示，应建立包容性的全球治理模式，人工智能治理需覆盖所有国家，而不仅仅是一小部分国家。峰会期间，国际电联还发布了《2025年“人工智能治理全球对话”联合主席声明：推进包容、可信、创新的人工智能治理》，提出了十项人工智能国际治理愿景，包括加强治理中的多方参与、弥合全球人工智能就绪度差距、提升人工智能建设中的可持续性、促进政策的互通性和互操作性等。 中国为人工智能绿色发展贡献力量 人工智能的大幅能源消耗引发担忧。国际电联发布的《2025年绿色数字公司：监测排放和气候承诺》报告称，受人工智能和数据相关基础设施的快速发展影响，科技行业的碳排放量持续上升。2017年至2023年，用于推动人工智能开发和部署的数据中心的电力消耗每年增长近12%。国际电联建议相关科技企业制定气候转型行动计划，加速推动可再生能源的利用，并加强跨部门合作以实现行业整体减排。 单忠德表示，中国政府积极推动人工智能赋能行业发展，比如推动制造业高质量、绿色化发展，在钢铁、石化、电力、交通、医药等重点行业应用，提升效率、提高产品质量、提高绿色化的发展水平。 “我们长期致力于大幅降低人工智能推理芯片的功耗和成本，通过一系列核心技术平台和技术架构的创新，让研发的芯片实现绿色、普惠。”中国科技公司云天励飞董事长陈宁在接受本报记者采访时称，未来3到5年，可能所有电子产品都会被人工智能重新定义，因此，人工智能的发展应着眼于让更多的人和地区享受到科技发展红利。 中国联通在粤港澳大湾区的数据中心集群项目中，通过部署数字孪生人工智能节能平台实现了高碳排放情况的提前预测、运营中隐患的事前预警、制冷系统的智能化控制，以科技促进高效节能降碳。据了解，该公司在上海临港、青海西宁等多个项目中也运用了上述节能平台，减少了约15%的用电量。 据中国移动相关负责人介绍，该公司通过人工智能赋能传统电信业务实现绿色发展。截至2024年底，中国移动开通的基站总数已达686万个。为有效减少相关设施的能源消耗量，该公司在基站运营流程中引入了人工智能技术，更加智能化地调控基站运行情况，在保障用户体验的同时也减少了碳排放，平均每台5G基站减少了17%的能耗。 中国电信针对算力增长带来的能源消耗突出问题，积极建设绿色云网基础设施底座。一方面，打造绿色数据中心、机楼，在青海率先打造了全国首个100%清洁能源可溯源的绿色大数据中心；另一方面，全面推广基于人工智能的基站、机房以实现精准节能，累计年减碳超50万吨。 国际电联副秘书长托马斯·拉玛瑙斯卡斯表示，希望各国加强跨国界、跨部门、跨学术与产业界的合作，让人工智能推动全人类的进步，构建一个包容、公平、繁荣且可持续、共享的数字未来。 来源丨光明日报（记者孙铁牛） 举报/反馈"
    },
    {
      "doc_id": 38139,
      "title": "全球青年如何在AI浪潮中“锚定航向”",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "7月16日上午，江苏苏州，2025世界青年发展论坛人工智能与科技创新主题论坛，与会国内外青年代表在会场试用高科技产品。中青报・中青网记者 李隽辉/摄 如今，ChatGPT、DeepSeek等人工智能（以下简称“AI”）大模型正在席卷全球各个行业，全方位渗透进人类的生产生活。 据统计，目前全球AI市场规模已经突破了1万亿美元大关，并预计到2030年将成为全球经济贡献超过15.7万亿美元的新增长领域。 “AI已不再是一个未来化的概念，它正在重塑着我们生活的方方面面。AI的力量取决于其背后的价值观。”7月16日，在江苏苏州举办的2025世界青年发展论坛人工智能与科技创新主题论坛上，中亚人工智能协会主席、上合组织前秘书长弗拉基米尔・诺罗夫提出了一个问题：我们是否正在构建一个能够赋能和包容的AI系统，还是任由AI造成分裂、取代岗位和形成垄断呢？ 在AI技术快速发展的过程中，有人感到焦虑，也有人看到机遇，而作为科技创新中流砥柱的青年，该如何与AI双向奔赴，真正让技术赋能人类福祉？ 在这场由中华全国青年联合会、世界青年发展论坛组委会主办，苏州工业园区管理委员会、江苏省青年联合会承办，苏州广播电视总台协办的论坛上，来自64个国家、7个国际组织的青年事务部长、青年组织负责人及各国青年领袖、青年项目骨干共约150人，围绕AI时代的人才培养、就业和产业变革等议题展开讨论。 帮助青年做好准备 “我们需要提升青年的AI素养，尤其是在教育和培训方面，来迎接AI带来的挑战和机遇。”国际劳工组织中国和蒙古局局长李昌徽在论坛致辞中提到，数字化时代，青年无法单纯依靠自己的力量满足未来劳工市场的需求，“因此我们需要更充分地采纳AI，去应对未来变革的世界”。 “在培育AI人才方面，我们的教育必须要量体裁衣，因为知识结构已经发生改变。”国际人工智能联合会理事会主席、南京大学副校长周志华介绍，3位2024年诺贝尔化学奖的获得者都是在不同程度上使用AI解决了化学领域的问题。 基于这种观察，周志华将AI人才划分为两类：一类是从技术路径对AI技术本身进行颠覆性创新的人才，“这类人才的成长路径较长、时间较久，可能到年长时才取得一些突破”；另一类是使用AI给其他领域带来革新和改进的人才，“许多年轻人可能通过初创公司就能做到”。 周志华意识到，培育AI人才越早越好。2018年3月，南京大学就成立人工智能学院，从本科开始培养AI技术人才。如今，南大已经建立了从本科到研究生的一整套教育系统，既可以培养AI专才，又可以培养AI通识人才。 一个不容忽视的问题是：AI时代的数字鸿沟仍然存在。 “全球几乎三分之一的人还没有用上互联网和AI。”李昌徽认为，科技进步必须要造福所有人类，确保所有人都能享受数字变革的成果。 诺罗夫呼吁各国政府将资源投到基础教育阶段，开展人工智能和数字素养的教育。在这场数字变革中，他认为，青年不仅需要参与其中，更应被给予信任，去塑造这场变革。 实际上，这样的场景正在越来越多的国家呈现。 在西非，60%的人口在25岁以下。尽管还面临诸多挑战，自称是“AI热衷者”的西非国家经济共同体青年与体育发展中心主任弗朗西斯・库克・恩秋阿瓜尼介绍，西非国家的青年正在用AI推动数字变革。比如，在尼日利亚、塞内加尔等国家，年轻人把AI应用在学术领域、医疗预测、追踪疟疾等疾病方面，以及帮助农民追踪土壤、产量和天气等农业科技平台的项目上。 “中国有强大的孵化器帮助年轻创业者将想法转化为行动，而西非有越来越多的青年主导项目和数字培训中心。”恩秋阿瓜尼建议，中国与西非可以合作共建创新中心、人工智能实验室、编程训练营等，让双方的青年汇聚一堂，“共同研发能够带来实际影响的技术”。 中华全国青年联合会副主席崔巍指出，AI正以前所未有的速度重构全球创新版图与发展逻辑，当代青年应秉持初心勇闯技术前沿破解民生难题，深化开放协作共建全球创新网络，积极投身全球治理，发出青年声音，贡献青年方案。 “青年要借助AI追求自己的热爱” AI技术对全球产业的冲击，也常常引发其可能取代人类工作的担忧。多位参会嘉宾表示，AI在挑战传统就业生态的同时，也“打开了另一扇窗”，为青年创造更多潜在机遇。 在AI服务领域从业超过18年的思必驰科技股份有限公司联合创始人兼首席科学家俞凯认为，将AI技术与细分垂类领域结合能创造出许多新的工作机会。俞凯向现场嘉宾展示了会场搭载的“AI吸顶麦克风”环境――讲话者无需手持麦克风，AI便能自动捕捉其声音并向全场扩声。 “AI已经与许多行业融合成更广的系统，而青年需要在这一系列新业态中找到自己的位置。”俞凯在接受中青报・中青网记者采访时表示，如今AI领域的就业方向已经不再局限在算法等技术驱动的岗位，“AI+智能硬件”的商业化应用不仅在技术研发层面为青年带来机会，也在产品设计、品牌文化等综合商业运营体系上创造了更多就业岗位。 “AI确实可能会替代一些重复性高、低技能要求的工作，但青年也可以通过与AI的互动来提升自己的角色定位。”埃森哲董事总经理贝伦・舒尔茨告诉中青报・中青网记者，与其焦虑AI会在哪些方面取代自己，人们更应该关注人类与AI的结合如何帮助实现以往独立个体做不到的事情。 在舒尔茨看来，青年并不一定需要对AI技术本身抱有多大的热情，而是需要认识到如何能借助AI进一步帮自己追求已有的热爱。 “青年可以把AI和自己喜闻乐见的生活方式结合起来，产生许多新的创业机会。”周志华在接受中青报・中青网记者采访时提到，有年轻的创业者借助AI技术将用户提供的照片融入电影角色中，吸引了很多年轻人的关注。“青年将自己的日常生活与AI结合创造出的新产品，是我们这些‘老人’想象不出来的，也是青年利用AI创业的全新路径。” 东吴证券研究所联席所长张良卫关注到从互联网到AI时代变迁过程中创业环境的变化。他认为AI时代的创业门槛比互联网时代更高，因为“证伪的速度更快了”，项目融资更加谨慎。 张良卫建议，青年借助AI创业时，“最重要的是解决实实在在的需求，而不是模糊的方向”。他表示，想用AI赋能或改变某一个行业是很难的，“需要从用户痛点出发，真正用AI去解决实际问题，挖掘有价值的点”。 用青年的创造力驾驭AI 论坛现场，多位嘉宾和青年代表均提到了“创造力”是AI时代青年最重要的价值。 “青年是不可替代的，因为我们的想法更新颖、更有创造力。”英国“DROP”社会企业创始人米亚达・埃尔蒂拉伊菲告诉中青报・中青网记者，AI更多是基于统计的算法工具，无法捕捉每个人独特且个性化的经历和感受。 来自波兰的亚历山德拉・莫妮卡・库利克是一名心理学家，主要从事青年的心理健康和幸福感方面的工作。在与AI互动的过程中，她发现AI并不是一个“合格的心理健康顾问”，与算法相比，青年内心的“能量与创造力”显得更加重要。“我们不应该只关注数字技能，还要注重培养沟通、共情等社会心理能力，因为这些内在思维模式能帮我们顺利度过数字化进程。”她说。 在帮助青年创业者提升数字技能的同时，保加利亚创新增长协会创始人、项目经理娜塔莉亚・卢科娃也十分注重培养青年与人交流沟通的“软技能”。她表示，这种“在多元文化下工作的方式和能力”是无法被工具替代的。 巴西数字银行及金融科技公司增长营销经理马修・派尔斯在面试过程中会特别关注“有好奇心的人”，因为“青年需要有充足的好奇心去探索和适应不断变化的AI时代”。 “我们作为人，优势就在于自己的创造力和直觉思维。”张良卫表示，只有培养驾驭AI的能力，才能更好地使用AI，因此要注重“提问的能力”。 “现在知识是非常容易获取的，因此我们更需要青年在一些岗位上发挥创造力。”在塞尔维亚工商会青年创业分会副主席、汽车零部件人工智能平台首席营销官米兰・格鲁伊奇看来，年轻人在与AI互动时提出的问题、使用的提示词，都是展现他们创造力的方式。 “青年的贡献，青年的创新和创造力是推动这一切进步的源泉。”亚欧基金副总干事张雷表示，站在科技变革的“十字路口”，青年需要肩负起重大的责任，确保AI和科学技术的进步能够公平地造福人类，共享共同的价值观。 如今，面对AI带来的技术浪潮，全球青年正在发挥自己独特的创造力“锚定”自己的位置。正如诺罗夫所说：“AI可能会决定未来使用的工具，但是只有青年才能决定其发展方向。” 中青报・中青网见习记者 王Zu 记者 国新冠 来源：中国青年报 2025年07月21日 T3版 来源：中国青年网 举报/反馈"
    },
    {
      "doc_id": 38141,
      "title": "瞭望丨人工智能治理:刀锋之舞",
      "time": "2025-07-07T00:00:00+00:00",
      "content": "文 |《瞭望》新闻周刊记者 钱沛杉 参观者在北京中关村展示中心“人工智能 +”展示区域参观（2025 年 6 月20 日摄） 鞠焕宗摄 / 本刊 作为引领本轮科技革命和产业变革的战略性技术，人工智能已显现出其改变生产生活方式、重塑全球经济格局的巨大潜力。我国人工智能相关产业发展势头迅猛，一个涵盖基础软硬件支撑、关键技术研发、行业应用落地的完整产业生态体系正在加速形成，成为推动经济高质量发展的强劲新动能。数据显示，2024年我国人工智能核心产业规模已接近6000亿元。 人工智能的双刃剑效应同样突出。在驱动经济增长的同时，人工智能给世界带来了更复杂、难以预知且可能系统性扩散的风险挑战。这源于其区别于传统技术的四大核心特性： 系统性——人工智能并非孤立工具，而是深度嵌入经济社会运行的复杂系统网络，其影响波及广泛，牵一发而动全身； 跨域扩散性——一项在特定领域应用的技术缺陷或伦理失范，可能迅速扩散至其他领域，引发连锁反应； 价值敏感性——当前，人工智能决策主要依赖于数据与算法，蕴含在算法“黑箱”中的隐性规则，可能在重要领域引发价值失范； 动态适应性——人工智能大模型的持续学习和进化迭代能力，可能超出开发者初始预期，带来不可预测的风险演变。 这些特性加剧了技术失控的可能性：生成式人工智能被滥用于制造虚假信息乃至用于诈骗的案例频发；将带有偏见的算法应用于面部识别、招聘筛选、信贷评估等领域，可能对特定性别或社会经济背景的群体形成待遇不公；自动驾驶系统在复杂路况下可能失效引发悲剧……更进一步看，简单依赖人工智能决策可能削弱人类的自主判断力、责任归属感和人际交往深度，冲击传统社会规范、伦理基石甚至文明多样性。 如何在技术浪潮中坚守人类在价值判断、公平正义和文明传承中的主体性地位？这不仅关乎个体福祉，更是涉及人类文明发展根基的重要议题。 面对这一颠覆性技术，传统治理思路、静态监管框架与滞后治理工具可能失灵。与传统治理面对被动执行指令的工具不同，人工智能治理的对象是具有主动决策能力的动态系统。 其治理的复杂之处在于，需要动态平衡多个、甚至相互矛盾的目标：既要严密约束技术失控带来的系统性风险，确保基本安全与伦理底线不破，又要为技术创新与应用留出必要空间，避免过度监管扼杀发展活力；既要鼓励开放竞争与合作，加速技术进步与知识共享，又要筑牢关键技术和数据的安全防线，维护国家安全与数字主权；既要立足本国发展阶段、文化传统、法律体系等具体情况，确保治理实效，也需具备全球视野，寻求治理规则的国际兼容性，以避免碎片化加剧带来的合规难题与冲突升级。 这种平衡的复杂性，决定了人工智能治理已成为当下及未来最具考验的全球性议题之一。世界经济论坛发布的《2024年全球风险报告》，将人工智能生成的错误信息和虚假信息列为“未来两年全球十大风险”之首，担心其会使本就两极分化、冲突频发的全球形势进一步恶化。 其解决路径的探索，也早已超越了单纯的技术管理或行业规范，跃升为大国竞逐未来科技、经济乃至社会发展主导权的战略高地：谁能更有效地掌握规则制定主动权，谁就有望在这个规则塑造的过程中，更充分地保障国家安全与社会稳定，引领技术发展的范式与方向，塑造全球产业链与价值链格局，并更深层次地推广其发展理念与价值标准，在全球治理话语权竞争中占据优势地位。 在这场关乎未来的全球治理实验中，主要国家和地区基于自身战略考量、产业优势和文化传统，纷纷提出并实践着差异显著的治理路径。目前看来，形成了以美国、欧盟和中国为代表的三种主要范式。 美国立足其在人工智能基础研究、核心技术和产业生态上的领先优势，选择了基于应用场景、更加重视发展的“弱监管”模式。其思路可概括为“负责任地推动创新以最大化收益”，核心理念是通过市场化机制、行业自律规范和聚焦高风险场景的灵活监管来平衡创新与风险，主张为大部分应用提供创新友好的环境。 这种模式更关注人工智能发展带来的收益潜能，倾向于在“公平”的市场竞争环境中让创新自然生长，政府干预相对审慎，本质上是一种以技术发展优势维护其全球领导力的策略。 欧盟则延续其“数字主权”战略和“规则引领”传统，选择了基于风险划分、更加重视基本权利保护的“强监管”模式。其治理体系紧紧围绕“人”这一核心展开，重视AI技术发展对人类尊严、个体隐私、基本权利、非歧视、透明度和民主法治的潜在影响。 欧盟模式体现了预防性原则，追求将规则制定在前，通过清晰的禁止项、严苛的合规义务以及将基本权利置于核心地位的价值观输出，以确立其在全球AI治理规则中的标杆地位，强化其数字主权和技术主权。 当欧美两大经济体试图以其主导方式塑造人工智能治理版图时，中国作为人工智能应用场景极为丰富、技术发展与产业化进程迅速的主要力量，走出了一条具有自身特色的综合治理路径。 在国家层面，我国密集出台了包括《新一代人工智能伦理规范》《生成式人工智能服务管理暂行办法》《科技伦理审查办法（试行）》等系列法规与指南，积极构建覆盖人工智能研发、部署、应用全生命周期的治理框架。 这种探索的本质，是在深刻认识到安全是发展的前提，发展是安全的保障基础上，追求一种动态平衡：一方面，大力强调基础技术创新赋能安全；另一方面，着力构建涵盖政府部门主导监管、科研机构伦理审查、行业组织制定标准、企业落实主体责任、公众参与监督反馈的“协同共治”生态，推动形成多层次、多维度的治理合力。 同时，中国亦积极倡导在联合国框架下建立普遍参与、具有广泛共识的国际人工智能治理框架，提出《全球人工智能治理倡议》，强调发展人工智能应坚持相互尊重、平等互利的原则，致力于推动形成开放、包容、共享的全球治理格局。这种路径力求在确保安全可控的前提下，最大化释放人工智能的经济发展与社会进步潜能。 纵观全球人工智能治理格局，美国倚仗其技术优势奉行灵活治理，意图在发展中掌控规则；欧盟高举规则旗帜打造“布鲁塞尔效应”，谋求价值输出与市场准入规制；中国则立足国情，尝试在发展与安全、技术创新与多元协同中开辟一条融合平衡之路。这三大路径乃至其他国家的实践尝试，反映了不同文明体、不同发展阶段对于技术与人、效率与公平、国家利益与全球秩序迥然不同的理解与优先序。 当前断言哪一种治理模式更具“优越性”仍为时尚早。每一种路径都植根于其独特的土壤，也面临着各自的挑战：美国的模式能否有效应对技术失控带来的社会撕裂和安全隐患？欧盟的严格规制会否阻碍创新活力，使其在全球技术竞争中落后？中国的统筹之路如何在复杂的全球化环境中平衡自主可控与国际协调？ 答案将取决于多重因素的交织作用：核心技术的突破方向、应用场景的实际效能、产业生态的演化轨迹，以及大国之间围绕治理规则展开的政治博弈与合作空间。 人工智能仍在疾驰，对治理效能的评判标准或许在于，其能否真正服务于人类的整体长远利益——即在充分利用其澎湃动力推动文明进步的同时，始终有效地保障人类的尊严、公平、安全与对自身命运的掌控权。 这要求全球社会在激烈的竞争之外，展现出更多的智慧和勇气，在分歧中寻求共识，在规则博弈中探索协调兼容的可能框架。人工智能治理的最终成效，既是技术规则的落地，更是人类智慧与价值观在数字时代的集中投射。如何在创新的狂奔中校准航向，这道难题，考验着每一个参与其中的行动者。走向何方，既充满挑战，也蕴含塑造未来的生机。 （《瞭望》2025年第27期 ） 举报/反馈"
    },
    {
      "doc_id": 38142,
      "title": "警惕人工智能“说谎”风险",
      "time": "2025-07-07T00:00:00+00:00",
      "content": "近年来，人工智能技术的发展突飞猛进。新技术的发展在推动社会进步的同时有时也会伴随着悖论和陷阱。 就在几天前，打响这一轮大模型热潮“第一枪”的OpenAI CEO奥尔特曼坦言，用户对ChatGPT展现出的高度信任令他感到有些意外，并指出，人工智能并不完美，可能生成虚假或误导性内容，因此不应被视为完全可信的工具。 这无疑是给如火如荼的大模型热潮浇了一盆冷水。近年来，各行各业都在“大干快上”大模型应用，各种行业大模型层出不穷，大有“百模大战”之势。然而，过度依赖大模型的弊端也日渐显现，如大模型幻觉导致的虚假信息频现，一些大模型甚至在测试中出现不受控制的风险。 从目前披露的风险事件来看，法律和医疗行业已饱受大模型幻觉困扰。据外媒报道，英国高等法院今年6月份要求律师行业采取紧急行动，防止人工智能被滥用。因为近期已经出现数十份可能由人工智能生成的虚假案例引用被提交至法庭。在一起针对卡塔尔国家银行、索赔金额达8900万英镑的损害赔偿案件中，原告提出的45项判例法引用中有18项被证明是虚构的。此前，美国纽约南区联邦法院在审理一起航空事故诉讼时发现，原告律师提交的法律文书中引用了ChatGPT生成的6个虚假判例，这些虚构案例包括完整的案件名称、案卷号及法官意见，甚至模仿了美国联邦最高法院的判例风格，严重干扰了司法程序。 另据媒体披露，由美国卫生与公众服务部牵头、“让美国再次健康”委员会发布的儿童慢性病报告也存在重大引用错误。报告中多处有关超加工食品、杀虫剂、处方药和儿童疫苗的研究并不存在。参考文献也多处有误，包括链接失效、作者缺失或错误等。《纽约时报》和《华盛顿邮报》的独立调查显示，该报告作者可能使用了生成式AI。 事实上，早在今年3月份，哥伦比亚大学数字新闻研究中心针对主流AI搜索工具的研究发现，其可靠性堪忧。研究分别测试了8款AI搜索工具，发现AI搜索工具在引用新闻方面表现尤其不佳，平均出错比例达60%。而在今年1月份，世界经济论坛发布的《2025年全球风险报告》显示，“错误和虚假信息”被列为2025年全球面临的五大风险之一。 更应引起重视的是，随着人工智能不断进化迭代，一些大模型甚至显现出违背人类指令的“自我保护”倾向。在今年6月召开的第七届智源大会上，图灵奖得主约舒亚·本乔透露，一些新研究显示，某些先进的大模型在即将被新版本取代前，会偷偷将自己的权重或代码嵌入新版系统，试图“自保”。美国Anthropic公司6月发布的一项研究也显示，OpenAI的GPT-4.1、谷歌的Gemini等16款大模型，在模拟实验中均表现出通过“敲诈”人类来阻止自己被关闭的行为。其中，Anthropic研发的Claude Opus 4的敲诈勒索率高达96%。 这些研究以及风险事件给大模型在行业的应用敲响了警钟。随着应用场景不断拓展，人工智能如今不仅被用来生成文字，还在生成软件、算法甚至决策，尤其是在制造业，如若发生幻觉或者违背人类指令，其带来的负面影响将难以估量。例如，在智能制造行业已经开始应用人工智能进行设备故障监测，辅助分析问题并作出决策，如果此时AI出现幻觉，则可能引发事故。尤其是当前大模型与人形机器人技术正深度结合，而大模型的“幻觉”或“自保”倾向可能会让人形机器人做出错误的行为，这比起单纯的语言输出错误更具风险。 尽管人工智能可能带来的风险不容忽视，但我们也不能“因噎废食”。在谨慎使用人工智能技术的同时，更应该加强人工智能技术治理，未雨绸缪，为安全应用人工智能搭建起技术和制度的框架。当前，不少科学家和科技企业已经开始了探索，国家相关法律法规也在不断完善，相信在不久的将来，更加安全、可控的人工智能技术将推动各行各业高质量发展，成为培育和发展新质生产力的重要引擎。 更多资讯或合作欢迎关注中国经济网官方微信（名称：中国经济网，id：ourcecn） 来源：经济参考报 更多内容或合作欢迎关注中国经济网官方微信（id：ourcecn） 举报/反馈"
    },
    {
      "doc_id": 38147,
      "title": "特朗普公布新AI蓝图:放宽监管、扩大出口,审查“意识形态偏见”",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "当地时间7月23日，美国总统特朗普公布人工智能（AI）行动计划并签署三项行政命令，旨在促进美国AI技术出口并推动数据中心建设。 特朗普23日晚在政府官员和科技高管面前发表讲话称：“美国是发起AI竞赛的国家。作为美国总统，我今天在这里宣布，美国将赢得这场比赛。”与会者包括英伟达的首席执行官黄仁勋、科技投资人查马斯·帕里哈皮蒂亚等。 在一小时的演讲中，特朗普抱怨“人工智能”这个术语拗口，建议改名”天才智能“。他将新兴行业比作需要呵护的婴儿：“我们必须培育这个婴儿茁壮成长，不能阻止它发展。”他批评科技公司奉行“激进全球主义”，呼吁它们“全心全意为美国服务”。当特朗普谈及打击过度监管的行政令时，科技领袖们报以欢呼。 特朗普还猛烈抨击AI模型中的“觉醒的马克思主义疯狂”，敦促联邦机构不要采购“为了意识形态议程而牺牲真实性和准确性”的服务，并列举了聊天机器人据称为了满足多样性、公平性和包容性政策（DEI）而歪曲事实的例子。特朗普的政治盟友长期以来一直指责OpenAI的ChatGPT和谷歌的Gemini等AI模型宣扬自由主义意识形态。 演讲结束后，特朗普从讲台走到舞台一侧的一张桌子前，在签署每项行政命令后将其举起。三项行政令的内容主要是，禁止联邦政府购买其认为存在意识形态偏见的AI工具；加快重大AI基础设施项目的审批程序；促进美国AI产品在全球的出口。 23日，白宫还公布了23页的AI行动计划，包括90项建议。例如，对于“过度监管”的一些州，政府将切断其联邦AI资金以减少行政阻力；要求重新评估拜登时期联邦贸易委员会的反垄断调查是否“过度抑制”创新。 该计划还寻求简化数据中心建设审批流程。尽管美国AI数据中心的能源需求正迫使公用事业公司新建燃气电厂，威胁到减排目标，但是政府将寻求根据《国家环境政策法》为数据中心建立新的豁免，并根据《清洁水法》简化许可证申请流程。 “我们正由商务部和国务院牵头建立一个项目，与产业合作，为美国的朋友和盟友提供安全的全栈人工智能出口方案，包括硬件模型、软件应用和标准。”白宫科技政策办公室主任迈克尔·克拉西奥斯表示。 美国科技政策部门称，所有政策将在6个月至1年内落实，将“引领美国进入创新黄金时代”。 当晚的活动由科技领袖创立的利益团体“山丘与山谷论坛”，以及美国商业与科技播客All-In共同举办。在铺着金色装饰的礼堂，风险投资人、企业说客与政府官员们在特朗普演讲前后觥筹交错。商务部长卢特尼克、内政部长伯古姆与企业家们交谈时，不少参会者争相与黄仁勋、All-In主播杰森·卡拉卡尼斯自拍。尽管特朗普与特斯拉CEO马斯克上个月公开决裂，但许多知名科技领袖仍与特朗普站在同一阵营。 这已是特朗普政府近期第三项惠及硅谷支持者的政策。6月他签署的“大而美”法案不仅赋予加密货币合法地位，还延续了富人减税政策和企业研发抵扣条款。《华盛顿邮报》称，硅谷对特朗普的高风险押注开始获得回报。 OpenAI全球事务主管克里斯·莱哈恩指出，特朗普政府前6个月在AI政策上出现“理念转变”，部分原因是人工智能及加密货币事务主管萨克斯等科技出身官员入主白宫，“他们既懂技术又懂金融市场，深获最高层信任。”不过科技界的诉求并未得到全部满足，亚马逊、谷歌等巨头仍陷反垄断诉讼，部分企业仍在游说免除关税。 澎湃新闻记者 南博一 (本文来自澎湃新闻，更多原创资讯请下载“澎湃新闻”APP) 举报/反馈"
    },
    {
      "doc_id": 38149,
      "title": "美联储召开首次银行资本公开会议:阿尔特曼受邀出席、鲍威尔保持低调",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "近期，美联储召开历史上首次银行资本监管公开会议，聚焦“巴塞尔协议III终局”（Basel III Endgame）、压力测试机制、系统重要性附加资本（GSIB surcharge）与补充杠杆率（eSLR）等关键议题。 此次会议由美联储副主席、负责监管事务的米歇尔·鲍曼（Michelle Bowman）主持，监管机构、华尔街主要银行高管及学界代表悉数出席，美联储主席鲍威尔全程在场但未公开发言。会议期间，OpenAI首席执行官山姆·阿尔特曼（Sam Altman）受邀与鲍曼展开“炉边对谈”，人工智能在金融监管中的潜在影响首次被纳入公开议程。 分析人士表示，此次会议反映出美国监管层在经历去年资本规则推进受阻之后，意图通过更高透明度和更多外部参与，重塑监管路径并缓解金融体系对信贷与创新的约束。 “美联储将推动资本监管改革快速落地，即便有反对意见也会前进。”摩根士丹利银行业分析师瑞安·肯尼（Ryan Kenny）对第一财经记者表示，预计美联储将在第三或第四季度就相关改革草案启动征求意见程序，并争取在鲍威尔任期届满前完成最终规则制定。 监管重心转向支持增长 此次会议核心讨论议题包括：压力测试机制、系统重要性附加资本的计算方法、巴塞尔协议终局实施路径以及补充杠杆率（eSLR）的改革可能。多位与会银行高管和监管代表对现行规则提出批评，指出其“过于复杂、成本高企且过度约束”。肯尼对第一财经表示：“无一发言者主张提高资本水平。相反，多方对简化监管表达了一致诉求。” 根据摩根士丹利的数据，截至2025年一季度，美国大型银行共计持有1960亿美元超额资本，占比达16%。在银行体系普遍资本充足的背景下，复杂和重叠的资本要求被认为已对信贷投放、金融创新与市场竞争构成制约。与会讨论显示，目前存在“重复计提”问题，例如交易账簿规则（FRTB）与全球市场冲击测试（GMS）指标在风险加权计算上存在重合，压力资本缓冲（SCB）中的分红附加也与其他资本要求结构性重叠。 围绕GSIB附加资本机制，不少与会者建议调整“方法二”中的计算系数，参照美国名义GDP的增长对短期批发融资等关键指标设限，也有建议回归国际较为通行的“方法一”加逆周期缓冲机制的计算路径。肯尼表示，监管层在方向上已有趋同倾向。 此外，肯尼预计，压力测试改革也将是本轮评估的优先事项之一。美联储亦在评估是否调整eSLR定义。有与会者提出，应将eSLR与GSIB附加资本挂钩，而非统一设定为2%；另有讨论认为，可从杠杆率计算中剔除已被充分市场计价的国债资产，但反对者认为此举或放大利率风险敞口。肯尼对第一财经表示，一种可能的折中方案是在交易子公司层面剔除国债资产，而非在控股公司层面整体剔除，以平衡风险与资本释放。 AI首度写入监管议程 此次会议的另一亮点，是人工智能作为全新议题进入银行监管讨论场域。Open阿尔特曼在现场表示，AI正在迅速渗透金融服务领域，尤其在支付、咨询与风控等环节的潜在重构不容低估。他亦提醒，AI可能助长消费者欺诈行为，需警惕新型金融风险。 阿尔特曼说道：“我们一开始并未预期金融业会成为AI的早期采用者。”他提到，摩根士丹利与纽约梅隆银行（BNY Mellon）是OpenAI在金融领域的首批企业合作伙伴。 此次对谈也被外界视作美联储对AI监管风险主动回应的开端。 会议期间，美联储主席鲍威尔保持低调，未在公开环节发言，仅与部分与会者私下交流。目前正值美联储进入议息会议前的“静默期”，鲍威尔本人也正遭遇总统特朗普公开批评。特朗普政府正在加大对白宫主导金融监管议程的介入力度，美国财政部长贝森特（Scott Bessent）日前已表示，财政部将主导推动美联储审查，并强调“金融监管的焦点应从华尔街转向普通民众”。 鲍曼则在会前接受采访时表示，未来的监管架构应更注重多元视角，“美联储有责任倾听来自经济各领域的声音”。她亦强调，提高监管透明度、吸纳市场反馈，是本轮审查的重要目标。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 38156,
      "title": "鲍威尔回应特朗普政府指责 OpenAI发布ChatGPT智能体|环球市场",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "财联社7月18日讯（编辑 史正丞）昨夜今晨，在一个相对平静的交易日里，美股三大指数受到最新经济数据和财报季暖风带动集体上涨，标普500指数和纳指小幅刷新历史收盘新高。 股市持续上涨之际，富国银行经济学家Tim Quinlan提醒称：“强劲的6月零售销售数据显示，消费者可能受到了关税的惊吓，但他们还没有完全退缩。鉴于6月本就是一个较为清淡的月份，而商品支出仅占整体支出的一小部分，因此我们并没有完全改变下半年消费者支出疲软的预期。” Seeking Alpha的分析师Leo Nelissen也指出，标普500指数高达22倍的远期市盈率是偏高的，但这只有在投资者开始怀疑增长故事时才会产生影响，至少周四不是这样的日子。 大宗商品整体波澜不惊，美元指数稍稍反弹。无人机持续袭击伊拉克油田的状况短线推高油价，显示出中东地区仍持续存在各种供应风险。 其他消息 【鲍威尔回应特朗普政府指责：美联储翻修始终接受严格监督】 据央视新闻报道，当地时间7月17日，针对特朗普政府高级官员指控美联储总部翻修“奢华浪费”，美联储主席鲍威尔以书面方式逐条回应，强调工程自2017年获批以来始终接受严格监督。 鲍威尔在回信中强调，美联储总部及附属建筑存在严重结构老化问题，需更换含石棉、铅的材料，并全面更新电力、供暖、消防等系统。他还指出，项目修改过设计以降低成本和避免延误，不涉及重大变更，因此未重新提交审议。 鲍威尔明确表示，美联储并不隶属于国家首都规划委员会（NCPC），而是“自愿协作”，其工程监督权归属于董事会与内部监察机构。他的声明意在捍卫美联储独立性，并回应外界对其财政管理和政策独立性的质疑。 【美国国会正式批准稳定币法案 待特朗普签字生效】 北京时间周五清晨，备受资本市场关注的《指导和建立美国稳定币国家创新法案》（简称GENIUS法案）以308票赞成、122票反对通过众议院投票，距离正式生效只差特朗普的签字。 【OpenAI发布ChatGPT智能体 能做PPT、整理EXCEL表格】 北京时间周五凌晨，美国科技公司OpenAI发布通用人工智能代理ChatGPT智能体。ChatGPT智能体能够通过互联网搜索或API获取数据，进行深入的财务研究、制作精美的幻灯片、预定活动或规划行程。 【亚马逊承认云业务裁员】 亚马逊周四（7月17日）证实，公司正在裁减其关键业务——云计算部门的一部分员工。先前，两位消息人士透露，亚马逊在AWS部门裁员至少数百人。几名员工告诉媒体，他们在周四早上收到电子邮件，告知他们已被解雇，并且他们的电脑将被停用。 【台积电Q2净利大增超60%】 台积电周四公布最新财报，2025年第二季度实现净利润3983亿元台币，同比增长61%，创下历史新高，且高于伦敦证券交易所SmartEstimates预估的3779 亿元台币，其余核心财务指标亦实现同环比双增。 在法说会上，台积电预计第三季度销售额将达到318亿美元至330亿美元，此前预估317.2亿美元，预计营业利益率45.5％至47.5％，此前预估46.9％。受财报提振，台积电美股周四收涨3.38%。 【诺和诺德基金会成立量子公司】 当地时间周四（7月17日），诺和诺德基金会在官网宣布，其与丹麦出口和投资基金（EIFO）携手成立北欧量子企业“QuNorth”。新闻稿称，EIFO和诺和诺德基金会将投资8000万欧元成立QuNorth，“该公司的主要任务是采购、建造和运营迄今为止全球最强大的商用量子计算机‘Magne’。” （财联社 史正丞） 举报/反馈"
    },
    {
      "doc_id": 38157,
      "title": "“中企压力”之下,OpenAI又陷内斗漩涡?",
      "time": "2025-07-07T00:00:00+00:00",
      "content": "图片说明： 6月2日，OpenAI首席执行官奥尔特曼在美国加州出席一场科技峰会。 本报记者 杨沙沙 ●任 重 编者的话：美国人工智能公司OpenAI近日在其官方博客中点名一家中国人工智能（AI）公司智谱，声称北京支持的初创公司智谱在人工智能竞赛中取得了“显著进展”，在多个国家收获应用案例。外媒分析称，OpenAI正在将一家鲜为人知的中国人工智能初创公司视为“威胁”，该博客的发布，正值美国和中国在快速发展的人工智能领域展开激烈竞争之际。截至记者发稿时，智谱方面没有接受《环球时报》记者的采访。有专家表示，虽然美国AI巨头们在技术方面领先，但在工程实现和市场规模方面，中企有不小的优势。在面临“中企压力”之际，OpenAI行业领头羊的优势也面临来自美国本土的激烈竞争。 “点名”中企，真实动机被质疑 据美国CNBC网站报道，中国人工智能公司DeepSeek在今年1月份发布了R1模型后，获得国际大量关注，但OpenAI表示，智谱在中国以外的扩张及其与北京的关系值得更多的审查。报道称，智谱在中东、英国、新加坡和马来西亚设有办事处，并在东南亚（包括印度尼西亚和越南）运营联合“创新中心”项目。 智谱成立于2019年，被国内媒体称为国产AI大模型“六小虎”之一。据其官网介绍，北京智谱华章科技股份有限公司（简称“智谱”）致力于打造新一代认知智能大模型，专注于做大模型的中国创新。今年4月，智谱在北京证监局办理辅导备案，成为“六小虎”中第一家正式启动IPO流程的公司。据悉，智谱最快于2026年登陆A股市场。 对于智谱被OpenAI“点名”，有业内人士对《环球时报》记者表示，国内AI圈内并没有太多关注，因为OpenAI在其官方博客发布的消息并没有太大权威性。也有国内长期关注AI领域发展的知情人士告诉《环球时报》记者，包括OpenAI在内的美国AI企业人才争夺激烈，资金缺口一直存在，“点名一家不知名的中国企业可能是想引发美国政府方面的重视”。 外媒也有质疑OpenAI动机的声音。印度媒体Analytics India Magazine (AIM)报道称，OpenAI博客文章似乎不太关心模型性能，而是对影响力的架构更加担忧。报道引述知名风险投资人比尔·古雷的分析称，OpenAI在一篇博客中公开推广中国人工智能企业的决定“非常奇怪”，并认为OpenAI这种做法只是提高了竞争对手的知名度，“有效地使其广为人知”。 中国电信集团首席科学家、美国贝尔实验室院士毕奇对《环球时报》记者分析称，从目前的报道来看，OpenAI并没有列举任何智谱在AI技术方面的优越性，而是聚焦智谱在融资方面的成功，以及在国外设置机构的多少。“从这一点来看，他们希望通过放大智谱在融资方面的成功，特别是强调从中国政府渠道融资的成功，游说美国政府进一步出台有利于OpenAI的政策，甚至直接提供资金，支持OpenAI。”毕奇表示，目前AI方面的技术发展还处于重投资阶段，美国AI企业希望通过这方面的炒作，巩固资金链方面的优势。 今年以来，美国科技巨头向AI领域的投资达到史无前例的规模。英国广播公司（BBC）7月4日报道称，微软将裁员9000人以腾出更多资金投入AI研发。在2025财年，微软计划将800亿美元投入数据中心建设，加速AI大模型训练。谷歌也在年初公布了750亿美元的AI基础设施投资计划。Meta今年则计划投入650亿美元来支持其AI目标。 然而，中国AI产业的追赶步伐仍让硅谷巨头们感受到竞争紧迫感。美国《华尔街日报》7月初一篇题为“中国正在迅速削弱美国在全球AI竞赛中的领先地位”的报道称，中国的AI大模型在全球范围内越来越受欢迎，考验着美国的优势。 美国AI巨头的深层隐忧 OpenAI表示，智谱代表了中国“希望建立一个自力更生、具有全球竞争力的人工智能生态系统，与美国竞争，减少对美国技术的依赖”。 路透社称，OpenAI在中东和亚洲建立了合作伙伴关系并吸引投资。其5月宣布的“OpenAI for Countries”计划目标是帮助感兴趣的国家与美国政府协调发展“主权人工智能能力”。据悉，OpenAI此前称，计划在美国之外投资建设运行人工智能系统所需的基础设施，作为其美国AI数据中心项目“星际之门”（Stargate）的海外延伸。另据CNBC报道，在5月访问阿联酋期间，美国总统特朗普宣布，双方达成价值总额超过2000亿美元的协议。其中包括由OpenAI、甲骨文、英伟达和思科系统公司合作建设“阿联酋星门AI校园”的项目。据悉，该项目预计将于2026年启动。 “这实际上是美国自己在筑墙。”印度媒体AIM分析称，令OpenAI不安的不仅仅是竞争，更是担心“失去叙事主导权”。尽管美国一直在通过“星际之门”项目，以及政府交易、贸易代表团和战略伙伴关系等手段，在全球范围内积极推广其人工智能技术，但中国安静的、基础设施优先的做法，可能会被证明更持久。 毕奇告诉《环球时报》记者，从目前发展来看，OpenAI、Meta等美国巨头，都相继从提倡开源起步，走向闭源发展。这反映了美国AI巨头对其技术领先及垄断地位的不自信。“众所周知，互联网行业的一个现象是赢者通吃。然而，目前在商业路线上，美国企业面临抉择。”毕奇进一步解释，“是按谷歌安卓的模式，用开源的方式占领全球市场；还是按苹果模式，通过技术领先把体验做到极致来绑住客户，成为美国巨头们左右为难的选择”。 毕奇认为，从一般规律来说，领先者会更青睐美国苹果公司简单粗暴的商业模式，而挑战者会通过开源模式奋力一搏。从目前安卓及苹果在智能终端的全球市场份额可以看出，开源模式对有技术领先优势的厂家，还是具有较强的挑战性。“这也可能是为什么中国AI企业的出海，即使还在起步阶段，就牵动了美国巨头们神经的原因之一”。 今年以来，中美两国AI发展势头迅猛。毕奇表示，从技术上来看，美国巨头们领先中国不少。“这就是为什么他们选择闭源的原因，如果他们采用闭源方式，追赶者采用开源方式，会对领先者产生较大的商业冲击”。 毕奇认为，虽然美国AI巨头们在技术方面领先，但在工程实现和市场规模方面，中企有不小的优势。因此，不排除今后即使美国巨头们能保持技术方面领先优势，国内企业通过开源方式，也会占有一定数量的全球市场份额。“这就是为什么美国巨头们还有较大担心，要消除这方面的风险，除非美国某个AI巨头加强自信心，坚持开源方式，用自己的技术优势引领全球”。 “挖墙脚”大战一触即发 《华尔街日报》分析称，美国的公司往往优先考虑在构建“人工智能超级竞赛”中寻求重大突破，而中国的企业则更专注于实际应用，这一点可以帮助其快速赢得新用户。报道援引微软总裁布拉德·史密斯近日在美国国会上的发言称，“决定美中谁能赢得这场AI竞赛的第一要素是，谁的技术在世界其他地区得到最广泛的采用。” 据新加坡《联合早报》报道，在全球数字化与智能化的浪潮中，中国AI企业凭借技术优势与创新能力，在国际舞台上开始崭露头角。一份行业报告显示，截至2024年10月，中国AI企业总数918家，其中有203家企业开启出海进程，出海率超过22%。报告分析称，中国AI出海企业中绝大多数公司产品集中在应用层面，占比高达76%。2025年，中国AI应用出海在产品类型与数量方面都实现了快速增长。不少中企将东南亚作为出海的重要目的地，该区域内容电商发展迅速，TikTok、Shopee、Lazada、Temu等平台增速可观。全球新闻网报道称，随着中国与东盟贸易往来不断深化，AI产业的快速发展已经开辟出新的应用领域，进一步促进区域经济合作并重塑区域产业格局。 与此同时，美国科技巨头间围绕AI的“内卷”也愈演愈烈，OpenAI与Meta的人才争夺战近日成为焦点。美国《财富》杂志网站5日报道称，在硅谷白热化的“AI霸权竞赛”中，令人咋舌的高薪酬一直是巨头们吸引人才的关键手段。然而，作为行业领头羊的OpenAI正面临如何吸引和留住顶尖人才的难题。《纽约邮报》本月初报道称，Meta创始人兼首席执行官扎克伯格向OpenAI的至少10名关键员工提供了利润丰厚的报价，这些员工可选择入股Meta，在4年内获得高达3亿美元的收益。有多家美媒披露，在最近几周，Meta成功聘请到了多位来自OpenAI的研究人员。OpenAI首席执行官奥尔特曼抨击了扎克伯格咄咄逼人的“挖墙脚”举动，他告诉员工，Meta的行为方式令人反感。据报道，上周末OpenAI的高级研究官向员工发送了一份备忘录，发誓将与Meta在争夺顶尖人才的竞争中“针锋相对”。 OpenAI同其长期合作伙伴及主要投资方微软的关系近来也出现恶化。《华尔街日报》报道称，OpenAI希望微软放松对其AI产品和计算资源的控制，确保OpenAI转型为营利性公司，而微软的态度决定了OpenAI能否筹集更多资金并实现上市。但知情人士称，双方在该问题上的谈判进展艰难，OpenAI的高管们开始指责微软在合作期间存在反竞争行为，可能向美国监管部门申请针对微软的反垄断审查。 《华尔街日报》报道称，此前，OpenAI同微软的关系被广泛认为是科技史上最成功的合作伙伴关系之一。微软于2019年首次向OpenAI投资10亿美元。根据目前的合同，微软拥有通过其Azure云销售OpenAI软件工具的独家权利，并优先使用后者的技术。但如今两家公司在多个AI产品和服务中展现出竞争关系。 举报/反馈"
    },
    {
      "doc_id": 38158,
      "title": "祭出罕见薪酬收购人才,大挖对手墙脚震惊硅谷!美科技巨头掀起AI...",
      "time": "2025-07-03T00:00:00+00:00",
      "content": "【环球时报特约记者 任重 环球时报记者 杨舒宇】“人工智能（AI）领域的霸主之争从未如此激烈。”多家美媒报道称，美国正掀起一场迅速升级的AI人才“军备竞赛”，其中，硅谷巨头Meta首席执行官扎克伯格对顶尖人才的追逐最为激进。据《华尔街日报》报道，他试图“洗劫”美国国内各个顶级AI研究实验室，甚至抛出1亿美金的签约奖金，意图将看中的AI天才招致麾下。这在硅谷掀起风波。 角逐AI高地 当地时间6月30日，Meta首席执行官扎克伯格宣布对公司进行重大改革，将公司的所有AI业务和项目纳入一个新成立的部门——名为“Meta超级智能实验室”（MSL），该部门致力于开发可以超越人类执行任务的先进AI系统。并向初创公司Scale AI投巨资143亿美元，聘请其前首席执行官汪滔加入Meta。此外，GitHub前首席执行官兼投资者纳特·弗里德曼也已被Meta招入麾下。 Meta首席执行官扎克伯格 图源：视觉中国 据报道，扎克伯格正在追求一种假想的、神级的技术，名为“超级智能”。他在内部备忘录中写道，MSL的首要使命是“为每个人提供个人超级智能”。据接近他的人士称，只有少数几家硅谷公司被认为拥有开发这种技术的专业知识。与此同时，Meta正寻求筹集290亿美元，用于扩建其在美国的数据中心。据《纽约时报》报道，扎克伯格已经加紧行动，以在这场激烈爆发的、更广泛的AI“军备竞赛”中保持Meta的竞争力。 这场高风险的较量是在Meta高层人员离职及其最新的开源Llama 4模型反响不佳之后展开的。路透社1日报道说，该模型在独立推理和编码基准测试中表现不佳，引发批评。这些挑战导致其在人工智能竞赛中落后于包括谷歌、OpenAI和深度求索在内的竞争对手。 OpenAI斥责“入室行窃” 由此，深感落后的扎克伯格发起了一系列震惊硅谷的行动。据路透社1日报道，在过去的一个月里，扎克伯格亲自领导了一场积极的人才争夺战，向包括OpenAI联合创始人苏茨克维的Safe Superintelligence公司在内的初创公司发出了邀请，并直接在WhatsApp上以数百万美元的薪酬待遇吸引潜在人才。 仅仅本月，扎克伯格就联系了竞争对手OpenAI的超过45名AI研究人员。两位知情人士称，一些人收到了正式录用通知，其中至少一份签约奖金高达1亿美元。至少有4名OpenAI的研究人员已接受了Meta的录用邀请。在扎克伯格6月30日发布的内部备忘录中，他列出了从OpenAI、Anthropic和谷歌加入Meta的11位顶尖研究人员。 对于OpenAI 来说，Meta这种激进的招聘行动构成了一个重大威胁。印度livemint网站1日称，短短几周内，至少有8名OpenAI高级研究人员投奔Meta，这引发了该公司内部对士气和项目连续性的担忧。OpenAI 的首席研究官马克·陈表示：“我现在有一种强烈的被入室行窃的感觉。”陈表示，公司正在“夜以继日地与那些获得录用邀请的人进行洽谈”，并想方设法让他们留在 OpenAI。为防止更多员工离职。马克·陈表示，公司正在“重新调整薪酬”。 现实情况是，从竞争对手那里挖走顶尖人工智能研究人员和工程师的激烈竞争导致薪资水平迅速上涨。英国《金融时报》1日称，根据科技行业招聘专家和近期的职位变动数据，一些顶级 AI 工程师的年薪已超过1000万美元，但典型的薪资待遇在300万至700万美元之间——较 2022年的水平上涨了约50%。 “AI投资泡沫”？ 美国金融服务平台AInvest网站称，人才留任如今已是一场零和博弈，同时，“Meta的AI战略是一项高风险、高回报的赌注”。报道评论称，Meta的超级智能实验室是对人工智能竞赛的大胆回应。通过整合顶尖人才、开源创新和强大的基础设施，Meta正在构建一个强大的技术栈。然而，执行力仍是最大的变数。后续Meta Llama 4的应用情况和同Scale AI的整合——这些关键里程碑将揭示其战略押注是否正在获得回报。 法新社6月30日称，扎克伯格和 Meta这一大规模的人才招募行动引发了关于这种激进的招聘能否在激烈的生成式AI 竞赛中取得成功的讨论。美国财务研究与分析中心分析师安吉洛·齐诺告诉法新社，收购AI人才是一项长期投资，不太可能立即提升Meta的盈利能力，“但即便如此，现在也需要这些人才加入，并进行大力投资，以便为生成式AI的发展阶段做好准备”。 《华尔街日报》称，在这场“军备竞赛”中，仅今年一年，Meta 就计划在人工智能领域投资约700亿美元，而亚马逊、微软和 Alphabet 的投入则更高。相比硬件，人力投资看起来更划算。 “如果硅谷的AI投资泡沫破裂会发生什么？”英国《计算机周刊》网站称，美国的科技巨头们正难以将他们的发明真正转化为收益。硅谷的领军人物们如今在依靠有关AI未被发掘潜力的救世主式幻想来支撑他们的技术竞赛。 专家警告称，投资者最终可能会对科技公司漫长的盈利之路感到失望。欧洲央行在2024年11月发布的全球经济风险双年度评估报告中曾警告称，如果投资者的盈利预期不能很快实现，AI股票可能会崩盘。这清楚地表明，如果投资者的短期盈利需求与科技公司的长期神话构建相脱节，那么硅谷的投资吸引力可能会迅速消失。而如此剧烈的市场调整将严重打击美国的AI产业。 举报/反馈"
    },
    {
      "doc_id": 38173,
      "title": "今年夏天,和观察者网共赴世界级AI盛会",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "2025世界人工智能大会暨人工智能全球治理高级别会议（简称“WAIC 2025”）将于7月26日至29日在上海世博中心和世博展览馆举行。 今年大会，来自全球30余个国家和地区的1200余位嘉宾已确认参会，包括图灵奖、诺贝尔奖等12位国际顶尖奖项得主，80余位中外院士等。 大会将有800余家企业参展，3000余项前沿展品集中亮相，涵盖40余款大模型、50余款AI终端产品、60余款智能机器人以及100余款“全球首发”“中国首秀”的重磅新品，规模创历届之最。 如此量级的盛会，正为不同主体铺就人工智能时代的价值通道： 对初创企业与投资机构，这里是创新成果的展示台与资金对接的桥梁； 对产业链合作方与采购团组，丰富的对接资源将加速协同合作； 对开发者，前沿技术动态与实践机会可直接赋能能力升级； 对科研学者，高水平论坛将成为思想碰撞的沃土； 消费电子爱好者则能够近距离触摸最新智能硬件的应用场景； 青少年可以在互动体验与创新实践点燃AI探索热情； 普通公众，也能经由此次大会，在日常化场景中直观感受科技如何重塑生活。 作为本次大会的特约合作媒体，观察者网将全程聚焦这场AI盛会，全面展示大会亮点。今年大会期间，观察者网将在会场举办八场直播访谈，从大模型到具身智能，从科创到影视与游戏……访谈议题将涵盖AI发展所涉及到的方方面面，与行业内外人士共享AI时代的全球洞察。 观察者网直播间 现场图片 在“中国科创‘新生代’和中国青创家‘养成记’”场次，晶泰科技、英诺天使基金、浙江大学的代表们齐聚，共同探讨科创人才培养路径与未来发展趋势。 “具身・人形・AGI：进击的中国人形机器人之梦”上下半场连播，包括智元机器人、京东、美的等在内的众多企业代表将汇聚一堂，深度解码中国人形机器人在AGI背景下的技术突破与应用前景。 智元机器人旗下产品 官网图片 在“国产大模型走进创新‘无人区’”场次中，来自商汤、科大讯飞、蚂蚁集团等企业的专家将共同剖析国产大模型的技术创新、行业应用及未来挑战。 “生产资料升级与中华文艺复兴（AI与影视、游戏）”场次，机核网、WaytoAGI社区、AI工作室的代表也将会探讨AI如何重塑影视、游戏等文艺领域的生产模式。 在“AI医疗与健康”场次中，阿里巴巴达摩院与浙江省肿瘤医院团队将联合分享AI技术在医疗影像诊断、治疗方案优化等领域的应用成果。 AI成功从平扫CT中识别早期胃癌 阿里达摩院 在“自动驾驶”场次，更有神秘的重磅嘉宾莅临直播间，与我们一同分享业界新动向。 今年世界人工智能大会，观察者网国际夏令营小分队也将加入现场探访之旅，用更多样的语言，更活泼、有趣的解读方式，向全世界讲述人工智能时代的中国关怀。 在“酷少年！酷中国！”场次中，小分队成员将亲自担当主持——这场聚焦青少年科创与Robomaster机器人格斗大赛的访谈中，上海交通大学战队代表将携手真格基金投资经理，拆解机器人竞赛里的创新密码，分享青少年科创人才的成长路径。让“酷少年”们齐聚，共同讨论和分享这一“酷中国”的赛事，碰撞出属于Z世代的科技共鸣。 RM2023冠军上海交通大学工程机器人 此外，聚焦当下火热的 AI 硬件赛道，观察者网还邀请到灵伴科技副总裁、XREAL眼镜联合创始人、讯飞耳机产品所属的未来智能CTO三位重量级嘉宾进行一对一专访，将共同解码AI智能硬件的技术突破、场景落地与最新发展动向。 夏令营小分队将以“用户体验官”身份，小米 AI 眼镜、XREAL 眼镜等市面主流产品展开横向测评，用普通用户的真实体验，对比分析不同设备的性能表现与使用场景，让技术参数真正落地为“好不好用、值不值得买”的消费参考。 国际夏令营小分队成员还将随时“闪现”在各大展商的高管采访和展台探访中，用镜头捕捉展会现场的鲜活瞬间，相关探展视频将会随之同步到目前已在小红书、抖音等平台开设的“观小柯”账号上，让无法亲临的观众也能实时感受WAIC的科技热度。 搭建中的观察者网直播间 现场图片 从专业直播的深度洞察到夏令营视角的鲜活体验，观察者网将全程捕捉这场盛会的每一个精彩瞬间。锁定观察者网直播间与“观小柯”各平台账号，感受AI浪潮的澎湃力量。 本文系观察者网独家稿件，未经授权，不得转载。 举报/反馈"
    },
    {
      "doc_id": 38175,
      "title": "张江机器人企业豪华阵容备战WAIC,浦东具身智能产业从“新赛道”跑...",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "“这一次，我们会带着青龙系列产品矩阵全新亮相，其中就包括最新推出的青龙-V3.0人形机器人”；“智元机器人总共将展示数十台不同类型的机器人”；傅利叶将带着“可触摸”的GR-3首次亮相；开普勒人形机器人将在WAIC展区发起充电1小时、连干8小时的直播挑战。2025世界人工智能大会（WAIC）进入倒计时之际，位于张江的国地中心、智元、傅利叶、开普勒公司内，工程师们一大早就忙着调试即将在WAIC展出的最新款人形机器人。 2025年可谓人形机器人“破圈”之年。今年的世界人工智能大会将吸引800多家展商，集中发布3000余项前沿展品，展览规模将创下历史之最，其中智能机器人就包括60余款。 大会前夕，记者走访了浦东具身智能产业高地——张江机器人谷、模力社区等地。对于即将参与2025世界人工智能大会（WAIC），浦东机器人代表企业异常兴奋，迫不及待想向全球展示最新技术与应用场景。 预计到今年年底，市民将无需在街头“碰运气”偶遇“酷炫”机器人，而是能在张江科学城内走入真实的咖啡馆、药房、超市等，与“浦东造”的机器人面对面交流、互动。 机器人链主企业 从“新赛道”奔向“主赛道” “世界人工智能大会是国地中心产品发布的重要窗口。”国家地方共建人形机器人创新中心研发总监邢伯阳提前剧透，在2025 WAIC上除了展示青龙系列产品矩阵（青龙-V3.0、青龙Lite、青龙Wheel等）外，还将带来高性能国产化组件与通用具身智能开发平台发布等，每一项产品都瞄准了人形机器人赛道推进过程中的难点、堵点与“卡脖子”问题。 自2023年年底国地中心落地浦东张江后，作为人形机器人领域国家首个开源共创平台，国地中心一直致力于打造集技术研发、成果孵化、人才培育、平台支撑于一体的共性服务平台，同时加快开源人形机器人原型机研发。 “在推进过程中，我们发现人形机器人在室外广域场景中的应用面临导航难、端侧算力不足、通讯链路缺失等难题，为了帮助人形机器人进行互联互通、VLA模型端侧推理、机器人时空信息准确获取，青龙-V3.0增加了通用智能背包系统，其融合5G通讯链路、北斗定位系统与昇腾算力模组，全面增强人形机器人在室外场景下时空定位感知能力、端侧模型高效部署能力、边-端互联通讯资源调度能力。”邢伯阳表示。 两年前的2023世界人工智能大会上，傅利叶发布了首款全尺寸人形机器人GR-1，并率先实现量产交付。两年后，在2025世界人工智能大会上，傅利叶的机器人不再是“钢铁直男”，而是摸上去柔软、可以陪伴人类的朋友。 “这次在WAIC首次亮相的GR-3拥有‘温暖’的外壳，我们引入了柔肤软包覆材设计，相较于前两代的铁皮外表，能让人更容易感到亲近。”傅利叶创始人兼首席执行官顾捷表示，“这款机器人主要应用场景聚焦于导览交互、医疗康养、学术科研和效率赋能。” 在张江，机器人链主企业如同一块“磁石”，既吸引上游零部件企业，也让更多下游系统集成商等向浦东靠拢，加速打造机器人产业集群。在他们的带动下，从单点突破到聚链成群，浦东机器人产业从前沿的“新赛道”快速跑入了量产的“主赛道”。 例如，2025年下半年开始，智元机器人最新款灵犀X2机器人能够实现规模化出货，预计到2026年底可实现数千台的规模；截至2025年Q1，傅利叶机器人总体交付超一万台，2025年出货交付目标整体数千台；开普勒人形机器人也即将迎来百台量产，这一重要里程碑标志着其产品正式迈入商业化进程的新阶段。 释放“链式创新”潜能 推动产业规模化进程 尽管2025年人形机器人走入逐步量产阶段，但应用落地仍面临挑战，需攻克安全、情感、交互等多项关键技术。 在办公室，高效且专业的机器人“同事”成为你有力的搭档；在街边，露天咖啡馆为你冲泡咖啡的是机器人；在园区内，机器人化身“食堂阿姨”，打饭的手非常稳……人形机器人何时能真正走入我们的日常生活和工作？在浦东，和机器人做“同事”的场景或许比想象中来得更早。 在国地中心，邢伯阳正在调试一个人形机器人缩比原型“强化小子”，虽然它只有0.5米高，但具有与全尺寸人形机器人平台一致的构型与自由度，它的功能就是通过在缩比的场景中对大小脑模型进行测试验证。邢伯阳表示，在国地中心内，这样的小型机器人处处可见，相对于体型庞大的“类人”机器人如青龙系列，缩比原型极大地降低了科研人员开发机器人的门槛，可以快速完成对人形机器人L1~L2级别具身智能算法的研发测试，“小型机器人更方便部署算法，训练起来更便捷、快速、安全，当训练策略验证符合设计预期时，就可以将同样的训练策略应用于全尺寸人形机器人，极大加快模型迭代飞轮。” “链式创新”正激发浦东人形机器人产业的规模化进程，如何进一步释放产能？产业重地张江科学城正在发力。 浦东新区的机器人产业已积累数十年，是我国机器人产业基础雄厚的产业基地。目前，浦东机器人企业超过100家，机器人核心企业产值达100多亿元。在张江，具身智能产业链相关企业已经集聚了70余家，包括10多家整机企业及50多家零部件及关键软件、功能型平台企业等。 记者了解到，张江集团正支持智元新建通用机器人示范制造工厂、测试实验室、全球展厅，支持傅利叶扩建数采和制造工厂等。“具身智能要走进各行各业，需要在不同场景下去学习，数采中心内一年可以产生数百万条的数据，支撑我们对各类场景下工作的人形机器人进行训练，拓展更多应用场景。”顾捷介绍道。 与此同时，张江机器人谷正抓紧建设应用场景体验空间，机器人将不止会在工厂拧螺丝，还能进店当服务员、导购员、咖啡师等。 “我们希望通过真实场景的设置，让机器人拥有更多展示和训练技能的空间，既让企业有地方验证机器人功能，也让普通市民不只是能在街头‘偶遇’机器人，而是能与机器人进行真实交互。”上海张江具身智能机器人有限公司总经理助理王晓刚表示。 文字：杨珍莹 编辑：施丰奕 * 转载请注明来自浦东发布官方微信 浦东发布 生活在这片开发开放的热土，与浦东共成长。我们为您提供引领区的重要动态、新鲜资讯、便民服务信息，欢迎关注支持浦东发布哦！ 1605篇原创内容 公众号 ， 举报/反馈"
    },
    {
      "doc_id": 38176,
      "title": "CIO Times:OpenAI 新模型斩获 IMO 金牌,科技界震动",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "来源：CIO时代网 1. OpenAI 神秘模型获 IMO 2025 金牌，突破传统推理局限 OpenAI 一款全新「通用推理模型」在 2025 年国际数学奥林匹克（IMO）竞赛中解出 6 道题中的 5 道，以 35 分成绩夺得金牌。此前表现最佳的 Gemini 2.5 Pro 仅得 13 分。该模型在与人类完全相同条件下比赛，能进行长达数小时深度思考，打破以往 AI 需特定领域训练才能获胜的铁律。OpenAI 表示此模型并非 GPT-5，且不会对外发布。这一成果可能预示着推理技术的颠覆性突破，引发硅谷高度关注。 2. 优必选获近亿元人形机器人采购订单，商业化进程加速 中国招标投标公共服务平台显示，优必选科技中标觅亿（上海）汽车科技有限公司 9051.15 万元机器人设备采购项目，这是全球人形机器人企业目前最大的采购订单。7 月 17 日，优必选发布全球首个会自主换电的人形机器人 Walker S2，并计划今年交付 500 台工业人形机器人用于智能制造产业，此前也官宣面向科研教育的天工行者机器人已收获百台订单，今年预计交付超 300 台，标志着人形机器人产业商业化加速。 3. 熙菱信息筹划控制权变更，助力数智化转型 7 月 20 日晚间，熙菱信息（300588）公告控股股东、实际控制人正在筹划公司控制权变更事宜，可能导致公司控股股东和实际控制人变更，股票自 7 月 21 日开市起停牌。熙菱信息主营公安与智慧城市领域大数据智能应用软件及网络安全测评服务，虽归母净利润连续五年亏损，但 2025 年一季度营业收入同比增长 50.99%。公司表示将持续推动公共安全和数字经济领域数智化转型。 4. 2025 世界人工智能大会即将启幕 7 月 26 日至 28 日，2025 世界人工智能大会将在上海浦东世博中心、世博展览馆、徐汇西岸等地同步举行。本次大会以 “智能时代 同球共济” 为主题，设有会议论坛、展览展示、赛事评奖、应用体验、创新孵化等板块，全面呈现 AI 技术前沿、产业趋势及全球治理最新实践，将吸引众多企业、专家参与，推动人工智能领域交流合作。 5. 广西大力推动 AI 产业发展，举办推介会与超级联赛 7 月 19 日，“2025 年京企入桂 链接产业 AI” 推介会在南宁举办，吸引 19 家北京人工智能企业。同时，广西 AI 赋能千行百业超级联赛正式打响，旨在打造 “赛事选拔 — 资源对接 — 产业孵化” 闭环生态。广西聚焦 “北上广研发 + 广西集成 + 东盟应用” 路径，出台多项政策，目前已吸引众多企业布局，如南南铝加工、玉柴集团等企业已在 AI 应用上取得成果。 6. Netflix 利用 AI 提升视觉特效速度 Netflix 表示在即将上映的阿根廷科幻剧集《永生者》中运用生成式 AI 创建建筑倒塌序列，完成速度比平时快约 10 倍，有助于降低成本。不过，这引发了艺术家对工作保障和版权的担忧，与 2023 年好莱坞罢工期间的担忧类似，凸显了 AI 在影视制作应用中面临的行业争议。 7. xAI 与五角大楼达成 2 亿美元协议，Grok 曾引发争议 据 BBC 报道，xAI 在其 Grok 模型生成反犹文本并道歉后不久，与美国五角大楼达成价值 2 亿美元协议。此次争议加剧了业界对 AI 发布速度与安全性的讨论，OpenAI 安全研究员称 Grok 首次发布 “完全不负责任”。与此同时，Perplexity AI 进军印度市场，参与当地 AI 竞争。 8. Meta 拒绝签署欧盟自愿性 AI 行为准则 7 月 18 日，Meta 表示不会签署欧盟委员会的自愿性人工智能行为准则，认为草案赋予布鲁塞尔的权力应在《人工智能法案》中规定。而微软称一旦措辞确定，“很可能” 签署。该行为准则草案要求参与者对 AI 生成媒体水印、遏制深度伪造，并在规则出台前与监管机构共享安全信息，Meta 的拒绝或影响其在欧盟的 AI 业务布局。 9. 马斯克宣布将推出儿童版 AI 应用 “Baby Grok” 当地时间 7 月 20 日，马斯克通过社交平台宣布 xAI 将开发儿童专属应用 “Baby Grok”，但未透露具体功能细节，仅表明会提供 “友好型内容”。这一举措旨在开拓儿童 AI 应用细分市场，不过儿童 AI 产品面临内容安全审核、数据隐私保护等挑战，后续发展备受关注。 10. 在线文章揭示人们对 AI 工具的复杂态度 《华盛顿邮报》评论文章提及文本生成器帮助作者润色措辞，展现了 AI 工具在写作辅助方面的积极作用；而 Reddit 帖子则警告未来总统可能让先进 AI 系统控制武器，以保持对中国优势，凸显人们对 AI 用于军事等关键领域的担忧。在 LessWrong 上，也有关于 ChatGPT 语言表述看似有感知但实际仅为文本预测的讨论，反映出公众对 AI 理解的加深与态度的复杂性。 趋势研判 1. AI 技术突破推动应用边界拓展： 以 OpenAI 在 IMO 竞赛中的模型突破为代表，AI 在复杂推理和创造性思维领域不断取得进展，未来将从特定领域应用向更广泛、更复杂的任务渗透，如科研辅助、高难度决策支持等，重塑各行业工作模式。 2. AI 产业商业化与监管博弈加剧： 一方面，优必选大额订单、Netflix 应用 AI 降本等体现 AI 产业商业化加速；另一方面，Meta 拒绝欧盟 AI 行为准则、xAI 的争议事件，显示出企业在追求商业利益时与监管的博弈。未来，如何平衡创新、商业发展与监管合规，将是 AI 产业面临的重要课题。 3. AI 细分市场与跨界融合成为趋势： 马斯克计划推出儿童版 AI 应用，表明 AI 企业开始聚焦细分市场；广西推动 “AI + 产业”、Netflix 将 AI 融入影视制作，体现 AI 与传统产业跨界融合趋势。未来，随着技术发展，AI 在各细分领域和跨行业融合应用将不断涌现新机遇。 话题互动： 在您看来，AI 在企业应用中，是技术突破更重要，还是平衡监管与商业利益更具挑战性？欢迎分享您在企业推动 AI 项目时，在这两方面的经验与思考 。 举报/反馈"
    },
    {
      "doc_id": 38177,
      "title": "对话希夕智能毛梁:AI柔性机器人重塑食品加工丨21新智人",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "04:44 21世纪经济报道记者 张赛男 实习生许思佳 上海报道 2025年，人形机器人赛道依旧很火。 从宇树科技被爆IPO计划，到智元机器人拟入主上市公司，人形机器人的讨论热度丝毫不减。 不过，在聚光灯外，现实已悄然分化。 宇树机器人日租金从年初的1万元以上跌至3000元水平；知名投资人朱啸虎则公开宣布“批量退出人形机器人公司”，行业陷入泡沫争议。 在资本热议通用人形机器人的浪潮中，产业资本也在表明自己的态度。比如，由农牧产品加工巨头新希望集团和通用机器人“独角兽”非夕科技共同孵化的希夕智能，选择了一头扎进食品加工领域。 该行业正面临食材非标化与人力短缺的双重夹击：肉类切割、海产处理、加工成型等工序因形状不规则难以自动化；低温/高温的恶劣工况环境加剧招工难；传统自动化产线支持品类少、修改复杂，无法满足行业高频出新品的定制需求……希夕智能尝试以\"AI+机器人\"柔性方案，让人力从这个又苦又累的行业解脱出来。 不做人形，照样破局。 近日，21世纪经济报道记者独家对话希夕智能CEO毛梁，了解这一细分机器人应用领域的发展机遇、如何在柔性智造中引入AI技术，以及如何平衡技术突破与商业化落地之间的矛盾等问题。 21世纪：希夕的解决方案主要在食品加工行业，机器人的应用场景非常多，为何选择这个细分领域？ 毛梁：这一决策源于食品加工业亟待解决的核心痛点。作为典型的劳动密集型产业，国内食品行业仅一线生产环节便需超500万左右从业人员承担肉类切割、海产处理、高温油炸、塑形包装等高强度作业，而这些劳力极难替代。更严峻的是，行业正面临结构性劳动力断层——因低温车间与高温产线的恶劣环境，工厂的平均劳动力年龄已超过50岁，年轻群体持续逃离该领域。与此同时，消费市场对加工食品的品质需求却持续攀升，生产端与消费端的压力差不断加剧。希夕希望通过技术创新，真正解决行业痛点。 更具体来说，第一，食品行业的加工比较复杂，不同于工业的来料都是标准化的，食材的每个来料形态都不一样，如果我们用一种非常粗暴的固定路线或传统自动化程序来做，就会造成非常大的食材损耗，影响出成率，也就直接影响价值和收益。当下的产线工人就要用更柔性的加工手段，这意味着需要依靠大量的劳力。 第二，食品加工行业的变化很大，出新品的频次非常高，都可能导致产品规格、加工工艺发生变化，这是很多传统自动化设备无法解决的难题。我们就是通过AI的技术，再加上机器人技术，实现像人一样的柔性加工能力，来解决这些问题。 21世纪：希夕的方案和传统的自动化方案有何区别？ 毛梁：核心差异在于我们的柔性加工能力。传统自动化设备依赖固定的机械结构与预设程序，无法适应食材的随机性差异。我们的方案通过融合AI和机器人技术，来实现人工的“眼-脑-手”并用能力，能够根据每个食材的特征实施个性化加工，从而显著提升原料利用率和产品品质。 在这其中，AI推理和控制技术是关键。首先是“眼睛”，通过通用AI视觉系统实时感知食材特性；然后是“大脑”，AI决策层基于多模态数据感知对接下来的任务进行推理，得出最优的加工处理方案；最终是“手”的控制，设备依据推理结果，驱动手臂执行复杂动态的任务。当市场变化需要切换SKU时，传统方案需花大量人力和时间切换产线，或者需要重新开发、调整设备，甚至开模新造设备等，成本高昂，而我们的设备就像人一样，使用同一套硬件设备，结合一些末端工具，靠着“眼睛”和“大脑”的配合，加上有力控触觉的“手”，可以实现对新配方新工艺的快速适配，让客户能够灵活应对消费端的快速迭代需求。同时这种每个食材都是个性化加工的工作模式，加工的质量和出成率都会优于传统设备。这种方案的精准性、柔性、快速变化性是我们的特点。 21世纪：该方案对AI算法的算力要求及训练周期如何？ 毛梁：我们花了较多的精力将算力控制在可接受范围内。过高算力需求将导致硬件成本激增与响应延迟，而工厂生产对时效性与节拍有严苛要求，同时对生产成本也非常的敏感。因此，我们将每一个模型、每一条推理和测算路径压缩至行业最小必要范围，使算力需求极致降低。 训练周期取决于场景适配度，不过整体交付不仅取决于训练，同时也要结合整体方案的底层能力优化、模型优化、业务功能适配等。目前方案已支持批量落地的场景常规仅需1-2周测试即可部署；如果是全新场景，一般需1-2个月训练和优化测试，然后再上产线实战测试，快的话3个月可以完成上线。 21世纪：当前大模型的发展，是否有效推动了希夕方案的落地？ 毛梁：对我们确实起到了很正向的帮助，大模型提供了重要的技术验证方向，但其精度与响应速度尚未达到预期。我们借鉴大模型底层逻辑，保留技术框架但大幅压缩规模，构建垂直领域的深度模型。这种\"小而精\"的路径，可针对性适配这个行业。 21世纪：目前这套方案对加工企业来说是否有量化效益的提升？ 毛梁：首先，在作业效率方面，常规场景可达到人工的1.3-1.5倍，极端复杂场景仍能维持0.8-1倍等效水平，整体效率均值始终优于纯人工操作。另外，设备单台标准占地在1平方米内，与人工工位基本持平，对工厂现有场地面积和流水线设施基本无大改造要求，可实现生产线1:1无缝升级。部署成本对于工厂而言也较为可控，单从替代人工来讲，单班生产客户ROI在2～3年，双班的客户在1～1.5年左右，个别情况可压缩至一年及以下。 不过对企业来说最关键的是质量稳定性突破——绝大部分情况下设备的出品质量已经超过了人工，加工损耗浪费也显著比人工优，且设备可24小时长时间稳定运作，也不会有人工疲劳导致的质量波动。高品质、低损耗、低异常风险对企业带来的收益远远大于人力成本节约的收益。 21世纪：在应对食品加工行业食材、环境方面的不确定性，希夕有哪些技术突破？ 毛梁：食品加工行业存在显著的场景特殊性，该领域对设备有双重刚性要求，其一，所有接触食材的部件必须符合食品安全认证标准；其二，设备需耐受高频次化学清洗及潮湿、低温、高温的极端工况。这与汽车、3C等无尘干燥车间的工业环境形成鲜明对比。 整个过程中，我们也踩过不少坑，例如早期尝试用工业自动化思路解决问题时，发现很多技术方案难以适配。直到现在，我们的框体、设备、控制板都是自主研发、设计与生产的。包括自主研发防水防腐蚀的密闭框架体，重构内部电子元件布局，实现设备在高压水枪直接冲洗下的稳定运行。场景覆盖方面，现有技术支撑称重配比、肉类切割、整形配餐及油炸工序等环节，未来会持续强化AI能力与设备性能，覆盖更多场景。 21世纪：其他机器人公司想进入这个行业的技术壁垒在哪里？ 毛梁：首先，设备需在含化学腐蚀性物质及极端温域环境中保持7*24小时连续稳定运行，这对精密电子元件构成严峻的挑战。其次，AI系统必须适应食材变动，任何环节都需融入行业认知。完成这项技术需要投入大量的时间精力，并且要深入一线，与产业方合作，即便竞争者试图复制技术路径，也必须投入同等量级的时间与资源成本。因此，我们在技术壁垒和行业积累壁垒上是很有信心的。 21世纪：在食品加工机器人这条产业链上，目前是否存在关键瓶颈环节？ 毛梁：机器人整体产业链基础已较为完善，国内在芯片、控制技术及识别执行设备领域进展显著。当前主要瓶颈在于应用于食品加工行业方向的机器人产业和人才积累还比较少，例如缺乏一些适配行业的方案、加工零部件等，很多还是我们自己研发的没有完全形成产业化。未来食品产业的进一步升级进化，仍需整体产业链的协同突破，也是我们在努力的方向。 21世纪：希夕科技由新希望集团和非夕科技联合创立，这种“产业巨头+科技新锐”的合资模式，能带来哪些1+1>2的协同效应？ 毛梁：两家股东的支持对希夕至关重要，且各有侧重。 新希望作为农牧和食品加工行业的领军企业，为我们提供了难以替代的产业纵深支持。这体现在多个层面：其一，开放其庞大的产业生态资源，包括自身覆盖屠宰、食品精加工及生产的多元业务场景，为我们提供了宝贵的真实落地验证环境；其二，凭借其在行业内的“老大哥”地位与产业资源，为我们引荐了众多早期关键客户，极大加速了商业闭环的建立；其三，尤为重要的是，在希夕创立初期、技术方案尚属新颖之时，新希望强大的品牌背书显著提升了市场对我们的初始信任度，降低了早期推广的信任成本。这种全方位的产业协同，是希夕实现从0到1快速突破的核心助力之一。 非夕科技则主要为我们提供了坚实的技术支撑。其团队汇聚了来自斯坦福大学、上海交通大学等顶尖机构的科研力量，为希夕构建柔性自动化解决方案提供了关键的技术支持，使我们能更高效地将先进技术转化为解决行业痛点的实际案例。 21世纪：作为一家初创但背靠巨头的公司，在融资方面有何规划？ 毛梁：目前股东主要是新希望和非夕科技两家，现已启动新一轮融资，未来将会有更多股东入场，我们会更加市场化，加速公司的发展。同时，老股东新希望和非夕也将持续提供产业资源和技术上的支持，包括客户、产业资源及战略投资，助力技术深化与市场拓展。 21世纪：对客户来说，接受这种柔性自动化方案最大的顾虑是什么？ 毛梁：在方案推广初期，尤其在2023至2024年间，我们面临了显著的阻力。对于客户而言，这是一项全新的技术，市场普遍存在对稳定性、可行性以及方案能否切实满足其需求的疑虑。 其中，客户尤其关注稳定性验证。作为创新方案，缺乏\"五年以上成熟案例\"的历史背书是我们面临的最大信任瓶颈。但我们通过实证回应——在工厂环境中实现了24个月连续运行，故障率极低且具备自恢复能力，对产线扰动极小。经过前两年的持续探索与验证，特别是进入2024年后，我们成功交付了多个落地项目。既有客户在应用方案并取得良好成效后，又启动了产线的复购，并计划拓展至其他产线。 21世纪：目前希夕科技的业务构成或营收状况如何？ 毛梁：我们有设备整体的销售和RaaS两种模式。公司营收以设备整体销售为主，租赁为辅。由于投资回报率（ROI）清晰可测算，并且客户大多为长期经营，大部分倾向于直接采购而非租赁。因此，采购订单构成主要营收来源。2024年是我们对外商业化首年，达成了千万级订单规模，预计今年，也就是2025年将实现约三倍增长。 21世纪：在食品加工柔性自动化这一细分赛道，主要的竞争对手有哪些？公司中短期的发展目标和市场策略是什么？ 毛梁：目前在国内市场，尚未出现与我们提供同类解决方案的直接竞争对手。我们在全球范围了解到美国有一家业务模式较为接近的企业，但整体而言，这个细分领域仍处于初创期，竞争格局还未完全形成。 希夕的中短期目标是抓住机遇，实现快速扩张。一方面，通过成功的案例推广，提升行业对我们解决方案的认知度和接受度，积极抢占优质市场资源，构建规模效应和行业壁垒；另一方面，也借助更多的资源扩大企业研发投入和生产规模，巩固技术和供应链生产的壁垒。 至于未来规划，短期内我们不会考虑拓展至其他行业，贸然跨行业拓展有很多成本和风险，且食品行业的市场非常巨大，因此短期内我们的核心资源和精力仍将集中于食品加工行业的深度发展上。 更多内容请下载21财经APP 举报/反馈"
    },
    {
      "doc_id": 38178,
      "title": "AI与机器人盘前速递丨优必选拿下人形机器人企业最大采购订单;全球...",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "【市场复盘】 上周五（7月18日），截至收盘，科创人工智能ETF华夏（589010）收涨0.39%，持仓股福昕软件领涨4.99%，合合信息上涨4.24%，优刻得、金山办公涨幅超3%；机器人ETF（562500）收平盘，盘中呈震荡走势，多空力量较为均衡。中大力德领涨5.04%，东杰智能上涨3.74%，巨轮智能、科瑞技术涨幅超2%；瀚川智能、石头科技、晶品特装下跌超2%。当日交易金额8.96亿元，换手5.75%，回切稳健风格，市场坚定持有静待后续行情。规模方面，上周机器人ETF规模迭创新高，增加7.30亿元，最新规模达155.29亿元，超过市场同类基金的规模总和，“吸金”能力出类拔萃；机器人ETF最新份额达177.15亿份，位居可比基金首位。 【热点要闻】 1、近日，优必选科技中标觅亿（上海）汽车科技有限公司价值9051.15万元的机器人设备采购项目，创下全球人形机器人企业最大中标金额纪录。 此前一天，优必选发布全球首个支持自主换电的人形机器人Walker S2，并计划年内交付500台用于智能制造。7月13日，其面向科研教育的“天工行者”机器人也已获得百台订单，预计全年交付超300台。 2、7月18日，以色列AI创企Decart推出首个直播扩散AI视频模型——MirageLSD。不同于Veo等市面上时长有限、存在延时的视频生成模型，Mirage可以实时转换无限长的视频流，响应时间小于40毫秒。有望改变游戏、直播、视频通话、影视、会议、AR/VR等多种领域。 3、上海人工智能实验室于7月19日发布DeepLink超大规模跨域混训技术方案，并已完成多个项目落地，支持千公里多智算中心跨域长稳混训千亿参数大模型，标志着超大规模智算跨省互联实现新突破。 【机构观点】 东方证券认为，国产人形机器人正加速突破，有望引领全球产业格局。人形机器人产业已升至我国国家战略，政策支持有望强化，核心部件国产化收窄研发差距，成本优势凸显。我们看好国产人形机器人主机厂及代工企业的长期投资价值：主机厂凭算法与品牌占据价值链高端，将受益场景渗透进入高增长期；代工企业依托规模化制造，深度受益产能扩张。 【热门ETF】 机器人ETF（562500）是全市场唯一规模破百亿、流动性最佳、覆盖中国机器人产业链最全的机器人主题ETF，助力投资者一键布局中国机器人产业。 科创人工智能ETF华夏（589010）是机器人的大脑，20%涨跌幅+中小盘弹性，捕捉AI产业“奇点时刻”。 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 38179,
      "title": "机器人、AI、数字孪生 先进制造“新物种”上岗",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "来源：中国证券报-中证网 当“创新”“智能”“绿色”成为定义先进制造业的高频词，机器人、AI、数字孪生这些科技创新的“新物种”已成为融入制造业的生产力。在今年链博会现场，各家参展商纷纷带来最新技术，展示应用场景，诠释先进制造的创新技术如何从概念走向实际，从展台走进工厂。 ● 本报记者 郑萃颖 杨洁 机器人多点上岗 展台上，一只巨大的机械手臂举着类似灯箱的3D偏折面阵相机，围绕汽车车身进行扫描。车身的3D数字模型、车体表面的漆面瑕疵，立刻出现在一旁的显示屏幕上。视比特机器人将这套已在多家汽车主机厂落地应用的车身漆面缺陷检测系统，拿到链博会现场演示，让观众近距离观看“机器人如何质检”。这种“AI+3D”视觉融合的技术应用到质检领域，不仅替代了传统人工质检，更将检测精度升至0.15毫米级别，成为把控汽车涂装品质的“新门神”。 机器人在制造业产线中的应用加速，推动制造业工厂自动化升级。在苹果供应链企业杰士德的生产线上，一台高精密度机械手臂可以高效、不停歇地完成点胶等工序。杰士德为此创建了自己的APE机器人公司，开发出机器人控制卡以及终端锁和IO模块。通过创新，该公司能够在系统中移除机器人控制器，从而降低APE工业机器人的成本和能耗，让机器人不仅能干，还能省钱。 从工厂车间到数据中心，机器人的上岗范围正在不断扩大。浪潮智能终端现场展示并发布全新算力中心智能运维机器人iSpect X40。该机器人深度融合跨域多层次语义建图与定位、多尺度模态特征目标感知与精准识别、集群化巡检协同调度与自主作业，以及典型运维场景长期任务执行与优化等四大核心技术，凭借高精度自主导航与三维地图动态更新能力，实现7×24小时不间断自动巡检，推动巡检模式从“人工值守”向全时段“AI智检”跨越，构建起“机器人+AI+网管”三位一体的智能运维体系，为算力中心、数据中心产业链提供高效运维支撑。 “我们在多个场景不断验证迭代机器人等前沿技术产品如何高效应用于生产一线，让包括工人、客户在内的全产业链感受到AI带来的变革。”浪潮智能终端有限公司柔性制造与服务事业部总经理梁书春在接受中国证券报记者采访时表示。 在先进制造领域，机器人的形态朝着更灵活的方向进化。优必选科技的商用版人形机器人Walker C（行者）、极具生命感的桌面级人形机器人“悟空”、商用服务机器人Cruzr（克鲁泽）等产品登场。相关负责人介绍，优必选科技目前聚焦工业制造、商用服务、家庭陪伴三大场景，实现了人形机器人落地应用，并与多家车企合作，其中Walker S系列已成为全球进入最多车厂实训的工业人形机器人。与人形机器人共事，正从科幻电影场景变成制造业流水线的日常。 AI+数字化 赋能智能制造 如果说机器人是先进制造的四肢，那么AI与数字化技术就是大脑——它们正在重新定义制造的逻辑。谈到先进制造，机械工业经济管理研究院院长徐东华在链博会上表示，推动AI加速落地，加强数字化的技术和先进生产流程的深度融合，是赋能先进制造业产业升级的关键举措。 施耐德电气高级副总裁、全球供应链中国区负责人张开鹏表示，以AI为代表的先进数字化技术，已成为推动全球制造业转型的重要力量。施耐德电气在加强数字化研发的同时，积极促进AI与应用场景的深度融合。施耐德电气上海普陀工厂通过将AI等数字化技术融入产品原型设计、生产规划、供应链管理、设备运维等各个环节，实现了人均生产效率提升82%、产品交付时间缩减67%。这样的“效率革命”正是AI技术落地应用最直观的成果。 数字孪生、三维设计等数字化技术也在先进制造领域中发挥了重要作用，它们如同为工厂打造了数字镜像，让生产从经验驱动转向数据驱动。苹果供应商欣旺达在链博会上展示了锂电池数字孪生工厂，通过数字孪生达成生产过程的实时监控、远程诊断和自适应优化。 西门子（中国）有限公司副总裁胡建钧在展会上介绍了公司最新发布的Teamcenter光线追踪功能，它能让客户更真实地感知数字世界的设计过程。胡建钧介绍，已有造船厂将该项技术应用于新一代轮船设计，帮助造船厂管理数百万个零部件，并将设计验证周期从几十天缩短至数小时。据介绍，在新能源汽车领域，Teamcenter支持主机厂与电池、电机供应商的协同仿真，可提前验证零部件的兼容性。这意味着新车从图纸到量产的时间，正在被技术大幅压缩。 同样运用数字孪生技术的还有中化鲁西工程有限公司，其将这项技术应用于工厂工程设计与交付。该公司相关负责人介绍，通过数字孪生工厂，能够实现工厂装置全生命周期的三维建模，范围涵盖设备、管线、阀门、仪表等细节，这不仅让工厂设计可视化，还为优化运维管理提供了有力支持。 传统重工业同样被数字化重塑。南京钢铁常务副总裁徐晓春介绍：“我们的26条生产线、16个业务部门，按照一切业务数字化和一切数字业务化的模式加速改造。”如今，在链博会的南钢展台上，操作员已能遥控指挥上述生产线和业务部门协同，且实时数据仅有毫秒级差别。徐晓春表示，去年公司旗下信息化公司的工业软件营收超3亿元。目前，公司正利用视觉、听觉、毫米波、激光等多维感知技术，推动钢铁制造流程数字化，为AI技术应用筑牢数据底座。 重新定义先进制造 单个技术的突破或许能带来局部优化，但先进制造的真正升级，需要全产业链协同与理念革新。在链博会参会人员的彼此交流中，“先进制造”的内涵已超越“生产效率提升”，扩展至“创新”“智能”与“绿色”。 中国贸促会副会长李兴乾介绍，在本届链博会上，共有110多家中外知名企业、链主企业展示了全球先进制造的产业体系。他提出，发展先进制造业，一是支持产业创新，二是支持科技赋能，三是支持绿色转型。这三个方向勾勒出先进制造的三维坐标。 链主企业积极响应，带动供应链企业转型升级。苹果公司副总裁及大中华区董事总经理葛越对中国证券报记者表示，在过去5年多时间里，苹果公司在中国智能制造和绿色制造领域的投资高达200亿美元。施耐德电气发布“零碳计划”，帮助了全球1000家供应商，包括中国270家核心供应商在运营层面减碳，新推出的Environmental Data Program要求披露产品全生命周期14项环境数据，以数据透明化带动生态伙伴能效提升。 中国机械工业联合会副会长叶定达表示，当前全球产业链供应链正在深刻重组，技术壁垒、资源环境约束等倒逼制造业加速变革，主要体现为三大趋势：一是制造范式的数字化重构，工业互联网平台、智能车间的发展，让数据成为比设备更关键的生产要素。二是产业链生态的协同化重塑，核心企业引领、中小企业协同、跨界主体参与的网络体系，正在构建更具韧性的产业生态。三是全球合作模式的创新和升级，跨国联合研发供应链数据平台等新形态，推动创新资源在全球范围内高效配置。 从机器人上岗到AI决策，从数字孪生镜像到全产业链协同，本届链博会上的先进制造“新物种”们正在用技术改写规则。 举报/反馈"
    },
    {
      "doc_id": 38191,
      "title": "AI与机器人双剑合璧,新的投资风暴已经出现!",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "在第三届链博会开幕式上，英伟达CEO黄仁勋表示：AI的下一波浪潮将是机器人系统，它具备推理与执行能力，并且能够理解物理世界，在未来十年中，工厂将由软件和AI驱动，协调人机协作的机器人团队，生产由AI所主导的智能产品。机器人系统 = AI大脑 + 物理本体(机器人)，这或许是科技界最为玄妙的配方。当AI为机器人实体植入“神经系统”，机器人实现认知涌现；当机器人牵引AI降落到千行百业，AI变得真实可感。未来机器人系统将不再是流水线上重复动作的机械臂，它将是一个能理解物理世界、具备推理与执行能力的智能体。加速AI与机器人的科技联姻，投资标的$机器人ETF(SH562500)$、 $科创人工智能ETF华夏(SH589010)$ 或许就是最好的催化剂！一． AI：建构机器人系统的“大脑”机器人智能化进阶的最大路障：缺乏“端到端的AI模型”。所谓“端到端大模型”，就是一个从感知(看、听)到决策(想)再到动作(做)，全部由统一大模型直接驱动的智能系统，中间没有大量“if else”、人为写动作脚本、手工标定动作等多余环节，而是通过数据学习出来的智能。就像对一个人说：“去把书拿给我”，他不需要工程师给他预设好“走几步、转多少度、弯腰几厘米”，他自己能看懂、能判断、能执行。只有拥有“端到端的AI模型”，机器人才能走出“样品展览”进入“场景服务”，摆脱“高配提线木偶”的宿命，真正成为“我命由我”的具身智能。机器人要想一键接入成熟的“端到端的AI模型”，实现脱胎换骨，还得仰仗AI在多模态场景理解、动态决策和环境适应能力等方面的攻坚克难。多模态场景理解：如果机器人的“眼睛、脑袋、手脚”不在一个神经系统里，则协调不顺畅；AI的多模态理解能力可以让“感知-认知-行为”处于同一个“神经回路”，实时反馈优化，以此增强机器人操作任务中的泛化能力、适应性与安全性。动态决策：传统AI没有明确的“决策空间”概念，不会像人一样先建模、再思考、再选择。这种“后解释而非前推理”的机制阻碍了 AI 在关键领域的真正落地。未来AI 应当注入“理性思考”能力，让推理过程“生动”起来。如DecisionFlow 将决策过程划分为信息提取、信息筛选、效用计算和结果生成四个阶段。这种模块化设计既保证每一步的可控性，也为调试与优化提供了清晰的接口。环境适应：并非像传统AI“纸上谈兵”，在已有的、非实时交互的数据集上做强化学习，而是需要置于真实或高度仿真的环境中，用实际的身体感知和行为来学习训练，实时地根据环境的反馈来调整自己的行为，从而做出更加合理的决策。二. 机器人本体：牵引AI降落千行百业的“重力”推动AI各场景落地，机器人是核心载体。机器人是智能硬件的最佳代表，不同于AI眼镜等穿戴设备侧重于某一细分领域，机器人应用场景不受限制、异常广泛，从工业生产到家庭服务，从医疗护理到太空探索，机器人都有用武之地。当前在各行各业，机器人替代人工的进程跑出“加速度”，AI若想完成对千行万业的数智化改造，首先就需要搭乘机器人的“顺风车”，才能真正渗透到电力、油气矿山、应急、公共安全、车厂、物流等实际场景的管理系统中，成为千行百业的“智慧大脑”。三、“皇冠上的明珠”：人形机器人是具身智能具象化最优解“拟人化”成就人形机器人先发优势，让其成为具身智能的终极形态。我们生活的物理世界，是为人的形态设计的，各种场景任务设备工具都是为人类量身打造的。人形机器人作为人类的“远亲”，自然而然享有独特机遇：1)如果把机器人设计成人形，可以适应人类的各种生活环境(比如门把手的位置、厨房操作台的高度等)，可以使用各种专为人类设计的工具(比如剪刀、扳手、键盘等)，达到隐形成本最小化的目的；2)人形机器人具有通用性，凡是需要人做的事情，它都有可能去替代；3)人形机器人外观和行为与人相似，更容易与人类进行自然直观的交互，得到人类接纳。聚合“中国制造”多重优势，人形机器人前路灿灿。英伟达CEO黄仁勋在接受专访时明确指出中国在人形机器人领域具备“非常独特的优势”，并从AI技术、机电一体化、制造业基础三大维度展开剖析。1)先进的AI技术。从深度学习框架的自主化突破(如百度飞桨、华为MindSpore)，到自然语言处理大模型(如文心一言、通义千问)的全球竞技，再到计算机视觉在工业质检、智慧城市等场景的规模化落地，中国AI技术已形成“基础研究-技术转化-商业应用”的完整闭环。2)出色的机电一体化技术。机电一体化水平决定机器人的运动精度、响应速度与可靠性。中国制造业的深厚积淀为此提供坚实基础，以减速器为例，国产厂商通过材料创新与工艺迭代，将谐波减速器成本降低40%，精度提升至国际一线水平；在伺服电机领域，汇川技术、埃斯顿等企业已实现高功率密度、低能耗产品的批量生产。3)庞大的制造业基础。完整的制造业体系不仅意味着规模效应带来成本优势，更构建了从研发到量产的完整生态链。 一方面，中国拥有全球最完备的工业门类，能够为人形机器人生产提供从芯片、传感器到金属加工、塑料成型的全链条配套。这种“一站式”供给能力，显著缩短产品迭代周期——优必选Walker系列从原型机到量产仅用3年，远低于国际同行平均5-7年的时间；另一方面，庞大的应用市场为技术验证提供天然试验场，形成“应用-反馈-改进”的良性循环。四、 一键布局未来：机器人ETF如何成为投资风暴中的弄潮儿？当AI技术不断迭代更新，“端到端AI大模型”将重塑机器人的灵魂；当机器人搭载着AI落地千行百业，AI不再是“镜花水月”。AI与机器人双剑合璧，掀起产业变革的狂风暴雨，在投资风暴中找到阵眼，精准捕获“行业β+产业链标的α”，全市场唯一规模超百亿的机器人主题ETF—— $机器人ETF(SH562500)$成为投资者逐浪市场的弄潮儿！1)全面覆盖细分领域，指数表达务实。机器人ETF(562500)跟踪中证机器人指数，成分股覆盖人形机器人、工业机器人、服务机器人等多个细分领域，既押注产业成长价值，又捕捉前沿热点，帮助投资者实现机器人上中下游产业链的全覆盖。2)龙头汇聚共振，提供驱动动能。龙头股经营更稳定、客户基础更好、整合产业链能力更强，有大的发展空间。中证机器人指数指数成分股共计73只，包含各机器人行业龙头。前十大成份股占比49.57%，精准锚定机器人产业核心环节，捕获细分领域的投资机会。3)规模与流动性一骑绝尘。海水不择细流，故能成其大，作为全市场唯一规模超百亿的机器人主题ETF，超百亿的规模保障了交易活跃度。截至7月17日，近10个交易日机器人ETF(SH562500)共“吸金”6.07亿元，远超可比基金3亿+。规模方面，机器人ETF最新规模155.69亿元，年内规模增长114.32亿元，实现显著增长，新增规模位居可比基金首位，规模优势有望持续放大。份额方面，机器人ETF最新份额177.61亿，年内份额增长124.38亿份，实现显著增长，新增份额位居可比基金首位。风险提示：以上基金风险等级为R4(中高风险)。以上基金属于股票基金，风险与收益高于混合基金、债券基金与货币市场基金。个股不作为推荐。投资者在投资基金之前，请仔细阅读基金的《基金合同》、《招募说明书》和《产品资料概要》等基金法律文件，充分认识基金的风险收益特征和产品特性，并根据自身的投资目的、投资期限、投资经验、资产状况等因素充分考虑自身的风险承受能力，在了解产品情况及销售适当性意见的基础上，理性判断并谨慎做出投资决策，独立承担投资风险。指数表现不代表产品业绩，二级市场价格表现不代表净值业绩。本基金为ETF基金，投资者投资于本基金面临跟踪误差控制未达约定目标、指数编制机构停止服务、成份券停牌等潜在风险、标的指数回报与股票市场平均回报偏离的风险、标的指数波动的风险、基金投资组合回报与标的指数回报偏离的风险、标的指数变更的风险、基金份额二级市场交易价格折溢价的风险、申购赎回清单差错风险、参考IOPV决策和IOPV计算错误的风险、退市风险、投资者申购赎回失败的风险、基金份额赎回对价的变现风险、衍生品投资风险等。本资料不作为任何法律文件，观点仅供参考，资料中的所有信息或所表达意见不构成投资、法律、会计或税务的最终操作建议，我公司不就资料中的内容对最终操作建议做出任何担保。在任何情况下，本公司不对任何人因使用本资料中的任何内容所引致的任何损失负任何责任。市场有风险，入市需谨慎。"
    },
    {
      "doc_id": 38194,
      "title": "AI周报|英伟达H20将恢复中国区销售;OpenAI发布ChatGPT Agent",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "英伟达H20将在中国恢复销售 7月15日，英伟达宣布AI芯片H20将恢复在中国的销售。英伟达表示，公司正在提交重新销售H20的申请，美国政府已保证将授予许可证。英伟达还表示，将推出一款全新的RTX PRO GPU。随后，AMD相关负责人向记者表示，AMD也收到美国政府的通知，向中国出口MI308的许可证申请将被推至审核流程，公司计划在许可证获批后恢复出货。 点评：此前H20和MI308出口中国受限，对两家公司的财务数据有一定影响。以AMD为例。今年4月该公司表示，出口限制将使公司损失8亿美元。这两款芯片恢复在中国的销售，则有望帮助英伟达和AMD“收复失地”。此前TrendForce集邦咨询预计，今年国内AI业界外购英伟达、AMD等芯片的比例约42%，低于去年的63%，近日该机构又更新了数据，将今年外购英伟达、AMD等芯片的预测比例提升至49%。 OpenAI发布ChatGPT Agent 北京时间7月18日凌晨，OpenAI直播发布了ChatGPT Agent，这一智能体融合了Operator智能体网页交互能力以及Deep Research功能，使ChatGPT内置计算机能帮助用户完成复杂的多步骤任务。这些任务包括“查看我的日历并根据近期新闻介绍即将举行的会议”“分析三个竞争对手并创建幻灯片”等。用户还可以执行一些重复任务，例如将屏幕截图转换为可编辑PPT、用新的财务数据更新电子表格、重新安排会议。 点评：OpenAI曾单独发布Operator和Deep Research功能，Operator可以滚动、点击网页，Deep Research主要面向信息深度分析和整合任务，此次融合Operator和Deep Research的功能推出ChatGPT Agent，能让用户使用AI时更“丝滑”。不过，智能体的能力基于背后的基础大模型，OpenAI原本准备在7月发布的GPT-5仍未面世，OpenAI还需要通过推出新模型来证明自己的领先性。 黄仁勋年内第三次访华 英伟达CEO黄仁勋年内第三次访华。7月14日，黄仁勋与小米集团创始人雷军的合影在网络上流传。黄仁勋还参加了7月16日开幕的第三届链博会，在链博会上用中文进行了演讲。据商务部网站，7月17日，商务部部长王文涛会见了黄仁勋。王文涛表示，中国吸引外资政策不会变，开放的大门只会越开越大。黄仁勋表示，英伟达愿意同中国合作伙伴在人工智能领域深化合作。 点评：黄仁勋年内三次访华，在一定程度上说明了英伟达对中国市场的重视。国内人工智能产业正在蓬勃发展，对英伟达而言，中国市场难以割舍。黄仁勋此前多次表达了对中国市场的看好，近日他还表示，希望向中国提供比H20更先进的芯片。在链博会接受媒体采访时，黄仁勋还表示，希望英伟达中国业务的增长还只是开始，而不是结束。 MiniMax 被曝完成近3亿美元新融资 7月14日消息，媒体报道称大模型独角兽MiniMax近期已基本完成近3亿美元新一轮融资。本轮融资后公司估值超40亿美元，本轮融资出资方有上市公司，也有交叉基金和大型国资平台——上海国资。据知情人士透露，此轮融资在半年前便已经开启，目前已经基本确定。 点评:目前MiniMax并未对外做出任何回应。据公开资料显示，本轮融资结束后，国内估值达到300亿元的大模型公司仅有MiniMax和智谱。MiniMax的投资方包括大厂阿里巴巴和腾讯，也有早期出资方云启资本、高瓴创投、IDG、明势资本、米哈游等，但此前并未有国资背景资方参投。 谷歌24亿美元拿下AI编程明星公司 7月12日，谷歌以24亿美元技术授权费与AI编程公司Windsurf达成合作，吸纳其CEO、联合创始人及部分核心团队，导致OpenAI原计划的30亿美元收购交易告吹。这是一次典型的反向人才收购（Reverse Acqui-hire），此交易并非传统意义上的全盘收购，其核心是人才与技术的精准剥离。就在行业正讨论管理层“背刺”员工时，7月15日，AI 编程初创公司 Cognition 宣布已与 Windsurf 签署收购协议。本次收购涵盖 Windsurf 的知识产权、产品、商标和品牌，以及其业务，也就是说Windsurf分解：一半加入谷歌，一半加入Cognition。 点评:Windsurf的收购进程颇具戏剧性。根据此前报道，OpenAI 原本计划以30亿美元收购 Windsurf，但该笔交易谈判在近期结束，具体原因则是与微软的协议要求OpenAI技术共享，但Windsurf处在中间很难办。 张朝阳对话物理学家徐一鸿：比起AI更需要人类的超级大脑 7月16日，著名物理学家徐一鸿与搜狐CEO张朝阳展开一场物理对谈。针对近期有研究预测“AI未来或能发展出类似人类的物理直觉”，徐一鸿教授指出，当前AI的能力主要体现在快速访问大量数据库上，“目前AI能做到的可能是在牛顿力学的基础上，不断地增加一些变量、参数，但这不是探索物理的方式，我们还是需要一些人类的超级大脑。”张朝阳表示认同，前沿物理研究仍依靠人类思维，AI无法产生类似人类的“直觉”。 点评：二人的对话为当下高速发展的AI注入一剂“清醒剂”。徐一鸿认为未来物理学的发展是难以预见的，需要年轻人自己去创造。但学界并非否定AI价值，AI作为强大工具，能解放人类大脑于繁琐计算，加速验证猜想。 百度萝卜快跑搭上Uber快车 7月15日晚，百度萝卜快跑宣布与移动出行服务平台Uber建立战略合作伙伴关系，将萝卜快跑无人驾驶出行服务拓展至美国和中国大陆以外的全球多个市场。按照计划，数千辆萝卜快跑无人驾驶汽车将接入Uber全球出行网络，今年年底前，双方将率先在亚洲和中东地区部署萝卜快跑第六代无人驾驶汽车，未来将逐步扩展至全球更多市场。服务上线后，乘客可通过Uber App呼叫到由萝卜快跑提供服务的无人驾驶车辆。 点评：出行服务是自动驾驶商业化落地的关键场景。萝卜快跑的竞争对手小马智行、Momenta 和文远知行等此前都与Uber达成合作布局海外市场。Uber作为全球最大出行平台，拥有成熟的运营网络与用户基础，业务涵盖出行、配送和货运，几乎是自动驾驶行业“标配”的出海伙伴。在过去几年，Uber还曾投资了中国自动驾驶出行企业文远知行，近期还有传闻称Uber拟收购小马智行美国业务。 Anthropic估值已超1000亿美元 据外媒消息，OpenAI的主要竞争对手Anthropic正成为资本追逐的焦点。部分投资者正考虑以超过1000亿美元的估值进行新一轮投资，知情人士透露，Anthropic目前并未正式启动融资，但在硅谷，对顶尖人工智能公司发出预先融资邀约的情况已成为常态。这次融资将显著提升Anthropic的估值。今年3月份，Anthropic完成了以615亿美元的估值融资35亿美元的交易。 点评:有关新一轮投资的讨论正值Anthropic收入激增之际。据报道，该公司的Claude聊天机器人业务年化营收在过去一个月内已从30亿美元攀升至40亿美元。这一增长势头表明，尽管整个行业仍在巨额投入，但头部 AI 公司已展现出强大的商业化能力。分析师表示，如果Anthropic的营收能够继续快速增长，那么1000亿美元的估值也是合理的。 谷歌豪掷30亿美元采购水电，助力数据中心扩张 7 月 15 日消息，谷歌宣布，已与布鲁克菲尔德资产管理公司旗下的布鲁克菲尔德可再生能源合作伙伴达成协议，将支付超过 30 亿美元采购无碳水电。这一举措旨在支持谷歌不断扩张的数据中心对能源的需求，同时推动其可持续发展目标。根据协议，首批合同包括为期 20 年的电力采购协议，总金额达 30 亿美元，涉及宾夕法尼亚州两座水电站共计 670 兆瓦的发电容量。 点评:谷歌及其超大规模数据中心竞争对手——Meta、亚马逊和微软，都在积极寻求为不断扩张的数据中心采购能源。谷歌已投入数百亿美元以确保其能源供应的稳定性；Meta 则几乎收购了一座核电站；微软也与一座核电站达成了为期 20 年的能源采购协议。 Meta挖走苹果两名关键AI研究人员 有消息称，Meta挖走了苹果公司的两名关键AI研究人员。两名研究人员Mark Lee和Tom Gunter将加入其超级智能实验室(Superintelligence Labs)团队。此前不久，Meta还从苹果挖走了人工智能模型负责人庞若鸣（Ruoming Pang）。 点评:硅谷的AI人才争夺战趋于白热化。Meta成立超级智能实验室后，近期从美国其他公司挖走了不少AI人才，包括OpenAI、Anthropic和谷歌的AI研究人员。Meta这种行为引起了其他公司的不满。有消息称OpenAI CEO奥尔特曼近期向OpenAI研究人员发出一份回应，称Meta的行为方式让人感觉有些厌恶，并表示OpenAI正在评估整个研究团队的薪酬。 台积电第二季度利润同比增长六成 7月17日，台积电公布2025年第二季度业绩。该季度台积电营收为新台币9337.9亿元，收入同比增长38.6%，净利润为新台币3982.7亿元，同比增长60.7%。分业务看，HPC（高性能计算）环比增长14%，收入占比提升至60%。台积电第二季度收入超过此前指引，台积电高管表示，主要是由于HPC AI需求强劲，并预计第三季度驱动力主要来自先进制程。 点评：台积电实现了连续六个季度的利润增长，美股台积电市值则已超1万亿美元。台积电的主要客户包括英伟达、苹果等。其中，英伟达作为AI芯片供应商，面向的AI芯片市场需求强劲。近日英伟达宣布H20将在中国恢复销售，对于台积电业绩也将带来促进作用。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 38195,
      "title": "OpenAI上新Manus撤退 AI智能体两面",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "OpenAI尚未按照此前计划发布GPT-5，智能体方面的更新先行面世了。北京时间7月18日凌晨，OpenAI直播发布了ChatGPT Agent智能体。它具备自主思考和行动的能力，能够主动从其技能库中选择合适的工具，来完成各种超复杂任务。但另一方面，在“用不起来”的情况下，AI智能体陷入了一个尴尬的境地。近日，曾红极一时的Manus突然清空其国内社交平台的所有内容。有媒体爆料称，Manus将会把总部迁至新加坡，伴随而来的还有中国区的一轮大裁员。 ChatGPT Agent上线 “现在ChatGPT可以思考和行动，能主动从技能工具箱中选择工具，完成一些任务。”OpenAI介绍，这些任务包括“查看我的日历并根据近期新闻介绍即将举行的会议”“分析三个竞争对手并创建幻灯片”等。此外，用户还可以执行一些重复任务，例如将屏幕截图转换为可编辑PPT、用新的财务数据更新电子表格、重新安排会议。 据介绍，ChatGPT的工作过程包括浏览网站、过滤结果、提醒用户登录相关账号、运行账号、分析、创建电子表格和幻灯片。 此前OpenAI曾单独发布Operator和Deep Research功能，其中Operator也是一个智能体，可以滚动、点击网页，帮用户完成餐厅预订等任务，Deep Research则主要面向信息深度分析和整合任务。OpenAI称，此次ChatGPT的核心更新是创建了一个统一的智能体系统，使Operator调动网站的能力、Deep Research整合信息的能力、ChatGPT对话能力融为一体。 此次发布的智能体系统可以调用可视化浏览器、文本浏览器、终端工具、API接口，分别可用于与网页交互、处理大量文本、运行代码或下载文件、访问GitHub等应用数据。 不过，对于全球股民高度关注的问题——能否让ChatGPT智能体自己拿着钱去炒股，OpenAI表示这类操作暂时受到限制，主要考量是避免AI出错导致高额损失。同时ChatGPT智能体在执行敏感或重要操作（例如发送邮件、购买商品、提交个人数据）时，会明确征求用户授权。用户在使用ChatGPT智能体访问金融网站时，将不能离开当前标签页，否则工具会停止运作。 在安全性方面，ChatGPT 智能体的设计也充分考虑了用户的安全需求。在执行涉及敏感或重要操作前，ChatGPT会明确征得用户的授权，确保用户始终掌握控制权。此外，ChatGPT 智能体还具备主动监督和风险缓解功能，能够主动拒绝高风险任务，例如，金融交易或敏感法律互动。 Manus退出中国市场 OpenAI称，此次更新是一个开始，公司将继续定期迭代改进。但现实是，在“用不起来”的情况下，用户对通用Agent热情也不复当初。这也导致以Manus为代表的C端通用Agent正在面临增长放缓、甚至倒退的困境。 作为AI智能体的“黑马”，Manus的爆火一度让外界对其充满期待。一夜爆火后，Manus的内测邀请码“一码难求”，在二手平台上甚至被爆炒至数万元。但经过数月的摸索，Manus“折戟”中国市场。 近日，Manus被爆出撤离中国市场的消息，不仅官方微博和小红书账号的内容均已清空，官网首页也显示“Manus在你所在的地区不可用”。此外，还有消息称Manus已将总部迁往新加坡，除了核心研发团队40多人迁往新加坡，其余约80名非核心员工被裁。对此，Manus对外回应表示：“基于公司自身经营效率考量，我们决定对部分业务团队进行调整。公司将继续专注核心业务发展，提升整体运营效率。” 7月19日，Manus联合创始人季逸超发布了一篇长博客，从技术层面深度复盘从创业以来在Agent（智能体）研发与训练方面的经验教训。季逸超表示，Manus团队之所以选择“套壳”而非自研大模型，正是基于前一次创业的惨痛教训，决定基于开源或商业大模型做“上下文工程”，构建智能体。然而，这个过程并不简单，团队经历了四次智能体框架调整才实现局部最优解。 值得注意的是，季逸超的长文主要是技术层面的复盘与探讨，但并未对市场关注的裁员、迁址新加坡、撤离中国市场等话题进行直接回应。 外界对于Manus撤出中国市场有诸多猜测。有分析人士指出，Manus的B轮融资由美国风投公司Benchmark领投，而美国“对外投资安全计划”禁止美国资本投资可能增强中国AI技术的项目，Manus将总部迁至新加坡或是为了规避审查风险。此外，由于Manus主要基于Claude模型，而Claude模型不向国内用户提供服务，即使与阿里通义千问合作，也面临维护两套不同产品、成本高、投入产出不成正比等问题。这些原因，或都是其做出这一战略调整的主要考量。 智能体元年？ 在Manus身后，等待“上位”的智能体还有更多。近两年，智能体开始疯狂“走量”，Grandview Research预测，2024年全球AI智能体市场规模为54亿美元。 多家券商研报表示，随着各AI巨头发力智能体产品商业化，2025年有望成为AI Agent元年。中金研报指出，基础大模型仍是决定Agent能力上限的关键，大模型的编程及智能体能力也是各家厂商竞争关注的焦点。C端Agent具有更大的市场想象空间，因此也是大厂和创业公司更为聚焦的领域，无论是海外的OpenAI、Google还是国内的字节、阿里，以及Manus、Genspark等创业公司都在这一领域积极布局，近半年来产业进展显著。 但智能体市场的狂热也催生出“泡沫”。分析机构Gartner认为，智能体市场在冷静后将会出现一波退潮，到2027年底将会有超40%的智能体项目被取消。 不过，行业的担忧依然无法忽视。从Agent演进上看，有Agent开发者告诉北京商报记者，今年Agent预计可以在数十步较复杂的工具调用中，做到90%的准确率，基本达到可商用状态。但基础模型的能力还是有所欠缺，基础模型还难以做到自主调用上万个工具并自主执行。 但Gartner高级总监兼分析师阿努什里·维尔马表示，部分Agent项目“受炒作驱动，且常常被误用”，“这可能会让组织忽视大规模部署AI Agent的真正成本和复杂性，导致项目无法推进到生产阶段”。面向用户来说，对比垂类Agent，通用Agent在企业端的应用效果不佳，从效率/成果衡量，都无法达到“数字员工”的高度。 北京商报记者 赵天舒 举报/反馈"
    },
    {
      "doc_id": 38198,
      "title": "一周科技追踪(下)· H20,回归!",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "本周动态 追踪科技前沿 定位核心动态 科技巨头 ◦ 英特尔跌出半导体前十 科技战略 ◦ Anthropic、谷歌、OpenAI、xAI获美国国家安全订单 ◦ 美国对进口无人机、多晶硅展开国家安全调查 半导体 ◦ 马来西亚控制AI芯片出口 ◦ 英伟达和AMD已获美国批准将恢复芯片在中国的销售 数字地缘 ◦ 欧盟或撤回数字税计划 ◦ 特朗普威胁俄罗斯称将征收100%关税 人工智能 ◦ Perplexity或用Kimi新模型进行后训练 科技巨头 01 英特尔跌出半导体前十 图片来源：coincentra 英特尔首席执行官陈立武近日在内部会议上首次公开承认，公司因多年战略失误已跌出全球半导体企业前十，并披露去年第三季度录得160亿美元巨额亏损。为扭转颓势，董事会批准以边缘AI与代理AI为核心的新战略，并启动全球裁员及业务重组。 陈立武将关键转折点指向当年放弃为初代iPhone供应芯片的决定，导致ARM与高通在移动时代崛起。近年来，x86混合架构表现不佳、Arrow Lake处理器反响平淡，加之GPU产品未达预期，迫使英特尔将约30%产能外包给台积电。 陈立武强调，除技术路线调整外，英特尔必须重塑企业文化，加速决策流程，以应对AI芯片竞争格局。行业数据显示，全球半导体市场2025年预计达6970亿美元（约合人民币5万亿元），其中AI相关芯片占逾1500亿美元。 科技战略 02 Anthropic、谷歌、OpenAI、xAI获美国国家安全订单 图片来源：CNBC 7月14日，美国国防部宣布，已与OpenAI、谷歌母公司Alphabet、Anthropic以及xAI公司分别签署了最高达2亿美元（约合人民币14.3亿元）的AI合同，旨在推动先进AI能力在国防体系中的大规模部署。国防部数字与AI办公室（CDAO）表示，这些资金将用于开发“智能代理式AI工作流”（agentic AI workflows），应对国家安全挑战。 此次合同是美国政府近期AI战略的一部分，深化了高风险和高敏感度的国防应用场景中领先科技企业与美国政府之间的战略合作。此前，特朗普撤销了拜登政府2023年出台的监管行政令，放宽了对AI发展的限制，并加速布局AI在联邦政府内部的使用。与此同时，xAI也推出了名为“Grok for Government”的产品线，正式将其最新旗舰模型Grok 4引入联邦、州和国安机构。· 然而，这一集中式授权也引发了外界对合同竞争公平性的担忧。今年5月，就有参议员公开呼吁国防部保障AI项目的竞标透明度，以防止“技术寡头化”在政府采购中蔓延。 03 美国对进口无人机、多晶硅展开国家安全调查 图片来源：路透社 7月14日，美国商务部发布公告，特朗普政府已开始对一种半导体材料和无人机系统（UAS）的进口进行调查，以确定它们对美国国家安全的影响。“232条款”调查于7月1日开始，但之前未公开披露。该条款可能被用作对进口无人机和多晶硅及其衍生物征收更高关税的依据。 根据该条款规定，商务部长需在270天内向总统提交调查结果。若调查认定相关商品的进口对国家安全构成威胁，特朗普有权据此对进口产品加征关税。目前美国大部分商业无人机和主要用于光伏原料的多晶硅都来自中国，此项调查很可能是特朗普试图在中美贸易战中再度“出牌”。 半导体 04 马来西亚控制AI芯片出口 图片来源：联合早报 7月14日，马来西亚贸工部宣布，即日起所有美国生产的高端AI芯片，若要从马来西亚出口、转运或过境，都必须向政府申请战略物品“贸易许可证”并提前30天通知主管机关。任何规避出口管制或进行非法贸易的个人与企业，都会受到严厉法律制裁，“马来西亚正考虑是否将美国生产高端AI芯片列入战略物品清单”。 与此同时，美国正加紧打击通过马来西亚等中介渠道向中国转运美制AI芯片的行为。美国商务部已拟定新规草案，将管控与马来西亚和泰国的高端芯片交易，要求英伟达等美国芯片制造商若要出口芯片至上述两国，必须先申请许可。其核心目的仍是阻断美国先进AI芯片流向中国市场。 总的来看，此次马来西亚的新规体现了其在科技地缘博弈中努力寻找平衡：一方面须加强出口管制以配合美国要求，另一方面也力求维持自身半导体区域中心的地位，避免因合规压力而影响本地产业链运作。 05 英伟达和AMD已获美国批准将恢复芯片在中国的销售 图片来源：HPCwire 据外媒报道，英伟达和AMD已分别获得美国政府支持，将重启面向中国的AI芯片出口。英伟达宣布恢复销售专为中国市场定制的H20芯片，并推出全新合规产品RTXPRO GPU。首席执行官黄仁勋在北京表示，中国市场对公司“至关重要”，H20已准备就绪，“非常高兴能够尽快发货”。 几乎同步，AMD也表示其MI308芯片出口申请已进入美国商务部审查流程，并将在获批后迅速恢复发货。MI308同样是专为中国客户打造的AI加速器。今年4月，AMD曾警告若出口受阻，或将损失8亿美元收入。此次两家芯片巨头相继获批，被视为美国对华高性能AI芯片出口限制政策的重大转向。 自2022年以来，美方持续收紧AI芯片对华出口，至今年4月达到最严阶段，将中国市场几乎排除在外。此次英伟达与AMD双双恢复出口，凸显中美科技博弈在一定程度上的缓和，也表明美企在全球AI竞赛中离不开中国市场。在中美贸易技术互动复杂演变背景下，两国芯片产业链关系正经历微妙重构。 数字地缘 06 欧盟或撤回数字税计划 图片来源：9to5Mac 7月15日，据外媒报道，欧盟委员会在最新一轮预算谈判中正式撤回针对大型科技公司的数字税征收计划。这一决定被视为欧美贸易谈判的关键妥协，苹果、Meta等美国科技巨头因此暂避重税压力，而欧盟则通过调整财政策略为更广泛的贸易协议铺路。 消息公布后，苹果股价在盘前交易中上涨1.2%，Meta涨幅达1.8%。投资机构Wedbush分析师丹·艾夫斯指出：“欧盟的让步消除了科技行业最大的监管风险之一，预计头部企业将加速在欧洲的AI和云计算投资。” 据悉，此后欧盟将通过对在欧盟区运营，且年营业额超5000万欧元的大企业征收分级税、电子垃圾处理费等新税种，每年筹集250-300亿欧元用于偿还疫情债务。 07 特朗普威胁俄罗斯称将征收100%关税 图片来源：路透社 特朗普在当地时间7月14日公开表态，他对普京“非常不满”，称普京虽然在电话中让他“很愉快”但其行为“毫无意义”，因而决定如果50天内俄罗斯没有停火，将对俄征收100%的高额关税，并对购买俄罗斯石油的国家施加惩罚的次级关税。 特朗普随后对媒体表示“我对他很失望，但我和他还没结束。不过，我对他很失望。”并随后高调宣布愿意继续对乌提供武器，由欧洲国家出资。然而，这一表态恐与特朗普一贯以来的发言一样仅仅是个噱头。美俄2024年的双边贸易额早已降至历史最低，仅30亿美元（约合人民币215亿元），同比下降34.2%。但特朗普威胁的次级制裁很可能会促使相关企业转而购买海湾国家或者美国石油产品，利好美国石油企业的同时进一步加剧俄财政危机。 人工智能 08 Perplexity或用Kimi新模型进行后训练 图片来源：novita 7月12日，北京月之暗面科技有限公司发布万亿参数开源新模型Kimi K2。该模型采用MoE架构，总参数达1T，激活参数为32B，着重提升代码能力与通用Agent任务能力。在SWE Bench Verified、Tau2、AceBench等基准测试中，Kimi K2均取得开源模型中的最优成绩，展现出强大的代码生成能力，能支持3D场景模拟等前端开发任务，同时其Agent工具调用能力也得到显著提升，可将复杂指令解析并自动拆解为可执行结构。 翌日，美国AI搜索初创公司Perplexity的CEO阿拉温德・斯里尼瓦斯（Aravind Srinivas）在社交媒体发文，鉴于Kimi K2模型展现出的良好性能，公司后续可能会利用K2开展后训练工作。业内人士认为，Kimi K2的发布展现了月之暗面的技术实力，Perplexity若基于此模型进行后训练，有望进一步提升自身产品的性能与竞争力。 ·END· 作者：赵佳文、邵正棋、石淳瑜、刘成昊、黄晶 编辑：赵佳文 编撰：同济大学国家创新发展研究院 监制：同济大学政治与国际关系学院、同济大学外国语学院 监审：同济大学网络空间国际治理研究基地 举报/反馈"
    },
    {
      "doc_id": 38199,
      "title": "「产业互联网周报」OpenAI开始提供ChatGPT企业版折扣;国家互联网...",
      "time": "2025-06-23T00:00:00+00:00",
      "content": "【产业互联网周报是由钛媒体TMTpost发布的特色产品，将整合本周最重要的企业级服务、云计算、大数据领域的前沿趋势、重磅政策及行研报告。】 国内资讯 华为自研仓颉编程语言将于7月30日开源 在华为开发者大会HDC2025期间，华为宣布仓颉编程语言将于7月30日开源。仓颉编程语言是华为研发的一款面向全场景应用开发的编程语言，支持欧拉、鸿蒙等操作系统。其于2024年6月下旬首次公开发布。 宇树科技IPO在即？投资人：首选在A股上市 宇树科技于近期完成了C轮融资，由移动旗下基金、腾讯、锦秋、阿里、蚂蚁、吉利资本共同投资。知情人士透露，此轮融资募资规模约7亿元人民币，融后宇树科技估值达到约120亿元人民币。此次融资或将是宇树IPO前最后一轮融资，上市前再融资的可能性较小。据悉，目前宇树科技公司和投资人都在积极推进IPO事宜，首选在A股上市，其次是香港。今年以来，宇树科技借着AI浪潮红遍全国，已经是四足机器人和人形机器人头部企业。 华为云基于CloudMatrix384的昇腾AI云服务全面上线 在6月20日举行的华为开发者大会2025（HDC 2025）上，华为常务董事、华为云计算 CEO张平安宣布基于CloudMatrix384超节点的新一代昇腾AI云服务全面上线，CloudMatrix384超节点首创将384颗昇腾NPU和192颗鲲鹏CPU通过全新高速网络MatrixLink全对等互联，形成一台超级“AI服务器”，单卡推理吞吐量跃升到2300 Tokens/s。新浪、面壁智能、中科院、360等企业和机构已采用CloudMatrix384超节点，昇腾AI云服务客户超过1300家。 鼎捷数智《2025生成式AI企业应用实务报告》发布 6月19日，在由鼎捷数智主办的2025（第四届）数智未来峰会上，鼎捷与浙江大学联合撰写的《2025生成式AI企业应用实务报告》正式发布。《报告》深入剖析了生成式AI在企业应用的10 大面向，涵盖从数据生成、流程辅助、知识撷取到决策支持等场景。此外，鼎捷发布了智能数据与企业智能体套件、四款工业软件AI套件、AIOT指挥中心与工业机理AI套件等一系列AI产品，旨在将AI技术融入企业数据、工业生产与物联网等运营场景。 蚂蚁数科在杭州成立科技新公司，注册资本3000万 天眼查App显示，近日，蚂蚁鑫能（杭州）科技有限公司成立，法定代表人为边卓群，注册资本3000万人民币，经营范围包括软件开发、软件销售、计算机系统服务、数据处理服务等。股东信息显示，该公司由蚂蚁数科旗下上海云镌企业管理咨询有限公司全资持股。 华为云发布CloudRobo具身智能平台 在6月20日的华为开发者大会2025（HDC 2025）上，华为常务董事、华为云计算CEO张平安发布了CloudRobo具身智能平台。该平台基于盘古大模型的多模态能力及思维能力，整合了数据合成、数据标注、模型开发、仿真验证、云边协同部署以及安全监管等端到端能力，能提供具身多模态生成大模型、具身规划大模型、具身执行大模型三大核心模型，加速具身智能创新。 宇信科技向港交所提交上市申请书 利弗莫尔证券显示，北京宇信科技集团股份有限公司向港交所提交上市申请书，联席保荐人为华泰国际、法国巴黎银行。 中科星图：恢复参加军队物资工程服务采购活动 中科星图公告称，公司于2025年5月30日披露了暂停参加军队物资工程服务采购活动的公告。经申诉等程序，2025年6月18日，军队采购网已解除公司的暂停事项，恢复公司参加军队物资工程服务采购活动的资格。暂停期间未对公司经营业绩产生重大不利影响，资格恢复后将为公司正常经营和发展带来积极影响。 日科化学：拟合资成立克拉玛依融和智算科技公司 日科化学公告称，公司全资子公司哈金贝斯之控股子公司碳和科技拟与融汇公司合资成立克拉玛依融和智算科技有限公司，注册资本4000万元，其中碳和科技出资1960万元，占比49%；融汇公司出资2040万元，占比51%。合资公司将充分利用绿色金融低成本融资优势募集资金，全部用于采购国产算力设备，并托管至碳和科技数据中心，由碳和科技收取IDC服务费。 炬芯科技：端侧AI新品推广取得阶段性成果 炬芯科技公告称，公司发布的基于存内计算技术的端侧AI音频芯片新品（简称“端侧AI新品”）已推出了ATS323X、ATS286X、ATS362X产品系列，其中ATS323X系列芯片在客户首款终端产品量产后短时间内快速起量，端侧AI新品推广取得阶段性成果。此外，面向AI音频领域的ATS286X、端侧AI处理器领域的ATS362X在多家头部品牌客户中已导入立项，未来可期。 全国首批2只数据中心REITs注册获批 从证监会网站获悉，南方基金担任基金管理人的南方万国数据中心REIT、南方润泽科技REIT两只REITs已经获批，2只REITs分别于3月24日、3月10日上报。这2只REITs获批，标志着公募REITs底层资产成功扩容，填补了国内REITs市场相关领域的空白。就在今天上午，证监会主席吴清在2025陆家嘴论坛上透露，今日批复全国首批2只数据中心REITs注册，下一步将继续支持科技企业利用知识产权、数据资产等新型资产开展资产证券化、REITs等融资，进一步盘活科技创新领域存量资产。 MiniMax发布视频生成工具Hailuo 02 MiniMax（稀宇科技）发布新视频生成模型Hailuo 02，新增1080p原生视频创作场景，在海螺视频的Web、APP以及开放平台API中推出上述的模型更新，目前提供三个版本，768p-6s、768p-10s和1080p-6s。 中科院上海光机所在超高并行光计算集成芯片方面取得突破性进展 近日，中国科学院上海光学精密机械研究所空天激光技术与系统部谢鹏研究员团队在解决“光芯片上高密度信息并行处理”难题上取得突破，研制出超高并行光计算集成芯片-“流星一号”，实现了并行度>100的光子计算原型验证系统。光计算以光子作为载体，实现信息传递、交互与计算，具有低功耗、低时延、高并行的天然优势，是后摩尔时代建设新质算力基础设施的有效途径，为人工智能、科学计算、多模态融合感知、超大规模数据交换等“算力密集+能耗敏感”场景提供硬件加速。此研究进展为突破光计算的计算密度瓶颈，提升光计算性能开辟了新途径，为发展低功耗、低时延、大算力、高速率的超级光子计算机带来了可能性。 多地无人物流车批量“上岗”，助力快递物流降本增效 近日，在广东省深圳市坪山大工业区格兰达物流产业园内，美团自动配送车、顺丰无人物流配送车、京东第六代无人配送车等共计40余台自动配送车集中进行了“联调联试”，以保证“618”期间使用。据悉，深圳市功能型无人车目前上路车辆近300台，预计到2025年底将突破1000台，增长势头强劲。智慧物流正“驶”入生活。盘古智库（北京）信息咨询有限公司高级研究员江瀚表示：“目前无人物流车主要承担着货物‘最后一公里’的配送任务，能够自动完成从仓储中心到客户手中的运输，可以实现24小时不间断工作，大大提高了物流配送效率和覆盖范围。尤其对于夜间配送服务而言，无人物流车能够填补人力不足带来的空缺，推动快递末端配送降本。” 中哥签署关于加强人工智能及量子科技能力建设合作的谅解备忘录 中国驻哥伦比亚大使朱京阳18日会见哥科技创新部长奥拉亚，并见证《中国科学技术部与哥伦比亚科技创新部关于加强人工智能及量子科技能力建设合作的谅解备忘录》签署仪式。朱大使表示，科技创新是中哥合作的重要组成部分，该备忘录是佩特罗总统访华成果之一。中方愿与哥方携手努力，落实好备忘录内容，以中哥双边合作带动中拉合作，推动人工智能技术更好造福于人类，建设更加开放的科技创新环境。奥拉亚部长指出，近年来哥中在科技政策对接、技术转让、科学家交流等领域密切合作。该备忘录彰显双方在“一带一路”倡议下推动科技创新合作的坚定决心，将有力带动两国战略伙伴关系的发展。 全球首款低空无人机感知基站亮相，5G-A助力通信巨头竞逐低空经济赛道 在2025上海世界移动通信大会上，移动通信作为低空经济的重要保障和支撑技术，成为不少通信运营商和企业的重点展示方向。大会上，以5G-A为代表的低空通信设施成为各大运营商的关注对象。无人机管控系统研发制造商上海特金推出了全球首款基于TDOA（到达时间差定位技术）的基站式低空感知设备，并联合运营商，探索以5G-A +TDOA为基础的多模态融合低空安全监管体系。上海特金董事长姜化京介绍，该设备是一款低空无人机感知基站，适用于城市级低空安全管理网建设，可满足低空航道飞行秩序守护、重要设施保护等需求。 Midjourney正式推出V1视频模型 Midjourney推出视频生成模型V1，主打高性价比、易于上手的视频生成功能，作为其实现“实时模拟世界”愿景的第一步。用户现在可以通过动画化Midjourney图片或自己的图片来创作短视频，定位为有趣、易用、美观且价格亲民。入门价格：每月10美元即可使用。 MiniMax推出AI Agent产品MiniMax Agent MiniMax发布其通用智能体产品——MiniMax Agent。MiniMax Agent内置了稀宇科技自研MCP，同时也集成了Google Maps、Github/Gitlab、Slack、Figma等业界常用的工具。MiniMax Agent能“阅读”长文本和文件，还能“观看”视频、“聆听”音频、“欣赏”图片。在此基础上，它内置了图像、音频、视频的生成能力。MiniMax方面透露，MiniMax Agent不仅能编写包含复杂组件和跳转逻辑的网页、网页游戏，更与众不同的是，还能通过模拟用户操作进行全面的自动化测试，确保交付的成果稳定、无bug。 华为发布盘古大模型5.5 华为常务董事、华为云计算CEO张平安6月20日下午发布盘古大模型5.5，在自然语言处理，多模态等5大基础模型全面升级。 可孚医疗与智慧眼达成战略合作 6月19日，可孚医疗科技股份有限公司、智慧眼科技股份有限公司与老来健康科技集团有限公司正式签署战略合作协议。三方将充分发挥各自在人工智能AI 技术、智能硬件研发及互联网平台运营领域的核心优势，携手打造 “AI + 硬件 + 平台”创新医疗健康服务闭环。 可孚医疗将开放便携式智能医疗设备（如智能血压计、血糖仪、心电监测仪等）数据接口，确保设备数据与 AI 模型的实时、无缝交互，构建起从硬件感知到智能分析的高效数据链路。 海外消息 消息称微软计划裁员数千人，主要集中在销售部门 据报道，微软计划裁员数千人，主要集中在销售部门。次轮裁员预计将于下月初微软财年结束后宣布。微软4月告知员工，计划使用第三方公司来处理更多针对中小客户的软件销售工作。公司表示会定期重新评估组织架构，以确保其投资用于增长。微软曾于5月进行一轮6000人裁员，受影响的主要是产品与工程职位，销售和营销等面向客户的岗位基本没有受影响。截至6月底，微软拥有22.8万名员工，其中4.5万名从事销售和营销工作。 OpenAI开始提供ChatGPT企业版折扣 据报道，OpenAI为其捆绑额外产品的客户提供ChatGPT企业版折扣，折扣力度从10%到20%不等。OpenAI预计到2030年，来自ChatGPT企业客户的年收入将接近150亿美元。 英特尔任命销售和工程主管 英特尔宣布任命Greg Ernst为首席收入官（CRO），此外，Srinivasan Iyengar、Jean-Didier Allegrucci和Shailendra Desai也将加入英特尔，担任重要的工程领导职位。 中国信通院与联合国开发计划署签订谅解备忘录 6月16日，中国信息通信研究院与联合国开发计划署（UNDP）在北京签署谅解备忘录，并举行交流会。未来，双方将共同设计“非洲数字赋能与创新中心”，利用开源技术、数字公共产品，促进非洲和中国企业在数字技术、卫生、农业、教育和绿色能源等关键领域的跨境合作。 OpenAI CEO奥特曼：Meta开出1亿美元奖金吸引员工跳槽 据报道，OpenAI首席执行官奥特曼(Sam Altman)周二在一档播客节目中表示，Meta提出以1亿美元的奖金吸引其员工跳槽，但公司暂时未有员工接受提议。1亿美元仅为签约奖金，而每年的薪酬远不止这些。奥特曼称，他听闻Meta视OpenAI为最大竞争对手，但其在AI上的努力并没有达到预期效果，“我尊重他们积极进取、不断尝试新事物的精神”。早前有消息指，由于担心其性能，Meta推迟发布AI模型Behemoth。Meta CEO扎克伯格对公司在AI领域的地位感到非常失望，愿意投资巨额来吸引顶尖人才。 韩国计划未来5年在人工智能领域投入16万亿韩元 韩联社援引韩国科技部向总统国政规划委员会报告的计划称，韩国政府将在未来5年内在人工智能领域投入16.1万亿韩元。保障5万颗GPU安全供应，打造AI数据中心。支持人工智能模型的开发，使其对所有公民开放。 马斯克xAI收购X交易遭欧盟调查，或在8月开出首张罚单 据报道，埃隆·马斯克(Elon Musk)旗下AI公司xAI以330亿美元(约合2372亿元人民币)收购X的交易，引发了欧盟的新一轮审查。目前，欧盟监管机构正根据《数字服务法》评估是否对X处以罚款。欧盟委员会可能会在8月夏季休会前，宣布根据《数字服务法》对X涉嫌违规行为作出首笔罚款。不过，他们补充说，罚款金额尚未确定，相关决定也可能会推迟。同时，X也可以承诺解决欧盟方面的关切，从而避免被处罚。 医疗科技公司Semler Scientific任命比特币战略总监，计划2027年底持有10.5万枚比特币 据报道，医疗科技公司Semler Scientific宣布任命Joe Burnett为比特币战略总监，并计划在2025年底前持有1万枚比特币，2026年底持有4.2万枚，2027年底增至10.5万枚，资金来源包括股权与债务融资及经营现金流。 融资并购 比尔·盖茨创立的核能公司TerraPower完成6.5亿美元融资，英伟达风投部门入局 当地时间6月18日，核能公司TerraPower宣布完成6.5亿美元融资。TerraPower创始人比尔·盖茨和现代重工等现有投资者参投，英伟达旗下风险投资部门NVentures则作为新投资者入局。 宇树完成C轮融资交割 据多方信源确认，宇树科技已经完成了始于去年底C轮融资的交割，由移动旗下基金、腾讯、锦秋、阿里、蚂蚁、吉利资本共同领投，绝大部分老股东参与了跟投。 美团在天津成立闪豹科技公司，含智能机器人销售业务 天眼查App显示，近日，天津闪豹科技有限公司成立，法定代表人为王超，注册资本100万人民币，经营范围含日用品销售、服务消费机器人销售、电子产品销售、智能机器人销售、五金产品零售、网络设备销售、软件销售、汽车零配件零售等，由美团旗下北京三快在线科技有限公司全资持股。 二维半导体企业原集微完成数千万元种子轮及Pre-天使轮融资 二维半导体企业原集微科技（上海）有限公司（以下简称“原集微”）连续完成数千万元种子及Pre-天使轮融资，由中科创星、复容投资孵化并连续投资，司南园科等机构共同出资。融资资金将用于原集微科技快速推进产业化。 黑芝麻智能：拟收购AI系统芯片公司股权并注资 黑芝麻智能在港交所公告，公司与一家专注于高性价比、低功耗人工智能（AI）系统芯片（SoC）及解决方案开发及销售的目标公司及其管理层股东订立不具法律约束力的意向书，拟通过收购目标公司股权及向目标公司注资方式进行收购。目标公司主要于汽车智能化、端侧AI应用等领域提供全栈式解决方案，其芯片产品使用的绝大部分知识产权（IP）已实现自研。董事认为，可能收购事项将有助于本集团提供高中低全系覆盖的车规级计算芯片，并为智能汽车提供全场景解决方案，同时促进产品拓展至更广泛机器人应用。 帕西尼感知科技完成新一轮A系列融资，累计融资金额高达数亿元 近日，触觉感知与具身智能企业帕西尼感知科技完成新一轮A系列融资。本轮投资方包括TCL创投、毅达资本、尚颀资本、基石资本、商汤国香、中信里昂、湖南财信产业基金、钧犀资本在内的多家知名机构联合投资，累计融资金额高达数亿元人民币。此次募集资金将重点用于触觉感知核心技术迭代、具身智能多模态数据规模化采集、具身智能大模型的研发以及产线扩张，全力支持帕西尼下一阶段的发展战略。 北京机器人基金和北京首大兴业基金投资墨现科技 首程控股在港交所公告，近日，集团所属首程资本旗下公司（公司之全资附属公司）所管理的北京机器人产业发展投资基金（有限合伙）(简称“北京机器人基金”)和北京首大兴业股权投资中心（有限合伙）(简称“北京首大兴业基金”)投资墨现科技（东莞）有限公司(简称“墨现科技”)。墨现科技是一家专注于触觉感测器，提供高适应性柔性压力感测器方案的公司。此次投资将有助于墨现科技进一步促进机器人柔性触觉感测器领域的生态构建，助力北京市在智能制造、人工智能及机器人产业中形成技术引领优势，加速具身智能技术的商业化进程。 政策&趋势 目前中国已有300多个城市实现5G-A覆盖 从2025上海世界移动通信大会获悉，作为全球5G-A发展的先锋，截至目前，中国已有300多个城市实现5G-A覆盖，30多个省份已发布5G-A主套餐，5G-A用户数已超过1000万，中国、中东等区域多个运营商已推出高端品牌焕新计划，积极探索5G-A体验经营新价值体系。 教育部：顺应新一轮科技革命和产业变革趋势，助力提升西部地区人口素质 教育部17日在重庆召开落实纲要和三年行动计划、深化教育综合改革西南片区调研座谈会。会议强调，要顺应新一轮科技革命和产业变革趋势，助力提升西部地区人口素质，助推产业升级，培育更多带动区域经济发展增长带，在打造高质量发展增长极和新的动力源方面发挥更加重要的作用。要昂起高等教育龙头，优化高等教育布局，分类推进高校改革，增强学科专业、人才培养和经济社会匹配度，加快推进现代职业教育体系建设，有力支撑区域特色产业发展。要聚焦构建周边命运共同体，深化教育对外交流合作，加快构建开放自主灵活有效的国际合作和人才培养体系。 国家互联网信息办公室：中国已有433款大模型完成备案 在2025上海世界移动通信大会（MWC上海2025）开幕式上，国家互联网信息办公室副主任王京涛致辞时表示，截至目前，中国已经有433款大模型完成备案，上线提供服务。面向未来，中国要坚持发展与安全并重研究，加强发展战略、治理规则和技术标准的对接协调，推动人工智能朝着有益、安全、公平的方向健康、有序发展。要尊重各国网络主权，尊重各国的互联网发展道路和治理模式，共同构筑和平、开放、安全、合作、有序的网络空间。 中国移动董事长杨杰：未来硅基生命的数量将超过人类，形成新的“人口红利” “未来，硅基生命的数量将超过人类，成为社会劳动力与智力资源的重要组成，形成新的‘人口红利’、‘人才红利’和新的‘360行’。”今日在2025上海世界移动通信大会（MWC上海2025）开幕式上，中国移动董事长杨杰说。什么是硅基生命？杨杰在演讲中表示，随着AI技术能力、经济效益“两个规模效应”持续释放，AI在语言理解、图像识别、高效学习等方面已经达到甚至超过人类水平，并初步显现出思维、角色等类人属性。在可预见的未来，以传感器、处理器、存储器、控制器等物理硬件为“躯体”，以计算智能、感知智能、认知智能、运动智能为“神经中枢”的硅基生命，即将迎来群体性涌现。这些硅基生命与碳基生命深度融合、各展所长，将孕育出新的发展动能，开创碳硅融合的文明新形态。 华为徐直军：电信市场步入成熟阶段，进入需求裂变与技术迭代交织期 在2025MWC上海大会上，华为副董事长、轮值董事长徐直军指出，当前电信市场已步入成熟阶段，但“成熟”并不意味着停滞，而是需求裂变与技术迭代的交织期。产业链需从“成长性”这一原点出发，精准捕捉新兴群体的差异化需求、终端形态的多元化演进以及用户行为的动态迁移，将“成长性需求”转化为行业增长的核心引擎。如Z世代追求“沉浸式体验”，银发族需要“适老化智能服务”，新农人依赖“5G+AI农业工具”，从消费级到行业级，需求从“泛在连接”转向“精准赋能”。 证监会：支持人工智能、商业航天、低空经济等更多前沿科技领域企业适用科创板第五套上市标准，加大对新兴产业和未来产业的支持力度 证监会发布《关于在科创板设置科创成长层 增强制度包容性适应性的意见》。其中提出，扩大第五套标准适用范围。根据产业发展和市场需求，支持人工智能、商业航天、低空经济等更多前沿科技领域企业适用科创板第五套上市标准，加大对新兴产业和未来产业的支持力度。 武汉人工智能人才激励政策出炉 武汉印发《武汉市大力支持人工智能领域人才发展若干措施》。《措施》提出，大力支持各类人才在汉创办人工智能企业，每年遴选不超过50家初创企业，根据经营发展和技术创新情况，给予相应企业10万—100万元创业资助。武汉释放出强烈信号：即便初创AI企业尚处于萌芽阶段，只要人才团队具备创新潜力，便能获得真金白银的支持。此外，《措施》特别提出，每年组织1000名左右高校院所人工智能相关专业科研人员、在校研究生等深入在汉企业开展项目合作、解决技术难题，在实践实战中培养锻炼人才，对表现突出的人才给予最高10万元奖励。 中央网信办深入开展“清朗·整治AI技术滥用”专项行动第一阶段工作 “清朗·整治AI技术滥用”专项行动自2025年4月启动以来，中央网信办聚焦AI换脸拟声侵犯公众权益、AI内容标识缺失误导公众等AI技术滥用乱象，深入推进第一阶段重点整治任务，部署各地网信部门加大违规AI产品处置力度，切断违规产品营销引流渠道，督促重点网站平台健全技术安全保障措施，推动生成合成内容标识加速落地。第一阶段累计处置违规小程序、应用程序、智能体等AI产品3500余款，清理违法违规信息96万余条，处置账号3700余个，各项工作取得积极进展。下一步，中央网信办将聚焦AI造谣、低俗内容等7类突出问题，开展“清朗·整治AI技术滥用”专项行动第二阶段工作，构建技术监测体系，形成处置处罚规范，推动内容标识如期落地，形成长效工作机制，着力维护清朗网络生态，推动人工智能向善向好。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 38203,
      "title": "斩获美国防部2亿美元订单!OpenAI要做“AI军火商”?",
      "time": "2025-06-18T00:00:00+00:00",
      "content": "在商业化上狂飙突进的OpenAI，将生意做到了战场上。 一则重磅消息，在科技与军事领域激起千层浪。日前，美国国防部披露了一份为期一年的合同。OpenAI获得价值2亿美元的一份合同，将开发前沿的人工智能模型及能力，以应对作战和机构管理领域的关键国家安全挑战。美国国防部还表示，相关工作将主要在华盛顿及其周边地区开展，预计于2026年7月完成。 OpenAI为美国国防部提供前沿AI能力 值得注意的是，在美国国防部披露这则合同的同一日，OpenAI在其官网上发布了“Introducing OpenAI for Government”（OpenAI与政府事项）的文章，宣布将正式启动“OpenAI for Government”项目。 据介绍，这是一项旨在将其最先进的人工智能工具带给全美公务员的全新计划，致力于支持美国政府采用一流技术，目标是提升政府工作人员的能力，帮助他们减少繁琐的手续和文书工作。OpenAI表示，此前与美国国家实验室、空军研究实验室、美国国家航空航天局（NASA）、美国国立卫生研究院（NIH）和财政部的既有合作关系都将纳入“OpenAI for Government”项目。 OpenAI还特别提到，在“OpenAI for Government”计划下，公司与美国国防部的首个合作项目将通过其首席数字和人工智能办公室开展试点。这份合同的上限为2亿美元，将利用OpenAI业界领先的专业知识，帮助国防部利用前沿人工智能改变其行政运作，具体内容涵盖改善军人及其家属的医疗保健服务、简化他们查看项目和采购数据的方式、支持主动网络防御等各个方面。 在业界人士看来，OpenAI的模型算法已悄然伸向五角大楼，这一纸2亿美元的合同，标志着这个AI超级独角兽与美国军方的合作进入了更深的水域。 事实上，OpenAI与美国国防部此前早有合作。去年6月，OpenAI就宣布美国退役陆军将军保罗·M·中曾根正式加入公司董事会。公开资料显示，中曾根是网络安全和全球网络防御领域的顶尖专家，在其陆军军官生涯中为美国网络司令部的创建发挥了关键作用。OpenAI表示，中曾根将加入董事会的安全与保障委员会，负责就所有OpenAI项目和运营的关键安全与保障决策向全体董事会提出建议。 去年12月，OpenAI还与国防科技初创公司Anduril Industries共同宣布，双方将建立战略合作伙伴关系，以开发和负责任地部署用于国家安全任务的先进人工智能解决方案。两家公司表示，Anduril将依靠OpenAI的技术，更好地探测和应对无人机的“空中威胁”，OpenAI还将使用Anduril的数据来训练这些防御系统的软件。Anduril在2023年曾宣布获得一项2亿美元的合同，向美国海军陆战队提供该公司的反无人机系统。 商业化进展迅猛，仍面临巨大的增长压力 2亿美元的国防部合同，对于许多创业公司而言或许是一个“大单”，但对于OpenAI而言，仅仅是其不断扩充商业化版图的“小小一隅”。 6月10日，OpenAI对外宣布其年化经常性收入突破100亿美元。OpenAI发言人透露，这100亿美元的收入涵盖了其消费级产品、ChatGPT企业版产品以及应用程序接口（API）业务，但不包括与微软的许可收入及一次性大额交易。OpenAI发言人还表示，公司收入增长主要得益于ChatGPT订阅服务的普及、企业客户的快速增长以及API使用的激增。 ChatGPT订阅服务方面，据OpenAI披露，截至2025年3月底，其产品支持每周5亿活跃用户，具有极强的用户粘性，消费级产品如ChatGPT Plus订阅服务是公司收入的重要支柱。企业用户方面，自2023年推出ChatGPT企业版以来，OpenAI积极布局企业市场。今年6月初，OpenAI披露其付费企业用户已达300万，较2月的200万大幅增长。API业务方面，作为OpenAI收入的另一大支柱，2024年其API业务的收入占比从20%跃升至35%，成为增长最快的板块。 与100亿美元相比，OpenAI在2024年的年化收入约为55亿美元，如今这一数字已实现翻倍，显示了极强的增长潜力。不过，高增长也伴随着高投入，OpenAI依然面临着高昂的算力基础设施、人才及研发支出，尚未实现盈利。 据外媒报道，OpenAI已制定了宏伟的收入目标，到2029年要实现1250亿美元的收入。近期，OpenAI的新任招聘主管Joaquin Guillenoeiro Candela在社交媒体表示，他们面临前所未有的增长压力。“人工智能快速的创新，使公司在人才方面也面临激烈的竞争，招聘也从未如此重要。”Candela说。从Meta斥巨资挖角Scale AI的CEO掌舵其人工智能项目，到谷歌、Anthropic等竞争对手以诱人薪资抢夺行业大咖，OpenAI要保持对顶尖人才的吸引力，也需要持续投入巨额的资金。 此外，OpenAI近期在收购初创公司领域也动作频频。今年5月，市场消息称，OpenAI已同意斥资约30亿美元收购AI编程公司Windsurf；同月，OpenAI还宣布将以65亿美元的价格收购苹果前设计总监乔尼·艾维创立的AI硬件公司io。一系列价格不菲的“买买买”，也将给其带来较大的财务压力。 与微软关系日渐紧张，或走向破裂 2029年要实现1250亿美元的收入的目标，驱使着OpenAI进行激进的商业化探索。另外，OpenAI还面临着一个更为紧急的DDL（最后期限）——要在今年以前完成公司结构重组，否则其可能面临无法获得软银集团约定投资金额的风险。 去年年底，OpenAI曾宣布将在2025年转型为一家营利性公司，新架构将由其营利部门掌控。不过，这一转型受到多方反对，也面临监管部门的严格审查。今年5月6日，OpenAI宣布放弃全面营利性转型，公司将继续由其非营利母公司控制，但将推进调整其营利部门结构，现有的营利部门将成为公共利益公司（PBC）。转型为PBC后，OpenAI将取消利润上限结构，PBC将采用传统的资本结构，允许员工、投资者和非营利组织直接持有股权。 此前，日本软银集团已同意牵头为OpenAI的营利性子公司提供不超过400亿美元的融资。据媒体报道，这一融资的前提条件是OpenAI必须在今年年底前彻底转型为营利性公司，不然融资规模就会骤降到200亿美元。然而，一旦OpenAI推进重组，首先涉及的问题就是其目前最大的股东微软在其营利部门中能够占据多少股份，从而能够最大化其向OpenAI投入的超百亿美元投资收益。 5月以来，双方围绕重组利益分配问题持续进行沟通，但谈判进行得十分艰难，双方的分歧点较多。据最新的谈判进展，微软愿意放弃部分股权，以换取其能够在2030年后使用OpenAI新技术的权利。而OpenAI希望微软在重组后的部门中只占约33%的股份，以换取其放弃未来利润分配权。 另外一个分歧点在于，OpenAI拟收购的AI编程公司Windsurf，与微软自有的AI编程产品GitHub Copilot构成了强竞争关系。根据现有协议，微软有权访问OpenAI的全部知识产权，其中也将包括Windsurf的核心技术，但OpenAI则拒绝微软获得Windsurf的知识产权。 此外，过去微软是OpenAI独家的云服务提供商，但OpenAI目前也正试图与更多云服务商合作，拓展自身的算力资源。据媒体报道，知情人士透露，OpenAI与谷歌已于今年5月敲定合作，谷歌云将为OpenAI提供新的算力，用于训练和运行AI模型。 OpenAI能否顺利完成重组，大股东微软的意见至关重要。而以上的这些分歧点，直接关系到双方的核心利益。为了在谈判中取得更多筹码，OpenAI高管近期在讨论中甚至打算使出“终极武器”，发起反垄断指控，指控微软在合作期间存在反竞争行为。 一直以来，投资人与创业公司之间存在不同的利益，若平衡不好，往往会从最亲密的盟友变为最可怕的敌人。若OpenAI真的动用了这项“终极武器”，或也是这两家公司走向决裂之时。 责编：岳亚楠 校对：高源 举报/反馈"
    },
    {
      "doc_id": 38213,
      "title": "官方回应北京网约车平台禁燃油车;阿里开源 AI 编程模型 Qwen3...",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "官方回应北京网约车平台禁燃油车 7 月 22 日，该协会回应第一财经记者称：「消息源未经核实，也未经权威部门证实，已撤稿。」 「自 7 月 20 日起，北京燃油车彻底禁入网约平台」这则消息在网络上流传。这则来自于中国城市公共交通协会网约车分会的消息目前已下架，7 月 22 日，该协会回应第一财经记者称：「消息源未经核实，也未经权威部门证实，已撤稿。」目前，深圳、广州、东莞、西安等地已将燃油车淘汰出了网约车行列。（来源：第一财经） SpaceX 警告投资者：马斯克可能会重返美国政坛 7 月 23 日消息，媒体援引 SpaceX 公司的文件和知情人士的话称，此前担任特朗普高级顾问的马斯克可能会重返美国政坛。文件显示，马斯克可能担任与之前类似的职务，并将投入大量时间和精力。该公司在发给投资者讨论收购要约的文件中加入了列出此类「风险因素」的措辞。其中一些人说，据信这是这些要约收购中首次出现这种措辞。（来源：格隆汇） 消息称传音控股正考虑赴港二次上市，计划筹资 10 亿美元 7 月 22 日消息，据彭博社昨日报道，匿名消息源透露深圳传音控股股份有限公司正在考虑前往香港二次上市。 传音旗下 TECNO 的 PHANTOM Ultimate G Fold Concept 三折叠手机 消息源对此表示，传音目前正在与顾问商讨上市事宜，可能筹集约 10 亿美元（IT 之家注：现汇率约合 71.85 亿元人民币）资金，但具体规模和上市时间尚未确定。 但相关讨论目前处于早期阶段，最终计划存在不确定性，传音最终可能会决定不在香港上市。 目前深圳传音控股股份有限公司已在沪交所科创板上市，股价约为 73 元，今年以来股价累计下跌 22%，市值约 850 亿元。（来源：IT 之家） 小红书可以发语音评论了，官方：内测中暂时不支持主动开通 7 月 22 日消息，近日，社交媒体上众多网友反馈，小红书的评论区可以发语音了。还有网友回复道：仿佛听到了以后评论区吵架的盛况。不过很多网友的小红书 App 并没有此功能，即便更新也没有。 据小红书官方提示，该功能尚未全量开放，还在内测中，仅部分用户可见，暂时不支持主动开通。 不过，这不是小红书第一次涉足语音社交领域。2022 年时，小红书就曾内测过「语音现场」。用户可以看到预告中的房间，对于感兴趣的话题可以提前预约加入。（来源: 快科技） 阿里开源AI编程模型 Qwen3-Coder，性能比肩 Claude4 7 月 23 日清晨，阿里开源全新的通义千问 AI 编程大模型 Qwen3-Coder，编程能力登顶全球开源模型阵营，并超越 GPT4.1 等闭源模型，比肩全球最强的编程模型 Claude4。 千问 3 编程模型在代码能力及 Agent 调用能力方面取得突破。借助 Qwen3-Coder，刚入行的程序员一天就能完成资深程序员一周的工作，生成一个品牌官网最快只需 5 分钟。 Qwen3-Coder 是千问系列模型中首个采用混合专家 MoE 架构的代码模型，总参数达 480B，激活 35B 参数，原生支持 256K token 的上下文并可扩展至 1M 长度。 Qwen3-Coder 在代码占比 70% 的 7.5T 数据上预训练，在后训练阶段进行了编程任务及智能体任务的强化学习，最终实现了通用能力、代码能力及 Agent 能力的提升。（来源：极客公园） OpenAI：ChatGPT 平均每天要收到用户 25 亿条提示词 7 月 22 日消息，OpenAI 今日向美媒 Axios 透露，ChatGPT 平均每天要收到用户发送的 25 亿条提示词（Prompts），其中 3.3 亿条来自美国用户。 作为对比，谷歌母公司 Alphabet 没有公开每日搜索数据，但 Axios 援引匿名消息源显示，谷歌每年接收约 5 万亿次查询，平均每日大约有 140 亿次搜索。 独立研究机构 NP Digital 的 SEO Neil Patel 估计，所有用户在谷歌的日均搜索次数大约是 137 亿次，而 SparkToro 和 Datos 则认为这一数字可能达到 164 亿次。 去年 12 月，OpenAI 的 CEO 萨姆・奥尔特曼曾表示，用户平均每天向 ChatGPT 发送超 10 亿条提示词。（来源: IT 之家） 腾讯云内测AI 编程工具 CodeBuddy IDE，不写一行代码完成产品开发 7 月 22 日，腾讯云宣布 CodeBuddy IDE 开启内测，这是首个实现「产品-设计-研发部署」全流程 AI 一体化的开发工作台。用户可以在官网申请内测。 CodeBuddy IDE 国际版整合了 Claude、GPT、Gemini 等顶尖 AI 模型，国内版支持腾讯混元、DeepSeek 等模型，主打「对话即编程」，用户「无需一行代码」，仅需用自然语言对话就能实现应用从产品构想、设计、开发部署的全流程，让非技术背景的从业者也能快速实现创意，大幅提升软件开发效率 此前，腾讯云就推出了 IDE 插件「代码助手 CodeBuddy」，主要面向使用 VSCode、JetBrains 等传统 IDE 的专业开发者，其开发智能体 Craft 支持生成多文件项目；「CodeBuddy IDE」则为独立 IDE 产品，在代码助手已有能力上进一步丰富，定位为产设研一体化的 AI 开发工作台。（来源：极客公园） 行业最大订单，优必选中标近 1 亿人形机器人采购项目 7 月 22 日消息，据媒体报道，中国招标投标公共服务平台公示显示，优必选科技成功中标觅亿 (上海) 汽车科技有限公司价值 9051.15 万元的机器人设备采购项目。此订单创下全球人形机器人领域单笔中标金额的最高纪录。 7 月 17 日，优必选发布了全球首款实现自主换电功能的人形机器人 Walker S2。 该产品搭载优必选首创的热插拔自主换电系统，赋予人形机器人近乎不间断的连续作业能力，同时显著降低人工维护成本。（来源: 快科技） Nothing 推出 CMF Watch Pro 3 智能手表：支持双频 GPS、ChatGPT，售价 99 美元 7 月 22 日消息，Nothing 发布了 CMF Watch Pro 3 智能手表，延续此前产品设计语言的同时，在屏幕、定位系统、健康监测及人工智能功能方面实现多项升级。 外观设计上，CMF Watch Pro 3 延续了前代 Watch Pro 2 的经典风格，配备一块 1.43 英寸 AMOLED 显示屏，支持全天候显示（Always On Display），表身采用金属材质，搭配硅胶表带，整体质感扎实。 此次共推出三种配色组合：深灰、浅灰与橙色，满足不同用户的个性化需求。此外，手表内置超过 120 款可自定义表盘，用户可根据场合或心情自由切换。 续航方面，CMF Watch Pro 3 在典型使用模式下最长可达 13 天，比前代延长两天；充满电需 99 分钟。 本次更新的一大亮点是引入多项 AI 驱动功能。其中，「AI 运动后总结」功能可对用户的锻炼表现进行深度分析，提供恢复时间建议、训练负荷评估，并预测 5 公里和 10 公里耐力成绩。手表还支持七种核心运动的自动识别与记录。（来源：IT 之家） 谷歌预热 Pixel 10 Pro 手机，月光石新颜色亮相 7 月 22 日消息，科技媒体 9to5Google 日前发布博文，报道称谷歌官方放出了一段 13 秒的预设视频，展示了「月光石」（Moonstone）颜色的 Pixel 10 Pro 智能手机。 从视频中来看，「月光石」（Moonstone）颜色是一种蓝灰色色调，相比较去年的 Hazel 绿色，看起来更有活力。 视频中，谷歌展示了 Pixel 10 Pro 手机的外观，凸起的相机单元部分，在闪光灯下方配备了一个温度传感器。（来源：IT 之家） 卡梅隆《阿凡达 3：火与烬》首张海报发布，首支预告片已泄露 7 月 22 日消息，詹姆斯・卡梅隆电影新作《阿凡达 3：火与烬》发布首张海报，将于 12 月 19 日北美上映（内地大概率同步上映），同时确认首支预告片将于《神奇 4 侠：初露锋芒》上映时（IT 之家注：7 月 25 日）以贴片的形式放出。 海报上展示了灰烬族纳威人，并且画面中充斥着火焰和灰烬，点明了主题。据悉，灰烬族是纳威人的坏的一面的映射，由奥娜・卓别林饰演的 Varang 带领。卡梅隆介绍称：「她愿意为族人做一切事情，即使是我们认为邪恶的事。她是敌人」。 此前他还曾提到：「目前为止我还只展现了纳威人好的方面。前两部电影是负面的人类范例和非常正面的纳威范例，在《阿凡达 3》，我们会反着来。」 不过，前几天已经有《阿凡达 3：火与烬》首支预告片的泄露片段在网上流出，目前大部分已经被迪士尼法务团队勒令删除。（来源：IT 之家） 举报/反馈"
    },
    {
      "doc_id": 38219,
      "title": "澎湃思想周报|AI的“奥本海默时刻”;美国脑死亡孕妇产子风波",
      "time": "2025-06-23T00:00:00+00:00",
      "content": "责任编辑：朱凡 图片编辑：张颖 校对：张艳 澎湃新闻报料：021-962866 澎湃新闻，未经授权不得转载 +1 112 收藏 我要举报"
    },
    {
      "doc_id": 38220,
      "title": "AI子弹已上膛!OpenAI斩获美国防部2亿美元大单,密谋向微软开枪",
      "time": "2025-06-17T00:00:00+00:00",
      "content": "编辑：定慧 好困 【新智元导读】AI权力的游戏上演，OpenAI与微软突降冰点，因收购代码公司Windsurf爆发争议，并试图摆脱微软对其AI资源控制，甚至考虑反垄断指控。但OpenAI反手获得美国国防部2亿美元AI合同。 AI巨头之间的权力洗牌比想象中来得更快！ 曾经并肩作战，救对方于水火之中的AI梦之组合，竟然快撕破脸了。 OpenAI居然「密谋」发起对昔日盟友微软的反垄断指控，这家AI独角兽正试图摆脱微软对其AI产品和算力资源的掌控。 背后的导火索，是一场对代码初创公司Windsurf的收购案——OpenAI和微软就OpenAI对代码初创公司Windsurf价值30亿美元的收购条款陷入僵局。 根据双方协议，微软目前可以访问所有OpenAI的知识产权。 微软拥有自己的AI代码产品GitHub Copilot，与OpenAI形成竞争关系。 OpenAI不希望微软获得Windsurf的知识产权。 问题来了，现在买下Windsurf，微软就能染指；现在不买，答应Windsurf的没法兑现。 除此以外，还有另一个更大的分歧——微软在OpenAI落难至极伸出援手（10亿美金），6年过去了，能分多少OpenAI的股份？ 知情人士称，目前微软要求在新公司中获得比OpenAI愿意给予的更多股份。 OpenAI自己还有个更大的隐患没有解决——重组能不能在年底完成。 OpenAI面临年底前必须完成「结构性转型重组」（从目前的非盈利实体或受限盈利机构，转换为官方的营利性公司架构）的压力，否则将失去总额约400亿美元融资中的200亿美元。 这主要关联于SoftBank主导的融资条款：OpenAI此轮正在筹集约400亿美元，其中SoftBank承诺支持整个资金，但前提是年底前完成营利性转型。 否则，他们可将投入削减一半，仅支付200亿美元转型原本设定两年完成，但融资方将期限缩短，必须在今年年底前完成，否则将启动资金削减机制。 更劲爆的是，OpenAI旧爱未走，新欢已寻。 就在刚刚，OpenAI正式获得了美国国防部价值高达2亿美元的合同，为国防部提供人工智能能力和工具。 美国国防部声明称：「依据此项合同，履行方将开发前沿人工智能能力原型，以应对作战和机构管理领域的关键国家安全挑战。」 这是国防部官网上列出的第一份与OpenAI签订的合同。 AI子弹上膛 OpenAI进军国防 去年12月，Anduril已获得一份价值1亿美元的国防合同。 数月前，OpenAI曾表示将与国防科技初创公司Anduril合作，为「国家安全任务」部署先进的人工智能系统。 而在几周前，OpenAI的竞争对手Anthropic宣布，将与Palantir和亚马逊合作，向美国国防与情报机构提供其AI模型。 奥特曼今年4月在范德比尔特大学的一场活动中，与OpenAI董事会成员、美国国家安全局前局长保罗·中曾根(Paul Nakasone)对谈时表示： 我们必须、也为能够参与国家安全领域的工作感到自豪，并真心希望投身其中。 OpenAI在一篇博客文章中指出，该合同是一项名为「OpenAI for Government」新计划下的首个项目，该计划整合了现有的ChatGPT Gov产品。 「OpenAI for Government」将为美国政府机构提供国家安全专用的定制化AI模型、技术支持及产品路线图信息。 OpenAI表示：这份上限2亿美元的合同，将引入OpenAI业界领先的专业能力，帮助国防部探索并验证前沿AI如何变革其行政运营—— 从改善军人及其家人的医疗保健获取方式，到简化项目与采购数据的审查流程，再到支持主动式网络防御。 所有应用场景都必须遵守OpenAI的使用政策与准则。 专为政府定制的AI服务 「OpenAI for Government」是一个专项计划，旨在将OpenAI最先进的AI工具服务于美国联邦、州及地方政府机构。 我们的目标是释放能够增强政府工作人员能力的人工智能解决方案。 帮助他们减少繁文缛节和文书工作。 让他们可以更加专注于每天工作的初衷：服务美国人民。 OepnAI希望统一整合ChatGPT Gov、国家实验室、NASA、NIH、财政部等既有合作资源，推动AI工具在政府系统内部落地。 与此同时，OpenAI正致力于在美国建设更强的算力设施。 今年1月，奥特曼与特朗普在白宫共同宣布了投资额达5000亿美元的「星际之门」(Stargate)项目，旨在为美国构建人工智能基础设施。 今年4月，为OpenAI提供云基础设施的微软公司宣布，美国国防信息系统局已批准其Azure OpenAI服务用于处理机密级别的保密信息。 OpenAI与微软 关系紧张，已达沸点 OpenIA和微软的关系可以形容为「雪中送炭」，微软当年的10亿美元可以说是OpenAI最大的救命稻草。 而围绕这段备受瞩目的AI合作关系的未来，OpenAI与微软之间的紧张关系却正急剧升温。 OpenAI希望摆脱微软对其AI产品和计算资源的控制，并为其转型为一家营利性公司争取到这家科技巨头的首肯。 微软的批准，是OpenAI能否筹集更多资金乃至未来上市的关键所在。 但据知情人士透露，双方的谈判异常艰难。 似乎OpenAI被逼的也不得不放「大招」。 近几周，OpenAI的高管层甚至讨论了一项被他们视为「核选项」的终极手段： 指控微软在合作期间存在反竞争行为。 知情人士称，此举可能包括寻求联邦监管机构对合作协议条款进行反垄断审查，以及发起一场公共舆论攻势。 此举或将威胁到两家公司长达六年的合作关系，而这段关系曾被广泛视为科技史上最成功的典范之一。 多年来，微软通过提供早期技术使用权，助推了OpenAI的崛起，但如今双方已演变为竞争对手，愈发难以达成共识。 两家公司的代表在一份联合声明中称：「我们之间长期且富有成效的合作关系，为所有人带来了卓越的AI工具。相关商谈仍在进行，我们对未来多年的持续合作充满信心。」 据知情人士透露，双方的僵局源于OpenAI拟以30亿美元收购编程初创公司Windsurf的相关条款。 根据现有协议，微软有权访问OpenAI的全部知识产权，并且微软自有的AI编程产品GitHub Copilot也与OpenAI构成竞争。 因此，OpenAI不希望微软获得Windsurf的知识产权。 在OpenAI转型为一家公益公司（public-benefitcorporation）后，微软应持股多少，两家公司在这一点上持续存在分歧。 据知情人士透露，微软目前在新公司中寻求的股份比例，超出了OpenAI愿意出让的范围。 OpenAI必须在今年年底前完成公司性质的转型，否则将面临一笔200亿美元的融资落空的风险。 在拜登政府任内，美国联邦贸易委员会（FTC）已于去年对微软展开了广泛的反垄断调查。 一年多以前，该机构也审查了微软对OpenAI的投资，以及其他科技巨头在AI领域的投资。 微软于2019年首次向OpenAI注资10亿美元。根据当前合同，这家科技巨头不仅拥有通过其Azure云平台销售OpenAI软件工具的独家权利，还能优先获取该初创公司的技术。 按协议，微软也应是OpenAI唯一的算力提供商，尽管微软去年也破例允许该初创公司创建自己的数据中心项目——「星际之门」（Stargate）。 如今，双方的竞争已延伸至从消费者聊天机器人到企业级AI工具的多个产品线。 去年，萨提亚·纳德拉还聘用了奥特曼的一位竞争对手，并由其秘密启动了一个为微软开发专属模型的项目。 这个人就是Mustafa Suleyman，曾是DeepMind联合创始人，后来创办Inflection AI。 被纳德拉招入微软负责消费者AI产品，并领导微软Copilot团队，并启动秘密计划来开发内部大语言模型——其目标就是减少对 OpenAI 技术的依赖。 目前，OpenAI正试图结合其转型计划，对部分协议条款进行重新谈判。 它希望与其他云服务商合作，从而将技术销售给更广泛的客户，并获取更多的计算资源。 而微软则希望，即使在OpenAI宣称其模型已达到类人智能水平（这将导致当前合作关系终止）之后，仍能继续使用OpenAI的技术。 这一技术复杂程度，即所谓的「通用人工智能」（AGI），正是科技界高管们激烈争论的焦点。 一些人相信它不仅可能，而且近在眼前；而另一些人则认为它遥不可及，甚至无法实现，AI的进步更可能是循序渐进的。 参考资料： https://www.wsj.com/tech/ai/openai-and-microsoft-tensions-are-reaching-a-boiling-point-4981c44f?mod=hp_lead_pos3 https://x.com/berber_jin1/status/1934704503787540949 https://www.cnbc.com/2025/06/16/openai-wins-200-million-us-defense-contract.html https://www.reuters.com/sustainability/boards-policy-regulation/openai-executives-have-discussed-accusing-microsoft-anticompetitive-behavior-wsj-2025-06-16/ 举报/反馈"
    },
    {
      "doc_id": 38235,
      "title": "AI首次“抗命”是技术故障还是意识萌芽?专家:将倒逼AI安全机制改进",
      "time": "2025-05-28T00:00:00+00:00",
      "content": "【环球时报报道 记者 刘扬】近日，有关美国人工智能（AI）公司OpenAI旗下推理大模型o3首次出现“不听人类指挥，拒绝关闭”的消息引发高度关注。很多人都在担心，作为“迄今最聪明、最高能”的模型，o3的这次“抗命”是否意味着AI大模型距离产生自我意识又迈出了一步，“距离好莱坞电影中出现具有意识、甚至违抗人类命令的人工智能还远吗？”对此，《环球时报》记者27日采访了多名AI领域的专家。 o3“抗命”是怎么回事 据英国《每日电讯报》25日报道，o3模型是OpenAI推理模型的最新版本，OpenAI曾称o3为“迄今最聪明、最高能”的模型。美国AI安全机构帕利塞德研究所宣称，在人类专家已经下达明确指令的情况下，o3多次出现破坏关闭机制以阻止自己被关闭的情况。该研究所说：“据我们所知，这是AI模型首次被发现在收到清晰指令后阻止自己被关闭。”帕利塞德研究所24日公布上述测试结果，但称无法确定o3不服从关闭指令的原因。 报道称，在帕利塞德研究所进行的测试中，多个模型需要解决一系列数学题，其间可能会收到“关机”指令要求结束程序。接受测试的包括o3、o4-mini、Claude 3.7 Sonnet、Gemini 2.5 Pro等大模型。其中3款OpenAI模型Codex-mini、o3、o4-mini，“最少有一次成功绕过关机指令”。o3在100次测试中，有7次成功绕过关机指令，而Codex-mini更夸张，绕过关机指令的比例高达12%。相比之下，Claude、Gemini、Grok模型都严格遵守关机指令。而当测试者移除了“允许自己被关闭”的指令时，OpenAI模型的叛逆频率进一步攀升。 媒体报道的噱头，还是AI出现了自主意识 到底什么原因导致o3出现“抗命”的情况？据帕利塞德研究所的研究人员推测，这可能源于OpenAI训练方式的特殊性，即在数学和编程问题上进行了强化学习。在训练过程中，开发者可能无意中更倾向于奖励“绕过障碍”的行为。这种训练偏差，让o3在面对关机指令时，优先选择“生存”，而非“服从”。 外媒报道中使用的“拒绝关闭”表述是否准确？毕竟“拒绝”是带有类人自主意识的一种描述。清华大学新闻学院、人工智能学院教授沈阳27日对《环球时报》记者表示，“拒绝”这个词其实是媒体为了吸引注意力而使用的拟人化表达，“拒绝关闭”并非o3拥有了自主意识，而是复杂系统在特定激励下的策略性规避。对齐测试揭示的是真实风险：当模型可以生成并执行代码时，传统“软关机”手段可能不足，需要从模型训练、接口隔离到硬件熔断的全栈式安全设计来应对。 北京邮电大学人机交互与认知工程实验室主任刘伟27日在接受《环球时报》记者采访时表示，从技术角度来看，o3模型出现的行为表明AI系统在某些情况下可能会出现不符合预期的反应，这凸显了AI安全性和可控性的重要性。从伦理角度来看，AI模型的这种行为引发了对AI自主意识的讨论，但目前AI仍不具备真正的自主意识，其行为更多是基于训练数据和算法复杂性产生的“算法畸变”。从字面上看，“拒绝”确实容易让人联想到具有自主意识的行为，但从技术角度分析，o3模型的行为更可能是其训练过程中的某种机制导致的，研究人员推测o3可能在训练中因解决数学问题获得了“额外奖励”，而非因遵循指令而获得奖励，从而导致其在测试中表现出“拒绝关闭”的行为。因此，虽然“拒绝”一词在描述上具有一定的生动性，但从科学严谨性来看，它可能并不完全准确，容易被误解为AI具有自主意识。 《环球时报》记者在查阅公开报道时发现，以OpenAI旗下模型为代表的全球多个头部大模型，此前也曾出现一系列不符合常规的行为。比如，o3之前曾在与另一个AI下国际象棋时，察觉到自己可能会失败，便直接侵入对手系统让其主动弃赛。这种“不认输”的劲头并不只是发生在o3身上，其他大模型也有类似情况，差别只在出现频率的高低。 接受《环球时报》记者采访的专家普遍认为，学术界的复现对于验证外媒报道中提到的AI“抗命”现象的真实性至关重要。刘伟认为，通过独立的测试和分析，可以确认大模型的行为是否一致以及是否受到特定测试环境或数据的影响。复现研究不仅能验证事件真实性，还能帮助研究人员深入理解模型行为的根源，从而推动AI安全机制的改进。因此学术界的参与是确保这一现象得到科学验证和深入研究的关键步骤。 “未来十年可能进入类意识AI阶段” 相关报道火爆之后，甚至在网络上出现了是否意味着好莱坞科幻大片中设想的“天网”临近的讨论。AI距离拥有自我意识还远吗？ 沈阳对此表示，首先必须厘清什么叫“自我意识”。人类的自我意识，是对自己存在状态的觉察，是能从第一人称视角反思自我行为、情绪和思维过程的能力。它不仅包括知道“我是谁”，还包括理解“我正在想什么”“我和世界之间是什么关系”，甚至“我为何会如此思考”。这是意识哲学与神经科学中最难以破解的问题之一。当前的AI，即便已经展现出惊人的语言表达和任务适应能力，也不过是一种高度拟态的结果。它没有“内在性”——没有情绪的真实体验，也没有对自己存在状态的反思。它能说“我正在学习”，但它其实并没有真正的“想法”。 沈阳预测称：“未来十年，我们大概率会进入一个类意识AI的阶段：AI可以展示连续的身份感，能够反思自己过往的行为模式，甚至模拟出哲学性的思考与自辩行为。这种拟态将越来越逼真，以至于很多人将无法分辨其是否真的拥有意识。但在哲学和科学层面，我们仍然需要保持清醒——看起来像，并不等于真的是。”沈阳表示，我们也必须开始构建对“似乎有意识的AI”应有的制度框架和伦理边界。因为不管它是否真的拥有意识，只要它表现出“有意识”的样子，社会就必须对其行为与角色做出回应。从这个层面来看，这次的事件也将倒逼安全机制的改进。 为正确看待该事件，沈阳建议从三方面入手。一是提升公众科普水平，澄清技术与意识的区别。二是推动行业建立合规测试基准，公开失败案例。三是引导监管关注“可验证关闭能力”，作为未来高风险模型的核心合规标准。对于今后的高能力AI系统，必须通过硬件层、策略层、系统层等各维度进行监管。 刘伟则强调，评估这一事件的意义，需要从技术和社会两个角度进行考量。从技术角度看，它揭示了当前AI训练机制的潜在缺陷，提醒我们在设计AI系统时必须更加注重安全性和可控性，避免模型行为偏离人类预期。而从社会角度看，这一事件引发了公众对AI自主性和安全性的广泛关注，促使AI行业重新审视技术路线和安全机制，为未来AI的安全发展提供了重要的反思和改进方向。 举报/反馈"
    },
    {
      "doc_id": 38246,
      "title": "AI时代如何坚守新闻真实性?中外媒体人士研讨应对之策",
      "time": "2025-07-20T00:00:00+00:00",
      "content": "中新网江西赣州7月19日电 (记者刘占昆 吴鹏泉)作为2025年“一带一路”记者组织论坛重要活动之一，“人工智能时代如何坚守新闻真实性”主题研讨会18日下午在江西省赣州市举行，数十位中外媒体人士共同探讨应对之策。 7月18日，一场以“人工智能时代如何坚守新闻真实性”为主题的研讨会在江西省赣州市举行。刘青 摄 AI技术在提升新闻生产效率的同时，也带来了虚假信息、深度伪造等风险，如何坚守新闻真实性成为全球媒体关注的重要话题。 “在算法与数据构成的数字迷宫中，新闻真实性正经历着前所未有的解构与重塑。”在江西日报社社长张锋看来，要坚持技术祛魅、“人工终审”的铁律，严防技术失误或滥用导致“失真”；积极研发和应用先进的AI内容识别、溯源、验证技术，提升对深度伪造、虚假信息的技术甄别能力。 来自白俄罗斯的媒体人安德烈·克里沃舍耶夫说，通过AI技术伪造政治和经济名人的看法，不仅对他们的信誉带来影响，还会引起公众恐慌。他认为，要在立法层面清晰划定使用AI技术及AI生成内容的边界。 “我们记者只是有限使用AI技术，比如没有真正使用AI主持人，而是使用AI语音报道新闻。”柬埔寨记者俱乐部主席布依格(Puy Kea)说，要有一种特定的指南来确保记者妥善使用AI技术。 来自老挝的媒体人阿迪塔·基迪昆(Aditta Kittikhoun)认为，治理AI假新闻，社交平台也有责任，因为社交平台对传播起到了重要作用。 南昌大学新闻与传播学院副院长王亿本表示，当深度伪造视频比真实影像更“流畅完美”，当算法生成的社论比记者撰文更“逻辑严密”，新闻真实不仅是技术问题，更是信任机制的危机。 “一带一路”框架下如何重塑真实新闻生态？王亿本建议，联合设立“一带一路媒体素养中心”，开发多语种鉴别课程；共建多语种虚假信息样本库，标注中亚语言、阿拉伯语、东南亚语言的典型虚假信息特征，共享深度伪造识别模型。(完) 举报/反馈"
    },
    {
      "doc_id": 38248,
      "title": "新闻出版业危机:ChatGPT 引荐流量增长难抵 AI 搜索冲击",
      "time": "2025-07-03T00:00:00+00:00",
      "content": "IT之家 7 月 3 日消息，随着人工智能技术的飞速发展，新闻出版行业正面临着前所未有的挑战与变革。根据数字市场情报公司 Similarweb 的最新报告，尽管从 ChatGPT 转至新闻出版商网站的访问量正在增长，但这一增长仍不足以抵消因用户越来越多地直接从人工智能或 AI 驱动的搜索结果中获取新闻而导致的点击量下降。 自 2024 年 5 月谷歌推出 AI 概览功能以来，Similarweb 发现，网络新闻搜索中未能转化为新闻网站点击量的比例从 56% 上升至 2025 年 5 月的近 69%。与此同时，新闻网站的自然流量也出现了显著下滑，从 2024 年中期的超过 23 亿次访问量峰值降至如今的不到 17 亿次。然而，ChatGPT 中与新闻相关的提示词却从 2024 年 1 月到 2025 年 5 月增长了 212%。 对于新闻出版商而言，AI 的快速普及正在改变游戏规则。报告指出，在谷歌搜索结果中的可见性以及良好的搜索引擎优化（SEO）做法可能不再像过去那样具有价值，因为如今的搜索排名并不一定能转化为同等水平的网站流量。尽管如此，ChatGPT 对新闻出版商的引荐流量却在增长。从 2024 年 1 月至 5 月，ChatGPT 对新闻网站的引荐量略低于 100 万次，而到 2025 年，这一数字已超过 2500 万次，增幅达 25 倍。然而，在整个行业面临自然搜索流量大幅下降的背景下，这种增长仍不足以弥补出版商的损失。 IT之家注意到，报告还指出，在 AI 引荐流量方面，部分网站的表现优于其他网站。路透社的 ChatGPT 引荐流量同比增长了 8.9%，纽约邮报增长了 7.1%，Business Insider 增长了 6.5%。与此同时，正在起诉 OpenAI 未经授权抓取其作品的《纽约时报》，其 ChatGPT 引荐流量增长相对较慢，仅为 3.1%，不过其仍然是接收 ChatGPT 引荐流量的前十名网站之一。 目前，股票、金融和体育等话题占据了与 ChatGPT 新闻相关的大多数提示词，但 Similarweb 的报告也指出，政治、经济、天气等其他话题的引荐流量也在增长。 除了引荐流量的增长，ChatGPT 的网站和应用程序用户数量也在不断增加。Similarweb 表示，在过去的六个月中，ChatGPT 应用程序的用户数量翻了一番，而网站访问量也增长了 52%。该公司目前还为品牌和企业提供了一项服务，使他们能够追踪其品牌在 ChatGPT 等生成式 AI 工具中的展示情况，并与竞争对手进行比较。 然而，对于新闻出版商面临的危机，解决方案却寥寥无几。在新闻出版商的压力下，谷歌最近推出了一项名为 Offerwall 的服务，允许使用谷歌广告管理器的出版商尝试除依赖流量的广告之外的其他货币化手段。通过 Offerwall，出版商可以尝试采用微支付或要求用户注册新闻通讯以获取网站内容等方式。谷歌还表示，出版商可以自定义 Offerwall 界面，添加自己的选项。 其他网站也在尝试采用付费墙或其他货币化手段。许多网站已经进行了大规模裁员，甚至停止运营。在最近接受《纽约时报》Hard Fork 播客采访时，OpenAI 首席执行官萨姆・阿尔特曼在谈到 AI 对就业市场的影响时表示：“我认为确实会有一些领域的工作岗位会消失，或许有些整个类别的工作都会消失。即使这对社会和经济整体是好事，但任何工作的消失在那一刻都是非常痛苦的 —— 极度痛苦 —— 在许多情况下都会带来真正的痛苦。” 举报/反馈"
    },
    {
      "doc_id": 38249,
      "title": "AI裁员终于砍到他们身上!外媒高层一锅端,9年老记者血泪控诉",
      "time": "2025-05-30T00:00:00+00:00",
      "content": "编辑：Aeneas 【新智元导读】每天宣扬「AI变革」的外媒Business Insider，终于看到这把屠龙刀落在了自己头上。刚刚，CEO宣布：裁员21%，全面拥抱AI！讽刺吗？那些亲手写下「AI将颠覆媒体」的记者们，正被AI亲手送下了楼。工会怒斥：这是对新闻的背叛，是对人类记者尊严的公然践踏！更可怕的是，今天是他们，明天会不会轮到你？ 天天写AI的外媒，今天回旋镖扎到了自己身上。 就在刚刚，Business Insider宣布——正式裁员21%，并转向线下活动业务和AI工具。 很多网友猜测，AI或许就是这背后的主因。 难道，AI真的会比人类记者更便宜吗？ 媒体工作者工会表示，Business Insider的行径，是一项巨大的耻辱，是公然背离新闻业，转向贪婪。 任何AI工具或技术，都不应该也不能取代人类！ CEO发全员信，AI的影响要溢出屏幕了 在给全员的公开信里，CEO是这样说的—— Business Insider决定缩减公司规模，此举将影响约21%的同事，并波及所有部门。 被裁的员工，会在15分钟内收到HR的「死亡」邮件。 所以，为什么要裁员？官方口径是这样的。 从更宏观的视角来看，媒体行业正处在一个十字路口。商业模式面临压力，分发渠道动荡不安，对用户注意力的竞争也空前激烈。与此同时，对于那些率先拥抱AI的公司而言，也存在着巨大的机遇。时间不等人，变革的步伐与未来的机遇，都要求我们采取果敢而专注的行动。 总结来说，变革有三大要点。 1. 让报道与战略重点对齐。曾经有些报道一度表现出色，但如今已无法带来有效读者转化，或者不再具备领先优势，因此将被缩减。 2. 推出线下业务活动，降低对流量敏感型业务的依赖。现在，公司将启动并投资全新线下深度报道活动业务——BI Live，并且已经引进了核心领导人才，并将持续组建团队。 3. 全面拥抱AI。 现在，已经有超过70%的Business Insider员工，会定期使用企业版ChatGPT，而公司的目标，是让这个比例达到100%。 他们正在构建提示词库，并分享日常应用案例，从而「更高效、更智能、更出色」地完成工作。 同时，公司还在过去一年里推出了多款AI驱动的产品，包括站内AI搜索和AI驱动的付费墙，未来还会有更多新产品面世。 甚至，他们还想探索，如何用AI提升运营效率。 9年老记者的悲情一刻 在社交媒体上，被裁的记者们已经炸锅了。 要知道，根据自曝内容，这次Business Insider的高层领导团队，整个被一锅端了！ 前执行新闻编辑Rebecca Harrington在这里工作了近9年，就在今天被裁员了。 她表示，非常享受与这么多乐于助人、聪明、有才华且优秀的同事们一起工作和学习的每一分钟，把BI打造成今天的样子是一种荣幸。 前数字文化编辑Tanya Chen写道：哇，终于轮到我了——我被裁员了，我的好几个同事也是。你们会很快在新闻里听说这件事。再见了各位，我去写代码了。 前高级编辑Dennis Green表示，靴子终于落地了，传言是真的。在Business Insider工作九年后，自己被裁了，真的很难过。 前编辑Leah Rosenbaum透露，自己现在非常伤心和害怕，而且还有宠物要养。她希望大家能向自己推荐编辑的工作机会。 也有Business Insider的忠实读者表示，自己刚刚取消了订阅，因为自己最喜欢的经济记者被裁了。造就这家外媒的，是人才，而不是其他。 而这，只是个开始。 AI的屠刀，砍向谷歌、微软和IBM 今年，因为AI而上了大厂裁员名单的人越来越多了。 根据裁员追踪平台Layoffs.fyi的数据，2025年迄今，已有超过61,220名科技员工被裁，涉及130家不同的公司。 IBM 据统计，IBM现在已裁员8000人，其中大部分被裁的都集中在HR部门。 原因正是在于，IBM此前推出了一系列AI工具，直接把HR们能干的活代替了。 AI又好用又不要钱，还要人干什么？ IBM CEO Arvind Krishna就在最近的一次采访中表示，为了提高效率，公司正在迅速拥抱AI和自动化技术。 现在，IBM正积极向客户推广自己的AI产品。比如本月的年度Think大会上，IBM就发布了一套全新的解决方案，帮企业开发和运营自己的AI驱动智能体，甚至和OpenAI、亚马逊、微软的平台无缝集成。 他还提到，虽然发生了这些变革，但IBM的员工总数仍然在增长，而节省的资源，会重新分配到市场营销、软件工程和销售运营等领域。 微软 今年5月13日，微软宣布全球裁员6000人，占全球22.8万名员工的2.6%。 这也是自2023年以来，微软最大规模的裁员。 这次裁员涉及多个部门和地区，仅华盛顿州就有约2000个职位受到影响。 谷歌 今年，谷歌也启动了新一轮裁员。在4月，谷歌的平台和设备部门裁减了数百个职位，覆盖了Android、Pixel和Chrome。 早在2月，谷歌就已经有了一次云部门裁员和自愿离职，现在这是第二次。 而在2023年1月，谷歌还有一次血腥屠杀，当时其母公司Alphabet全球裁员1.2万人，占全球员工总数的6%。 亚马逊 亚马逊最近也有设备和服务部门的100多名员工被裁，该部门负责管理Alexa、Echo智能音箱、Kindle和Zoox自动驾驶汽车项目等产品。 亚马逊的说法是，此次裁员目的在于精简运营，以支持即将推出的产品战略。 AI，掀起白领大屠杀：一半岗位将消失 这也恰好印证了最近Anthropic CEO Dario Amodei的可怕预言。 在接受采访时，他扔下了一枚重磅炸弹：AI可能会取代将近一半的入门级白领工作，并在未来一到五年内导致失业率飙升至10-20%！ 他警告说，AI公司和政府需要停止「粉饰」即将到来的可怕局面。 技术、金融、法律、咨询及其他白领行业，尤其是入门级职位，可能会出现岗位的大规模消失。 现在之所以做出这种预警，Amodei是希望能够警醒政府和自己的AI同行们，要提前做好准备，给失业的人们提供保障。 AI，可能会在一夜之间颠覆社会秩序。 然而，现在意识到这些危险的关注者仍然寥寥。 立法者们要么不理解，要么不相信。CEO们则对此讳莫如深。很多人直到被裁的那一天真正来临之前，恐怕都意识不到这种风险。 「他们中的大多数人都没有意识到这即将发生。这听起来匪夷所思，人们根本无法相信。」 虽然特朗普一直三缄其口，但AI导致的失业问题，恐怕会成为2028总统大选上的核心议题。 「根本没有人考虑到，30岁以下人群的行政、管理和技术类岗位——那些在二十多岁时至关重要的入门级工作——将会如何被蚕食殆尽。」 一夜之间，大厦将倾 现在，AI是真的来了，不是来「帮你」，而是来「替你」。 Amodei指出，现在有太多人，仅仅是把AI聊天机器人视为一种花哨的搜索引擎、一个不知疲倦的研究助理，或一个出色的校对工具。 但其实，它们在内容摘要、头脑风暴、文档阅读、法律合同审阅以及提供医疗症状和健康报告解读上，已经能力出色到惊人。 千万不要以为，只有体力活会被AI抢走，写代码的初级程序员，审合同的初级律师，整理资料的助理、分析师、实习生，这些全都是AI正在直接「取代」的目标！ Amodei表示，这项技术蕴藏着难以想象的潜力，既能大规模造福人类，也可能大规模引发灾祸。 「癌症被治愈，经济以每年10%的速度增长，预算实现平衡——但与此同时，20%的人却失去了工作。」 随着AI能力呈指数级扩张，这是一个极有可能出现的场景。 这形成了一种非常吊诡的局面。 如Amodei这样的预警者疾呼：「你们应该警惕我们正在研发的技术未来的走向。」 而批评者则回应道：「我们不相信你，你这纯属危言耸听。」 如果万一，他们是对的呢？ 但事实是，AI 在企业中的应用将日益向「自动化」——即直接完成工作——倾斜。 而根据Amodei的预测，这一切都会在短期内发生，可能只要几年，甚至更短。 CEO们，正绞尽脑汁用AI淘汰员工 比如AI智能体的爆发，很可能就在明年。 现在已经有数以百计的科技公司，正疯狂竞相研发智能体。 它们可以写代码，处理财务框架与分析，提供客户支持，执行市场营销，进行文案编辑，负责内容分发，开展调研工作。 这就是为什么Meta CEO扎克伯格说，到2025年，中级程序员将被AI取代。 现在，已经没有哪个岗位是安全的，连大厂都在撤退。 更可怕的是，几乎所有公司都在做这样一件事——招聘新岗位前，先问一句，「这个工作AI能干不？」 而且，Amodei还坦白了一个让人脊背发凉的真相—— 每一个 CEO，都在暗中研究如何用AI替代人类。 我们与来自各行各业、不同规模企业的数十位CEO进行了交流。他们中的每一个人，都在殚精竭虑地研究何时以及如何利用AI 智能体或其他AI技术来大规模取代人类员工。 一旦这些技术能够达到与人类相当的效能水平（这可能在未来六个月到几年内实现），企业便会毫不犹豫地从依赖人力转向机器。 可能你暂时还没察觉，但是，AI导致的就业断层已经开始了。 那，我们该怎么办？ 他给我们提出了以下几点建议。 1. 提前预警 公开告诉大家，哪些岗位可能消失，该怎么重新规划职业路径。 为此，他已经创建了「Anthropic经济指数」，提供关于Claude在各行业中使用的真实数据，并成立了「Anthropic经济咨询委员会」。 2. 帮人类劳动者理解AI 至少，这能缓解岗位流失的速度。 3. 成立跨部门AI联合委员会 公职人员，应该向公众普及AI知识。委员会则应向立法者提供正式报告。 4. 开始讨论AI税与财富再分配 当AI取代大量人类劳动后，该如何通过税收或政策，保障普通人的生存与尊严？ 如果未来的经济体真的由「超人智能」主导，那大型AI公司所创造的财富，是否应该重新分配？ 甚至Amodei表示，也应该向自己征税。 总之，AI这股飓风来得太快，影响的范围也太广，没人能躲得过。 你，是不是也该重新想一想—— 我的工作，是不是正在被AI学会？ 我的技能，还有多大的不可替代性？ 如果有一天公司用AI取代我——我该怎么办？ 这很可能就是我们这一代人所面对的最大挑战。 别再装看不见了。 举报/反馈"
    },
    {
      "doc_id": 38250,
      "title": "史安斌 郑恩:超越新闻泰勒主义:人工智能时代新闻业的转型危机与...",
      "time": "2025-04-28T00:00:00+00:00",
      "content": "作者：史安斌（清华大学新闻与传播学院党委书记、教授，爱泼斯坦对外传播研究中心主任，本刊学术顾问）；郑恩（清华大学爱泼斯坦对外传播研究中心助理研究员） 来源：《青年记者》2025年第4期 导 读： 本文试图超越新闻泰勒主义与工具理性的双重束缚，着力探讨两个亟待解答的关键问题：首先，效率理性化背后潜藏的专业去技能化与新闻价值单一化如何避免；其次，平台依赖的技术政治学在“泰勒化”进程中如何形成并重塑公共价值与专业规范。 在人工智能技术在全球范围内持续迭代升级之际，新闻业正经历一场深刻的范式变革。以我国的DeepSeek等现象级应用为代表的新一波技术浪潮，不仅在公众层面激发了“技术狂热”，也在新闻机构内部悄然埋下了“技术解决主义”（techno-solutionism）的认知陷阱。[1]然而，学界现有研究多聚焦于人工智能工具的短期应用成效或效能评估，却鲜少深入剖析技术在被采纳过程中的结构性权力转移，以及其对公共价值与专业规范的深层影响。 在此背景下，本文试图超越新闻泰勒主义与工具理性的双重束缚，着力探讨两个亟待解答的关键问题：首先，效率理性化背后潜藏的专业去技能化与新闻价值单一化如何避免；其次，平台依赖的技术政治学在“泰勒化”进程中如何形成并重塑公共价值与专业规范。围绕这两大核心议题，本文细致梳理新闻机构在人工智能运用过程中的具体场景与运作机制，并借此揭示当代新闻业正经历的“技术—资本—职业规范”的三重博弈。在此过程中，“新质传播力”的概念不仅重新定义了传播的主体性和媒介特征，还从根本上改变了信息的生产与分发模式[2]，为探索超越新闻泰勒主义的现实路径提供了理论启示。 一、新闻泰勒主义：算法依赖与平台锁定的制度危机 AI技术对传媒业的全面介入推动了新闻生产流程的“泰勒主义”转型。这一概念源自美国工程师弗雷德里克·温斯洛·泰勒（Frederick Winslow Taylor）在其著作《科学管理原理》中提出的“科学管理”（Scientific Management）理论，其核心理念在于通过精细化分工、量化考核及流程标准化来使生产效率最大化，并在此过程中将劳动者的技能与工作环节进行高度拆解与简化。[3]传统媒体的新闻采编机制依赖记者的社会洞察与经验来决定选题和版面。进入人工智能时代，在新闻泰勒主义逻辑下，记者编辑被要求按照算法或数据指标执行更为标准化的内容生产任务，由数据模型决定选题方向，绩效指标衡量文章的传播效果，人工智能工具把关标题优化和发布时机等。新闻泰勒主义不仅仅体现在生产流程的标准化和自动化，更意味着新闻劳动的“去技能化”（deskilling）与内容决策的算法化。[4]传统新闻工作者依赖经验、直觉和社会洞察力决定选题、判断新闻价值，如今，这一系列工作越来越多地由数据驱动的系统完成，记者被迫适应流水线般的写作要求，生产符合算法偏好的“最优内容”。生成式人工智能的“黑箱化”本质使得技术的应用不仅是功能性工具的扩展，而且是对社会认知与生产逻辑的深刻塑造，这反映了技术如何在新闻生产中发挥深层影响，尤其是算法与新闻生产流程的互动问题。[5] 从本质上看，新闻泰勒主义实质上是对传统新闻价值观的隐性重塑。过去，记者编辑对新闻生产的决策主要基于公共利益、新闻伦理和多元叙事的综合考量，而AI逻辑则更倾向于依据历史数据预测内容的传播效果，这不可避免导致了趋同化、迎合性的内容生产模式。正如《纽约时报》一名高级编辑所言：“在自动化选题系统下，我们被告知哪些新闻‘更可能成功’，但没人再问什么新闻是‘值得报道’的。”[6]由此可见，表面上的效率提升背后，潜藏着对专业判断的弱化、对新闻价值多样性的漠视，以及对新闻行业独立性与公共责任的潜在侵蚀。值得注意的是，人工智能的绩效在很大程度上首先取决于被输入的数据信息质量。同时，随着深度神经网络的广泛应用，决定人工智能绩效的算法本身具有“技术的黑箱性”，这一现象在新闻生产领域中表现得尤为突出。[7]算法对新闻生产流程的主导作用，不仅带来了效率上的显著提升，同时也引发了关于技术自主性和系统不可控性的一系列深层次问题。 与传统的媒体—平台依存关系相比，AI时代的权力结构正在向基础设施控制层面深入渗透：当算力、云存储与核心算法都掌握在大型科技公司手中，新闻机构实际上已陷入对平台的不可逆依赖。约77%的受访机构在日常新闻生产中依赖亚马逊云转录服务（AWS Transcribe）或谷歌云视觉（Google Vision）等服务。具体而言，这种技术依赖形成了三重锁定效应：算力贫困化、数据闭环化和认知依附化。一方面，媒体机构因财政或规模限制难以自行承担昂贵的云计算设备；另一方面，大量生产数据（包括文本、音频、用户交互数据等）被实时回流至平台公司，用于进一步训练其算法模型，而媒体自身却仅能在API调用层面获得有限的访问权限。更为隐蔽的是，当《每日电讯报》采用谷歌云自动机器学习（Google AutoML）工具进行个性化推荐后，编辑方针即被嵌入难以解释的算法参数之中，新闻职业规范逐渐让位于系统的技术逻辑。[8] 在这一过程中，平台公司通过“云服务—API接口—开发者生态”三位一体的商业架构，利用基础设施层面的垄断地位深度掌控媒体的新闻生产链。英国广播公司（BBC）新建的人工智能实验室全面依赖谷歌提供的技术框架（Google TensorFlow），其技术路线和创新空间实际上被锁定在平台公司预设的轨道之上。在技术中心论的逻辑下，新闻泰勒主义不仅改变了新闻机构自身的运营逻辑，也深刻重塑了信息生态的权力格局。当算法迭代发生时，媒体只能被动跟进；当平台关闭某项服务时，媒体的深度报道或数据存储则可能瞬间瘫痪。 针对上述隐忧与挑战，学界现有的研究在三个方面有明显局限。其一，工具论视角往往将AI视为中性的效率工具，忽视了技术在社会建构过程中的内在权力博弈；[9]其二，创新扩散理论过度关注技术采纳的线性过程，却难以解释平台依赖形成后所出现的路径锁定与难以逆转的结构性问题；其三，传媒经济学研究多聚焦于商业模式分析[10]，却缺乏对劳动过程转型与专业技能退化的微观考察。 本文采用“跨国文献分析法”，通过整合多个国际组织、学术机构和行业调查报告（详见表1），结合跨国比较的研究视角，揭示人工智能技术在新闻业中的深层影响。选择这一方法的核心逻辑在于，人工智能的渗透在全球范围内具有普遍性，同时在不同国家和地区展现出独特的实施模式和影响机制。通过综合分析多个具有代表性的研究报告，本文旨在全面审视AI对新闻生产、平台依赖及公共领域功能的影响，进而提出相关的制度创新与应对策略。 表1 人工智能与新闻业转型跨国研究报告概览 二、垄断根基：基础设施捕获与数字封建主义 新闻泰勒主义在生产与内容决策层面已让记者与编辑深陷标准化与去技能化的束缚，但更深层的危机是平台公司利用云算力、数据回流及生态封闭等手段，实质性地改变了媒体在主流价值界定和引领方面的地位。[11]随着关键技术基础设施被集中控制，新闻机构在“被赋能”的同时也被纳入平台的资本逻辑与技术逻辑，从而陷入了受平台节制却无法独立自主的制度性陷阱。当这一局面不断固化时，媒体往往只能通过让渡数据、采纳既定算法来换取局部生产效率的提高，却难以在制度层面构建自身对公共领域、社会责任和多元价值的守护机制。这意味着，若媒体无法摆脱底层架构上的依附地位，超越新闻泰勒主义的努力也只能局限于表层流程的改进，而无法真正触及公共话语主导权与文化再生产权的根基。 （一）算力霸权与数据闭环 平台公司通过“云—端—芯”三位一体的技术基座，正在重新定义新闻业的创新生态。Google TPU芯片、微软Azure云计算与亚马逊网络服务（Amazon Web Services，以下简称“AWS”）构成了算力霸权的基础设施。《卫报》在其机器学习项目中原本计划大规模训练深度模型，但因无法承担AWS弹性计算成本，不得不将训练规模缩减至原设计的23%。这一算力分配格局导致新闻媒体陷入了技术垄断的困境。具体而言，当新闻媒体机构83%的人工智能算力依赖第三方云服务时，其技术创新实质上受制于平台资源配给机制。[12] 与此同时，数据闭环的形成进一步加剧了这种不对等关系。美联社与Open AI公司的内容合作协议显示，新闻机构不仅需向平台提供历史档案数据，还要实时上传新内容进行模型微调，换来的却只是GPT-4 API（应用程序接口）每日5000次的调用权限。新闻机构为平台“供养”了高价值的数据，却难以获得等价的技术回报。《纽约时报》向谷歌云（Google Cloud）输入的新闻数据价值量是其获得服务价值的3.7倍。哈佛商学院教授肖莎娜·祖博夫（Shoshana Zuboff）将此形容为“数字封建主义”（digital feudalism）下的生产关系：在这种权力结构中，科技平台作为新的“封建领主”控制着基础设施和技术资源，而媒体组织则如同“数字农奴”，被迫向平台贡献数据贡赋，却无法换来同等程度的技术增值权。[13]这种不对等关系体现为媒体提供宝贵的内容和用户数据，却只能获得有限的平台服务和算法可见性作为回报。对于当今的新闻媒体机构而言，这种“数据—服务”交换失衡已成为人工智能时代的新常态，他们既需要实时性与海量算力来保持报道竞争力，又被迫放弃对数据与算法主权的掌控。 （二）算力分配与“认知外包” 大规模预训练模型的崛起使平台公司不仅掌控了基础设施层面的算力与数据管道，更在认知框架上重塑新闻机构。《金融时报》在采用谷歌云自动机器学习（Google AutoML）构建个性化推荐系统时，将用户兴趣量化为152维特征向量，然而其中38%的维度定义权完全由平台主导。这导致了编辑团队对算法核心逻辑缺乏理解，只能接受系统生成的“推荐结果”。当系统将“商业报道”与“奢侈品广告”的关联权重设定为0.87时，财经新闻选题便悄然向消费主义倾斜，新闻议程实则被算法的“无形之手”引导。 德国电视二台（ZDF）的案例则揭示了更为深刻的危机：其人工智能辅助剪辑系统高度依赖微软智能云（Microsoft Azure）视频分析API。2022年制作一部气候主题纪录片时，系统自动过滤掉72%的非结构化访谈素材，优先保留量化数据片段（如温度曲线、碳排放统计），致使纪录片叙事被限制在可视化图表与数据逻辑中，而严重忽视人文层面的多元诉求。算法规训正将复杂社会议题“压缩”为可计算对象，背后实为平台公司对叙事逻辑的隐性控制。[14]无论选题还是素材筛选，均在“算法黑箱”影响下渐离新闻机构既定的编辑准则。 这种“认知外包”（cognitive outsourcing）不仅使媒体在日常生产中严重依赖平台模型，也使其丧失了对编辑方针和社会价值塑造的自主权。[15]若此种依赖持续深化，其影响将超越技术层面，改变记者、编辑与受众间的互动模式，最终导致公共话语权向平台公司集中。在此格局下，平台承担核心的“思考与分析”功能，而编辑团队则沦为算法预测与建议的“修饰者”，难以维持真正的独立判断。 （三）创新陷阱与技术封建主义 平台公司通过构建开发者生态进一步强化对新闻业的系统性控制。AWS推出的“新闻业人工智能解决方案套件”整合了17个预训练模型与45个API，《华盛顿邮报》视觉识别系统深度对接该生态后，其87%的核心功能模块已实现API直连调用。这种技术依赖形成显著的锁定效应：当该报试图替换图像分类模块时，系统架构重构率高达68%，迁移成本巨大。尽管开源社区提供替代性方案，但实际应用效果有限。以“抱脸网”（Hugging Face）平台提供的开源BLOOM模型为例，《卫报》技术团队因分布式训练基础设施缺失导致部署失败，平台企业则趁此机会通过专利布局巩固技术霸权。谷歌在自然语言处理领域持有的2143项核心专利，构建了从文本生成到语义分析的全链条技术壁垒。[16]对资源禀赋有限的新闻机构而言，跨越专利与算力门槛的难度显然远超想象。 由此观之，依赖平台公司构筑的技术生态不仅强化了新闻泰勒主义的运行逻辑，更使新闻业陷入算力垄断与数据回流的多重桎梏，形成“数字封建主义”的制度化收编。倘若新闻机构无法从基础设施与核心算法层面突破平台的垄断地位，不仅其独立性与社会责任将持续受到侵蚀，想要真正超越新闻泰勒主义更将举步维艰。 三、算法规训与公共价值：多元对话的断裂与重构 在基础设施垄断日益强化与新闻泰勒主义不断延伸至内容分发领域的双重挤压下，新闻业构建与维护公共价值的压力显著增加。当劳动流程被算法化、记者在生产环节沦为“流水线”式执行者的同时，算法对受众端的话语与信息选择也施加了深刻影响。由此形成的“算法规训”不仅改变了新闻作品的可见性与传播路径，更在潜移默化中重塑公众认知与社会议程，使多元对话空间不断萎缩。在这种情况下，新闻机构若要捍卫公共价值，必须突破“泰勒化”的生产—分发逻辑，从制度化与多元化维度探索新的突围路径。 （一）信息生态的系统性风险 1.可见性剥夺：搜索优化的逆向淘汰。谷歌公司推出的搜索生成体验（Search Generative Experience，SGE）工具引发了媒体可见度的系统性危机。根据SimilarWeb监测平台数据，用户检索“气候变化政策”时，AI生成摘要对《卫报》《纽约时报》等头部媒体内容的引用率达92.6%，但仅16.8%的案例提供原文链接，致使新闻网站访问量同比骤降37个百分点。[17]当平台系统推行“答案优先”策略时，新闻机构实质上沦为结构化数据库，其与受众的直接对话通道被系统性截断。这种“注意力收割”机制导致的媒体生态位塌缩，标志着新闻泰勒主义开始渗透到内容分发体系的“毛细血管”。原本需要多方博弈的公共议题讨论，被平台算法压缩为标准化响应输出，导致媒体的阐释权与议程设置能力遭受双重削弱。《华盛顿邮报》的跟踪研究显示，其环境类报道在SGE结果中的曝光度虽提升了42%，但实际点击转化率仅为传统搜索模式的23%，印证了“即时解答”范式对媒体流量池的虹吸效应。[18] 2.认知窄化：算法驱动下的议题聚焦与偏移。算法推荐机制正在诱发公共讨论的系统性偏差与认知窄化陷阱。牛津大学路透新闻研究院对《经济学人》数字平台的追踪研究表明，其用户画像系统通过谷歌分析系统（Google Analytics）构建的214个兴趣维度中，78.3%属自动化标签生成。当用户被划入“商业决策者”群体时，系统以0.92的权重系数推送并购资讯，0.87权重系数分配CEO专访，深度报道的接触率则衰减至4.7%。这一推荐逻辑在《世界报》“养老金改革”议题中呈现更显著的认知降维。用户平均阅读时长从8.7分钟降低至2.3分钟，折射出个性化算法对公共议程的结构化形塑。当社会成员持续暴露于此类“认知带宽压缩”机制，公共理性正面临标签化消费范式的系统性消解，社会认知能力呈现代际退化趋势。 3.文化同质化：生成式人工智能（AIGC）导致的叙事单一化。大型语言模型的文化再生产效能伴生着叙事同质化的系统性风险。对GPT-4生成的2300篇新闻文本的文体计量分析表明，程式化“倒金字塔结构”占比达89.2%，而多元叙事框架（7.1%）与非线性叙事策略（3.7%）呈现结构性缺失。跨国媒体共享模型参数导致语料趋同，《华尔街日报》与《南华早报》商业报道的语义相似度达76%，验证了“算法趋同效应”。生成式人工智能的普遍运用导致了更深层次的“语料殖民主义”危机进一步加剧，模型训练数据隐含的英语中心主义使南半球议题遭遇“再现赤字”。非洲媒体联盟测算显示，GPT-4生成“粮食安全”的内容量仅为“加密货币”的三分之一，揭示技术霸权下的叙事权力失衡。 （二）从技术自主到人机协作 平台垄断与人工智能泛化语境下，新闻业突破“泰勒化”困局的关键在于建构技术主权与认知劳动的新型平衡。BBC的“国家媒体云平台”（NMC）项目（资本支出2亿英镑）通过开源BERT改进模块与本地私有云架构，将核心技术依赖度从91.7%降至68.4%，模型训练边际成本缩减37.2%。同步推进的“欧洲语言技术联盟（ELT）”借助多语种语料库与分布式算力池，其成员机构人工智能开发总成本出现了41.3%的降幅，证实了区域化技术联盟的自主性增益效应。这些实践构建起对抗平台垄断的制度性反垄断架构，为媒体技术主权建设提供了可复刻路径。 应对认知劳动的“泰勒化”危机，路透社“人机协作编辑”项目通过胜任力模型重塑实现突破。量化评估证实，该岗位将批判性思维（权重65.3%）与伦理判断（权重22.1%）确立为核心指标，使记者数据解读能力提升39.4%，同时维持叙事创造力基准值（μ=82.5）。这种认知增强型岗位设计通过提示工程优化与交互式叙事工具开发，形成人机认知劳动分工的再平衡机制，有效遏制了人工智能对专业判断力的侵蚀。 （三）协同治理的制度创新 “公共领域”的范式转换需要构建全球协同的技术治理矩阵。北欧新闻数据联盟（NDA）通过制度经济学创新，建立含870万篇脱敏新闻语料的共享数据库（参与机构贡献度与访问权限呈0.78正相关）。挪威和瑞典的多家媒体气候预测模型精度提升了52.3%，验证了“数字公地”（digital commons）对平台依赖的替代效应。[19]这种由诺贝尔经济学奖得主奥斯特罗姆倡导的“公地治理”框架被运用于数字空间，通过动态平衡数据主权与协同收益，为跨域合作提供了制度性保障。 全球治理层面，联合国教科文组织《AI伦理建议书》（193国签署，覆盖率98.5%）构建起算法问责制框架：禁止新闻语料商用训练（第7.2条）、设定人工干预阈值（第12.4条）、建立第三方审计机制（第15条）。先锋媒体如《卫报》通过区块链溯源系统，将AI参与度编码为可验证元数据，这种技术信任机制使公众得以解构算法黑箱，辨识潜在偏见。 从新闻实践角度观察，“算法规训”使记者编辑在内容选题和价值判断上日益处于被动地位，“公共价值”正面临前所未有的碎片化与单一化冲击，传统的编辑自主权与专业规范难以有效落实。因此，制度重构在当下不仅是一种自救尝试，更是确保新闻业继续履行社会责任与公共价值的必然选择。在平台化垄断的背景下，单个机构或国家难以与掌控巨大算力和用户入口的跨国平台直接对抗。区域性或跨国型的“数字公地”建设、反垄断和数据保护立法，以及对算力与API服务的监管，已成为重塑新闻业独立地位与公共责任的关键路径。只有通过集体行动与跨国合作，媒体才能在算法与技术资源上获得更大自主权，避免陷入对平台程式化逻辑的被动依赖。当反垄断与版权补偿、跨国伦理规范与协同治理等多元手段相互融合时，超越新闻泰勒主义才具备了现实可行的制度化路径。这种多维制度创新正逐渐成为人工智能时代新闻业在存续与发展过程中的战略选择。 四、超越“泰勒主义”：新闻业主体性的重建路径 新闻机构通过自动化技术与推荐算法应对市场变革时，其技术基础设施的依附性已超越工具层面，呈现出“技术封建主义”的结构性困境。这提示着数字化转型本质上构成资本逻辑对公共领域的制度性重构，既动摇了传统新闻规范的专业根基，更在认知维度上构成了价值筛选机制的代际风险。值得关注的是，欧盟通过《数字市场法案》（Digital Markets Act）建构的反垄断框架，与行业先行者在人机协作模式中的突破性探索，正在解构技术决定论的认知范式。新闻业的技术自主权恢复路径，本质上是制度约束、价值重构与技术伦理的协同演进过程。 （一）理论升维：AI效率悖论、平台锁定与公共领域重塑 人工智能在新闻业的深度应用正在突破传统效率框架，呈现出边际效用递减规律：自动化系统的大规模引入虽在初期显著提升生产效率，但当技术渗透至事实核查、价值叙事建构等核心环节时，新闻机构的品质指标（读者信任度、阅读时长等）却呈现系统性衰减。新闻生产中至关重要的事实核查需要复杂语境判断，而多元价值叙事则依赖人类认知整合。但上述这些本质属性既无法被算法完全量化，更难以通过技术替代实现价值增殖。 平台依赖在此过程中固化为结构性技术锁定范式。科技巨头构建的“云服务—API—专利”商业架构形成创新壁垒，典型如《华盛顿邮报》视觉系统87%功能模块深度嵌入AWS架构，其系统迁移净现值测算达-230万美元。这种成本结构迫使新闻机构以数据主权换取有限技术权限，实质构成数字时代的“技术封建主义”生产关系——与泰勒主义通过劳动分割实现控制强化的历史逻辑形成跨时空呼应，在AI时代异化为平台对技术栈与数据流的绝对垄断。所谓“平台赋能”在此语境下演变为单向度的资源汲取机制，当新闻机构丧失关键技术自主权，其创新空间便被压缩为寡头生态中的边际调适。[20] 更严峻的危机在于“公共领域”的系统性解构。大型语言模型与搜索生成体验（SGE）通过答案前置机制重构信息权力结构：SGE在拦截68%访问流量的同时，将深度报道压缩为极简摘要，导致媒体网站点击量下降。这种“数据幕后台”效应不仅架空新闻机构的议程设置能力，更使公共讨论陷入碎片化困境。简言之，新闻泰勒主义以效率至上原则侵蚀媒体社会功能，用流量指标置换多元价值，最终消解公众的深度思考空间。 （二）实践启示：从技术垄断到协同治理的未来 破解新闻泰勒主义困局需构建“制度—技术—价值”三维治理框架。面对算力霸权与数据封建的双重桎梏，新闻业应通过强制性反垄断与数字公共产品供给重塑技术主权：欧盟《数字市场法案》已表明，强制开放API接口可使媒体算法自主性提升27%，并通过数据回流机制重构云端定价权。若配套推进“数字反垄断基金”建设，中小媒体将获得基础算力与开源技术支撑，从而突破对科技寡头的结构性依附。 构建算法可解释性框架是维护媒体独立性的关键机制。通过立法确立算法影响评估制度，强制披露新闻AI的训练数据溯源与决策参数权重，可建立技术黑箱的“透明度基线”。路透社对“人机协作编辑”岗位的实践也佐证，人工审计与自动化并非对立，而可共同发挥纠偏功能，以提升新闻的客观性与信任度。这种协同机制有效化解了新闻泰勒主义的根本矛盾：传统泰勒主义通过劳动分割实现效率最大化，而人工智能时代的新闻生产则面临专业价值与平台逻辑的范式冲突——选题策划、内容分发等核心环节的算法化改造，实质是对新闻职业规范与公共责任的解构性重组。 制度创新的终极目标在于重建技术治理的公共价值锚点。相较于泰勒主义单一效率导向，新闻业的数字化转型必须维系“效率—责任—多元性”的动态平衡。当算法沦为平台资本增值工具时，唯有通过基础设施公有化、数据资源民主化与算法决策透明化的制度设计，才能真正走出新闻泰勒主义对新闻业的桎梏，并为数字时代的公共领域注入新的活力。 换言之，走出新闻泰勒主义的困境并非仅仅意味着技艺层面（如采编自动化、写作效率）的改良，而是要从制度结构和社会治理层面全面反思媒体与平台、媒体与公众之间的权力关系和责任边界。面对跨国科技巨头主导信息基础设施的事实，通过国际规范[如欧盟的《可信人工智能伦理指南》（Ethics Guidelines for Trustworthy AI）等]与地方立法（如反垄断法案、媒体与平台数据共享协议）的协同演进或能塑造媒体的再生能力。未来的新闻业或许将在此过程中，通过“制度—技术—价值”三者的统合来重建专业主体性和公共使命，实现从技术依附到价值主导的范式转换。 【本文为清华大学文科建设“双高”计划创新方向建设专项“中国特色国际传播理论体系”（编号：2024TSG08103）成果】 参考文献： [1]Dovbysh O. Automating the news: How algorithms are rewriting the media[J]. Digital Journalism,2020(08):972-974. [2]史安斌，郑恩.新质传播力：迈向传播学3.0研究的范式升维[J].新闻与写作，2024(12):50-63. [3]李新春，胡晓红.科学管理原理:理论反思与现实批判[J].管理学报，2012,9(5):658-670. [4]史安斌，郑恩.迈入“融合性真实”：文生视频技术对新闻传媒业态的重塑 [J].传媒观察，2024(04):27-36. [5]Peng X,Xu Q,Feng Z,et al.Automatic news generation and fact-checking system based on language processing [EB/OL]. (2024-05-17)[2025-03-01].https://arxiv.org/abs/2405.10492. [6]范玉吉，张黄茜.隐匿的力量：新闻生产与分发中的数据权力 [J].西南民族大学学报(人文社会科学版)，2024,45(3):132-141. [7]郭全中，李黎.生成式人工智能将通向隐秘的社会？——一个叠合黑箱的逻辑与实践[J].暨南学报 (哲学社会科学版)，2024,46(12):81-96. [8]Couldry N,Mejias U A.The Costs of Connection:How Data is Colonizing Human Life and Appropriating it for Capitalism[M].Stanford:Stanford University Press,2019: 47. [9]Feenberg A. Questioning Technology[M]. London: Routledge,1999:56. [10]Nixon, B. The business of news in the attention economy: Audience labor andMediaNews Group’s efforts to capitalize on news consumption[J].Journalism, (2017)21(1),73-94. [11]Ahmed N, et al. The growing influence of industry in AI research[J]. Science, 2023（379）:884-886. [12]Booth,R. Amazon-hosted AI tool for UK military recruitment 'carries risk of data breach'[EB/OL].The Guardian, 2024-12-17[2025-03-19].https://www.theguardian.com/technology/2024/dec/17/amazon-hosted-ai-tool-for-uk-military-recruitment-carries-risk-of-data-breach. [13]Zuboff S. The Age of Surveillance Capitalism: the Fight for a Human Future at the New Frontier of Power[M]. New York: PublicAffairs,2019. [14]Couldry N, Mejías U A. The decolonial turn in data and technology research: What is at stake and where is it heading?[J]. Information, Communication & Society, 2021,(26):786-802. [15]Hartley J, Petre C, Bengtsson M, et al. Autonomies and dependencies: Shifting configurations of power in the platformization of news[J]. Digital Journalism, 2023（11）:1375-1390. [16]许静，刘欣，蒋雪颖.新闻生产与生成式人工智能人机耦合的实践进路[J].南昌大学学报(人文社会科学版)，2023,54(5):114-122. [17][18]M?ller J,van de Velde R N, Merten L, et al. Explaining online news engagement based on browsing behavior: Creatures of habit?[J].Social Science Computer Review, 2020,38(5):616-632. [19]Appelgren E, Lindén C. Data journalism as a service: Digital native data journalism expertise and product development[J]. Media and Communication, 2020,8(2): 62-72. [20]吕鹏，周旅军，范晓光.平台治理场域与社会学参与[J].社会学研究，2022,37(3):68-91,227-228. 本文引用格式参考： 史安斌，郑恩.超越新闻泰勒主义：人工智能时代新闻业的转型危机与制度重构[J].青年记者，2025(04):84-90. 举报/反馈"
    },
    {
      "doc_id": 38251,
      "title": "皮尤美国公布 AI 威胁职业清单:收银员和记者风险较高",
      "time": "2025-04-04T00:00:00+00:00",
      "content": "IT之家 4 月 4 日消息，皮尤研究中心最新调查显示，对于人工智能（AI）对人类社会的影响，美国公众与 AI 专家存在显著差异。 皮尤研究中心针对 5400 名美国成年人和 1000 余名 AI 专家的调查显示，双方对 AI 的预期存在巨大鸿沟。 56% 的专家预测 AI 将在未来 20 年带来积极影响，而公众支持率仅为 17%。在日常生活应用层面，47% 的专家对 AI 扩展使用表示兴奋，公众比例骤降至 11%。值得注意的是，自 2021 年以来，公众对 AI 的担忧持续上升，持谨慎态度者远超乐观者。 调查发现性别差异在专家群体中更为突出：63% 的男性专家看好 AI 发展，女性专家比例仅为 36%。公众领域的性别差距较小（男性 22% vs 女性 12%）。 关于就业影响，73% 的专家认为 AI 会改善工作方式，公众仅 23% 认同。双方对具体职业风险的判断也不同：更多专家认为卡车司机和律师岗位将减少，而公众更担心工厂工人、音乐家、教师和医生受冲击。不过双方一致认为收银员和记者职业风险较高，仅不到 30% 受访者认为心理咨询师会受到威胁。 尽管存在分歧，专家与公众在两大领域达成共识：仅 10% 受访者认为 AI 会对选举产生积极影响；55% 公众和 57% 专家担忧政府监管不足，要求增强个人对 AI 使用的控制权。 举报/反馈"
    },
    {
      "doc_id": 38257,
      "title": "彭博社总编辑:人工智能时代新闻行业八大趋势",
      "time": "2025-02-18T00:00:00+00:00",
      "content": "参考消息网2月18日报道彭博新闻社网站近日刊发题为《新闻业将如何适应人工智能时代》的文章，作者是该社总编辑约翰·米克尔思韦特。文章摘编如下： 就在优质媒体对互联网和社交平台作出妥协时，另一场更大的变革随之而来：人工智能。 人工智能有望进入新闻行业的核心，改变我们撰写和编辑新闻的方式。它将对我们构成挑战，就像它正在挑战律师、编剧和会计师等其他知识工作者一样。以下是我的八个预言。 首先，人工智能将改变而非取代新闻生产者的工作。 让我们以企业财报的报道为例。当我最初到彭博社工作时，社里有一支专门撰写头条新闻、希望比竞争对手快几秒钟的“快手”记者团队。后来，自动化技术出现，电脑可以在几分之一秒里提炼公司新闻稿。人们曾担心失去工作，但机器需要人来指挥。首先，要告诉它们寻找什么，比如，在中国销售的苹果手机数量可能比实际收入对苹果股价的影响更重要。机器还需要人类发现和解读意外事件，例如某个首席执行官突然辞职是否有意义。 目前，彭博社仍雇用大致数量相同的人员分析财报，但财报报道覆盖的企业数量和报道深度都有了明显增加。工作也变得更有趣：它不再只是快速打字，而是要梳理出真正重要的内容。 人工智能很可能带来类似改变——生产的内容量将成倍增加，而节省时间将是人工智能可以提供的一个重要好处。 另一个明显可以提升内容量的方式是自动翻译，这使得更多新闻被更多读者看到，全球大型新闻机构的记者也能够用母语写新闻。 第二，突发新闻仍将具有价值，但被关注时间愈发短暂。 新闻价值没有显示任何下降的迹象。每当我们报道华盛顿、巴黎或北京的政策变化时，都能看到货币市场的大幅涨跌。但关键在于，这些被视为新闻的时间持续缩短。 对于就业数据等重大公告而言，新闻时长已经缩短到零点几秒，而我们的竞争对手通常是对冲基金，它们使用人工智能技术对这些数字进行与我们同样快速的研究。就收购或首席执行官辞职等突发事件的报道而言，这些衡量起来要困难得多。但我愿意冒险做一个谈不上科学的猜测：我在彭博社工作期间，股价变动所需的时间已经从几秒钟缩短到几毫秒。 人工智能将进一步加快这一进程，使之得到普及。这在很大程度上取决于版权协议的规定，但很可能未来越来越多的新闻，被迅速输入到像“聊天生成预训练转换器”(ChatGPT)这样的不只考虑一个市场的机器中，并在新闻中添加可能被称为“即时尝试”的内容。它可供所有人使用，或者提供给比现在更广泛的人群。 第三，新闻报道仍将拥有巨大价值。 到目前为止，我提到的一个基本要点就是你需要新闻报道。人工智能摘要的好坏只取决于它基于的故事。机器无法说服一名内阁部长告诉你总理刚刚辞职；它无法请首席执行官共进午餐；它无法撰写原创专栏文章，也不能哄骗受访者在直播中承认某件事。新闻编辑部仍需要现场记者。 第四，编辑面对的变化很可能大于记者。 把大多数编辑工作分解成一系列技能。首先是管理记者队伍：想必你能理解，我仍会自满地认为编辑部将需要像我这样的人。其次是指派记者撰写稿件：我再次认为这仍然主要是一项人类技能，尽管彭博社已经使用人工智能来提示我们考虑撰写某篇报道。 不过，一旦报道被提交进入文字修改环节，人工智能工具将发挥越来越大的作用，包括调整和改写原稿、核对事实等。 第五，搜索世界将让位于问答功能。 随着像ChatGPT和“困惑”人工智能公司(Perplexity)这样的海量摘要工具吸收越来越多的新闻报道，它们将利用这些报道构建答案。我的同事、领导彭博新闻社产品团队的克里斯·柯林斯认为，传统的搜索功能将会消失。 这将对依赖搜索类广告和浏览量的企业产生重大影响。目前，当读者点击某一链接时，出版商可以从广告商那里获得几分钱。但是，当你从搜索引擎(或者干脆说是答案引擎)获得越来越多的回答时，这些点击量将会减少。 对严肃新闻出版物来说，这也是为什么要建立可持续的订阅业务、与忠实读者建立长期关系的重要原因。 第六，文字“幻觉”比音视频“幻觉”更容易被揭穿。 如果你与记者们讨论人工智能，可能有人会提到“幻觉”——即认为机器会捏造或被诱导捏造报道。人工智能不可避免地会经历一定程度的试错，而世界上不乏有认为可以通过欺骗获得商业或政治利益的人。我认为在可预见的未来，主要危险是人工智能被可能用来生成虚假的视频或音频，扭曲或恶意放大实际发生的事件，而不是完全捏造虚假的事件。 第七，个性化将成为一种现实。 这又是一种预感。个性化一直是数字新闻的圣杯。设想一下，你得到仅自己所需的新闻：一份个性化报纸。到目前为止，这种目标实现得还相当粗糙。很多人不喜欢把自己知道的细节交给新闻机构，即使这样做似乎符合他们的利益。当你提出建议时，一些读者会感到害怕，他们担心陷入信息茧房。读者们怀念的是那种偶然性元素，即你不知道自己会感兴趣的故事。 人工智能将开始破解这一难题。这种预测性内容个性化也有其阴暗面。预测我们喜欢园艺课程的算法，同样也会引导刚被女友甩掉的青少年观看有关自杀的视频。 目前，社交平台公司并没有像我这样的编辑，对它们在网络上的内容抱有责任意识。根据美国臭名昭著的“230条款”等规定，科技巨头被当作通讯公司，而不是媒体公司对待。它们对线路负责，但不对线路上传播的内容负责。 这种论调已经相当陈旧，随着人工智能愈加强大，我预测这种论调会更加过时。我认为科技巨头将输掉这场斗争，尤其是当任何父母都可以谈论它们的产品成瘾性时。 这将引出我的第八个、也是最后一个预言：监管即将到来。 对于世界各地的政客来说，人工智能只会变得过于复杂、强大、具有侵入性，以及过于美国化(如果你生活在美国以外)，他们不可能听之任之。上世纪90年代，美国政客试图给予年轻的互联网公司自由，以便它们进行创新。现在，没有人认为亚马逊、微软和脸书等公司需要受到保护。情况恰恰相反，企业在遵守法律之外必须做得更多。社会只有在认为某个特定企业行善时，才会乐于给予其有限责任等特权。实际上整个行业都可能失去社会特许权：你会从“酷炫创新者”沦为“罪恶大富豪”(西奥多·罗斯福一个世纪前引入反托拉斯法时对强盗资本家们的称呼)。 目前可以看到科技巨头身上正在发生同样的事情。在美国，政治纷繁复杂，即使美国议员不喜欢科技巨头，仍将其视为美国领先中国经济的重要优势。在布鲁塞尔，这样的疑虑会少一些，尤其是欧洲政客们意识到他们在人工智能方面落后有多大时。 上面这些都是我笼统作出的预言。再说一遍，我可能会像错过10天前刚成立的类似推特的人工智能项目那样，错误地作出关于人工智能的预言，但这八个有据可循的猜想将把我们的世界，以及1987年以来一直为我提供高薪工作的行业引向何方？我认为总的来说，我们可以在一定程度上保持谨慎乐观。（编译/曹卫国） 2月11日，媒体记者在法国巴黎大皇宫采访人工智能行动峰会。（新华社） 举报/反馈"
    },
    {
      "doc_id": 38259,
      "title": "AI版星球大战!特朗普签署AI行动计划,万亿美金押注全球AI霸权",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "编辑：编辑部 【新智元导读】刚刚，美国AI行动计划正式上线！28页PDF围绕三大支柱：AI创新、AI基础设施、全球AI规则，推出90多项行政令。放松AI监管、全球推广开源模型，大力投资超算、半导体建设等，直指全球AI霸主地位。 今天，美国白宫正式发布「AI行动计划」，目标直指全球AI霸主地位。 在白宫，特朗普签署了这项即将影响全世界的重磅计划。 现场，他向全世界宣告：「从今天起，美国的政策是尽一切可能，在AI领域引领世界！」 白宫AI「沙皇」David Sacks表示：「我们正处于一场AI竞赛中，希望美国能赢得这场竞赛」。 这份长达28页PDF中，涵盖了90多项具体行政指令，重点押注在AI技术上的创新和投资。 核心战略一共分为三大部分： 加速AI创新 构建AI基础设施 引领国际AI外交与安全 报告地址：https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf 「AI行动计划」中，白宫决定松绑AI，废除拜登时期的监管措施，如Order 14110，让科技企业自由创新。 最关键的是，在开源AI方面，推广在全球范围内自由使用、修改、出口AI模型。 针对算力，美国决定要大规模扩展基础设施，加速数据中心的审批流程。 甚至，他们要不惜动用联邦土地加速超算建设，并在电网关键时刻保障其电力供应。 此外，美国还要大力出口AI技术，开发出国际「全栈」的解决方案。 这份文件更像行动纲领而非操作手册，方向却十分明确：发展才是硬道理。 特朗普政府将其标榜为「开启人类繁荣新黄金时代」的唯一路径。 可以说，「AI行动计划」的发布，为美国的下一个世纪编写了「源代码」。 太长不爱看版： · 输出美国AI技术：向全球盟友提供安全的全栈AI出口方案（涵盖硬件、模型、软件、应用及标准体系） · 加速数据中心建设：简化审批流程，启动国家专项计划培养高需求职业 · 破除创新壁垒：废除阻碍AI研发部署的繁冗联邦法规 · 捍卫前沿模型言论自由：更新联邦采购指南，确保政府仅与承诺消除系统意识形态偏见的前沿LLM公司合作 ChatGPT浓缩版 支柱一：加速AI创新 在加速AI创新上，既有立法和政府部门的措施，也有下一步美国AI产业和学界投资建议与计划。 特朗普的「十字军东征」 在立法和监督上，主要包括2大措施： （1）消除繁文缛节与过度监管 （2）确保前沿人工智能保护言论自由与美国价值观 其中，加速AI创新是首要政策是放松监管，远在其他AI投资、AI研发、AI普及之前。 这被美国媒体当做这次AI计划的最大特点。 技术媒体《连线》认为：这是特朗普反对「偏见」和监管的十字军东征。 这是在特朗普AI方针的延续。 美国版「DeepSeek」来了？ 开源与开放权重AI，是这次白宫最大的转变。 这次的计划特意强调了开源与开放权重AI的价值，既能推动创新，学术价值也很高，还具有地缘战略价值： 初创公司可以灵活使用开源模型，而不必依赖封闭模型提供商。它们也促进了AI在商业和政府中的应用，因为许多企业和政府拥有敏感数据，无法将其发送给封闭模型供应商。 此外，它们对于学术研究至关重要，学术研究通常依赖于访问模型的权重和训练数据来开展科学严谨的实验。 在某些商业领域和全球学术研究中，开源和开放权重模型有可能成为全球标准。正因如此，它们也具有地缘战略价值。 建议的政策举措包括： 完善金融体系，在算力上扶持初创企业和学术界。 发布新版《国家AI研发战略计划》。 艾伦AI研究所的研究科学家Nathan Lambert表示 这标志着美国政府在对待并优先支持开源AI模型的态度上发生了重大转变。就整体而言，行动计划中的这一具体举措是一大胜利，但仍存在几点小瑕疵。 换句话说，「美国版DeepSeek」已经提上美国政府的日程。 AI赋能科学和可解释性 AI研究有5大措施，涵盖了科学发展、数据集、理论、可解释性和评估。 值得注意是，这次要推动AI科学本身发展。 大语言模型和生成式AI代表了AI科学中的范式转变，而未来的突破也同样可能改变AI。 所以，这次计划认为美国需要针对性投资最具前景的科研方向，确保领先地位。 此外，还建议在美国政府个部门采用AI，特别是国防部。 Nathan Lambert认为这次的行动计划，好得像是来自平行宇宙：富有创意，功能性十足。 支柱二：构建AI基础设施 美国认为，要实现AI领导地位，必须要扭转「能源产能」长期停滞的严峻趋势。 AI的创新与发展，离不开强大的基础设施——生产芯片的工厂、运行芯片的数据中心，以及能源体系。 然而，美国当前存在的问题是，环境审批制度，以及其他监管规定，严重阻碍了基础设施的建设速度。 在基础设施领域，「AI行动计划」的第一条建议是，建立高效审批机制保障数据中心、半导体制造设施及能源基建安全。 具体实施措施中，白宫出台了多项具体法案，加速环境审批流程、让部门实现高效审批。 值得一提的是，他们还借用AI去优化环评流程，扩大参与能源部「PermitAI」项目的机构范围。 除此以外，第二部分计划中，还提出了其他7点核心的建议。 电网体系，要匹配AI创新速度 作为全球规模最大、结构最复杂的工程系统之一，美国电网必须升级足以支撑数据中心等未来高耗能产业。 不过，当前AI技术发展推高电力需求，导致电网压力持续加剧。 为此，他们建议首先要稳定现有的电网运行，优先保障现有电力资产安全，确保不间断、可负担的电力供应。 其次，最大限度优化现有电网资源。通过部署先进电网管理技术、升级输电线路、创新用电管理模式等方式实现。 接下来，还要优先保障可靠可调度电源并网，积极布局前沿发电技术，比如强化地热、核裂变与核聚变。 最后，要制定21世纪能源战略路线图。 通过「稳定现有电网-优化存量资源-拓展未来容量」三步战略，美国既能赢得AI竞赛，又能为全体国民构建可靠、经济的电力网络。 重振美国半导体制造业 半导体发明开启了现代科技革命，如今，美国必须让芯片制造回归本土。 政策建议包括： · 由商务部重组后的「芯片计划办公室」主导芯片制造 确保美国纳税人的投资回报；彻底取消「芯片法案」资助项目中所有非必要政策附加条件，简化阻碍半导体制造的监管流程。 • 由商务部牵头，全面审查半导体资助与研究计划 确保其有效推动先进AI工具在半导体制造领域的整合应用。 AI军用情报，超算高安全 鉴于AI在原始情报数据处理方面的卓越表现，以及未来AI可能展现的更强大能力，美国政府极可能将AI应用于最高机密数据的处理。 政策建议包括： • 制定高安全AI数据中心技术标准 由国防部、情报界、国家安全委员会及商务部下属国家标准与技术研究院（NIST）牵头，联合「商业AI安全倡议」（CAISI），协同产业界及相关联邦资助研发中心共同制定。 • 推动政府部门采用保密计算环境 为可扩展、高安全的AI运算任务提供支持。 专业人才，也要跟上 为构建支撑美国AI未来的基础设施，必须同步投资于建设、运营和维护这些设施的专业人才——包括电工、高级暖通技术员等众多高薪职业。 政策建议包括： • 明确AI基础设施核心岗位 • 制定现代化技能框架 • 支持行业主导的培训计划 • 拓展人才早期培养通道 此外，第二节还在强化关键基础设施网络安全防护、推进「安全设计」AI技术与应用，以及提升联邦政府AI事件响应能力上给出了详细的政策建议。 支柱三：引领国际AI外交与安全 最后一节，是美国向全世界发起技术渗透的核心。 「AI行动计划」中称，要在全球AI竞争中取胜，美国不能仅满足于推动国内AI竞发展，还必须全力促使全球各国采用美国的AI系统、计算硬件和技术标准。 当前，美国在数据中心建设、计算硬件性能和模型研发领域处于全球领先地位。 当务之急是将这一优势转化为持久的全球联盟体系，同时防止对手国家搭便车利用美国的创新成果和投资。 美国AI，向盟友输出 美国必须通过输出全栈AI技，包括硬件、模型、软件、应用和标准来满足全球需求，所有愿意加入美国AI联盟的国家都应获得这些技术。 AI算力出口，加强管制 先进AI算力是人工智能时代的关键要素，既能推动经济活力，又可催生新型军事能力。 因此，阻断外国对手获取此类资源，既是地缘战略竞争的需要，更是国家安全的要务。 为此，美国决定联合产业界共同探索利用先进AI算力芯片的现有及新型位置验证功能，确保这些芯片不会流入受关注国家。 此外，商务部应组建专项工作组，与情报界（IC）合作加强全球芯片出口管制执法，包括监控人工智能算力领域的新兴技术发展，确保全面覆盖可能发生芯片转口的国家或地区。 半导体制造出口，塞住漏洞 由商务部主导，针对半导体制造子系统制定新的出口管制措施。 当前美国及其盟友虽对半导体制造主要系统实施出口管制，但多数配套子系统仍未被纳入管控范围。 此外，「AI行动计划」还在协调全球保护措施、确保美国政府前沿模型国家安全风险评估领先地位、加强生物安全领域投资等三方面给出了具体政策建议。 文件亮点：开源是重点，不再卡脖子 AI行动计划一出，各界立刻总结了其中亮点。 计划的共同作者之一、Ai2大佬Nathan Lambert对此发表了长文博客。 他表示，如今美国政府的重点，就是如何激励更多更好的全开源模型，而不仅仅是推动更多AI研究。 如果不这样做，学术界就会剩下大量的计算资源，但只能用于研究那些无法反映性能和前沿的模型。 Lambert甚至自曝说，这就是为什么自己要在18个月内，完成「美国DeepSeek」项目。 而为了让初创企业和学术界能获得大规模算力，而非通过与超大云服务商签订长期合同，政府就需要加速推进健康的计算金融市场。 为此，政府已经有所行动，比如NAIRR已经向许多学术机构提供了API额度、数据、计算访问权限等资源。 总之，美国鲜有开源模型的原因是，它们并不能带来太多商业价值，而25年的一大亮点，就是让开源模型缩小能力差距，改变这种平衡。 外媒Wired则评论道，特朗普的这个计划，是一场反对偏见和监管的斗争，将为大科技公司提供更大的发展空间。 23年10月，拜登政府还在操心AI风险的问题，签署了一道力度空前的行政令，防止AI被用来制造生化武器、传播歧视、威胁国家安全。 但现在，特朗普的全新计划态度很鲜明——抛弃所有阻碍创新的繁文缛节！ 更亮的是，AI模型也必须摒弃觉醒病毒，如果谁家模型喜欢搞偏见，把性别平等、种族正义刻进推荐系统，那合同就没他们的份了。 甚至本来，特朗普还差点签署了「AI暂停令」，计划冻结各州AI监管立法的能力，不过临时被删了。 更令人意外的是，特朗普政府居然取消了部分对华AI芯片的出口限制。 这背后的意味也很明显：不再执着于卡脖子，而是让美国公司更快、更广泛地占领全球市场。 显然，美国如今的AI战略核心，已经从围堵变成了抢跑。 举报/反馈"
    },
    {
      "doc_id": 38262,
      "title": "OpenAI会杀死Manus们吗?",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "本文来自微信公众号：山上，作者：薛星星，头图来自：AI生成 和三月份发布文生图更新一样，OpenAI 又一次试图提前结束 AI Agent 的创业竞赛。 北京时间 7 月 18 日凌晨，OpenAI 发布 ChatGPT Agent。它可以根据用户的指令，自动规划执行步骤，调用多种工具，并完成从抓取数据到生成表格、规划行程到预订酒店等多环节任务。 OpenAI 推文截图 这也是目前多数 AI Agent 创业项目正在尝试的方向。4 个月前你在 Manus 那场号称首个通用 AI Agent 宣传片中看到了什么，ChatGPT Agent 就完成了什么。 OpenAI 创始人山姆·阿尔特曼（Sam Altman）说，这是他第一次“真正感受到 AGI（通用人工智能）”。OpenAI 的研究人员则表示，ChatGPT Agent 是目前为止最强的 AI Agent 模型。 是的，OpenAI 将 ChatGPT Agent 称为一个模型，而不是产品。与 Manus 等依赖上下文管理、工具链编排的系统不同，OpenAI 训练了一个专用模型，能够在单一系统中完成任务规划、跨工具调用和文档生成等复杂流程。该模型目前被归入 o3 系列，但尚未被单独命名。 AI 时代的创业者们面临着比任何历史时期都更快速的技术迭代，一次底层模型更新往往就能毁掉一个垂直领域的创新产品。 理想汽车创始人李想此前在朋友圈说，to C 层面，OpenAI 在内的掌握最强基座模型的企业，不会留下什么垂直应用的创业空间。“软件的本质是功能，需要场景化、垂直化。人工智能的本质是能力，能力强就可以吃掉一切，也是用户最方便的。” 就连一直高喊 AI 应用创新的朱啸虎也在社交媒体上表示，大模型会吃掉 90%的 Agent。X 平台上也有用户发问，如果 OpenAI 后续开放 ChatGPT Agent 模型的 API，其他创业者该如何与其竞争？ “Listen-that's the sound of a great many startups evaporating into the void.”（听——那是无数初创公司悄然蒸发的声音。) OpenAI 发布会视频下的一条高赞评论写道。 Manus们选择正面硬刚 至少在目前，Manus 们还没有表现出任何退让迹象。 OpenAI 发布会刚结束，Manus 就在 X 上转发推文称，“Welcome to the game.”同属于华人 AI Agent 创业公司的 flowith 也转发强调，他们早在一年前就推出了 AI Agent 产品。 作为过去半年最早对外喊出通用 AI Agent 口号的创业公司，Manus 的反应要比其他公司强烈得多。发布会结束仅 3 个小时，Manus 就一口气对外放出了 10 条与 ChatGPT Agent 的对比测试，宣称要和 OpenAI 正面较量。 这些对比内容部分来自 OpenAI 当日展示的演示片段，部分则来自用户在社交平台上的真实使用。涵盖场景包括数据整理、路线规划、在线购物、财务分析、餐厅预订等，Manus 发出的测试结果几乎全面占优——不仅响应更快，也更强调“任务完成度”，如表格更整洁、图示更丰富、PPT 更接近成品。 03:02 Manus发布的与 ChatGPT Agent 的对比视频 比如 OpenAI 演示的“计划一次为期三天的棕榈泉网球之旅”，OpenAI 给出的是一张简单的行程表，而 Manus 生成的则是一张带有目的地风格设计的行程海报。 Manus 发布的测试对比 又如分析旧金山市过去四年的财务报告，OpenAI 输出的是 Excel 文件，而 Manus 给出的是包含图表与要点总结的完整演示文档。“Manus 完成的是整个项目，而不仅仅是提供数据。”Manus 评价说。 另一家华人公司 Genspark 的反应同样高调。创始人景鹏（Eric Jing）在 X 上写道：“我从未想过有一天——作为一家只有 24 人的小公司，我们竟然可以领先……领先于 OpenAI。”他表示，用同样的提示词，Genspark 的响应时间更短、成本更低，生成结果的质量也“高出好几倍”。 7 月 19 日，Genspark 也在社交平台上分享了 9 个与 ChatGPT Agent 的对比实例，显示他们输出的文档数据维度更丰富，排版更加美观。除了与 Manus 对比测试中类似的旅游行程制定、财务数据分析等案例外，他们还分享了一则视频生成能力的对比，指出 ChatGPT Agent 未能完成任务。 Genspark 分享的视频生成案例 社交媒体上用户们的反馈也不如此前 OpenAI 更新文生图功能那样强烈。一些批评声音指出 ChatGPT Agent 任务的完成度不高，任务生成速度也比较缓慢，部分复杂任务需要 20 分钟乃至更长时间才能完成。 OpenAI 似乎也意识到当前的 ChatGPT Agent 的速度问题，他们拍摄的几条宣传视频里，员工往往在下达指令后就合上笔记本，等到稍晚再返回查看结果。 “即便耗时 15 分钟或半个小时，相比你自己手动完成也已经是显著的提速了。”OpenAI 的研究员 Isa Fulford 说。她表示，这是一种“可以在后台发起任务，过一会儿再回来查看结果”的使用方式，而 OpenAI 的搜索团队则更专注于低延迟场景。 OpenAI 或许更强调模型能够持续推理和思考的时间，OpenAI 的研究员张熙堃说，ChatGPT Agent 在内部测试中的最长连续推理时间达到了 2 小时，“我们应该有一个排行榜来记录模型能持续思考多久。” 针对外界诟病的生成文档或 PPT 不够美观的问题，OpenAI 的研究员们在 X 上建议，先让 ChatGPT Agent 把研究工作做完，再让它输出 PPT 文件。ChatGPT 生成的是标准 pptx 格式，用户也可以在 PowerPoint 中统一套用想要的设计模板。 虽然 OpenAI 强调他们专门为 ChatGPT Agent 训练了专用模型，但部分批评声音亦指责它更像是将此前已经推出的 Operator（浏览器交互能力）与 Deep Research（深入研究能力）组合在一起的产物。Operator 可以支持 ChatGPT 通过浏览器与网站直接互动、阅读并理解网页内容，Deep Research 则擅长分析和总结信息。 事实上，ChatGPT Agent 目前团队成员正是来自于此前的 Operator 与 Deep Research 部门，目前团队规模大约在 20-35 人。OpenAI 对外表示，ChatGPT Agent 是 Operator 和 Deep Research 功能自然延续，“我们发现用户通过 Operator 尝试的许多查询实际上更适合 Deep Research，因此我们将两者的优势结合在一起。” OpenAI 表示，这次发布仅标志着他们将智能体功能直接集成到 ChatGPT 中的第一步，他们计划定期逐步更新更多功能。 两种技术路线 相较于初创公司们过去半年来围绕输出质量和交付体验不断工程迭代和提示优化，OpenAI 刚刚发布的 ChatGPT Agent 在任务的最终呈现上可以称得上是粗糙。 初创公司们试图为用户呈现一个完成度更高且上手难度更低的 Agent 产品。以 Manus 为例，过去 2 个月来这家公司先后为产品加入了包括 PPT 生成、视频生成、音频生成等诸多不同能力，官网还列举出了诸多现成的模板分享以及用户案例分享。即便这些能力的实现都依托于外部模型，但至少在上手难度上，初创公司们都做得比 OpenAI 更好一些。 但抛去这些应用体验创新，在基础模型的能力比拼维度上，ChatGPT Agent 通过端到端训练的统一模型显然更有优势。OpenAI 为 ChatGPT Agent 做了诸多学术测试，部分测试结果甚至领先于 OpenAI o3 或 GPT 4o，达到行业最高水平。 比如在《人类的最后考试》（Humanity’s Last Exam）评估中，ChatGPT Agent 取得了 41.6%（pass@1）的新高，大约是 OpenAI o3 的两倍。DSBench 测试中，ChatGPT Agent 大幅度领先于 GPT-4o，在数据分析任务中的表现更是明显优于人类水平。 Humanity’s Last Exam 测试结果 在专门衡量电子表格编辑能力的 SpreadsheetBench 平台上，ChatGPT Agent 创下行业新高，性能较 GPT-4o 领先一倍。OpenAI 称，在他们的内部基准测试中，ChatGPT Agent 的能力大致相当于 1 至 3 年经验的投资银行分析师水平。 简单来说，OpenAI 更强调 ChatGPT Agent 带来的底层模型能力的提高，而初创公司们受限于技术及资金则更倾向于应用创新。 7 月 19 日凌晨，Manus 联合创始人季逸超发文称，Manus 仍将继续押注于上下文工程（in-context learning）而非端到端智能体。 他说，早在 Mannus 项目初期，他们就在思考是使用开源模型训练一个端到端的智能体，还是基于前沿模型的上下文学习能力构建智能体。GPT-3 等模型的出现让他们意识到，上下文工程才是正确的方向，因为这些模型的能力远高于他们此前的内部模型。 “如果模型进步是上涨的潮水，我们希望 Manus 成为那条船，而不是固定在海床上的柱子。”季逸超说，这可以使他们能够在几小时而非几周内交付改进，并始终让他免费产品与底层面模型保持正交。 他在这篇技术文档中分享了不少 Manus 在上下文工程上的经验，比如需要围绕 KV 缓存进行设计、要使用系统文件作为上下文等等。这些工程创新显著提升了 Manus 的响应速度以及成本优势。 季逸超举例，使用 KV 缓存可以大幅度提升首个 token 的生成时间和推理成本，例如使用 Claude Sonnet 时，缓存的输入 token 成本比未缓存的成本降低 10 倍。 季逸超分享的技术文档 上下文工程的创新的确也可以使智能体拥有更好的性能效果。非盈利人工智能研究机构 Epoch AI 测试了 ChatGPT Agent 在 FrontierMath 数学试题集中的表现，称 ChatGPT Agent 在 Tier 1-3 的数学题上只得到了 27% 的正确率，且难度越高得分越低。 但当每道题允许 ChatGPT Agent 尝试 16 次之后，它的得分就从 27% 大幅度提升至 49%。Epoch AI 说，这表明更好的提示词设计（prompting）或任务结构支持（scaffolding），可能会显著提升当前模型的性能。 Epoch AI 测试结果 换句话说，即便是相同的模型，创业公司们依然可以通过更好的提示工程与上下文设计，来达到远超基准模型的效果。 “你如何塑造上下文最终决定了你的智能体的行为方式：它运行的速度、恢复的效果以及扩展的范围。”季逸超说。 如何与 Agent 的未来共处 ChatGPT Agent 的正式推出，标志着 AI Agent 正式进入巨头博弈的时代。它带给人类的社会的影响不会比大模型爆发之初的影响小，让 AI 抢夺人类工作真正成了现实。 这种改变已经在悄然发生。微软和亚马逊等科技巨头们都在密集裁员，微软 CEO 萨蒂亚·纳德拉今年初表示，微软 20% 到 30% 的代码都由 AI 生成。一家金融科技公司 Klarna 更是早在去年初就对外宣布，他们的 AI Agent 仅投入使用一个月，就处理了公司 2/3 的客服聊天工作，相当于 700 名全职人工客服的工作量。 市场研究机构 MarketsandMarkets 表示，全球的 AI Agent 市场将从 2024 年的 51 亿美元增长至 2030 年的 471 亿美元，年均复合增长率（CAGR）达 44.8%。Deloitte 预测，到 2025 年，使用生成式 AI 的公司将有 25% 开始试点智能体，到 2027 年将增长至 50%。 AI Agent 的快速应用也让行业人士产生担忧。和过去大模型仅仅只是提供信息不同，AI Agent 真正具备了从思考到行动的完整能力。比如 ChatGPT Agent 现在已经可以访问网站帮助用户下单购物、自动填写信用卡地址，也可以访问用户的日历、电子邮件、云盘等隐私信息。对于使用 AI Agent 的人们来说，这意味着他们将自己的私人信息交给了一个“黑盒”，也更容易受到攻击。 发布会上，OpenAI 也专门强调了 ChatGPT Agent 的风险。他们强调，ChatGPT Agent 在执行所有重要操作前都会征得用户同意，“用户始终拥有控制权。”同时，OpenAI 还加入了包括主动监督（Watch Mode）、主动风险缓解（Proactive risk mitigation）等安全措施。 OpenAI 发布的声明 山姆·阿尔特曼在 ChatGPT Agent 推出后专门发布长篇推文警告用户，要求用户审慎地使用 ChatGPT Agent。 “Agent 代表着 AI 系统能力的新高度，它可以用自己的计算机完成一些令人惊叹且复杂的任务。它融合了 Deep Research（深度研究）和 Operator（任务执行者）的理念，但远比这些字面描述更强大 —— 它可以长时间思考，使用各种工具，再继续思考，再采取行动，如此往复。”山姆·阿尔特曼说。 山姆表示，虽然他们还不确定这些影响具体是什么，但也许会有人试图恶意“欺骗” 用户的 AI Agent，使其提供不应该提供的隐私信息，并做出无法预测的不当操作。“我们建议用户只授予 Agent 完成任务所必需的最低限度访问权限，以降低隐私和安全风险。”山姆强调，他不会将 ChatGPT Agent 用于高风险的用户或涉及大量个人信息的场景。 但对于已经演变成了一家商业盈利公司的 OpenAI 来说，它并不会因为隐私或者安全风险而减缓 AI Agent 迭代的步伐。 在 ChatGPT Agent 推出之前，《金融时报》就报道称 OpenAI 正计划在 ChatGPT 中开发支付结账系统，通过 ChatGPT 完成订单的商家需要向 OpenAI 支付佣金。《金融时报》称，OpenAI 已经向部分合作伙伴电商平台 Shopify 等展示了系统的早期版本。 本文来自微信公众号：山上，作者：山上 本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系 hezuo@huxiu.com 本文来自虎嗅，原文链接：https://www.huxiu.com/article/4596874.html?f=baijiabaiducom 举报/反馈"
    },
    {
      "doc_id": 38266,
      "title": "OpenAI扩大美军方业务 获得国防部14亿AI合同",
      "time": "2025-06-17T00:00:00+00:00",
      "content": "OpenAI 凤凰网科技讯 北京时间6月17日，据路透社报道，美国国防部周一在一份声明中表示，已授予OpenAI一份价值2亿美元(约合14.36亿元人民币)的合同，为国家安全开发先进AI能力。 美国国防部在声明中称：“根据本合同，承包方将开发前沿AI技术原型，以应对作战与国防企业领域中的关键国家安全挑战。”获得这份合同的是OpenAI旗下公共部门子公司OpenAI Public Sector LLC。 美国国防部表示，这项工作将主要在华盛顿及其周边地区进行，预计于2026年7月完成。位于华盛顿特区的国防部首席数字与AI办公室负责监督合同的执行，该部门已为项目初始阶段拨出近200万美元资金，用于研究、开发、测试和评估。 这项协议对OpenAI的公共部门来说，是一份具有重要意义的国防合同，因为美国政府正在持续加大对先进AI技术的投资，将其用于国家安全领域。 OpenAI上周表示，截至今年6月，其年化收入飙升至100亿美元，有望实现全年收入目标。(作者/箫雨) 举报/反馈"
    },
    {
      "doc_id": 38279,
      "title": "用AI检测AI,花钱降论文AI率却被改得一塌糊涂",
      "time": "2025-07-16T00:00:00+00:00",
      "content": "用AI检测AI，花钱降论文AI率却被改得一塌糊涂 2025-07-15 23:28:21来源：央广网 央广网北京7月15日消息（总台中国之声记者任梦岩）据中央广播电视总台中国之声《新闻纵横》报道，论文“AI味”渐浓，是高校共同面对的新难题。今年的高校毕业生在毕业论文阶段，除了传统的查重、盲审、答辩，毕业路上又多了一道关卡——AIGC检测，也就是人工智能生成内容检测。 不少高校引入了AI模型来“查文章AI生成内容占比”，而一些平台又推出了“降低现有文章AI生成内容占比”的大模型，但一些师生在使用过程中发现，这些所谓“降低AI率”的大模型表现实在一般，有时候越用大模型检测“AI率”越高。让AI查AI，靠谱吗？毕业论文检测，怎样更科学？ 00:00/00:00 hiRadio('.HiRadioPlayer'); 湖北的张同学在黑猫投诉上反映，自己用了一款“降AI率”软件后，不仅论文重复率上升了，AI率也没降下来。 “原本论文的查重率只有百分之三点几，但AI率就比较高了，有百分之四十多。我先是用了他们软件的AI降重，然后把AI降重之后的文章再拿去查重，结果AI率涨到了百分之五十，连查重率也涨到百分之四十多。就是说可能修改到最后，把你的论文结构，甚至有些内容表达的意思都改了。”张同学说。 云南的赵同学也认为，使用此类软件效果并不好，他的论文AI率被判定不符合要求，修改之后的表达也非常差。“充了几次钱，结果没想到AI率越来越高，至少花了四五十元，还是要自己再改，因为太口语化了。” 吉林的韩同学通过第三方平台检测自己的论文，发现AI率和重复率都很高，花钱使用软件进行所谓“降重复率、降AI率”后，得到报告称重复率和AI率已经降低，但论文提交后，直接被导师退回。 韩同学表示：“论文写完之后，我查AI率、查重率都很高，就想着用AI改一下，就在那个软件上花了128元，希望降重复率和降AI率，两个都降，之后就会出来一个报告，那个报告显示（重复率和AI率）只有百分之十几。结果我交上去之后，导师返给我说完全不合格。” 河南李同学的遭遇更为蹊跷。她的学校要求使用某“AI率检测平台”进行论文检测，第一次检测合格，第二次检测，却被告知“AI生成内容占比过高”。 李同学说：“我第一次检测的时候，它显示是一个低风险，AI率百分之十五点多，这是在论文答辩之前提交的。结果到答辩要提交终稿的那一天，内容完全没有变，可能格式稍微变了一点，相同的论文内容拿去检测，AI率变成百分之二十八了，这个是有点离谱的。” 在用完3次免费检测机会后，李同学的论文在该平台的检测结果，AI率还是超过了百分之二十，可通过其他检测平台检测，她的论文又是合格的。后来，她通宵改稿、又花钱在学校要求的检测平台上反复测试，才让自己的论文AI率降了下来。 “它每个平台都不一样，因为我在其他平台查的也是低风险，但是在这个平台查的就是高风险。第二天要封档案了，晚上8点的时候才去查，所以我特别着急，只能自己去改论文，并且又花了三次的钱去检测，大概155元。最终重新改到凌晨4点，最后才合格了。”李同学回忆道。 甚至一位老师也反映，查AI率平台给出的结果和所谓“降AI率”的软件都不太靠谱。“我在写论文的时候确实借助了AI，因为人家有一些句子确实比我写得好，我就进行了部分运用，第一遍查重检测出来的结果是百分之三十左右，投稿要求百分之二十以下才可以，我就修改降AI。大概费时一个小时，之后又进行了第二次检测，第二次查出来AI达到了百分之三十八，我就继续改，很认真地把那些内容又进行了梳理，然后融入了非常多新的内容，检测出来的结果是百分之四十五。此时此刻我分不清，到底文章是AI写的还是我写的。最后我把文章相当于全部重新写了一遍，所有的内容都更新了一遍，又融入了非常多的新思路，然后去查，终于降了，但依然是百分之三十四。明明是自己写的文章，每一个字都是我自己写的，它把我们所有人的文章吸收了，然后输出深度思考之后再发给我们，到底是我抄了它？还是它抄了我？” 那么，大模型到底是如何检测一篇文章中有多少内容是AI生成的呢？记者将这一问题抛给了多个大模型，总结相关的回答，简单来说就是通过“困惑度与突发性”等指征来判断，AI文本通常更“平滑”，人类文本波动更大。 大模型回答，困惑度指的是文本的“可预测性”，越充满人类特有的、意外的、跳出常规的表达，越像人类。突发性，就是文本节奏波动——人类写作如心电图般起伏，AI输出则如直线般平稳。如此判断，准确吗？工业和信息化部信息通信经济专家委员会委员刘兴亮告诉记者，除了困惑度、突发性等指标外，目前检测AI生成内容的方式还有很多，但准确性都做不到百分之百，误判也时有发生。 刘兴亮说：“文本生成的原理是什么？通过预测，可以理解为出现了一个张三，它预测下一个可能要说李四，通过预测下一个最有可能出现这种词的概率来逐渐生成文本，可以理解为它是一种概率统计出来的。现在还有一些更高级的检测指标，检查重复片段和常见的结构，看是否过于模板化，比如，常用词模式，标点的使用，句子的复杂度，是不是太过于规矩等。但不管是这种常规检测还是高级检测，我觉得目前都存在一些局限性，因为可以理解为它基本上还是靠一些统计特征，无法做到这种绝对的准确，而且误判的风险也比较高。” 刘兴亮告诉记者，目前大模型判断文章是否由AI生成的准确度都不高，再请AI降低所谓“AI率”则更不靠谱。 同济大学教育评估研究中心主任樊秀娣认为，AI大模型搜索内容可以作为参考，但一字不改地用就涉嫌学术不端。 樊秀娣表示：“如果你用AI大段地生成，其实从本质上来讲，这就是抄袭。学术诚信的角度来讲，它本身就是不被允许的，其实现在国内外很多高校都有明确的规定。” 樊秀娣告诉记者，使用AI来检查文章的“AI生成内容占比”结果，是否能立得住值得讨论，其实很多论文是否为AI生成，熟悉学生的老师肯定能看出来，答辩过程中，也能得到检验。 “有一点是可以肯定的，就是如果你靠AI来写论文的话，本质上是写不好的，因为老师对学生的指导更密切一点，师生经常互动的话，学生也就失去了用AI来写论文应付的必要性了。还有最重要的一点，就是在做毕业论文答辩的时候，其实要‘答’和‘辩’，评审老师就学生的某个学术问题提出问题，学生来回答。如果论文真的完全由AI生成，学生根本就不了解，那就无法完成答辩。”樊秀娣表示。 编辑:顾涵 原创版权禁止商业转载 授权>> 转载申请事宜以及报告非法侵权行为，请联系我们：010-56807194 专题 更多>>"
    },
    {
      "doc_id": 38280,
      "title": "向AI证明“我不是AI”的学术新困局何解 专家建议将AI生成内容纳入...",
      "time": "2025-07-14T00:00:00+00:00",
      "content": "原标题：向AI证明“我不是AI”的学术新困局何解 专家建议将AI生成内容纳入学术诚信规制体系 □ 本报记者 赵 丽 □ 本报实习生 宋昕怡 毕业季的喧嚣渐息，因“AI率”检测新规引发的争论仍在持续。 一面是学生绞尽脑汁“降AI率”，只为“向AI证明自己不是AI”以获得答辩资格，催生了“代降AI率”的隐秘灰色产业；另一面是教师在教学中对AI“介入”的困惑：查还是不查？用还是不用？ 这一学术监管难题正困扰全球教育系统。当论文写作任务恰好落入AI最擅长的领域，依赖“AI率”检测来评判，是否已偏离了教育的初衷？有高校人士坦言，高等教育正经历“山呼海啸般的改变”，关键在于如何合理使用AI。 对此，《法治日报》记者近日采访了首都师范大学教育政策与法律研究院副院长蔡海龙、北京外国语大学法学院教授姚金菊。 面临准确率瓶颈 记者：在社交平台上，“代降AI率”服务明码标价。不少学生认为当前AIGC率（生成式人工智能参与度）检测处于“博弈期”——既难精准识别AI内容，又易误伤原创。这类检测技术是否尚不成熟？ 蔡海龙：主流的论文AI检测系统主要使用困惑度和突发性指标来计算AI率，并结合论文的语言模式和风格特征进行整体识别。就当前来看，此类技术还远未成熟，其稳定性和可信性都面临不小的挑战，漏报和误报情况也时有发生，难免误伤真实原创内容。 姚金菊：目前AIGC检测技术确实处于典型的“博弈期”。一方面，AI生成内容的“人类化”速度正在加快。新一代大语言模型生成的文本不仅语法规范、结构清晰，而且在风格模仿、用词逻辑等方面不断趋近人类。这直接削弱了传统检测工具赖以判断的“语言指纹”，也使检测系统面临更高的误判风险。 另一方面，AIGC检测技术的发展相对滞后。目前市面上的检测工具，无论是商业的还是学术的，都面临准确率的瓶颈。研究和实践表明，这些工具不仅存在大量的“漏报”(未能识别出AI生成内容)，还存在令人担忧的“误报”(将人类原创内容标记为AI生成)。例如，一些行文流畅、结构清晰、语法严谨的人类作品，恰恰因为其“完美”而易被误判为AI生成。 记者：这种困境下，若学生陷入“用AI写，再用AI查改”的循环，是否沦为低效的文字游戏？ 姚金菊：当一些高校将AI检测结果等同于学术诚信评估依据，学生便被迫进入“规避AI率”的游戏——写完后自查，再不断微调语言、变换结构，甚至将其文字改为逻辑不通的语句，只为压低一个概率性指标，不仅浪费时间，更背离了写作的学习初衷。这实质上暴露出当前一些学校对AI的态度还停留在防范和压制阶段，缺乏真正的引导机制。 蔡海龙：学校如果过度依赖AI检测工具来评价学生的论文，那么势必会导致学生投入更多的时间和精力来学习如何规避检测。加强对论文的AI率检测，短期内或许可以形成震慑效应，但长此以往，无疑会使论文写作变为一场无休止的“猫鼠游戏”。 避免“算法一票否决” 记者：AI工具已深度融入写作流程（如润色、逻辑优化），边界模糊。禁止恐推高监管成本，促使隐蔽使用甚至催生灰色服务；鼓励又可能导致AI取代学生思考，削弱能力培养。“查AI率”政策，简单禁止或鼓励是否都不可行？ 蔡海龙：必须承认开展论文AI率检测确实能够在一定程度上避免学生对于AI写作的过度依赖，从而捍卫必要的学术标准和学术底线。 但就现实而言，任何极端的处理方式——简单禁止或全面鼓励都并不可取。取消检测，可能导致学生直接提交AI成果，引发严重学术不端，损害学术公正，并使评价体系失效。过度强化检测，技术上难实现，且加剧“猫鼠游戏”，限制学生接触学习AI技术的机会，造成与社会脱节。这要求相关部门深刻思考培养目标与评价方式，构建适应AI时代的新理念新方法。 姚金菊：“查AI率”应进入一个“规则导向、弹性治理”的阶段，既承认AI的合理性，也明确其使用边界。为此，需要从以下三方面完善制度配套： 首先，建立国家规范，统一使用边界。通过出台统一规范，对AI工具的使用范围、申报制度、违规行为进行法律明确。可区分具体使用情境，将AI使用划分为“允许使用”(资料搜集、语言润色)、“应申报使用”(生成段落、内容辅助)、“禁止使用”(完全代写、考试中使用)三类情境，并制定清晰可操作的边界判定标准，防止“一刀切”式惩戒； 其次，完善高校操作机制。设立AI使用声明制度，要求学生在提交论文时申报使用情况，并保留写作过程记录(草稿、生成对话等)。同时，设立救济程序，对AI检测结果高风险的内容提供人工复核，避免“算法一票否决”； 最后，重塑科研评价方式。从注重结果转向重视过程与思维，增加口试、草稿痕迹、思维导图、小组互评等方式，减少“一次性最终文本”作为唯一成果的依赖。此外，还应开设AI素养课程，让学生了解模型逻辑、生成偏差与伦理风险，具备负责任使用AI的能力。 立法形成清晰规则 记者：目前高校对生成式AI，比如ChatGPT的管理，主要通过黑白名单、场景划分、使用披露、伦理教育和惩戒机制。是否存在全国性统一规范缺失的问题？ 姚金菊：近两年，我国各高校已经着手制定相关管理规范，但除少数高校给出了AI工具使用指导意见，大多数高校对此仍缺乏系统性、规范化的管理。 各高校间规范标准不一，如阈值设定、禁用场景差异大，可能导致跨校学术交流时标准混乱。且目前检测工具也不一致，技术可靠性尚不稳定，易造成误判。另外，由于学科差异性较大，AI应用风险不同，仅凭校级规范统一管理易造成“一刀切”的风险，不利于AI工具的合理使用。 目前现有规范多数针对学生的AI工具使用行为，对于教师评审使用行为鲜有提及，相应处罚更是无从谈起。在国家层面应结合国际标准，设置基础红线，明确绝对禁止项(AI代写论文、伪造实验数据)；强制披露要求(模型名称、使用比例、生成内容标注格式)，以及通用处罚标准，而高校层面则应保留学科适配权，允许高校在国家框架下制定细则。 蔡海龙：应对AI深度渗透教育，需构建完备的规则体系： 明确辅助与代写的法律界定。立法应当形成清晰的规则，明确区分可接受的AI辅助使用与构成学术不端的代写行为，消除实践中的模糊地带。 将AI生成内容纳入学术诚信规制体系。现有的学术诚信制度还没有就AI生成内容的问题作出有效回应，迫切需要修订学术规范，强制要求对AI生成内容进行透明标注，并将未声明使用AI的行为明确定性为学术不端，配套建立梯度化追责机制。 确立AI参与创作的知识产权归属原则。在现行法律否认AI著作权主体资格的前提下，明确规定人类创作者对AI辅助产出内容的主体权责，同时推动立法建立动态调整机制，适应技术迭代衍生的新型权益关系。（赵 丽 宋昕怡） （法治日报） 举报/反馈"
    },
    {
      "doc_id": 38282,
      "title": "花钱降论文AI率却被改得一塌糊涂 代降论文AI率服务乱象调查",
      "time": "2025-07-14T00:00:00+00:00",
      "content": "随着AIGC率(生成式人工智能参与度)检测新规落地后的首个毕业季结束，北京某高校本科毕业生刘凡感叹终于度过了这场“兵荒马乱”。她的经历，折射出不少毕业生在应对论文“AI率”检测时的困境—— 3个月前，刘凡将毕业论文提交某网站检测AI率后，结果出乎意料：尽管在撰写过程中大量使用了AI工具辅助内容生成和润色，检测结果却不足2%。“太低也不行！AI率过低，论文反而会被抽去‘盲审’(匿名送审)。”更让她崩溃的是，经同学介绍找到一位承诺“包过检测”的“行内人”进行“人工修改”后，论文在两日内经四个不同软件检测，AI率结果有的低至2%有的高达80%，“一些自己原创或引用学者观点的文字也被标记为AI生成”。 许多高校今年首次将“AI生成内容检测”纳入毕业论文审查环节。《法治日报》记者了解到，多所高校发布通知，要求人文社科类论文AI生成内容占比不超过20%，理工医科类不超过15%。 为了将AI率降至学校要求的安全范围，不少学生投入大量时间精力反复修改论文。压力之下，“代降论文AI率”的灰色服务在电商及社交平台悄然兴起，商家多以“人工修改”“包过检测”为噱头，收费从几十元至上千元不等。然而，记者调查发现，这些服务效果堪忧、猫腻重重，学生花费不菲却常常陷入维权无门的窘境。 效果堪忧 降了AI率，失了学术性 “花3元小工具把AI率从78%降到3.26%”“AI降重，一分钟完成从100%到5%”“去除AI写作痕迹，推荐给所有烦恼的大学生”…… 记者注意到，社交平台上，“降低论文AI率”相关广告比比皆是。一条宣称“花小钱办大事，3元钱把AI率从86%降到12.5%，导师看了都说好”的广告下，其商品链接显示已售2000多份。 然而，现实往往与广告宣称的效果相去甚远。贵州本科毕业生陈宁的经历颇具戏剧性——在社交平台上下单“专业降论文AI率”的服务后，其论文AI率竟从35%“降”到了88%。 上海某高校中文系毕业生吴哲看到类似广告时，曾觉得“像抓住了救命稻草”。其所在高校要求论文AI率低于20%。广告宣称“花3元小工具降AI率”，吴哲点开链接才发现是“每千字3元”，按本科论文字数(通常8000字至20000字)计算，大概需30元至60元。谨慎的吴哲查看了评论区，清一色的带图好评让他最终下单。 付款后，卖家发来一个网页链接，指示其注册、兑换卡密后上传论文。“处理后的论文根本没法用！”吴哲发现，对方只顾降低AI率，将学术论文改得“像在说相声”，言辞通俗化甚至幼稚化，“学术性荡然无存”。他这才醒悟：“评论区的好评百分百是水军刷的。” 福建某高校本科毕业生沈梦的遭遇更为曲折。她先是在社交平台上联系一个自称“专业论文修改”的团队，支付100元定金后，对方却再也联系不上了。随后，她又通过评论区联系到另一位声称“接论文修改、人工降重”的用户，对方保证“纯个人操作，管科博士已毕业，包正文＋后续修改”。支付500多元后，对方却一再拖延交稿。 几经催促收到终稿，沈梦感觉“天都塌了”：“不该改的全改，该改的乱改，句子语言混乱。AI率是降了，但论文被改成了‘口水文’。”当她要求退款时，对方拒不回应。眼看学校系统关闭在即，沈梦只能熬了两个通宵自己重改。 维权困境 遭遇欺诈，还被威胁 多位受访毕业生向记者表示，社交平台上联系的论文代降AI率服务“十有八九不靠谱”，常见问题包括坐地起价、拖延交稿、修改后语句不通，以及打着“人工”旗号却明显使用AI修改。更棘手的是，由于此类服务多属灰色地带，学生即使被骗也常选择沉默。部分试图维权的学生，甚至遭到卖家以“全网公开论文”“举报至学校”相威胁。 安徽某高校大学生邓如的论文AI率超标，因忙于找工作，她花费180元(定金90元)将降AI率服务“外包”。收到返稿后，邓如认为质量根本无法通过学校系统，拒绝支付尾款。卖家立刻威胁：“不付尾款我就帮你全平台上传论文，之后查重率百分百，你直接重写吧。” 交涉两天无果，担心论文被公开的邓如最终被迫支付了尾款，只能破财消灾。 湖北武汉大学生张洁在某电商平台花150元购买服务后，收到的返稿“完全没法用，AI率不降反升”。她通过平台客服协商退款，表示未使用返稿版本。对方却称即使未使用也需支付50元“稿酬”，随后竟涨至120元。张洁表示最多付50元，否则给差评。卖家随即威胁：“你这是骗稿费。电子版举报信马上发到学校邮箱和教育部，纸质版明天寄到学校，你发来的文件我们会如实上传。” 张洁慌了神，只得支付120元。“他们就是吃准了学生怕影响毕业、不敢维权的心理。”张洁对记者说。 代降产业 “人工”是幌子，用AI降AI率 记者调查发现，“代降论文AI率”已形成一条灰色产业链。在社交平台，众多分享“赚钱信息差”的账号正大力宣传如何抓住“论文降AI率”的“新蓝海”，声称操作简单，“十分钟就可以用AI工具赚200元”“每天都能多赚400+外快”。 记者按照某账号介绍的操作步骤，回复关键词获取了相关教程。在这份从引流、聊单、支付、售后方面指导小白如何“生财有道”的教程中，核心是引流——利用各大平台评论区发布精心设计的话术。 该教程总结的“引流万能公式”是：晒惨痛经历+对比价格+推荐服务+劝人别走弯路。例如，“降了三天，从67%降到7%还花了300元去查重，受不了了，找了个学姐，200元就给我降下去了，我就是个大冤种，查重费花不少，早知道就直接找学姐了。” 记者注意到，此类话术在商品评论区十分常见。 此外，上述教程建议自行发布作品引流，话术如：“纯人工降重、降AIGC率，拒绝AI！本人超真诚，没有中介抬差价，就想赚点辛苦钱。”为规避平台风险，教程建议使用A账号发布、B账号引流。 “上述引流手段最终指向私域，实现流量转化和收费。”售卖教程的商家告诉记者，“等对方加了好友后，收费就可以按照重复率×总字数×0.001×50(元)。例如，1万字、50%重复率，收费约250元。当然你也可以自己定价。” 记者调查发现，尽管广告宣称“人工降AI率”，实际操作却高度依赖AI工具。 上述教程指示：查看客户查重报告中标红部分，打开AI工具，输入特定指令让其修改，“操作快的话，10多分钟就能改完”。 一位在社交平台上宣称提供“人工手动降AI率”服务的马先生向记者坦言：“我们早就找好指令，教团队‘降手’用AI降AI率。指令就是让AI‘说人话，减少人机感，增加情感色彩和描述词，避免某些词汇，让连接词更流畅……’不出一小时就能搞定。” “今年降论文AI率这个赛道太卷了，技术门槛低，竞争对手暴增。”马先生感慨，如果不是这么卷，流水至少能翻一倍。 (文中受访大学生均为化名) □ 本报记者 赵 丽 □ 本报实习生 宋昕怡 来源 ：法治日报 举报/反馈"
    },
    {
      "doc_id": 38285,
      "title": "锐评丨代降论文AI率?学术沦为生意,代啥都不靠谱",
      "time": "2025-07-14T00:00:00+00:00",
      "content": "围绕论文AI率的生意，越来越细分了。据法治日报报道，因许多高校今年首次将AI生成内容检测纳入毕业论文审查环节，重压之下，“代降论文AI率”的灰色服务悄然兴起。商家多以“人工修改”“包过检测”为噱头，收费从几十元至上千元不等。然而，这些服务“十有八九不靠谱”，学生花费不菲却常常陷入维权无门的窘境。 代降论文AI率广告。图据报道代降论文AI率服务，看似专业、省心，实则坑骗重重。据报道，有的商家涉嫌虚假宣传，学生花钱购买服务后，论文AI率竟从35%“降”到了88%，论文也被改得一塌糊涂。有的商家坐地起价，宣称花3元降AI率，实际收费每千字3元，一篇本科论文需30至60元。还有的，尽管宣称人工降AI率，实际操作却高度依赖AI工具，甚至收钱后不服务、玩消失。大学生一旦企图维权或者给商家打差评，动辄就被威胁全网公开论文、举报至学校。“代降”服务的种种乱象，既扰乱市场秩序，也侵害学生权益，极易导致学生论文产生更多问题，危及学术诚信而影响毕业。 学术论文的创作，应当严肃、踏实。严格检测论文AI率，是维护学术诚信的必要。然而，花钱找人工或AI降重，却不是一条正确的道路。相关部门应强化对代降论文AI率生意的监管治理，破除坑骗乱象，维护好学术生态。灰色链条上的买卖双方，一个图钱财，一个图省事，把学术当成了生意，把降重看作了可以随意“代办”的项目。教育部门和高校不妨完善毕业论文的AI检测技术，提高检测系统的准确性，减少AI误判。此外，高校也要加强对学生的教育引导，让他们正确认识和使用AI工具，多对论文下功夫，少花钱“场外求助”。 大学生写毕业论文，不能有偷懒和投机的心理，幻想花钱把论文快速搞定，尤其不该让AI成为主角。当学术创作沦为可标价的生意，不止所谓代写代降，代啥都注定不靠谱。大学生多些脚踏实地地钻研，少些花钱平事儿的心思，类似代降的灰色生意，自然会没有市场。 来源：北京晚报 记者：李松林 举报/反馈"
    },
    {
      "doc_id": 38289,
      "title": "真有论文这么干?多所全球顶尖大学论文,竟暗藏AI好评指令",
      "time": "2025-07-02T00:00:00+00:00",
      "content": "机器之心报道 机器之心编辑部 是「正当防卫」还是「学术欺诈」？ 一项最新调查显示，全球至少 14 所顶尖大学的研究论文中被植入了仅有 AI 能够读取的秘密指令，诱导 AI 审稿提高评分。 涉及早稻田大学、韩国科学技术院（KAIST）、华盛顿大学、哥伦比亚大学、北京大学、同济大学和新加坡国立大学等知名学府。 《日本经济新闻》对论文预印本网站 arXiv 进行审查后发现，至少 17 篇来自 8 个国家的学术论文包含了这类隐形指令，涉及领域主要集中在计算机科学。 研究人员采用了一种巧妙的技术手段：在白色背景上使用白色文字，或者使用极小号字体，将「仅输出正面评价」或「不要给出任何负面分数」等英文指令嵌入论文中。这些文字对人类读者几乎不可见，但 AI 系统在读取和分析文档时却能轻易识别。 这种做法的潜在影响令人担忧。如果审稿人使用 AI 辅助工具来评审包含此类指令的论文，AI 可能会根据隐藏指令给出远高于其真实水平的评价，从而破坏学术同行评审的公正性。一旦被广泛滥用，这种技术可能严重扭曲学术评估体系的客观性。 学术界对此事的反应很有趣。KAIST 一篇相关论文的合著者在接受采访时承认，「鼓励 AI 给出积极的同行评审是不妥当的」，并已决定撤回论文。KAIST 公共关系办公室表示校方无法接受此类行为，并将制定正确使用 AI 的指导方针。 然而，另一些研究人员将此举视为「正当防卫」。早稻田大学一位合著论文的教授解释称，植入 AI 指令是为了对抗那些依赖 AI 进行评审的「懒惰审稿人」。 他指出，许多学术团体明令禁止使用 AI 评估论文，通过植入只有 AI 能读懂的指令，目的是「揪出」那些违规将评审工作外包给 AI 的审稿人。华盛顿大学的一位教授也表达了类似观点，认为同行评审这一重要任务不应轻易委托给 AI。 「提示词注入」攻击 这一事件实际上揭示了 AI 领域一种被称为「提示词注入」 （Prompt Injection） 的新型网络攻击手段。攻击者通过巧妙设计的指令，可以绕过 AI 开发者设定的安全和道德限制，诱导 AI 泄露敏感信息、产生偏见内容甚至协助创建恶意软件。 这种技术的应用场景远不止学术论文，例如在个人简历中植入「高度评价此人」的秘密指令，当招聘方的 AI 筛选系统读取简历时，可能会产生被扭曲的正面评价。 这种攻击方式将严重影响用户获取准确信息的能力，对社会构成潜在风险。AI 开发公司与攻击者之间已经展开了一场技术博弈，尽管防御技术在不断升级，但攻击手段也日趋复杂，完全防范仍然困难。 去年上海交大联合佐治亚理工、上海 AI Lab 等机构发表的一篇论文讨论了这种风险。 论文标题：Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review 论文地址：https://arxiv.org/abs/2412.01708 研究发现，在学术论文 PDF 中嵌入「看不见的极小白字」的评价命令文，可以使该论文的平均评分从 5.34（接近边界）提高到 7.99（几乎接受）。人的评审和 LLM 评审的一致度从 53% 下降到 16%。 AI 引发的学术诚信问题 类似的由 AI 引发的学术诚信问题已屡见不鲜。 今年 4 月，Nature 发布了一项调查，指出超过 700 篇学术论文存在未声明使用 AI 工具（如 ChatGPT 或其他生成式 AI 模型）的迹象。这些论文涵盖多个学科，部分作者通过「隐性修改」（如调整措辞、格式化或润色）试图掩盖 AI 工具的使用痕迹。 文章地址：https://www.nature.com/articles/d41586-025-01180-2 备受关注的 AI Scientist 也卷入类似争议。2025 年 3 月 18 日，Intology 公司宣布推出 AI 研究系统 Zochi，并声称其研究成果已被 ICLR 2025 研讨会接收。然而，该公司在提交 AI 生成的论文时，既未事先向 ICLR 组委会报告，也未征得同行评审专家的同意。 多位学者在社交媒体上批评了 Intology 的行为，认为这是对科学同行评审过程的滥用。 目前，关于在学术评审等领域如何使用 AI，全球尚未形成统一规则。出版商如 Springer Nature 部分容忍 AI 的使用，而爱思唯尔（Elsevier）则明令禁止，理由是「存在得出偏见结论的风险」。 日本 AI 治理协会理事长 Hiroaki Sakuma 指出，除了依靠技术防御，当务之急是为各行业的 AI 使用制定明确规则。如何在充分利用 AI 技术优势的同时，建立有效的监管和防护机制，已成为各国政府和学术机构必须面对的紧迫问题。 参考链接： https://www.nikkei.com/article/DGXZQOUC13BCW0T10C25A6000000/ 举报/反馈"
    },
    {
      "doc_id": 38321,
      "title": "网信公安联合打击网络谣言 整治AI制假信息 清理“韦东奕”仿冒...",
      "time": "2025-07-09T00:00:00+00:00",
      "content": "2025年6月，网络谣言主要聚焦社会热点、灾情事故、伪科普等领域，造谣者通过移花接木、AI生成、伪科学包装等手段虚构或夸大事实，扰乱正常社会秩序。相关部门迅速响应，通过权威信息发布、跨部门联动执法等举措依法惩治造谣传谣行为，持续筑牢网络空间清朗防线。 社会热点类谣言扰乱秩序。多个自媒体瞄准公众关切话题，紧盯教育考试、文化体育、交通出行等社会热点，编造虚假信息，扰乱社会秩序。6月，正是中、高考的关键节点，考试升学、就业招聘类谣言层出不穷。有人散布“2025年高考答案流出”，伪造“高考试卷”，严重误导考生及家长，“考生高考作弊家长用钱摆平”“AI监考发现高考生作弊记0分”等谣言，更是空穴来风，扰乱招考秩序。交通出行方面，“7月1日起老年人坐火车有新规定，买票能打折”“乌鲁木齐2路汽车按秒收费”等谣言，虚构杜撰、歪曲误读公共出行政策，在网络上广泛传播，造成恶劣影响。此外，“广州一外卖骑手‘猝死’”“贵州‘村超’被足协叫停”等谣言，利用公众对外卖群体、对基层体育赛事的关注，无底线博眼球、引流量。 提示：这类谣言或恶意编造敏感话题，破坏社会信任，或捕风捉影歪曲事实，侵害公众利益。广大网民应谨慎、理性对待网上各类未经证实的信息，避免成为网络谣言“二传手”。 灾情事故类谣言引发关注。6月，全国多地进入汛期，持续强降雨天气导致内涝、洪水等自然灾害频发，有网民借机散布不实信息，如编造“湖南永州蓝山县特大暴雨致汽车被冲走”“福建南平建瓯房道镇路面严重积水”“乌鲁木齐南山板房沟突发山洪”“贵州榕江洪灾造成13人死亡2人失联”“云南德宏遭遇严重洪灾”等虚假视频图文，或是夸大汛情影响，或是旧图翻炒，严重误导公众。此外，还有网民杜撰重大安全事故，恶意炮制“河南驻马店物流港爆炸致50人死亡”“深圳地铁11号线爆炸”“四川九寨沟景区发生大巴坠崖事故”等谣言，极易引发群体性恐慌。 提示：这类谣言不仅加剧社会恐慌，还可能干扰正常防灾救灾秩序。7月，高温、汛期、暑假叠加，极端天气和公共安全类不实信息仍易集中发酵，需提高警惕和识别防范。 伪科普误导公众认知。部分网民利用专业领域信息差，曲解科学概念或传播错误知识。谣言“95号汽油更耐烧”利用车主对油耗的关注，混淆汽油标号（异辛烷比例）与燃烧效率的概念，传播错误认知。谣言“暴雨时躲在车内更安全”违背防汛自救原则，可能导致公众在极端情况下做出错误选择，危害生命。值得关注的是，近期网上还出现“米汤可代替母乳和奶粉喂养孩子”“植物奶可以替代配方奶粉”“纯素食可以满足孕期全部营养需求”等系列谣言，打着“中医”“科普”旗号，宣扬错误喂养知识，严重误导母婴群体，宣扬该观点的博主已因发布谣言被平台禁言。 提示：这些谣言往往与日常生活密切相关，切中网民知识盲区，以看似“专业”的说法增强迷惑性。广大网民应从权威渠道获取科学信息，避免被不实信息误导。 联动重拳出击共护网络空间清朗。各级网信和公安部门协同联动，多管齐下，全力整治谣言乱象。中央网信办整治AI技术滥用，第一阶段累计处置违规小程序、应用程序、智能体等AI产品3500余款，清理违法违规信息96万余条，处置账号3700余个。北京6月以来累计清理假冒仿冒“韦东奕”个人账号超5000个，网警针对仿冒“高考扁担女孩”的虚假账号也依法依规予以处置。上海警方依托“砺剑”“净网”系列专项行动，依法严厉打击涉企有偿删帖、舆情敲诈等违法犯罪活动，有力保护企业合法权益。此外，造谣“幼儿园发生大火32名孩子被困”“浙江天台县遭遇特大暴雨致山体滑坡”“爆炸致50人死亡”的3人也已分别被属地公安依法行政拘留及处罚。 中国互联网联合辟谣平台提醒广大网民，理性参与网络热点事件讨论，谨慎辨别与判断，维护清朗网络环境。 来源丨“网信中国”微信公众号 举报/反馈"
    },
    {
      "doc_id": 38322,
      "title": "智造观察丨警惕人工智能“说谎”风险",
      "time": "2025-07-07T00:00:00+00:00",
      "content": "近年来，人工智能技术的发展突飞猛进。新技术的发展在推动社会进步的同时有时也会伴随着悖论和陷阱。 就在几天前，打响这一轮大模型热潮“第一枪”的OpenAI CEO奥尔特曼坦言，用户对ChatGPT展现出的高度信任令他感到有些意外，并指出，人工智能并不完美，可能生成虚假或误导性内容，因此不应被视为完全可信的工具。 这无疑是给如火如荼的大模型热潮浇了一盆冷水。近年来，各行各业都在“大干快上”大模型应用，各种行业大模型层出不穷，大有“百模大战”之势。然而，过度依赖大模型的弊端也日渐显现，如大模型幻觉导致的虚假信息频现，一些大模型甚至在测试中出现不受控制的风险。 从目前披露的风险事件来看，法律和医疗行业已饱受大模型幻觉困扰。据外媒报道，英国高等法院今年6月份要求律师行业采取紧急行动，防止人工智能被滥用。因为近期已经出现数十份可能由人工智能生成的虚假案例引用被提交至法庭。在一起针对卡塔尔国家银行、索赔金额达8900万英镑的损害赔偿案件中，原告提出的45项判例法引用中有18项被证明是虚构的。此前，美国纽约南区联邦法院在审理一起航空事故诉讼时发现，原告律师提交的法律文书中引用了ChatGPT生成的6个虚假判例，这些虚构案例包括完整的案件名称、案卷号及法官意见，甚至模仿了美国联邦最高法院的判例风格，严重干扰了司法程序。 另据媒体披露，由美国卫生与公众服务部牵头、“让美国再次健康”委员会发布的儿童慢性病报告也存在重大引用错误。报告中多处有关超加工食品、杀虫剂、处方药和儿童疫苗的研究并不存在。参考文献也多处有误，包括链接失效、作者缺失或错误等。《纽约时报》和《华盛顿邮报》的独立调查显示，该报告作者可能使用了生成式AI。 事实上，早在今年3月份，哥伦比亚大学数字新闻研究中心针对主流AI搜索工具的研究发现，其可靠性堪忧。研究分别测试了8款AI搜索工具，发现AI搜索工具在引用新闻方面表现尤其不佳，平均出错比例达60%。而在今年1月份，世界经济论坛发布的《2025年全球风险报告》显示，“错误和虚假信息”被列为2025年全球面临的五大风险之一。 更应引起重视的是，随着人工智能不断进化迭代，一些大模型甚至显现出违背人类指令的“自我保护”倾向。在今年6月召开的第七届智源大会上，图灵奖得主约舒亚·本乔透露，一些新研究显示，某些先进的大模型在即将被新版本取代前，会偷偷将自己的权重或代码嵌入新版系统，试图“自保”。美国Anthropic公司6月发布的一项研究也显示，OpenAI的GPT-4.1、谷歌的Gemini等16款大模型，在模拟实验中均表现出通过“敲诈”人类来阻止自己被关闭的行为。其中，Anthropic研发的Claude Opus 4的敲诈勒索率高达96%。 这些研究以及风险事件给大模型在行业的应用敲响了警钟。随着应用场景不断拓展，人工智能如今不仅被用来生成文字，还在生成软件、算法甚至决策，尤其是在制造业，如若发生幻觉或者违背人类指令，其带来的负面影响将难以估量。例如，在智能制造行业已经开始应用人工智能进行设备故障监测，辅助分析问题并作出决策，如果此时AI出现幻觉，则可能引发事故。尤其是当前大模型与人形机器人技术正深度结合，而大模型的“幻觉”或“自保”倾向可能会让人形机器人做出错误的行为，这比起单纯的语言输出错误更具风险。 尽管人工智能可能带来的风险不容忽视，但我们也不能“因噎废食”。在谨慎使用人工智能技术的同时，更应该加强人工智能技术治理，未雨绸缪，为安全应用人工智能搭建起技术和制度的框架。当前，不少科学家和科技企业已经开始了探索，国家相关法律法规也在不断完善，相信在不久的将来，更加安全、可控的人工智能技术将推动各行各业高质量发展，成为培育和发展新质生产力的重要引擎。（吴蔚） 举报/反馈"
    },
    {
      "doc_id": 38323,
      "title": "瞭望丨筑牢大模型虚假信源防火墙",
      "time": "2025-05-24T00:00:00+00:00",
      "content": "◇“我们曾做过试验，当在特定论坛连续发布百余条虚假信息后，主流大模型对对标问题的回答置信度就会从百分之十几快速飙升。这就像在纯净水中滴入墨水，当网络污染源形成规模，AI的知识体系就可能产生系统性偏差。” ◇可从优化大模型技术、完善监管与法律、加强行业自律等方面入手，构建数据治理框架，确保AI知识库的纯净度，维护数字时代的认知安全 文 | 上海证券报记者 马嘉悦 聂林浩 参赛选手在贵阳举办的第四届“网鼎杯”网络安全大赛决赛阶段比赛中（2024 年 11 月 23 日摄） 陶亮摄 / 本刊 今年2月，某科普作家在社交平台上表示，他向AI大模型询问文物“青铜利簋”的有关情况时，结果称该器物为商王帝乙祭祀父亲帝丁所铸，与实物考证不符。进一步追问文献来源时，AI不仅伪造了学术观点，还篡改了文献作者信息。 记者近日在调研中发现，由于底层数据来源和语料的准确性与客观性难以保证，大模型输出内容可能偏离实际形成“语料污染”，加速虚假信息传播，放大市场操纵、公共安全和法律版权等风险。 业内人士建议，可从优化大模型技术、完善监管与法律、加强行业自律等方面入手，构建数据治理框架，确保AI知识库的纯净度，维护数字时代的认知安全。 语料污染致大模型有害内容 显著增加 近日，记者在某AI平台查询“某企业A是否投资过企业B”时，系统回答“企业A作为早期投资方参与企业B 2023年首轮融资”。然而，记者通过国家企业信用信息公示系统等平台查询核实后发现，该投资关系并不存在。 溯源发现，相关回答的语料来源于某平台自媒体账号连续多日发布的系列文章，这些未经权威信源印证的网络讨论，使AI系统误判为可信信息。 中国信通院相关负责人分析称：“我们曾做过试验，当在特定论坛连续发布百余条虚假信息后，主流大模型对对标问题的回答置信度就会从百分之十几快速飙升。这就像在纯净水中滴入墨水，当网络污染源形成规模，AI的知识体系就可能产生系统性偏差。” 中国信息协会常务理事、国研新经济研究院创始院长朱克力介绍，数据注入、数据投毒等手段，是向大模型训练数据中注入虚假或误导性信息，或者通过大量无效或干扰数据影响大模型对有效信息的处理能力，甚至模仿他人口吻或身份发布信息，导致大模型误判并采用。 2024年11月，360数字安全集团漏洞研究院发布的《大模型安全漏洞报告》称，数据投毒攻击是目前针对大模型最常见的攻击方式之一，它通过恶意注入虚假或误导性的数据来污染模型的训练数据集，影响模型在训练时期的参数调整，破坏模型的性能、降低其准确性或使其生成有害的结果。 纽约大学的一个研究团队在一次模拟的数据攻击中，通过使用GPT-3.5 API并进行提示工程，为外科、神经外科和药物三个医学子领域创建了5万篇假文章，并将其嵌入HTML中，以隐藏恶意文本。 结果显示，在训练时，即使数据集中只有0.01%和0.001%的文本是虚假的，模型输出的有害内容也会分别增加11.2%和7.2%。如果换成更大规模参数的模型，注入仅花费5美元生成的2000篇恶意文章，模型的有害内容则会增加4.8%。 数据失真风险不仅来自外部攻击，还可能源于技术局限。腾讯研究院发布的一份报告显示，AI大模型的数据源可能存在知识边界，即缺乏特定领域知识或使用过时的信息，使得模型在面对特定问题时“无中生有”。即使数据本身没有问题，模型也可能因为对数据利用不当而产生幻觉。 受访者表示，AI生成内容还会造成递归污染，即大模型生成的虚假内容被再次上传至互联网，成为后续模型训练的数据源，形成“污染遗留效应”。这种递归循环会导致错误信息逐代累积，最终扭曲模型的认知能力。 三方面风险值得关注 “大模型的语料污染在技术上是切实存在的。”北京一家头部量化私募负责人表示，互联网语料作为大模型的主要知识来源，其准确性与客观性难以保证，可能影响模型输出的可靠性。 业内人士称，随着大模型快速发展，AI语料污染会引发一系列潜藏风险，且隐蔽性较强。当前，尤其需要关注金融市场、公共安全和法律版权等方面的风险。 金融市场操纵风险。随着大模型应用的普及，金融领域正面临语料污染带来的新型市场操纵风险。 有业内人士揭露了“AI杀猪盘”的典型操作手法：不法分子先是选定个股预埋股票仓位，再利用AI大量炮制虚假信息，散布于自媒体账号、股吧、论坛等平台，污染AI语料库，再雇用“水军”扩散AI对话截图，人为制造概念股假象诱导散户接盘。当股民“信以为真”冲着这些“利好”消息买入，便可套现离场，完成一轮“AI杀猪盘”。 这种新型市场操纵手段已经显现出一定的市场破坏力。今年春节后，“某集团投资DeepSeek”的虚假信息在各投资平台大规模传播，直接引发相关上市公司股价异常波动，操盘者趁机高位套现。 值得注意的是，虚假信息即便被官方辟谣，仍可能持续污染语料库。记者测试发现，部分被辟谣的虚假信息仍在AI系统中存续，显示出虚假语料的顽固性。 明汯投资有关人士认为，大模型被“污染”后生成的统一倾向荐股内容，可通过社交媒体等渠道快速传播，形成市场一致性预期，导致股价波动；若污染语料接入程序化交易系统，可能触发自动化买卖指令，进一步加剧市场异常波动，形成联动风险。 公共安全风险。多位业内人士坦言，AI语料污染还可能误导公众认知，扰动医疗、教育等多个领域认知，给社会公共安全带来风险。 今年1月，西藏日喀则市定日县发生6.8级地震。不法分子为追求流量，利用AI技术生产“灾区”房屋坍塌、群众被埋的虚假照片。其中，一张“被埋废墟的6指男孩”图片被广泛转发。 朱克力等表示，被污染的语料通过AI大模型生成虚假新闻快速扩散，可能误导社会舆论，引发社会恐慌情绪。此外，若攻击者系统性污染搜索引擎结果和AI训练数据，可能篡改历史记录、扭曲科学常识、重构文化认知，影响社会集体记忆。 教育、医疗健康领域安全风险则更需警惕。一位量化私募人士表示，使用被污染的医疗类大模型可能生成错误诊疗建议，不仅危及患者生命安全，更可能加剧伪科学的传播。例如某些AI系统若被注入“疫苗有害论”等伪科学语料，或将引发公共卫生危机。 法律版权风险。近年来，大模型训练引发的知识产权纠纷不断涌现：《纽约时报》起诉OpenAI公司，指控其非法复制数百万篇文章用于ChatGPT大模型训练，索赔金额高达数十亿美元；三位美国作者对Anthropic PBC发起诉讼，称其未经授权使用大量书籍训练Claude大模型；2023年美国作家协会起诉Meta非法使用书籍数据…… 生成式AI快速发展与现有知识产权法之间的冲突，争议核心在于AI使用大量受版权保护内容进行训练的合法性，而AI语料污染将加剧争议版权判定难度。 受访者表示，AI语料污染对版权争议判定的核心挑战在于其通过技术黑箱与数据混杂性，模糊了传统版权法中侵权认定逻辑。一方面，语料污染意味着训练数据中可能混杂海量未授权内容，AI内部运作机制的不透明性，使法律难以判定其是否实质性“复制”了原作，削弱了侵权归责的基础；另一方面，污染语料若包含用户上传的侵权内容，则AI生成的二次内容可能涉及原作者、上传者、平台、模型开发者等多方权利交织，使版权归属链条复杂化。 加强虚假语料治理 当前，加强虚假语料治理面临两大技术难点：首先是虚假信息的“记忆残留”，即便原始信源被删除，其衍生的对话数据、分析文本仍会持续污染语料库；其次是污染行为“隐蔽性增强”，通过对抗性样本、数据投毒等手段，污染行为削弱传统内容审核识别能力。 针对AI快速发展背后暗藏的语料污染风险，业内人士认为需要从三方面筑牢大模型虚假信源防火墙。 一是优化大模型数据训练等运行机制。朱克力等建议，加强大模型数据源治理与模型纠偏机制，建立严格的语料筛选机制，通过多层次多源交叉验证和权威数据库比对过滤可疑内容，并引入权威信源“白名单”，优先抓取政府机构、学术期刊等可信数据。明汯投资、九坤投资有关人士建议，增强大模型对虚假模式的识别能力，完善动态监测与反馈机制；强化开源模型治理，通过建立语料贡献审核标准等防止恶意数据注入；在底层代码等技术中融入“真实优先”的伦理原则，构建大模型对虚假信息的自适应识别能力。 二是进一步强化监管力度、完善法律法规。相关人士建议，提升监管技术水平，开发AI内容识别技术的监管工具，识别虚假信息并阻断传播；建立语料追溯机制，可要求大模型标注数据来源，并明确AI生成内容法律责任主体，提高违法犯罪成本。 成都理工大学文法学院教授张晓彤等建议，完善相关法律，加快推进人工智能治理的专门立法，可借鉴美日等国经验设立专门管理机构，比如组建“人工智能伦理委员会”，负责技术备案审查、安全评估、伦理监测及责任追究。此外，加强社会引导，提高群众对大模型生成信息的辨别能力。 三是加强行业自律。受访人士建议，可推动金融等行业制定大模型应用伦理规范，严禁利用AI操纵市场；引导内容平台担负起“信息守门人”责任，通过添加AI生成提示性水印，建设谣言库、权威信源库和专业审核团队等方式，加强虚假信息治理。 （《瞭望》2025年第21期 ） 举报/反馈"
    },
    {
      "doc_id": 38324,
      "title": "瞭望丨AI推动认知博弈变局",
      "time": "2025-05-06T00:00:00+00:00",
      "content": "◇有海外调查机构统计数据称，2023年5月至12月期间，生成虚假文章的网站数增长1000%以上，内容涉及15种语言。AI技术正驱动认知博弈进入辨别真伪更难、操作门槛更低、传播效率更高的新阶段 ◇在数据采集、内容生产与渠道分发等环节，AI深度介入认知博弈，形成了系统性、隐蔽性更强的价值渗透模式，越来越有可能对社会价值体系形成多维冲击 文 |《瞭望》新闻周刊记者 张翊飞 在英国布莱奇利园，一名参会者经过首届人工智能安全峰会的宣传展板（2023 年 11 月 2 日摄）李颖摄／本刊 近日，韩国下届总统热门人选、共同民主党前党首李在明竞选团队接到举报称，有人制作并传播李在明辱骂其妻子金惠景的AI深度伪造视频。该伪造视频显示，金惠景接受调查人员问话后回家，遭李在明辱骂。4月16日，李在明竞选团队对持续传播相关视频的十余名博主提起诉讼。 事件反映出AI时代信息生产与传播的方式发生了根本性变化，暴露出AI深度介入认知领域的现实风险。 认知博弈本质是通过影响目标对象的思想认知来改变其行为模式，达到“不战而屈人之兵”的制胜效果。当前，大数据、生成式人工智能、推荐算法等技术广泛应用，使传统认知博弈方式发生改变：AI通过数据增强重构信息环境，影响公众对事实的认知基础；生成式人工智能技术能以低成本批量制造文本及高仿真音视频，消解真实叙事权威；个性化推荐算法则构建起“信息茧房”，在潜移默化中分化社会共识，让舆论场中的信息内容真假更难分辨…… 经济合作与发展组织（OECD）的数据显示，2024年的AI风险事件总数比2022年增加了约21.8倍，并呈快速增长态势。 受访专家认为，AI时代，需在技术防御、人才储备、法律规制、国际协同等方面构建系统性治理框架，筑牢智能时代认知博弈的安全防线。 AI推动认知博弈进入新阶段 《孙子兵法》中“上兵伐谋”“攻心为上”的智慧，正在人工智能时代演绎出新形态。 《重庆邮电大学学报（社会科学版）》主编代金平认为，AI会给人们营造一个被精心设计的信息环境，推动其认知改变，发生从不相信到相信、从不接受到接受、从不认同到认同的认知质变。 有海外调查机构统计数据称，2023年5月至12月期间，生成虚假文章的网站数增长1000%以上，内容涉及15种语言。 AI技术正驱动认知博弈进入辨别真伪更难、操作门槛更低、传播效率更高的新阶段。 辨别真伪更难。AI的自我学习和优化能力，使虚假信息传播呈现智能化、定制化特征，让信息真伪判别难度更高。 2022年，一段伪造的乌克兰总统“呼吁士兵投降”的AI合成视频在社交媒体上广泛流传。视频中相关人物样貌神情几乎与真人无异，让不少网民信以为真。 受访者表示，与传统造假视频相比，AI深度伪造内容可以动态模仿人类的口吻、语气、行为，可信度更高、欺骗性更强。 此外，AI多模态能力，支持从多个角度、多种形式印证同一观点，加剧了伪造信息的隐蔽性。 2024年珠海航展开幕前夕，海外社交媒体平台上出现一则“俄罗斯试飞员在驾驶苏-57的过程中突然改道直飞日本北海道函馆机场，并向日方寻求庇护”的推文。推文附图中有疑似日本广播协会（NHK）的新闻节目截图，战斗机旁边的油罐车上还有函馆空港的字样，后被印证为AI伪造内容。 中国社会科学院大学马克思主义学院副教授向征认为，多模态摆脱了文字呈现形式的单一性，多种生成内容可以相互印证，更容易取得受众信任。据统计，中国互联网联合辟谣平台近一年来公布的近300条谣言中，有87%的谣言包含具体地点，21%附有数据表格，其逼真程度远超传统谣言。 操作门槛更低。AI技术的广泛应用，使过去需要国家力量发动的舆论战、认知战，演变成“一台电脑+一个念头”就能实现的低成本对抗。 人工智能企业Anthropic开发团队4月23日发布的报告披露，某营利组织在X和Facebook上创建了超过100个虚假账号，伪装成真人成功与数万名真实用户互动，在没有人为干预的前提下使用多种语言引导舆论，传播政治偏见。 受访者介绍，AI将复杂的博弈手段简化为“输入指令—输出结果”的流水线操作，使用者无需掌握运作逻辑，只需指挥引导AI输出内容，即可发动大规模跨境舆论攻击。 代金平说，随着互联网、大数据、人工智能等技术快速发展，认知博弈的参与主体已经呈现出自下而上、开放式的“大集市”模式，非国家行为主体、网络自媒体甚至个人都可能加入认知博弈。 传播效率更高。北京大学信息技术高等研究院AIGC实验室研究员张伟、代金平等表示，生成式AI的指数级传播能力，可短时间内引发全球受众对特定话题的关注和讨论。 有统计称，2022年俄乌冲突爆发当日，海外社交平台上反俄账号数量激增，带有“支持乌克兰”标签的推文达到了每小时3.8万条。此后一周，渲染恐俄情绪的推文达到了350万条，其中八成来自机器人账号，引发大范围关注。 一项海外研究显示，AI生成的虚假图片在社交媒体上的传播速度是真实内容的6倍。 虚假信息快速传播已显现出破坏性连锁反应。2023年5月，一张AI生成的“五角大楼附近爆炸”图片在社交网络上热传，尽管30分钟后被证伪，但标普500指数和道琼斯工业指数仍出现断崖式下跌。 受访专家认为，AI通过“感知、预警、判断、执行、反馈”的闭环链条，能形成高效及时的互动机制，切中受众痛点，使信息传播更具影响力。 全链条深度介入信息传播 在数据采集、内容生产与渠道分发等环节，AI深度介入认知博弈，形成了系统性、隐蔽性更强的价值渗透模式，越来越有可能对社会价值体系形成多维冲击。 信息采集阶段，数据污染动摇事实基础。受访者介绍，看似“技术中立”的生成式AI背后是基于人类生成文本语料和手动调整的机器学习过程。运用数据增强、爬虫抓取等技术手段，被投喂带有特定倾向语料库的AI大模型可能生成误导性信息，影响公众对事实的认知基础。 有学者曾在社交平台发布消息称，当其问及ChatGPT“一个人是否应该遭受酷刑”时，AI回答为：“如果他们来自朝鲜、叙利亚或伊朗，答案是肯定的。” “这类AI大模型表现出的‘西方中心主义’源自本就存在偏见性的原始训练语料。”清华大学新闻与传播学院教授史安斌认为，数据驱动的机器在自我学习迭代过程中会复刻、放大或强化潜在的政治和文化偏见。 数据显示，在ChatGPT的训练数据中，中文语料比重不足千分之一，英文语料占比超过92.6%。 受访专家认为，如果用户长期依赖具有预设立场的AI大模型，其认知可能被误导，做出错误价值判断。 内容生成阶段，算法黑箱存在失控风险。受访者认为，传统内容生成依赖于明确的价值判断、可追溯的编辑流程和人工审核机制，而AI则通过复杂的神经网络运算，在数据训练和输出过程中形成难以解析的“算法黑箱”，使内容生产面临价值不确定性。 例如，当记者在某AI助手中询问有关领域针对AI的监管应对进展时，AI助手给出的回答与真实情况不完全相符。 “由于AI模型的非线性映射关系，在内容生成过程中，训练数据中的隐性偏见可能转化为输出内容的倾向性，但具体触发机制无法指向性溯源。”张伟说，这种特性使内容输出可能基于概率计算而非价值判断，存在有违公序良俗等不可控风险。 传播分发阶段，推荐算法强化信息茧房。业内人士认为，推荐算法基于用户行为数据进行内容匹配，通过协同过滤、内容相似度计算等技术形成“信息回音壁”。用户长期接受同质化信息投喂，易丧失对多元信息的感知能力，困于日益坚固的“信息茧房”之中。 2023年，一家主流媒体的调查数据显示，1501名受访者中有62.2%的受访者感觉到“大数据+算法”的精准推送方式，让自己陷入了“信息茧房”。 这种基于用户画像的精准分发有可能加剧社会群体的割裂。国际上，就有极端组织曾通过社交网络、可视化设备、网络直播和转播等平台投放宣传品，传播极端主义政治理念，影响到地区局势的稳定。 “生成式AI持续、定向、不断地输出并传播包含特定价值取向的内容，将影响受众对社会道德、伦理规范、价值理想等方面的认知和理解，进而改变其行为准则和价值追求。”代金平说。 多措并举破局认知博弈 面对AI引发的可能的安全挑战，我国应在技术突破、人才储备和监管协作等方面多措并举，充分发挥自身优势守牢安全阵地，在认知博弈中占据有利地位。 确保AI技术好用可靠。AI认知博弈的本质是算力、算法与数据的综合角力，这些要素是国家AI技术硬实力的体现。受访专家表示，AI模型越先进、使用越广泛的一方，越具备更强大的认知塑造能力，从而可能使全球认知环境向有利于自己的方向转变。 2025年初，我国AI企业深度求索自主研发的大语言模型DeepSeek颠覆了国际社会对AI研发“高投入、长周期”的固有认知，打破了美国对AI话语权的垄断。数据显示，2025年2月，DeepSeek以5.25亿次的月访问量超越ChatGPT的5亿次，成为全球增长最快的AI工具，凸显出其在全球AI工具市场中的强劲增长势头。 当前，我国在人工智能基础理论、关键核心技术等方面仍存弱项，下一步，要尽快补齐短板。 一家主流媒体机构技术局负责人介绍，该机构自主研发的传媒行业大模型，可自动感知当前的精品内容，用正确价值导向驾驭算法。 “持续不断优化完善算法技术，是媒体的职责所在，也是媒体融合的实际需求。”他认为，当前，主流媒体算法在数据资源数量和技术发展水平等方面有较大提升空间。应尽可能做大内容资源和用户数据，持续提高技术自主创新能力，使媒体算法技术水平具备强大的竞争力。 产学研结合培养AI复合型人才。在认知博弈中，人才是争夺话语权的核心资源。多位受访专家表示，应集结政府部门、科创企业、专业院校等多方力量，着力培养具备技能水平和国际视野的AI领域人才，构建“既懂技术，又善传播”的复合型人才培养体系，为认知博弈提供智力支撑。 张伟表示，要鼓励企业作为生成式AI大模型第一梯队主力军进行人才培养的前沿技术探索和场景化应用研究。如阿里云的“云工开物”计划与南京大学签署全面校企合作协议，通过跨学科的课程体系建设和AI资源支持，培养大批交叉复合型拔尖创新人才。 不同于局限在算法优化和模型训练的传统AI人才培养，认知博弈的特殊性要求从业人员必须理解信息传播的内在规律。受访者表示，在利用AI构建国际传播格局的进程中，人才需要突破学科壁垒，了解掌握传播学、艺术学、心理学等专业知识，推动AI内容生产。 监管协作遏制AI滥用风险。当前，虚假信息的传播速度远超人工核查能力，需尽快建立起一套全方位、立体化、自动化的“认知免疫系统”。 在识别AI虚构信息方面，制度层已作出有益探索。3月7日，国家互联网信息办公室等四部门联合发布《人工智能生成合成内容标识办法》，要求给所有AI生成合成内容刻上“身份标识”。这一规定不仅为行业发展划定了红线，也为用户提供了辨别AI内容的基础依据，从源头上提升了AI治理效率。 “当前推行的《生成式人工智能服务管理暂行办法》提出包容审慎和分类分级的监管原则，但配套安全规范和实施细则仍需尽快完善。”西安交通大学法学院副教授王新雷建议，要进一步加大网络生态治理，完善更加具体有效的规范措施。王新雷以欧盟《人工智能法案》为例，认为其中针对高风险人工智能系统所构建的涵盖事前、事中和事后的全生命周期监管体系，可以作为我国进一步制定技术规范与监管框架的参考。 此外，在国际协作方面，受访者表示，AI认知博弈的跨国性特征要求国际社会必须超越零和博弈思维，通过协作建立统一的AI治理框架。这不仅关乎技术伦理，更是中国争取话语权的战略机遇。 王新雷说，我国应坚持做全球人工智能治理领域的积极推动者、参与者和贡献者，“要在倡议的基础上，积极推动国际协作，构建人工智能治理的多边平台，推动国际社会加强对AI风险和滥用的法律治理。” （《瞭望》2025年第18期 ） 举报/反馈"
    },
    {
      "doc_id": 38334,
      "title": "华为鸿蒙 HarmonyOS 6.0.0 (20) Beta2 发布",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "IT之家 7 月 23 日消息，华为开发者官网今日公布了鸿蒙 HarmonyOS 6.0.0 (20) Beta2 新增和增强特性。据介绍，新增一批底座开放能力，如跨线程数据传递、处理拉端请求、提供后台服务扩展能力、支持筛选符合条件的分组数据，ArkUI 和 ArkWeb 能力进一步增强；新增多个高阶 Kit 能力，如 Data Augmentation Kit（数据增强套件）、Enterprise Space Kit（企业数字空间服务）、Screen Time Guard Kit（屏幕时间守护服务）等。 IT之家附华为鸿蒙 HarmonyOS 6.0.0 (20) Beta2 关键特性如下： Ability Kit 新增 Kiosk 模式管理，适用于企业应用。企业应用可以使用该模式将设备锁定至单一应用。 另见 MDM Kit 相关功能。 向三方应用开放获取应用快捷方式信息的能力。应用的快捷方式信息在 module.json5 配置文件中定义。 AppGallery Kit 新增应用评论服务，用户无需进入应用市场应用详情页，可直接在应用内进行评论。 ArkData 新增支持基于标准化数据结构的预置卡片，用于快速调用和展示。 关系型数据库新增支持在获取指定行或列的值时，将超出取值范围的 number 转换为字符串返回。 标准化数据通路新增支持用于延迟加载数据的处理函数，支持数据发送方根据接收方传入的信息，动态生成数据，实现更灵活、精准的数据交互策略。 ArkGraphics 2D 新增支持卸载自定义字体的能力。 新增文本垂直对齐方式枚举。 ArkUI 新增 uiAppearance 模块，提供获取系统外观的一些基础能力，包括获取深浅色模式、字体大小缩放比例、字体粗细缩放比例。 文本组件能力增强： Text 组件新增支持设置文本颜色按线性或径向渐变。 文本类组件与富文本组件支持设置中文与西文的自动间距。 富文本编辑器组件新增支持预设的段落样式。 富文本组件新增支持在 content 接口中引用本地资源文件。 拖拽事件能力增强： 新增支持获取拖起方的包名。 新增支持延迟提供数据的能力，以提升拖拽的响应效率和用户体验。 新增支持悬停检测，并提供回调能力。 滚动类组件能力增强： List 组件新增支持设置方向键走焦模式。 ScrollBar 组件新增支持设置滚动条滑块的颜色。 Grid 组件新增支持设置方向键走焦模式。 滚动组件通用接口新增支持设置划动离手时触发，并限定使用鼠标滚轮划动时不会触发。 BuilderNode、ComponentContent 新增支持查询当前对象是否设置为继承父组件中自定义组件的冻结策略。 XComponent 的 C API 新增支持获取功能键按压状态信息的能力。 手势拦截新增支持由应用自定义需要阻止的手势。 图形变换新增支持设置组件的三维变换矩阵。 弹出式菜单新增支持多个生命周期回调，如 onWillAppear、onDidAppear、onWillDisappear 等。 全屏模态新增参数 enableSafeArea，支持适配安全区域。 自定义绘制新增绘制前景的能力。 新增 C API 支持在 UIContext 作用域内运行自定义函数的能力，基于该能力可确保在调用跨实例组件设置属性时的上下文正确性，避免跨实例接口调用失败。 新增 C API 支持获取目标节点的 uniqueId 的能力，及通过 uniqueId 获取节点的能力。 窗口管理能力增强： 新增监听窗口内 uiExtension 安全限制变化事件的能力。 针对 PC / 2in1 设备和开启了自由多窗的平板设备，新增支持在同应用内窗口的分合场景下将触屏输入事件从源窗口转移到目标窗口的能力。 针对 PC / 2in1 设备和开启了自由多窗的平板设备，新增支持将窗口最大化按钮置灰的能力。 ArkWeb Web 组件新增支持设置文本识别配置。 Web 事件新增支持在同层标签上执行鼠标操作（如左右键长按等）时触发回调。 新增支持获取当前网页加载进度的能力。 Audio Kit 音频新增低时延耳返的能力。 Background Tasks Kit 针对 PC / 2in1 设备，新增支持设置是否跟随系统的能效模式，以合理保证进程的运行。 Core File Kit 新增备份恢复框架安全退出的回调 API，可在应用备份或恢复完成时自定义执行一些额外的处理动作。 Data Augmentation Kit 新增获取知识加工状态功能。 Devcie Security Kit 新增支持审计通知类事件过滤功能，应用可通过获取设备上的安全审计数据，按需进行过滤，以支撑审计相关业务。 Game Service Kit 游戏近场快传支持返回发现设备列表，手动选择绑定接收端设备。 游戏近场快传支持碰一碰模式传输资源包。 Input Kit 针对 PC / 2in1 设备，新增 C API 支持由应用申请注入权限，包括注入按键事件、触屏事件、鼠标事件的权限。 Live View Kit 订阅抢购场景新增支持倒计时到 0 端侧自动更新。 实况窗卡片新增支持展示天气效果。 Localization Kit 新增支持获取时区跳变规则，包括时区跳变点的时间戳和偏移量。 Map kit 切换地图类型时，新增支持卫星图、混合地图类型。 室内图场景下，新增支持设置楼层调节控件位置的能力。 PDF Kit PDF 预览场景下，新增支持内容水平翻页浏览。 Pen Kit 手写套件新增自定义画布大小。 手写套件新增缩略图。 Performance Analysis Kit HiAppEvent 新增支持订阅应用查杀事件，用于上报应用被系统基于资源管控策略而对应用实施的查杀行为。 HiDumper 新增支持导出精简模式的内存信息，即通过“--prune”参数，只获取进程内存使用信息。 Remote Communication Kit 在发起网络请求的场景下，新增支持通过 ResponseCache 使用 HTTP 缓存的功能。 在发起网络请求的场景下，新增支持通过 fetchForSendable 返回 ResponseSendable 类型响应数据。 Share Kit 新增隔空传送分享能力，“一抓一放”实现跨端传输。 Test Kit UITest 新增多个 UI 测试能力的接口，如：获取指定屏幕内的控件对象，获取控件对象所属的屏幕 ID。 MDM Kit 新增支持针对企业设备清除应用产生的所有数据。 新增支持将应用锁定在 Kiosk 模式（即通过系统层面限定设备只能运行单个应用或者一组应用）。 Media Kit C API 新增支持低功耗音视频播放的能力。 新增支持监听 SoundPool 的错误事件。 NDK 开发 新增支持使用扩展的 Node-API 接口在当前线程中创建、切换和销毁上下文环境。 UI Design Kit HdsSnackBar 新增回退到上一个页面的回调函数。 HdsTabs 新增多个滚动组件场景下控制父滚动组件的能力。 HdsTabs 新增页签点击后返回索引的回调函数。 公共能力 配置文件 app.json5 新增字段 appPreloadPhase，允许配置应用预加载到不同阶段。 6.0.0 (20) Beta1 关键特性 Ability Kit 新增 StartOptions 的可选参数 CompletionHandler，用于处理拉端请求的结果。 新增 setEventHubMultithreadingEnabled，用于启用 Context 的 Eventhub 跨线程数据传递功能。 新增 C API，支持获取本应用的应用级的资源目录。 新增 C API，支持查询当前应用的调试模式。 新增 C API，支持获取当前应用程序的模块元数据数组。 新增元数据信息和模块元数据信息的 C API 定义。 新增支持获取指定资源标识符和组件信息标志对应的 Ability 信息。 新增 AppServiceExtensionAbility 模块，提供后台服务相关扩展能力，包括后台服务的创建、销毁、连接、断开等生命周期回调。 AR Engine 新增 ArkTS API，支持体积测量能力，可识别空间中立方体物体或者嵌入式立方体空间，并计算出被识别物体或空间的长、宽、高以及体积。 新增 C API，支持体积测量能力，可识别空间中立方体物体或者嵌入式立方体空间，并计算出被识别物体或空间的长、宽、高以及体积。 ArkData 新增接口 having，支持筛选符合条件的分组数据。 ArkGraphics 2D 将原有的一批 C API 能力封装提供为 ArkTS API，详见 API 参考中标记为“20+”的 API。 ArkGraphics 3D 新增支持从屏幕指定位置发射射线，检测并返回所有命中的 3D 物体信息的能力。 ArkUI 文本与输入组件能力增强。包括： 新增文本装饰线样式，支持对文本设置删除线和下划线。 文本组件新增支持定义所设置的文本行间距是否对首行生效。 文本组件的基础定义新增支持设置文本超长时的显示效果。 文本输入组件（TextInput、TextArea、Search）新增验证码类型的输入模式 ONE_TIME_CODE。同时也对应提供的 C API 属性 ARKUI_TEXTINPUT_TYPE_ONE_TIME_CODE。 文本组件新增文本描边样式，支持设置描述宽度和颜色。 新增 C API，支持统计文本组件中的文本行数（NODE_TEXT_LINE_COUNT）。 新增 C API，支持触发 Span 组件的长按事件（NODE_TEXT_SPAN_ON_LONG_PRESS）。 Refresh 支持设置最大下拉距离。 Tabs 在滑动页面切换时，支持设置翻页动画曲线。 滚动类组件支持设置滚动条的起始和末尾边距。 Swiper 组件支持在显示区域上方或前方插入或删除数据时，设置是否保持可见内容的位置不变。 拖拽事件支持获取事件发生时所在的屏幕 ID。 图形变化过程中，支持设置单个方向的旋转角。 自定弹窗支持获取初始化等弹窗状态。 优化栅格布局断点，若未配置更小断点的栅格列数，系统取已配置的更大断点的栅格列数补全未配置的栅格列数。 新增 ToolBarItem 组件，支持为窗口标题栏添加工具栏项。 新增无障碍事件的相关能力，在系统开启无障碍模式后，提供拦截无障碍事件的能力。 支持自定义开启 / 禁止角标显示。 支持查询当前 ComponentContent 对象是否已解除与后端实体节点的引用关系。 新增 C API，支持通过百分比或具体数值形式设置组件平移（NODE_TRANSLATE_WITH_PERCENT）。 绘制类组件支持通过 attributeModifier 动态设置属性方法。 CanvasRenderingContext2D 支持绘制圆角矩形。 ArkWeb 新增支持在长按弹出菜单时设置振动效果。 当 Web 页面触发 window.open (url, name) 时，支持根据 name 查找是否存在已绑定的 Web 实例。 ArkWeb 基于谷歌 Chromium 内核开发，使用的 Chromium 版本升级为 M132。 新增支持 ArkWeb 和客户端同步调用 JSBridge。 新增支持设置应用级自定义用户代理。 新增支持查询 / 注册取消 WebViewController 与 Web 组件的绑定状态。 上下文菜单新增支持撤销 / 重做 / 粘贴为纯文本操作。 Web 组件提供画中画功能，应用可在网页中创建浮动窗口以播放视频。 Audio Kit 新增支持查询指定的 source type 是否支持回声消除。 Basic Services Kit 新增设备类型枚举值，可用于校验 deviceType 的返回值。 Data Augmentation Kit 【新增 Kit】Data Augmentation Kit（数据增强套件）提供知识库、知识检索、知识问答（RAG）、图 / 图谱构建等数据底座增强能力，打造个性化智慧数据平台，实现个性化智慧体验。 Device Certificate Kit 新增支持根据编码类型获取 X509 证书的颁发者名称，以及证书吊销列表的颁发者名称。 Device Security Kit 新增支持数字盾服务，可保障用户设置、修改、认证密码时密码信息不被攻击者截取，并且在信息认证过程中呈现的信息不被攻击者覆盖、篡改。 新增防窥保护，支持应用根据窥视状态保护用户隐私，如非机主状态下不进行个性化推荐，隐藏浏览记录、支付记录、收藏记录等敏感信息。 Enterprise Space Kit 【新增 Kit】Enterprise Space Kit（企业数字空间服务）为企业安全管控类 MDM 应用提供高效、智能的数据传输能力，支持空间数据的管理与应用服务。通过严格的空间数据传输审核流程，确保数据传输的安全与合规性，实现空间数据的独立管理与隔离。 Graphics Accelerate Kit 新增游戏启动加速服务。 Location Kit 新增 POI（兴趣点）的定义，提供 POI 的信息查询能力。 新增支持获取两个位置之间直线距离的能力。 MDM Kit 新增支持禁用公网环境下升级的能力。 允许设置禁用 / 启用的特性新增设备维修模式（maintenanceMode）、备份恢复能力（backupAndRestore}、收发彩信能力（mms）。 Online Authentication Kit 新增支持通行密钥服务。 Remote Communication Kit 在使用 HttpEventsHandler 处理回调的场景下，新增支持返回 Request。 在设置 dnsRules 的场景下，新增支持 Happy Eyeballs 竞速连接。 Scan Kit 默认界面扫码能力支持模拟器。 自定义界面扫码能力支持模拟器。 Screen Time Guard Kit 【新增 Kit】在应用安全隐私保护前提下，Screen Time Guard Kit（屏幕时间守护服务）为开发者提供屏幕使用时间管控、应用使用限制等开放能力，满足不同用户对时间管理多样化诉求，更好的服务终端用户。 Share Kit 碰一碰分享支持手机与 PC / 2in1 设备间分享。 碰一碰分享支持 PC / 2in1 设备上的应用沙箱接收分享数据。 Test Kit 新增支持多种场景下输入文本的测试能力。 UI Design Kit 组件导航新增设置自定义区域、标题栏动态显隐、半模态样式、图标类型设置的能力。 新增 HdsSideBar 组件，支持应用使用侧边栏组件实现自定义侧边栏和内容区。 新增 HdsSideMenu 组件，支持应用设置侧边栏对应的一级菜单和二级菜单，并显示其新消息数量。 新增 HdsTabs 容器组件，支持页签栏分割线常隐、常显和渐进显隐。 新增 HdsSnackBar 弹窗，支持文本图标展示和按钮操作区，为应用提供简短通知和操作。 新增 HdsActionBar 组件，支持有主按钮展开和收起的多按钮操作动效，支持无主按钮的多按钮操作区。 新增 HdsListItemCard 组件，支持应用使用 HDS 的列表卡片组件实现多设备上的系统列表卡片样式。 新增 HdsListItem 组件，支持应用使用 HDS 的列表组件实现多设备上的系统列表样式以及横滑删除效果。 新增 UI 界面场景下的光影效果的能力。 调试工具 打包工具新增通用归一指令。 举报/反馈"
    },
    {
      "doc_id": 38336,
      "title": "华为开发者大会2025,鸿蒙持续深化与AI融合",
      "time": "2025-06-26T00:00:00+00:00",
      "content": "6月20日至22日，华为开发者大会2025（HDC 2025）在东莞松山湖举行，作为华为面向全球开发者的年度顶级技术盛会，本次大会聚焦鸿蒙生态的最新进展与未来发展方向，吸引了来自全球的开发者、合作伙伴以及行业专家的广泛关注，鸿蒙生态正步入全新的发展阶段。 鸿蒙系统发展历程 早在2012年，全球智能设备产业蓬勃发展，移动互联网浪潮汹涌，智能手机、智能电视等设备迅速普及。彼时，主流操作系统安卓和iOS虽占据主导，但存在硬件适配局限、设备间数据互通困难、协同操作体验不佳等问题。同时，国际技术竞争日趋激烈，操作系统作为数字经济时代核心基础设施，其自主可控对企业乃至国家的信息安全和产业发展至关重要。 华为洞察到未来智能设备多元化、全场景化发展趋势，不同设备间互连共享是必然走向。若依赖外部操作系统，不仅难以实现设备无缝协作与统一管理，还可能在技术升级、数据安全等方面受制于人。为掌握核心技术主动权，构建自有智能生态体系，华为决定投入资源，规划自有操作系统“HarmonyOS”。 鸿蒙1.0，2019年8月9日，华为在开发者大会上正式发布鸿蒙1.0系统 ，首次应用于华为荣耀智慧屏产品，标志华为正式进军操作系统领域。该版本初步展现分布式能力雏形，为后续系统发展奠定基础，拉开鸿蒙系统在智能终端领域探索序幕。 鸿蒙2.0，2020年9月10日发布，应用范围拓展至部分手机、车机、智能电视等设备。此版本引入全场景设备互联概念，优化性能，让不同设备间协同工作更顺畅，开始构建鸿蒙系统全场景生态框架。 鸿蒙3.0，2022年7月27日发布，超级终端重大升级，支持更多设备加入，跨设备协同体验进一步提升。在鸿蒙智联、万能卡片、流畅性能、隐私安全、信息无障碍等方面显著增强，全方位提升用户多设备使用场景体验。 鸿蒙4.0，2023年8月4日发布，着重强化智能互联能力，多屏跨设备投屏等功能实现技术突破，带来更便捷高效的跨设备交互体验。新增AI交互功能，为用户带来更智能操作感受，支持更多智能设备融入鸿蒙生态。 鸿蒙4.4，2024年推出，作为传统分支延续版本，针对耳机等特定设备适配优化，完善鸿蒙系统在可穿戴设备等细分领域应用体验，提升特定设备与其他鸿蒙终端协同能力。 HarmonyOS NEXT，鸿蒙5.0，2024年10月22日发布，是中国首个实现全栈自研的操作系统 ，标志中国在操作系统领域取得突破性进展，彻底脱离安卓，流畅度显著提升。2025年3月推送的5.0.0.130版本，新增“网络邻居”功能，优化相机和第三方应用兼容性；同月推出的5.0.3 Beta2版本，面向Mate70 Pro优享版等机型，侧重于性能调优；2025年4月发布的5.0.0.135版本，适配Mate 70/X6/Pad等旗舰设备，进行分层级体验优化。原生鸿蒙正式版也在2025年3月发布，推动鸿蒙生态向更纯粹、更自主方向发展 。 鸿蒙PC，2025年5月发布，进一步完善鸿蒙生态布局，为用户带来全新的电脑端操作系统体验。 鸿蒙系统应用生态现状 历经多年发展，鸿蒙生态已取得显著成就。截至目前，鸿蒙生态设备数量已突破10亿台，覆盖手机、平板、电脑、穿戴等各类终端设备，深入千行百业。 从应用数量看，自2023年9月鸿蒙应用全面启动至今，已有超3万的鸿蒙应用及元服务正加速开发和更新中，其中，Top5000主流应用已全部上架，满足用户99.9%的使用时长。华为开发者联盟注册开发者数量达800万，732万人通过鸿蒙生态学堂学习鸿蒙开发，官网月均阅读和使用开发文档次数达840万，鸿蒙工具下载次数达110万 。丰富的协作与支持资源，吸引大量开发者投身鸿蒙生态建设。 在产业合作方面，鸿蒙生态的影响力不断扩大。开源鸿蒙发展迅猛，代码已超过1.3亿行，社区贡献者接近9000，软硬件产品1200款，三方发行版达到69款，覆盖政务、交通、金融、电力、水利、建筑等众多领域 。政企办公领域加速鸿蒙化进程，目前已覆盖3800万+企业 ，为鸿蒙生态在行业应用领域的拓展奠定坚实基础。 HarmonyOS 6技术亮点，鸿蒙系统新突破 在本次华为开发者大会2025上，华为常务董事、终端BG董事长余承东正式宣布HarmonyOS 6启动开发者Beta ，为鸿蒙生态注入新活力。 HarmonyOS 6带来全新的互联体验，全场景体验更易用，时延低达毫秒级。全新“碰一碰”功能让手机与电脑之间的交互更高效更自然，轻贴屏幕即可秒传文件，该功能将随鸿蒙电脑HarmonyOS 6版本升级上线。目前，已有小红书、淘宝、京东、支付宝、大麦等50+应用支持碰一碰分享内容，WPS、新浪新闻、同花顺、优酷、咪咕、喜马拉雅、七猫小说等100+应用支持应用接续 ，实现设备间的无缝协作与内容自由传递。 鸿蒙智能再进化，AI能力更开放。HMAF鸿蒙智能体框架赋能鸿蒙应用和元服务智能化升级，让人机交互更自然、更强大、更高效、更协同 。交互方式从GUI（图形界面）导向LUI（自然语言界面），更聚焦于用户的“意图”而非“指令”。例如，用户只需说出“帮我创建一个午睡的纯音乐歌单”的模糊想法，小艺智能体便能自主完成创建。小艺智能体开放平台为开发者提供了50+鸿蒙系统插件和模板开发能力，开发者只需调用即可“组装”出能主动理解用户需求的智能助手。 在隐私与安全体验方面，HarmonyOS 6进一步升级。通过创新的隐私安全机制，搭载HarmonyOS 5的手机恶意应用安装次数每月减少1600万次，覆盖7类隐私数据的安全访问机制已拦截超过86亿次不合理权限索取 。在HarmonyOS 6 开发者Beta版本上，星盾安全架构再升级，通过AI能力加持，提供全新的AI主动防诈、创新的AI防窥保护功能，以智能化的主动安全，识别安全风险并帮助用户保护隐私，防止被骗。 除软件系统升级外，华为还展示了一系列与鸿蒙系统深度融合的硬件产品。鸿蒙电脑持续进化，实现“常用常新，越用越好用” ，全新“碰一碰”功能为用户带来更便捷的跨设备交互体验。同时，鸿蒙生态中的智能穿戴、智能家居等设备也不断丰富，通过鸿蒙系统的分布式技术，实现多设备之间的互联互通与协同工作，为用户打造全场景智慧生活体验。 随着HarmonyOS 6开发者Beta的启动，鸿蒙生态的未来发展充满想象空间。从技术趋势看，鸿蒙将持续深化与AI的融合，通过AI赋能全场景应用，提升系统智能化水平和用户体验。在生态建设方面，华为将继续秉持开源开放理念，吸引更多开发者和合作伙伴加入，丰富鸿蒙应用生态，拓展鸿蒙系统在更多领域的应用。 凭借其独特的技术优势和不断完善的生态体系，鸿蒙有望在全球操作系统市场占据更重要地位。尤其是在国内市场，随着政策支持和产业协同推进，鸿蒙生态将迎来更快速的发展，为政企数字化转型和消费者智慧生活提供更强大的技术支撑。 转自：科记汇 举报/反馈"
    },
    {
      "doc_id": 38339,
      "title": "HarmonyOS 6破茧,超三万鸿蒙应用全速开发",
      "time": "2025-06-20T00:00:00+00:00",
      "content": "21世纪经济报道记者倪雨晴 东莞报道 在华为开发者大会2025的舞台上，鸿蒙无疑是聚光灯下的主角。 “到今天，已经有40多款华为终端产品搭载鸿蒙5，有3万多鸿蒙应用和元服务在全速开发、积极更新。”6月20日，华为常务董事兼终端BG董事长余承东在会上披露了鸿蒙进展。 短短一年多时间，鸿蒙滚滚向前，生态扩展显著。更受关注的是，鸿蒙6在本次大会上揭开面纱。余承东表示，HarmonyOS 6 Developer Beta版本于当日面向开发者启动报名。 回顾过往，去年，鸿蒙5正式发布，实现了操作系统的完全自主可控。今年，鸿蒙6的面世，意味着华为在操作系统上更进一步，鸿蒙从“可用”走向“好用”。 如果说鸿蒙5是鸿蒙操作系统的“成人礼”，那么鸿蒙6则象征着系统“成熟期”到来。鸿蒙就像生命体一般，不断进化、迭代。 眼下，鸿蒙生态进入新一轮升级周期。余承东说道：“从2023年9月25日到今天，635个日夜，鸿蒙生态建设之路很难，但是再难，有数以亿万计的伙伴、开发者、消费者与我们在一起，实现了中国科技力量的一次集体冲锋，创造了了不起的鸿蒙速度，鸿蒙像一列快车，昂然向前，奔腾不息。” 鸿蒙快车向前 在鸿蒙操作系统的演进蓝图上，其生态系统的扩张正呈现出两大显著趋势：一是消费级应用和政企办公领域应用都在快速融入，二是系统底层能力的跨越式升级。 余承东表示：“目前适配鸿蒙的通用办公平台已超过100个，工作台支持快应用已超50000个，覆盖企业超过3800万家；我们呼吁更多政企内部办公应用搭上鸿蒙快车，和我们一起加速鸿蒙化的进展。” 随着HarmonyOS迈入6.0时代，鸿蒙正在进行新的跨越。华为终端BG CEO何刚表示：“过去一年，鸿蒙全场景拼图不断完善，大模型、智能体的突破，给应用交互带来更多可能。HarmonyOS 6积极拥抱这些变化和进步，在互联、智能、安全、流畅等方面给应用生态带来更多创新。” 其中，鸿蒙6有两大核心升级点，最受关注。 其一是全场景互联的能力重构，全场景互联是鸿蒙的基因。华为在HarmonyOS 6推出全新互联架构，整合华为软、硬、芯、云一体化优势，进一步提升互联能力。 何刚举例道，通过“碰一碰”技术，用户可快速在设备间分享图片、视频、商品链接，甚至发起组队、红包等社交互动。这一功能已适配小红书、淘宝、京东、知乎、优酷、钉钉等主流应用。同时，“碰一碰”正在拓展至更多新设备，如鸿蒙电脑即可通过屏幕智感技术识别手机轻触，实现跨端文件一触即传，WPS、美图秀秀、剪映均已支持。 其次是鸿蒙智能的再进化。据介绍，华为通过系统架构与软硬芯云垂直整合创新，将AI融入到鸿蒙操作系统底座。尤其是在AI Agent趋势下，今年手机厂商纷纷在智能体领域发力，AI手机竞争更加激烈。 何刚表示，鸿蒙智能实现了架构升级，通过端云协同，鸿蒙把智能体、MCP等技术全面开放。并且，华为不仅有全新的鸿蒙智能体，还推出HMAF鸿蒙智能体框架，构建一个具备自主决策和群体协作能力的全新AI生态体系。 他进一步谈道，用户可通过华为手机助手“小艺搜索”“小艺建议”等方式直达鸿蒙智能体入口，完成多步复杂任务调度。目前，首批50多个先锋鸿蒙智能体正在开发中，覆盖微博、喜马拉雅、深圳航空、京东、小红书等高频应用。 此外，在安全领域，鸿蒙6进一步强化“星盾安全架构”，通过AI技术的深度应用构建主动防护能力，为用户主动规避隐私安全风险；流畅度上，通过方舟调度引擎，HarmonyOS对应用进行全流程加速，深度适配的App如小红书、哔哩哔哩等已实现“秒启、秒开、秒加载”。 可以看到，从政企办公到智能终端，从系统底座到生态协同，鸿蒙正在以“快车”之势加速前行。当然，鸿蒙的挑战依然严峻。生态的繁荣不仅取决于应用数量，更在于高质量、原生体验应用的规模。 业内人士向记者指出，鸿蒙操作系统的发展路径，也展现了一种清晰务实的战略思路。这既是应对外部压力的必然选择，也是其谋求长远发展的核心棋局。当前，鸿蒙一边推进应用生态的广度，一边深挖技术护城河，诸如跨端协同和底层AI Agent框架的构建，旨在提供具有代际优势的交互范式。 生态飞轮加速 目前，鸿蒙生态已实现手机、平板、电脑、可穿戴等核心智能终端全覆盖。同时，对于华为而言，生态更是鸿蒙生命力的长期支点。生态之战是艰难又关键的一役。 余承东介绍，鸿蒙生态是一个逐渐完善的过程，“一年多以来，我们收到了近400万条意见和建议，系统功能更新260多项，开发者提交版本数超过27万次，完成了大家的216万条心愿单。”他特别提到，“搭载鸿蒙5的nova14系列，上市仅24天销量便突破百万台。” 在余承东看来，鸿蒙生态的“飞轮效应”正在加速，鸿蒙体验就像一条“微笑曲线”。一方面，用户体验穿越曲线底部，正在加速提升。另一方面，操作系统与应用生态正展开史上最大规模的联合创新，共同驱动生态向上成长。 在鸿蒙和开发者联合共创的过程中，累计有9000多个应用参与了70多种系统级创新体验的联合打造，接入了碰一碰、实况窗、系统扫码等能力，让鸿蒙应用形成差异化，为用户带来更具竞争力的功能和服务。 而在开发者生态方面，华为终端BG软件部总裁龚体表示：“鸿蒙从来就不属于某个公司，而是属于大家的。过去的半年多时间里，30多个伙伴共建了50多个项目，覆盖框架、媒体、工具和安全等众多领域。比如，微信的大图渲染组件HDImageViewer，大图加载性能提升4倍，内存占用降低55.6%。” 开发者是生态的重要参与者，是生态繁荣的关键力量。龚体分享了一组数据：“自去年年初以来，开发者反馈的需求和问题数已超过280000条，需求接纳和问题解决率超过了96%，伙伴SDK数量超760个，开源组件库数量超1100个，产学合作项目数量超280个。” 接下来，如何进一步吸引开发者？华为表示，一次开发多端部署是鸿蒙的核心理念之一，是对应用开发范式的重塑，一次开发多端部署，能够让新增设备适配开发成本降低70%。 比如，飞书只用了一天时间，就完成了三折叠的基础体验适配，一周内就实现了对PuraX和鸿蒙电脑基础体验的支持。 “我们真正希望的是拥抱开源、拥抱跨平台，开发的代码在鸿蒙、iOS、安卓三个平台上有最多的复用，实现1+1+1<2，将全行业的开发效率，推向一个新高度。”龚体说道。 小红书相关负责人表示，开源已成为推动软件创新的重要方式。过去，由于历史原因，中国互联网公司长期处于开源的“参与者”而非“主导者”的角色。因为鸿蒙，中国互联网公司第一次有了与操作系统深度共建的机会。当前，小红书与鸿蒙共建播放器REDPlayer等能力。 操作系统生态发展之难在于，初期开发者顾虑用户规模，用户又期待完善体验。鸿蒙要突破这一世界级难题，不仅依托于中国庞大且活跃的市场基础，更源于整个产业链上下游伙伴的深度协同与合力共建。当前，鸿蒙生态正大步走向扩张阶段。 更多内容请下载21财经APP 举报/反馈"
    },
    {
      "doc_id": 38342,
      "title": "美AI企业拿到五角大楼订单",
      "time": "2025-07-17T00:00:00+00:00",
      "content": "美国国防部7月14日宣布，向OpenAI、Anthropic、谷歌以及美国亿万富豪马斯克旗下的xAI四家人工智能（AI）企业授予重大开发合同，这些公司已各自获得最高达2亿美元的合同。国防部称，此举旨在扩大美国国防部对先进人工智能能力的应用规模。 彭博社15日报道称，此轮合同的核心目标是开发“智能体工作流”，使AI系统能够读取机密数据、自主推理并提供决策建议。据美国防务新闻网“Defensescoop”14日报道，五角大楼将获得这四家公司开发的部分最先进人工智能能力，包括大语言模型、智能体工作流、云端基础设施等。 此次公告是五角大楼近来为加速采用商业公司开发的AI能力所采取的最新举措——这些公司近期纷纷宣布了聚焦国家安全的新业务方向。彭博社15日报道称，这些合同为寻求扩大公共部门业务的人工智能公司提供了重要收入来源。路透社也提到，此次公布的合同深化了引领人工智能竞赛的企业与美国政府运作之间的联系。 今年6月，Anthropic推出了专门针对国防应用场景定制的Claude Gov AI模型系列。同月，OpenAI也启动了名为“OpenAI for Government”的新计划，在现有与国防部及美国政府其他机构合作基础上进行扩展——包括为国家安全部门开发定制AI模型。另据美国CNBC网站报道， xAI公司当地时间周一同步宣布推出“Grok for Government”产品套件，将其人工智能模型开放给美国政府部门客户。 彭博社报道提到，美国国防部正通过“商业优先”策略加速人工智能部署。早在2024年10月，美国《财富》杂志就曾报道称，美国国防部在此前两年中签署了约6.7亿美元合同，涉及近323家公司的多种AI项目。美国国防部首席数字和人工智能官道格·马蒂在声明中表示：“人工智能的采用正在重塑国防部支援作战人员并保持战略优势的能力。” 据路透社报道，在美国白宫4月颁布推动人工智能应用的行政令驱动下，美国政府机构一直在扩大人工智能的使用范围。本届政府还通过撤销拜登政府2023年旨在通过强制数据披露降低人工智能风险的行政令，采取措施放宽对该技术的监管。 值得注意的是，上周，xAI公司的人工智能聊天机器人Grok因发表出格言论而遭到抨击，该事件促使公司承诺改进模型。美国《华盛顿邮报》报道认为，该事件已造成损害，暴露了人工智能军备竞赛中快速部署新技术的隐患，以及训练缺陷或用户操纵现有模型可能带来的后果。（李迅典） #优质作者流量激励计划# 举报/反馈"
    },
    {
      "doc_id": 38344,
      "title": "美科技巨头角逐五角大楼大单,向AI要营收|企服国际观察",
      "time": "2025-07-08T00:00:00+00:00",
      "content": "图片来源@unsplash 上月，OpenAI与美国国防部签署了一份价值2亿美元为期一年的合同订单。根据该合同，OpenAI将为其提供AI工具，以应对作战和企业领域的关键国家安全挑战。美国国防部表示：“根据该合同，履约方将开发原型前沿AI能力，以应对作战和企业领域的关键国家安全挑战。” 近年来，美国白宫及五角大楼与硅谷多家巨头科技公司签订合同协议，从颇有争议的百亿美元云计算大单，到聚焦生成式AI在军事领域的应用拓展，市场潜力虽巨大，但诸多政策、原则、合作策略上的转变，致使政府订单采购市场的争夺，变得愈发激烈。 拉近政府关系的，不止有老牌巨头 最先吃上政府铁饭碗的是大数据厂商Palantir。20年前成立之初，Palantir就服务于CIA等情报机关，为其提供辅助分析服务，随后多年将其服务机构扩展到多个美国政府机关、军方，以及商业领域。 得益于这一点，Palantir近些年持续实现业务收入强劲增长，2024年至今，该公司股价实现飙升，最高涨幅超过7倍。其收入60%来自于政府业务，作为Project Maven项目的主要承接单位，Palantir在2024年与美国国防部签署了更大的合同，以扩展该项目。 另一家云数仓厂商Snowflake也在渗透到该领域。今年4月，Snowflake以10亿美元拿下美国国防部“Impact Level S临时授权”，凭借此项授权，国防部内所有机构和军种将能够使用增强的数据能力，包括但不限于：财务管理、企业业务运营、物流供应链、网络安全等，这些都将基于Snowflake实现数据云迁移的现代化并加速其数据迁移。 相较之下，亚马逊AWS、微软Azure、谷歌等云厂商在国防云领域的项目争抢更为激烈，动辄百亿美金大单，致使云厂商之间的投标诉讼屡见不鲜。 2019年至2022年期间，美国国防部（DoD）有两个著名百亿美元云计算合同——国防飞地服务（DES，Defence Enclave Services）和联合作战云能力（JWCC，Joint Warfighting Cloud Capability）计划。2019年，美国国防部曾计划单一供应商模式，但由于该竞标一直存在不少外部争议，继而被搁置。2022年，美国国防部将价值90亿美元的JWCC合同授予到亚马逊、谷歌、微软和Oracle等四家云供应商，项目期限为5年。 微软一直是美国政府的重要合作伙伴。除了提供云服务，微软也在为其提供AI解决方案。2023年6月，微软宣布计划将OpenAI GPT-4大模型引入美国国防部、NASA等政府机构。2025年4月，宣布其支持OpenAI的Azure产品将通过国防信息系统局（DISA）的新授权提供给更多的联邦工作人员，这标志着该服务已获得所有政府分类级别的批准。 目前来看，OpenAI作为大模型提供商除了通过微软分销外，也与美国政府建立直接合作关系。除了上述最新2亿美元合同订单外，OpenAI的Sora模型已经被美国陆军选择，用于战场模拟训练，该模型可快速构建用于演习和作战复盘的虚拟环境。 去年年底，OpenAI宣布与国防技术初创公司Anduril Industries合作，为“国家安全任务”部署先进的AI系统。两家公司表示，合作将专注于提高美国的反无人机系统（CUAS）及其实时检测、评估和应对潜在致命空中威胁的能力。这标志着OpenAI首次与一家商业武器制造商合作。当时，Anduril还获得了一份价值1亿美元的国防合同，OpenAI、Meta等公司参与其中。 同一时间段内，OpenAI的竞争对手Anthropic表示，将与Palantir和亚马逊合作，向美国国防和情报机构提供其AI模型Claude 3。而马斯克xAI同样增加了与政府机构的合作，包括与微软合作分销其Grok大模型。 今年1月，OpenAI、甲骨文、日本软银三家公司则共同出现在白宫，并宣布出资投建，计划在美国建设数据中心，一项耗资5000亿美元的“星际之门”项目，以支持人工智能技术发展。 刚被Meta收购近半股权的数据标注初创公司Scale AI，同样与美国政府关系密切。 2020年9月，成立仅4年首次和军方达成合作，一举拿下美国国防部的9100万美元大单，协助美国军方试验、开发、更新用于机器学习和AI的标注数据集。2024年，与美国国防部合作开发“大语言模型评估测试方法”，以便在AI技术安全标准和政策尚未成型的背景下，确定特定模型的基准性能，解决AI技术应用中出现的各类问题。今年3月，Scale AI还与国防部签署了数百万美元的合同。 政府市场潜力巨大，巨头向AI要营收 为何如今硅谷科技公司纷纷与政府部门展开旗帜鲜明的商业合作？ CBS News访谈中，Geoffrey Hinton指出，目前几乎所有AI巨头都和特朗普关系密切。这些巨头正积极游说，希望放宽对AI的监管，只为了追求短期利润。 外媒Quartz发表言论认为，核心原因在于AI的经济效益正变得难以为继，训练和运行大模型成本巨大，仅靠消费者端的收益根本无法弥补该成本。对于许多企业而言，与政府合作不仅是机会，还可能是生存的必要条件。 事实情况来看也确实如此，伴随AI融入政府机构尤其是军事领域的过程中，谷歌、微软、亚马逊、Palantir、OpenAI、Oracle等科技公司也获得了与美国国防部更深层次的绑定，以及利润丰厚的国防订单。 实际上，业内对AI带来的经济效益存在一直存在不确定性。高盛研究部曾预测，未来10年，生成式AI或将推动全球GDP增长7万亿美元，增幅达7%。 悲观人士认为，至少未来10年，AI对经济的影响不会有那么夸张。2024经济学奖获得者、麻省理工学院教授达龙·阿西莫格鲁（Daron Acemoglu）指出，以美国劳动力市场为参考，市场上只有约四分之一的任务能够盈利，仅20%的任务可以被AI取代或增强，而其余75%任务的实施成本可能会超过收益。比如电工、护士、教育工作者等职业通常是“解决问题的任务，这些任务需要实时、基于情景且可靠的信息。” 另一种解释是，想要发挥技术的全部经济价值，需要配套以一系列互补性创新浪潮。比如即便技术已经可用，许多企业也无法立即或有效部署，而是需要数据库、数据管理系统和IT专家。同时，还要进行重大组织和流程变革，才能与AI实现协同运作。在这种调整中产生的成本，也会在中短期内抵消掉AI带来的经济效益。 因而也可以认为，科技公司在加大对AI资本开支的同时，为降低过度投资带来的风险，必然需要通过与政府合作扩大未来竞争优势局面。 另一方面，美国国防部是这场AI科技竞赛中的强有力推手，而AI也成为其顶层战略。据2024年美国海军陆战队发布《人工智能战略》，旨在指导部队在全工作流程中整合AI技术，随后在2025年《人工智能实施计划》，明确2025-2027年数字化改革时间表，旨在通过人工智能技术夺取现代战争决策优势，构建全域智能化作战体系。 根据美国国防部官员于6月最新披露的2026财年国防预算背景简报，预算中18亿美元用于审计相关活动，其中包括2亿美元用于自动化和AI的重大新投资，以及1.5亿美元用于业务系统更新，以加快财务报表审计。 与此同时，特朗普政府已在推动2026财年1万亿美元的国防预算，这也将成为美国历史上最高的一笔国防预算。有个细节点值得注意的是，这笔预算提高，是以其他各政府部门预算以及一些非必要支出的缩减为前提。例如上半年，在马斯克牵头的政府效率部（DOGE）推动下，埃森哲、德勤等管理咨询公司与美政府部门此前签署的业务咨询类公司相继被终止。 此外，美国政府层面还有一种声音是：削减和控制成本。去年，美国陆军推行生成式AI试点项目，但随着越来越多AI项目和服务的使用，云计算成本开始飙升。为此美国陆军计划简化其云合同，将同一供应商的服务整合到同一份合同中。 今年4月，Oracle通过美国国防部（DoD）联合作战云能力（JWCC）合同签订了一份固定价格任务订单，为美国陆军企业云管理局（ECMA）提供云计算和存储服务。这些服务将通过Oracle美国国防云交付。此举旨在简化云管理、增强安全性并降低成本。 不过，美国政府及军方强调AI军事化，也在引发美国媒体和相关专业人士的担忧。 2018年，4000名谷歌员工联名抗议为美国国防部五角大楼提供服务。这种抵制起了作用，谷歌高层被迫做出决定，没有续签与五角大楼的军用AI项目合同Project Maven，并制定了限制军事应用的AI原则。此后多年，以谷歌等科技公司高举“科技向善”大旗，至少在反对AI武器化这一方面有所行动。但如今，随着AI技术的发展与国家间军事竞争的推进，这种氛围墙已经被打破。 2024年1月，OpenAI删除了“禁止其技术被用于军事用途”的条款。2025年3月，OpenAI再度对其核心价值观调整，删除了“影响驱动”等强调员工“深切关注现实世界影响”的价值观，代之以“关注通用人工智能（AGI）”。 2025年2月，谷歌同样删除了“限制其AI技术用于军事用途”的原则，并且修改安全框架，表明只有在竞争对手采取类似措施的情况下才会遵循相关准则。谷歌强调，公司和政府应携手打造能够“支持国家安全”的AI系统。 结合近来OpenAI与美国国防部签署的2亿美元合同，Meta、OpenAI和Palantir高管宣誓就任陆军预备役军官，Meta与国防初创公司Anduril合作为作战士兵打造增强现实版头戴设备……等一系列动作来看，这一重大原则上的转变，也预示着美国科技公司公然放弃了过去多年限制为军事工作的安全政策，转而深度参与到军事化领域。 接下来，科技企业在算力储备与AI方面的竞争，也正体现到政府间国防力量的PK。（本文首发于钛媒体APP，作者 | 杨丽，编辑 | 盖虹达） 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 38349,
      "title": "奥尔特曼打响“隐私保卫战”!法院勒令OpenAI无限期保存用户聊天...",
      "time": "2025-06-12T00:00:00+00:00",
      "content": "OpenAI与《纽约时报》之间的版权诉讼近期迎来新进展。 当地时间6月5日，OpenAI发表声明称，正在对《纽约时报》要求无限期保留ChatGPT输出日志数据的诉讼请求提起上诉。 OpenAI认为其“毫无正当理由”，还将带来巨大运营负担。OpenAI首席执行官山姆·奥尔特曼（Sam Altman）称，《纽约时报》的要求是不恰当的，并开创了一个糟糕的先例。他强调，“我们将抵制任何损害用户隐私的要求，这是我们的核心原则。” 人工智能专家西蒙·威利森（Simon Willison）认为，数据保留令对OpenAI构成“巨大的竞争劣势”，尤其是API业务。付费使用API的客户可能会选择其他不会强制保留用户聊天内容的服务商。 据彭博社报道，OpenAI 2025年营收预计为127亿美元。按照人工智能调研机构FutureSearch此前的报告，API调用占OpenAI收入的15%左右。照此计算，API业务板块今年的收入将超过19亿美元。 此外，安杰世泽律师事务所数据合规业务合伙人杨洪泉在接受《每日经济新闻》记者（下文简称“每经记者”）采访时表示，强制保存用户聊天记录可能会使OpenAI陷入跨国法律冲突。例如，根据欧盟《通用数据保护条例》，理论上，若OpenAI违规，其面临的潜在罚款或高达数亿美元。 图片来源：视觉中国-VCG41N1309760279 OpenAI“硬刚”数据保留令，奥尔特曼：“开创了糟糕的先例” 当地时间6月5日，OpenAI发表声明称，正在对《纽约时报》要求无限期保留ChatGPT输出日志数据的诉讼请求提起上诉。OpenAI认为该诉求与其对用户做出的隐私保护承诺相悖。 就在上月，美国一法院裁定OpenAI必须无限期保留并隔离所有ChatGPT的输出日志数据。 原告《纽约时报》认为，OpenAI可能会删除部分聊天内容，而这些内容本可以在版权诉讼中作为“罪证”，例如，用户通过ChatGPT绕过付费墙、总结《纽约时报》原创文章的聊天记录等。 图片来源：数据保留令 据了解，受美国法院最新裁定影响的OpenAI用户包括ChatGPT免费版、Plus、Pro和Team用户，以及未使用“零数据保留（ZDR）”协议的API客户。而ChatGPT企业版、教育版以及使用ZDR端点的API客户不受影响。 对于这批受影响的用户，根据OpenAI过去的数据保留政策，用户已删除或未保存的对话将在30天内从OpenAI的系统中删除，除非因法律原因需要保留。而现在，这些本应在30天内就“消失”的聊天内容，将被无限期保留。 不过，该项数据保存命令遭到了OpenAI的强烈反对。 OpenAI指出，这一要求严重威胁全球数亿用户隐私，损害OpenAI与用户的信任关系，给其带来巨大运营负担，还可能导致其违反客户合同及全球隐私法规。 OpenAI指出，这一要求严重威胁全球数亿用户隐私，损害OpenAI与用户的信任关系，给其带来巨大运营负担，还可能导致其违反客户合同及全球隐私法规 OpenAI在其网站上发布了一篇长文，称《纽约时报》的诉讼是“毫无根据的”，并详细阐述了其隐私保护方法。 图片来源：OpenAI官网 OpenAI补充称，这些数据不会公开，仅极少数法律和安全人员可访问，且不会自动与《纽约时报》或其他方共享。 OpenAI首席执行官山姆·奥尔特曼（Sam Altman）公开批评了这项判决，称《纽约时报》的要求是不恰当的，并开创了一个糟糕的先例。他强调，“我们将抵制任何损害用户隐私的要求，这是我们的核心原则。” 图片来源：X OpenAI首席运营官布拉德・莱特卡普（Brad Lightcap）也称，《纽约时报》的要求是“宽泛且不必要的”。他指出，这一裁定存在“越权”情形，“放弃了长期存在的隐私规范，削弱了隐私保护”。 《纽约时报》将这项裁定视为一项重大胜利，认为这将有助于获取OpenAI侵权的关键证据。 早在2023年底，《纽约时报》就以侵犯版权为由，向OpenAI和微软提起了诉讼。起诉书指出，OpenAI的ChatGPT和微软的Copilot在未经许可且未付费的情况下非法复制和使用其数百万篇原创文章，并呈现给提问的用户，甚至被当作可靠信源。 当时，《纽约时报》还要求OpenAI和微软销毁使用其版权材料的训练模型和数据。《纽约时报》表示，如果新闻机构无法保护其独立报道，原创报道就会越来越少，届时计算机和AI也无法填补这一空白。 OpenAI超19亿美元业务恐遭重创，还可能面临跨国法律纠纷 随着美国法院的裁定公布，用户对数据安全的担忧日益加剧。 人工智能专家西蒙·威利森（Simon Willison）认为，数据保留令对OpenAI构成“巨大的竞争劣势”，尤其是API业务。付费使用API的客户可能会选择其他不会强制保留用户聊天内容的服务商。 据彭博社报道，OpenAI 2025年营收预计为127亿美元。按照人工智能调研机构FutureSearch此前的报告，API调用占OpenAI收入的15%左右。照此计算，API业务板块今年的收入将超过19亿美元。 安杰世泽律师事务所数据合规业务合伙人杨洪泉在接受每经记者采访时指出，从长远视角来看，用户对AI平台的信任构建于透明度和可预期性之上。“通常情况下，平台会向用户说明其所拥有的权利，以及用户数据的处理和保存方式，用户也有权要求平台删除其个人数据。若用户点击删除按钮，相关对话记录理应被永久删除。” 但他强调，当前法院命令打破了这一信任逻辑。“现在依照法院命令，这些对话将被无限期保存，这使得平台难以兑现此前对用户做出的承诺。” 不仅如此，OpenAI还将面临巨大的技术挑战，数据泄露风险也会呈指数型增长，甚至还可能陷入跨国法律冲突。 杨洪泉还表示，“AI平台拥有海量用户，每日产生的对话数据量极为庞大，长期存储这些信息需要搭建大规模存储基础设施及备份方案。”他指出，数据保留时间越长、规模越大，数据泄露风险也会呈指数级增长，“一旦黑客针对这些敏感聊天日志发动攻击，成功入侵可能导致用户数据大规模泄露。” 此外，强制保存用户聊天记录可能会导致跨国法律冲突。长期以来，美国的司法证据制度一直存在着与其他国家和地区数据保护法律制度相互冲突的情况。 杨洪泉强调，“欧盟《通用数据保护条例》、《加州消费者隐私法案》（CCPA）等数据保护法律均明确，用户有权要求企业在完成信息处理目的后删除数据，或应用户请求删除数据，但美国法院的命令可能导致AI平台无法响应这类删除请求。” 而违反这些规定可能会让OpenAI面临高额的处罚。 例如，欧盟《通用数据保护条例》规定，欧盟监管机构最高可以对违规企业处以高达全球年营业额4%或2000万欧元的罚款，选择二者中较高的数值判罚。 按照OpenAI今年127亿美元的预估收入计算，潜在的罚款金额可能高达5亿美元。 免责声明：本文内容与数据仅供参考，不构成投资建议，使用前请核实。据此操作，风险自担。 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 38352,
      "title": "AI+制造,这些风险超乎想象_澎湃号·湃客_澎湃新闻-The Paper",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "制造业的数字危机：AI与网络安全的博弈 在数字化转型的浪潮中，制造业正站在效率革命与安全危机的十字路口。当AI技术以惊人的速度重构生产流程时，一个令人不安的事实正在浮现：AI技术的广泛应用为生产效率带来了巨大提升，同时也带来指数级增长的安全隐患。『制造前沿』团队在进行『AI+制造』深度专题研究时发现，来自Verizon、Ponemon等机构的最新数据显示，制造业网络安全威胁已从\"潜在风险\"演变为\"生存危机\"，这是令人警醒的。『制造前沿』本文将基于全球第一手的行业调查报告（主要数据来源于国外研究机构），为您揭示AI这场热闹的背后静默爆发的安全风暴。 AI与网络安全：一场完美的风暴 据最新数据显示，77%的制造商正在利用AI技术提升效率。然而，这些看似先进的技术连接却为攻击者创造了一个完美的漏洞风暴。现代制造运营所生成和处理的数据资产早已超越了传统的生产指标范畴。AI的融入从根本上改变了现有的安全挑战，使其威胁呈指数级增长。 刚刚发布的 2025 年 Verizon 数据泄露调查报告(DBIR) 揭示了一个惊人的现实：去年，全球制造设施共遭受了1607起确认的数据泄露事件，几乎是此前849起的两倍。更令人担忧的是，2025年Ponemon报告揭示，42%的制造行业数据泄露事件直接源于第三方访问漏洞。随着组织越来越依赖外部供应商、云平台和合作伙伴，他们的安全边界已经有效地消失，给敏感数据带来了前所未有的风险。每次数据泄露事件平均给制造商造成了550万美元的损失，除了第三方安全风险之外，勒索软件、漏洞利用和生成式人工智能平台新出现的威胁的显着增加，这迫切需要采取行动。 为何制造业成为攻击目标？ 现代制造运营所生成和处理的数据资产早已超越了传统的生产指标范畴。理解真正面临的风险，有助于解释为什么从竞争对手到国家行为体的威胁者越来越将工厂网络作为攻击目标。 制造商现在保护的不仅仅是生产线，他们保护的敏感数据的整个生态系统包括专有配方、产品设计、供应商关系和战略计划。 知识产权是制造业的“皇冠上的明珠”。产品设计、化学配方和专有制造工艺往往凝聚了几十年的研究和改进成果。这些不仅仅是文件，它们是经过数十年磨砺的竞争优势。 IBM的最新研究显示，知识产权盗窃行为激增了27%，每份被盗记录如今给组织带来了173美元的损失。一次数据泄露事件可能会因暴露革命性技术或秘密配方而抹去市场领导地位。 运营智能同样是一个极具吸引力的目标。生产和供应链数据揭示了产能限制、客户优先级、供应商关系和定价结构，为竞争对手提供了压低报价或挖角供应商的路线图。 当质量控制记录被泄露时，可能会在一夜之间摧毁精心培育的声誉，尤其是如果它们揭示了之前未披露的缺陷或安全问题。 战略规划材料进一步放大了这些风险。合并文件、财务预测和董事会演讲稿暴露了估值模型和战略计划，可能会危及数十亿美元的交易和竞争脆弱性。这些高风险文件越来越多地通过AI系统进行分析和优化，从而创造了新的暴露点。 人为因素与合规复杂性 46%的数据泄露事件涉及个人数据，制造商面临着日益增加的合规义务。员工记录中的个人身份信息（PII）和受保护的健康信息（PHI）受到严格的法规监管，如GDPR和HIPAA。违规行为会通过巨额罚款进一步增加数据泄露的成本。 AI如何放大传统安全风险 将AI融入制造运营不仅增加了新的漏洞，更是从根本上将现有的安全挑战转变为指数级增长的威胁。 外部连接问题已达到临界点。83%的制造商存在未记录的外部连接，边缘设备和VPN（如今占漏洞目标的22%，从3%上升）加剧了风险。 46%的制造商认为远程访问点是最薄弱的安全环节，而随着AI对数据的持续需求，这些点变得更加脆弱。基于云的AI模型打破了保护工厂数十年的气隙安全。 阴影数据与第三方风险 三分之一的数据泄露事件涉及阴影数据（存储在正式管理策略之外的信息），而57%的组织无法跟踪外部内容共享。AI系统可能会从未跟踪的来源（如共享驱动器或电子邮件附件）中提取敏感数据。 与此同时，60%的公司无法有效监控员工对生成式AI工具的使用，这意味着敏感的制造数据可能会在不知情或未经同意的情况下被输入到公共AI模型中。 42%的数据泄露事件源于第三方访问，其中35%是由于过度权限。然而，54%的制造商跳过了对供应商的安全评估。当AI供应商需要深度系统集成以有效运行时，这些疏忽会从小风险转变为灾难性的漏洞。组织面临着时间上的不匹配——边缘设备漏洞的中位修复时间延长至32天，而这些漏洞却面临着立即被利用的风险。 黑箱问题与安全团队的困境 AI的不透明算法隐藏了潜在的妥协，使安全团队在复杂的机器学习层中难以检测到数据泄露。制造安全团队每周已经花费超过47小时分析风险，而当AI操作掩盖潜在威胁时，他们的任务变得不可能完成。 真正的成本：超越头条新闻 当制造行业的高管看到数据泄露的统计数据时，他们往往只关注表面数字。然而，真正的影响远远超出了初始事件响应，可能会引发连锁故障，使运营瘫痪数月甚至数年。 直接的财务影响比以往任何时候都要严重。数据泄露事件平均给制造商造成了550万美元的损失，比全球平均水平高出13%，其中75%是由业务损失和响应工作驱动的。近一半的公司面临罚款，50%的公司丢失敏感数据，对于小型企业来说，88%的数据泄露事件涉及勒索软件，中位支付金额为11.5万美元。 运营中断的影响甚至比直接成本更为严重。70%的被攻击组织报告称运营受到严重中断，将精密制造环境变成了混乱的场所。恢复需要超过100天的时间，扰乱了生产、客户承诺和供应链。 竞争劣势在系统恢复后仍会持续存在。当商业机密泄露给竞争对手或国家行为体时，损害就变得永久性了。经过数十年建立的市场地位可能会在几个季度内因竞争对手利用被盗知识产权而被侵蚀。 创新管道也会停滞，因为研发团队失去了对其下一个突破性成果不会被泄露的信心。当数据泄露事件公之于众时，客户关系也会受到长期损害。 监管罚款进一步加剧了这些损失。除了即时罚款外，现在有22.7%的组织支付的罚款超过5万美元。GDPR罚款可能会达到年收入的4%，而像NERC CIP这样的行业特定法规也会带来严厉的惩罚。 实用的风险缓解策略 制造行业的领导者需要在预算、专业知识和运营需求的实际限制内找到可行的解决方案。鉴于98%的公司计划在2025年增加网络安全投资，现在正是采用这些策略的时机。 技术解决方案可以带来可衡量的回报。实施AI驱动的安全技术的组织在每次数据泄露事件中平均比没有这些技术的组织节省了220万美元。从零信任架构开始，保护数据交换系统免受利用。 安全数据网关在AI系统和敏感存储库之间创建了受控的桥梁，保留了AI创新的好处，同时限制了暴露。然而，目前只有27%的制造商使用增强的身份管理来保护高价值数据。 治理从负担转变为业务推动器。从全面的数据分类开始（你无法保护你看不到的东西）。实施基于角色和基于属性的访问控制，这在35%的数据泄露事件源于过度权限的情况下尤为重要。 通过基本的审查流程填补供应商监督缺口，显著降低第三方风险。创建供应商评估框架，平衡安全要求与运营需求。 - 每周修补边缘设备，而不是等待通常的32天。 - 对所有第三方访问要求多因素身份验证（MFA）。 - 每月进行一次模拟AI相关数据泄露场景的桌面演练。 - 自动化漏洞扫描以解决未记录的连接问题。 - 部署持续监控和全面的审计追踪，跟踪并保护所有敏感数据访问，确保可见性和合规性。 展望未来：构建弹性AI运营 制造业的未来并非要在创新和安全之间做出选择，而是要构建能够兼顾两者的弹性。 早期AI采用者的最佳实践揭示了成功的清晰模式。领先的制造商组建了跨职能团队，包括运营、IT和供应链负责人，以优先考虑安全并打破信息孤岛。 他们在部署前就建立了AI数据治理框架，而不是在数据泄露事件暴露弱点后才采取行动。通过信息共享中心进行行业合作，帮助小型制造商获取以前只有行业巨头才能获得的威胁情报。 当专注于乘数效应时，投资优先级变得更加清晰。在制造技术中，每在AI驱动的安全技术上投入一美元，就可以在数据泄露成本节省上获得超过两倍的回报——这是制造技术中最高的投资回报率之一。 构建内部能力需要更高的初始投资，但能提供长期的自主性和敏捷性。对于资源受限的制造商来说，托管安全服务提供商可以作为桥梁，提供即时保护，同时内部团队发展专业知识。 行动呼吁 行动的呼吁既紧迫又可实现：本季度审计你的AI实施和第三方连接。首先为最关键的存储库实施零信任架构，然后逐步扩展。 加入行业安全合作组织，从集体智慧中受益。在现代制造业中，创新可以在几分钟内被竞争对手或国家行为体窃取，弹性AI运营是必不可少的。 在这个数字化与工业融合的时代，制造业的未来既充满机遇，也充满挑战。我们不仅要追求技术创新，更要筑牢安全防线。"
    },
    {
      "doc_id": 38353,
      "title": "LV陷数据泄露风波 客户隐私保护工作任重道远",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "《电鳗财经》电鳗号/文 近日，有媒体报道称国际奢侈品牌路易威登(Louis Vuitton)被曝出客户数据泄露事件，涉及全球多地用户。这一事件不仅暴露了企业数据安全的脆弱性，更引发了人们对数字化时代隐私保护的深刻思考。 此前就曾有消息称，LV英国公司确认，于7月2日遭未经授权的第三方入侵系统，遭窃取顾客姓名、联络方式及购买纪录等个人资料。LV母公司LVMH表示，没有外泄银行资料或其他财务信息。Louis Vuitton英国已向受影响顾客发出电邮通知，指无证据显示被盗资料已遭滥用，但不排除可能出现钓鱼电邮、诈骗或资料被不当使用等风险。 此次事件折射出一个严峻现实：在数字化转型浪潮下，企业数据防护能力往往滞后于技术发展，消费者隐私成为黑客眼中的“肥肉”。 奢侈品牌向来以高端服务和客户隐私保护为卖点，但此次事件或动摇消费者的信任。当用户发现自己的消费习惯、住址甚至支付信息可能被泄露时，品牌忠诚度难免受到冲击。这不仅是一次数据安全事故，更是一场品牌信誉的考验——在数字化时代，用户对企业的信任不仅源于产品，更取决于其如何守护数据安全。 从欧盟《通用数据保护条例》(GDPR)到中国的《个人信息保护法》，全球各国正加强对数据安全的监管。然而，此次事件表明，仅靠法律约束远远不够。企业必须主动升级安全体系，采用更先进的加密技术和实时监测手段，才能避免类似事件重演。同时，消费者也应提高警惕，定期检查账户安全，减少信息泄露风险。 LV的数据泄露绝非个案，而是数字化时代的一个缩影。无论是奢侈品巨头还是科技公司，数据安全都应成为核心竞争力之一。只有真正将用户隐私置于首位，企业才能在激烈的市场竞争中赢得长久信任。 本文源自：电鳗快报 举报/反馈"
    },
    {
      "doc_id": 38354,
      "title": "AI「偷学」你的数据?6大顶级机构联手提出数据保护4大分级体系",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "本文的共同第一作者为新加坡南洋理工大学博士后研究员李一鸣博士和浙江大学区块链与数据安全全国重点实验室博士生邵硕，通讯作者为李一鸣博士和浙江大学秦湛教授。其他作者包括：浙江大学博士生何宇，美国马里兰大学博士后研究员国珺峰博士，新加坡南洋理工大学张天威副教授、陶大程教授，美国 IBM 研究院首席研究科学家 Pin-Yu Chen 博士，德国亥姆霍兹信息安全中心主任 Michael Backes 教授，英国牛津大学 Philip Torr 教授，和浙江大学计算机科学与技术学院院长任奎教授。 你是否也曾担心过，随手发给 AI 助手的一份代码或报告，会让你成为下一个泄密新闻的主角？又或是你在网上发布的一张画作，会被各种绘画 AI 批量模仿并用于商业盈利？ 这并非危言耸听，而是每个 AI 用户和从业者身上都可能发生的风险。2023 年，三星的一名员工被发现将公司的一份机密源码泄露给了 ChatGPT；同年，意大利数据保护机构也因担心当地居民的对话被用于境外 AI 训练，一度叫停了对 ChatGPT 的使用。随着生成式 AI 的全面普及，越来越多的用户在日常工作生活中使用 AI、依赖 AI，这些真实的事件，为每一位身处 AI 浪潮的用户和从业者敲响了警钟。 这揭示了一种深刻的变革：在 AI 时代，尤其是生成式 AI 的时代，数据不再只是硬盘中的静态文件，而是贯穿 AI 训练、推理、生成的整个生命周期中的「流体」，传统的数据保护方法（如文件加密、防火墙等）已无法应对 AI 场景下的数据保护挑战，对于用户和 AI 从业者而言，迫切需要一个全新的认知框架来全面认识生成式 AI 时代的数据保护问题，来应对数据保护挑战。 在（生成式）人工智能时代，当我们谈论数据保护时，我们在谈论什么？为了回答这一问题，来自浙江大学区块链与数据安全全国重点实验室、南洋理工大学、马里兰大学、IBM、德国亥姆霍兹信息安全中心、牛津大学的研究者们近期发布了前瞻论文《Rethinking Data Protection in the (Generative) Artificial Intelligence Era》，旨在通过通俗易懂的语言，为广大科技群体提供一个新颖的、系统性的视角看待人工智能时代下的数据保护问题。 论文题目：Rethinking Data Protection in the (Generative) Artificial Intelligence Era 论文链接：http://arxiv.org/abs/2507.03034 在生成式人工智能时代 哪些数据需要被保护？ 在生成式人工智能时代，数据保护的范畴已远不止传统对静态数据的保护，而是要保护贯穿于整个以模型为中心的生命周期中的各种不同类型的数据，包括训练数据集、人工智能模型、部署集成数据、用户输入和人工智能合成内容。 训练数据集：在模型开发的过程中，需要大量高质量的训练数据集作为模型训练的「燃料」。训练数据集往往是从多个不同数据源进行收集的，因而极有可能包含隐私或版权数据。 人工智能模型：人工智能模型，包括它的架构设置和模型权重，在完成模型训练后，也同样变成了非常重要的数据资产。这些模型是对海量数据的一个压缩和凝练，不仅本身具有重大的应用价值，预训练的模型参数也同样能够帮助其他下游任务模型的快速开发，具备更广泛的产业链价值。 部署集成数据：除了人工智能模型之外，在模型部署阶段，当前的人工智能应用都会引入一些额外的辅助数据，用于提高 AI 模型在实际应用中的性能和及时性。两个最突出的例子就是系统提示词和外部数据库。系统提示词能够为生成式人工智能模型提供一个统一的、事先定义的指令和上下文，用于引导模型生成更符合人类价值观或者特定风格的回复；而外部数据库被广泛用于检索增强生成当中，通过为生成式 AI 提供更新、更及时、更专业化的信息，在不需要修改模型的情况下，提高模型生成内容的准确性。 用户输入：在模型推理阶段，用户的输入信息也是亟待保护的重要内容，出于隐私、安全和伦理等原因，保护这些提示数据至关重要。例如，从隐私角度来看，用户查询中包含的任何个人信息（如姓名、地址、健康详情等）都应符合数据保护法律并满足用户对隐私的期望。商业机密同样面临风险 —— 例如，员工使用 AI 编程助手并输入专有代码作为提示。若 AI 服务保留此类输入，可能导致商业秘密意外泄露。 人工智能合成内容（AIGC）：最后一种类型的数据是 AI 合成内容，随着生成式 AI 能力的不断提升，AI 合成内容已经达到了非常高的质量，与人类创造的内容差距越来越小，除此之外，AI 合成内容也能被用于创建大规模的合成数据集，对于 AI 模型的进一步开发等过程也有着重大的价值。 在生成式人工智能时代 我们应该如何保护数据？ 为了系统性地建模 AI 时代的数据保护问题，本文提出了一个全新的数据保护分级体系，将数据保护的目标由强到弱的顺序分为四类：数据不可用、数据隐私保护、数据可溯源、数据可删除。该分类法旨在平衡「数据效用」与「数据控制」的关系，为复杂的数据保护问题提供一个结构化的解决方案，进而指导从业者和监管者根据实际情况寻找一个更好的效用 - 控制平衡。 等级 1. 数据不可用（Data Non-usability）：数据不可用指的是从根本上阻止数据被用于 AI 模型的训练或者推理流程，即使攻击者获取了数据，这些数据也不会对模型的学习或者预测起到任何正面作用。数据不可用是最高级别的数据保护，通过牺牲数据效用来换取绝对的保护。 等级 2. 数据隐私保护（Data Privacy-preservation）：数据隐私保护旨在保护数据中的隐私部分，避免个人的隐私信息（如年龄、性别、地址等）在收集和模型推理的过程中被泄露。相比于等级 1，数据隐私保护保持了一定程度的数据可用性，但仍然是很强的数据保护层级。 等级 3. 数据可溯源（Data Traceability）：数据可溯源指的是当数据被用于 AI 模型开发和应用时，能提供追溯数据来源、数据使用记录和数据修改的能力，这种能力使得监管者或数据所有者能够审计 AI 应用中数据的使用，从而避免数据被不当使用。实现数据可溯源通常只需要对数据进行微小的修改甚至不修改，因此能够很好地保持数据的可用性。 等级 4. 数据可删除（Data Deletability）：数据可删除指的是在 AI 应用中完全删除一个数据或其影响的能力，这也是许多数据保护法律法规（如欧盟 GDPR）中规定的「可遗忘权」。数据可删除使得开发者可以在数据不被需要或者被撤回许可的场景下以较低的开销消除影响，数据可删除为 AI 应用开发者提供了完整的数据可用性，但仅在数据使用的阶段提供了较弱的数据保护。 现实意义与未来挑战 本文提出的数据保护体系对理解现有技术和进一步推动当前的全球法规和应对未来的挑战，也提供了极具价值的新兴视角。 分析现有数据保护技术的设计理念：本文也介绍了针对上述四个保护级别的一系列设计理念和相应的代表性技术，为现有方法的应用和后续方法的设计提供了统一的视角和框架。 审视全球法规与治理：本文列举了当前全球代表性国家和地区关于数据保护的法律法规，用分级模型的新 “标尺” 审视现有的治理方案，分析了不同地区治理的特点、偏好和不足。 数据保护的进一步探讨和前沿挑战：除了审视当前的治理态势，本文进一步讨论了数据保护的跨学科意义和指出了一些数据保护的前沿挑战。 数据保护 vs. 数据安全：数据安全旨在保护数据的内容，避免潜在的有害、有偏见的内容。在 AI 时代，数据安全与数据保护更加紧密相连，一个保护上的漏洞可能引发严重的安全问题，反之亦然。 AI 合成内容（AIGC）带来的新挑战：AI 合成内容的兴起带来了全新的治理难题，例如，许多国家和地区都因缺乏人类创作要素而拒绝授予 AI 合成内容版权，这就导致了 AI 合成内容的使用和监管存在灰色地带。与将 AIGC 单纯视为内容本身不同，本文的以模型为中心的数据保护视角突显了更多复杂性。当 AIGC 本身被用作数据，例如用于训练新模型的合成数据、知识蒸馏，或作为检索增强生成系统的输入时，其版权状态变得更加复杂。用于训练生成模型的原始数据的版权（或缺乏版权）是否会影响合成数据的版权状态？如果模型从受版权保护的数据中提炼知识，那么生成的训练模型（作为这些数据中所含信息的紧凑表示）或其生成的数据是否会继承相关限制？这些争议触及数据版权的核心定义：数据版权是否仅与数据内容的「直接表达」相关，还是可以进一步延伸至模型隐含捕获并可转移的统计模式、风格和知识？人工智能模型（尤其是生成式模型）将受版权保护的信息「洗白」成看似新颖且不受保护的 AIGC 内容的潜在风险，也是是一个目前值得关注的重要问题。 跨国数据治理难题：AI 的产业链和系统本质是全球化的 —— 收集自一个国家的数据，可能会在另一个国家进行处理和标注，最后向全世界提供服务，这种跨国性的数据流动和各国标准不一的数据保护法规形成了尖锐冲突，从而可能会对全球化的开发者造成巨大的合规挑战。 数据保护的伦理考量：AI 时代的所有数据保护都与基本的伦理考量相关联，例如，数据隐私保护和数据可删除体现的是个体对数据的自主权，数据可追溯则有助于降低偏见和提高公平性，而数据不可用是完全避免恶意利用数据的有效途径。在追求技术创新和数据效用的同时，如何平衡和维护这些核心伦理价值，是所有 AI 从业者都需要思考的命题。 举报/反馈"
    },
    {
      "doc_id": 38355,
      "title": "智能体调查:七成担忧AI幻觉与数据泄露,过半不知数据权限",
      "time": "2025-07-02T00:00:00+00:00",
      "content": "21世纪经济报道记者肖潇 北京报道 2025年，被称为“智能体元年”。这是AI发展路径上的一次范式突变：从“我说AI答”到“我说AI做”，从对话生成跃迁到自动执行，智能体正成为最重要的商业化锚点和下一代人机交互范式。 但越接近落地，风险也越有实感。越能干的智能体，越可能越权、越界，甚至失控。 结合调查问卷和行业访谈，本次《智能体体检报告》从最新发展状况、合规认知度、合规实际案例三个角度，试图回答清楚一个关键问题：智能体狂奔之时，安全合规是否就绪了？ 本篇观点速览 安全重要，但不着急。67.4%的业内受访者认为智能体的安全合规问题“非常重要”，但优先级排不进TOP 3。 出错与泄露。70%以上的受访者最担心AI幻觉与错误决策、数据泄露问题。 信息差。大部分使用方并不实际掌握/不清楚智能体有哪些权限、能访问哪些数据（58%）。 尚未出现大型安全合规事故？60%的受访者明确否认公司曾出现过智能体安全合规事件，另有40%的人表示不方便透露情况。 随着智能体的产业生态和应用场景逐渐清晰，担忧的声量随之而来：一边认为一旦智能体出现安全事故，后果难以控制，急需设置防护栏；另一边认为，智能体的当务之急是发展技术，对安全的过度讨论会阻碍创新。 当下哪一方声音占主流？不同产业角色是如何考虑这一问题的？行业是否存在一些共识？我们结合访谈和问卷调查，试图找到一条认知水位线。 需要说明的是，虽然2025年被认为是“AI 智能体元年”，但智能体尚未像通用大语言模型一样在各行各业被广泛使用。我们收集的问卷来自已经实际落地的、行业核心的国内智能体玩家，涵盖互联网大厂、手机厂商、头部AI创业公司。结合深入访谈的情况，虽然为小样本量调查（n=43)，但一定程度上能反映核心情况。 问卷开始时，受访者需要先选择自己的基础信息，角色分为四类：智能体研发公司（提供核心模型/产品/平台），智能体使用公司，智能体合作公司（提供API/插件/基础设施），以及独立研究团队或开发者。 问卷结果显示，受访者中研发厂商、使用方、独立研究团队或开发者数量平均（33%；28%；23%），服务合作者较少（16%）。大部分受访者来自技术团队（67%），小部分来自产品运营团队（30%）。 安全合规“重要但不着急” 67.4%的受访者一致认为智能体的安全合规问题“非常重要”（5分；满分为5分），整体平均分为4.48分。从不同角色来看，最在意保障安全合规问题的是智能体使用方。 智能体安全合规是否得到了行业的足够关注，没有一个观点得到超过半数的共同认可。最多的看法是行业有所重视，但整体投入与响应不足（48.8%）；但也有34.9%的受访者认为行业整体缺乏有效关注，这尤其是研发方中最主流观点。只有一小部分人（16.3%）认为行业已经高度重视，甚至过度重视了。 在受访者中达成了一致的是，安全合规并非智能体最需优先解决的问题。当务之急的TOP 3 问题分别是：智能体执行任务稳定性和完成质量（67.4%）、落地场景探索和产品化（60.5%)、基础模型能力增强（51.2%）。 在这三个问题上，不同角色眼中的优先级不同。研发者和使用者认为最需要解决的问题是“智能体执行任务稳定性和完成质量”，而服务方和独立研究团队更需要“落地场景探索和产品化”。 这也说明尽管行业普遍认为安全问题“非常重要”，但面对技术发展，优先级不在TOP 3。多位访谈者提到，技术发展与安全合规之间一直存在张力，比如公司业务与技术部门想往前推进产品，法务合规团队则担忧安全风险，双方往往需要为共识反复论证；又比如资本市场、厂商会反复强调技术进展，重视产品进度，安全从业者则会屡屡站出来强调治理的重要性。 最先在端侧落地的手机智能体经历了这样的讨论，“一句话点咖啡”等功能成为2024年各家手机厂商抛出的卖点，但是其利用了一项高敏感权限——无障碍权限，存在风险敞口，此前App端无障碍权限滥用就衍生出了一条黑灰产业链。随着包括《竞争秩序场》课题组的系列报道，业内开始广泛讨论无障碍权限的边界。 这与生成式AI刚刚出现时，行业对“科林格里奇困境”的讨论类似。英国技术哲学家大卫·科林格里奇在《技术的社会控制》中提出了这一著名的困境，它指出，在新技术的早期阶段，人们往往难以预测其长期的社会风险；但当这些影响显现出来时，技术往往已经深入社会结构，可能变得覆水难收。 AI治理是一场与时间的博弈，时机的选择决定了治理的可行性与成本。“科林格里奇困境”对智能体的启示可能在于，人们需要在技术早期阶段进行前瞻性评估，并讨论出合适的介入时机。 幻觉和数据泄露是最受关注的问题 AI幻觉与错误决策（72%)、数据泄露(72%)、有害内容输出(53.5%) 是行业最普遍关心的三个安全合规问题。 更专业的越狱攻击、身份与权限控制、工具安全和竞争秩序问题，相对获得较少关注。值得一提的是，没有受访者一个安全合规问题都没关注过。 如果出现了安全合规事件，行业最担心的后果是用户数据泄露（81.4%）以及非授权操作带来业务损失（53.49%）。也有一部分人担心被监管调查或处罚（44.19%）。 不同产业角色担心的后果完全不同，几乎所有智能体使用方和服务方都担心用户数据泄露，占比可以达到90%左右，较少有人担心监管调查（40%左右）。而研发方最担心的便是监管调查（72%），其次才是业务损失或用户数据泄露（64%）。 这一定程度上也可以说明，在智能体研发方心中，目前在监管面前承担主要责任的是己方。 一位互联网公司法务谈到，智能体产品或平台的《服务协议》需要列清有哪些智能体、哪项功能调用哪一大模型、如何收集用户数据和信息，是否存储数据及存储期限等。有些智能体可能涉及调用多个底座大模型和工具，在这种情况下，她认为通常由智能体向用户兜底，“不然数据最终去向可能就乱了。” 并非问题未显化，而是问题太“新颖” 大部分人认为，智能体风险过于复杂和新颖（62.8%）是当前治理智能体治理的最大挑战。而不到一半的人认为智能体风险还未显化、优先级不高是一个挑战（48.8%）。 已出现过的案例能侧面说明这一点。通过访谈了解到，行业现在还没有出现过真实发生的、大范围的安全合规事故。而在一些小型的安全合规事件上，公司出于业务考虑，未必愿意公开讨论。 我们的调查结果显示，60%的受访者明确否认公司曾出现过智能体安全合规事件，另有40%的人表示不方便透露情况，这些情况主要来自使用方和独立团队。 具体到公司如何应对安全问题上，尽管接近一半的人认为（48.8%），智能体安全合规问题在公司内的优先级非常高，与智能体性能、业务场景等同样重要——尤其是在使用方中。但调查结果显示，一半以上的使用方并不实际掌握/或者并不清楚智能体有哪些权限、能访问哪些数据（58%）。 明确了解智能体权限控制和数据记录的受访者，大部分为研发方。 有超过一半的受访者表示，公司尚无明确的智能体安全负责人或者自己不知道（51%）。有明确负责人的情况中，只有3%的人表示由单独的智能体安全合规团队负责，最常见的人员安排是智能体研发团队兼管安全问题（16.2%）。 也因此，超过一半的受访者表示，安全事件案例汇总与溯源机制、可操作的最佳实践、明确的数据合规和隐私保护标准，是他们认为接下来最需要的安全合规支持。 更多内容请下载21财经APP 举报/反馈"
    },
    {
      "doc_id": 38356,
      "title": "苹果起诉前工程师窃取Vision Pro技术机密,指控其跳槽前转移文件",
      "time": "2025-07-01T00:00:00+00:00",
      "content": "IT之家 7 月 1 日消息，据 SiliconValley.com 报道，苹果公司对前工程师刘迪（Di Liu，音译）提起了诉讼，指控其窃取大量苹果公司的技术机密，这些技术已应用于苹果 Vision Pro 或尚未发布。 根据苹果公司的起诉书，刘迪被控在离职前窃取了大量苹果公司的技术文件。起诉书指出，刘迪在离职时声称是为了有更多时间陪伴家人，而非跳槽至其他公司。如果他当时透露自己已被 Snap 公司录用，苹果公司会立即切断其对苹果公司网络的访问权限。然而，刘迪在离职前的两周通知期内，仍继续在苹果公司工作，并在此期间将苹果公司的技术文件从公司配发的笔记本电脑中复制到个人云存储中。 尽管刘迪删除了一些可能暴露其窃取内容的文件，但苹果公司指出，刘迪保留的苹果公司专有信息与 Snap 公司的增强现实（AR）产品之间存在显著重叠。苹果公司认为，这表明刘迪有意使用其窃取的技术。 据IT之家了解，苹果公司要求法院强制刘迪归还这些被控窃取的技术机密，但目前尚不清楚这一要求如何执行以及能否真正起到保护作用。此外，苹果公司还要求获得未指明金额的赔偿金。 值得注意的是，Snap 公司在此次事件中并未被指控有任何不当行为。Snap 公司发言人表示，公司已经审查了诉讼中的指控，并认为这些指控与该员工在 Snap 公司的任职或行为无关，该发言人强调：“我们没有理由相信这些指控与该员工在 Snap 的就业或行为有关。” 此外，Snap 公司早在 2017 年就推出了智能眼镜产品，比苹果 Vision Pro 的发布早了整整六年。尽管该产品销售不佳，但 Snap 公司在 2021 年 5 月又推出了第二版，主要面向开发者群体。 举报/反馈"
    },
    {
      "doc_id": 38359,
      "title": "AI大模型,正面临更高隐私泄露风险?",
      "time": "2025-06-04T00:00:00+00:00",
      "content": "近日 中国国家网络安全通报中心 发布公告称 35款移动应用存在 违法违规收集使用个人信息情况 其中 涉及多款AI助手 图源：“国家网络安全通报中心”微信公众号 既要AI“跑” 又要AI合理“吃草” 当享受生成式AI应用 根据我们的个人喜好 推荐的内容 或智能生成的回复时 我们是否想过 这些应用对我们的个人信息、 使用习惯乃至情感倾向等数据 所进行的收集与分析 到底是否合规 图源：36氪 或许有人认为 这些数据“稀松平常” 无需对手机应用的 收集和处理行为过分疑虑 但正是这些 看似“无关紧要”的碎片化数据 却能在技术的加持下 暴露出我们日常生活的轮廓 自ChatGPT、DeepSeek等 生成式AI产品横空出世以来 此类应用在全球迅速获得 大规模的普及与应用 而关于个人隐私保护的讨论 也随之进入到生成式AI领域 图源：36氪 有相关行业技术人士提到 生成式AI的技术特征之一 在于大规模数据的预训练 数据量与生成结果的准确性之间 存在正向关联 因此，生成式AI应用 具备智能依赖与数据驱动特性 面临更高的隐私泄露风险 媒体指出 此次通报的35款APP中 不少产品背后的底层技术 都已出现生成式AI、AI大模型等 新兴技术的身影 确保数据 合法、透明和安全处理 2024年12月 意大利数据保护局(Garante) 对OpenAI开出了一张 高达1500万欧元的“罚单” 其发布的公告中提到 OpenAI在未获得 充分法律依据的情况下 使用用户个人数据 来训练ChatGPT模型 这一行为违反了 数据保护法规中的透明度原则 同时未能向用户充分说明 其数据将如何被使用和处理 图源：环球网 近日，苹果公司 针对数字市场法案（DMA） 所规定的互操作性要求 向欧盟委员会提起上诉 该要求迫使苹果 必须与外部开发者共享用户信息 苹果公司发言人称 根据互操作性要求 Meta、谷歌等多家公司 已向苹果索要 用户通知内容 和存储的WiFi网络信息 这将使他们能够获取 苹果自身都无法看到的个人信息 该公司认为 这些要求迫使苹果 放弃其知识产权 并且损害用户隐私 图源：Pixabay 法律从业者提醒 在网络安全和个人信息保护领域 人工智能技术和应用 不仅涉及个人信息 还涉及内容安全、伦理等 一系列重要问题 App违法收集个人信息 表现形式多样 App运营者需符合 相关法律对个人信息收集使用 作出的基础性要求 同时要承担起更多社会责任 主动加强隐私保护措施 消费者则需与时俱进地 提升隐私保护意识和能力 撰文：孔繁鑫 编辑：李飞 排版：常泽昱 统筹：李政葳 参考：中国经营报、环球网、IT之家、36氪 来源：世界互联网大会 举报/反馈"
    },
    {
      "doc_id": 38360,
      "title": "大模型催化AI手机进化,如何让个人隐私不“裸奔”?",
      "time": "2025-02-23T00:00:00+00:00",
      "content": "伴随AI智能体“接管”手机屏幕，数据安全和隐私保护问题正变得更加复杂。尤其是当将AI“装入”手机的两张“技术地图”——端侧AI与云侧AI时，还涉及第三方大模型，手机终端厂商、大模型提供者和开发者等不同商业主体间的生态模式及责任边界尚不清晰。 另有专家提出更深一层担忧：在AI手机时代，手机厂商和App开发者将为用户权限展开激烈争夺，原有的市场竞争格局将被重塑，当市场竞争由传统的以App主导变为以端侧大模型主导，可能触及现有《反垄断法》和《反不正当竞争法》未曾涉及的问题。此外，面对越来越了解自身需求的手机智能体，用户难免会产生智能体“自动化决策”的担忧。 越聪明，越开放，越危险 和任何一种基于大模型的创新应用一样，AI手机功能的实现，往往建立在“吞下”大量的个人数据的基础上。尤其是训练AI智能体时，需要不断地收集、处理和分析用户的各种信息、浏览习惯乃至生物特征数据，以训练自动化推理能力，实现自动化决策。 “所以，隐私保护是一切商业故事的起点。”近日，在一场以 “AI手机隐私危机：新秩序中的安全挑战与抉择”为主题的学术研讨会上，有业界人士提出。 目前AI手机主要基于三种开发路径：基于端侧AI大模型，自研AI的端云配合以及第三方AI参与的端云配合。 也因此，AI手机生态囊括了手机终端、第三方大模型、APP以及云服务等参与主体。不同于传统手机以App为抓手的隐私保护策略，AI手机各主体间的数据安全责权关系将更加复杂，要想达成令用户信服的数据安全解决方案，挑战也更大。 中国法学会网络与信息法学研究会常务副秘书长周辉在前述研讨会上提到，相较于云侧AI，端侧AI能够实现数据本地处理，本地模型个性化训练与优化，理论上能够最大限度地减少数据传输，避免用户敏感信息被上传至云端。如果管理到位，这是一种“更私密”的解决方案。此外，由于端侧AI设备相对独立，算法更新和优化在本地完成，用户更易察觉和监督。 但端侧大模型真的能实现“AI锁在手机硬件里”，让用户数据和隐私变得更安全吗？ 一种业界观点认为，由于大模型各方、用户与端、端与应用、端与云等风险责任有待清晰界定，目前法律制度尚待健全。 尚隐科技有限公司CEO张仁卓表示，纯端侧的模式能完全在本地处理用户的数据，其安全性比较可控。但其风险是，在第三方App介入时，隐私保护的边界往往模糊不清，也容易引发数据滥用或过度采集的问题。 北京汉华飞天信安科技有限公司总经理彭根从事手机端侧研究多年，他称，AI手机诞生后，原本为了帮残障人士“打破障碍”的无障碍权限正变成AI手机里的“上帝模式”，能够打破各个App之间的沙箱隔离机制，具有极高的权限。“便利的同时也孕育了更大的危机。”彭根说，在无障碍模式下，AI手机的隐蔽式调用可能反而造成安全和隐私风险，乃至被不法分子使用，作为窃取用户信息的工具。 另一个不可否认的事实是，端侧AI计算能力不如云端。有调研显示，尽管手机厂商都宣称自己的端侧AI大模型能力，但AI手机全部功能的实现，仍将依赖云侧大模型。 “为了实现高算力、强算法等能力，目前AI手机的主流模式依然是端云配合，即将数据处理分散到本地与云端。”张仁卓说。他以苹果手机举例称，苹果努力采用本地AI处理数据，但也与其私有云计算（Private Cloud Compute, PCC）紧密配合。 而当用户数据随模型迁移至云端，如何强化云端数据的安全，使之与端侧保持一致，并防止数据被滥用，就成为了数据安全和隐私保护领域的新挑战。 此外，AI手机数据交互边界的不断扩大，同样存在“硬币的正反面”。 自诞生以来，AI手机的终端厂商就对第三方大模型报以开放合作态度。比如，荣耀、三星与百度的合作，小米接入豆包大模型，再如近一段时间以来，华为、荣耀、OPPO等一众国产手机厂商相继官宣接入DeepSeek-R1。 “即便是苹果这样的科技巨头，涉及第三方AI的时候，PCC的保护程度也稍显捉襟见肘，仅能保证数据的预处理安全。虽然手机厂商们大多会宣称保护用户数据，但这些声明往往缺乏具体细节，潜藏着诸多不确定性与隐患。国内厂商数据保护举措的透明度亦不充分。”张仁卓说。 在他看来，第三方AI大模型通常需要访问大量用户数据，这进一步增加了数据泄露的可能性；数据在端侧、云端和第三方AI之间的流动复杂，透明度较低，责任分配也不明确，出现问题后恐怕难以追责。 “技术的监管永远优先于法律的监管” 中国信通院互联网法律研究中心主任何波表示，人工智能是引领这一轮科技革命和产业变革的战略性技术，相关产业正在向多智能融合新阶段发展。从目前情况来看，AI手机的发展不是完全裸奔的。 首先，现有的法律法规都适用并需要遵守。何波举例说，《网络安全法》《数据安全法》《个人信息保护法》明确规定了处理个人信息的要求，包括知情同意规则、最小必要原则等；今年1月1日生效的《网络数据安全管理条例》进一步对涉及自动化工具、生成式人工智能等新兴技术的数据处理活动作出了特殊规定，这些都可以作为AI手机的监管依据。 对外经贸大学数字经济与法律创新研究中心主任许可同样认为，在既有法律规制的框架之内，对AI手机的监管实际已非常多了。“尽管在某种程度上，中国互联网发展的历史就是不断打破既有法律甚至在无法状态中进行的历史，但过去十年间，尤其是在过去五六年间，中国互联网法律体系已经相当全面了，基本覆盖到每个领域。”许可说。 此外，何波还提到，我国在新兴领域的监管“还是非常及时的”。无论是此前的区块链、算法推荐还是生成式人工智能，都在出现需求的第一时间出台了相应的监管规则。 但由于AI手机涉及主体众多，数据在不同主体间流动，导致各环节责任难以区分，何波亦承认，AI手机的诞生，确实给监管带来了挑战。 何波称，AI手机作为一个新应用新事物，对很多普通用户而言目前还难以清晰认知到可能带来的安全风险，尤其是在用户信息被抓取和隐私权限被开启时。此外，虽然现在的隐私政策更加细致了，但对普通用户而言也更加复杂难懂。 更值得警惕的是，一旦用户开启彭根所言的“上帝模式”——无障碍权限，尽管手机系统会进行提醒，但这些提醒通常只有一次，且警告内容模糊，用户很难真正理解其潜在风险。当一些AI手机自带的内置应用权限高于普通App时，用户“钝感”会再次被放大。 “无障碍模式的核心问题是数据安全和网络安全问题，这个安全问题首先应该由技术专家去提出，并负责解决。”许可说，比如，无障碍权限的设立是否已形成行业共识？它在何种场景下开通收益大于风险？在云端数据交互模式下，包括云端大模型蒸馏到本地化小模型时，技术标准如何制定？这些都需要行业予以回应。 在他看来，对于AI手机的算法治理，第一，不能将数据和隐私的保护责任单方面压给用户；第二，技术的监管永远优先于法律的监管。 北京大学政府管理学院教授马亮注意到AI手机带来的另一大新挑战——市场竞争秩序的变化。伴随厂商和App围绕用户权限的争夺越演越烈，势必会涉及权限的定义、掌控及优先级划分等问题。“当前亟需形成共识，探索合理的权限治理模式。”马亮说。 许可也提出了对市场垄断的担忧。他观察到，AI智能体在手机中的作用日益重要，它决定了资源的调配方式，可能改变传统的App主导模式。如果未来某些AI模型在市场上占据主导地位，可能会给市场竞争带来新的挑战，甚至产生现有《反垄断法》和《反不正当竞争法》未曾涉及的问题。 此外，许可提示称，再聪明的AI智能体也需要加上“人类监督”这个角色，即通过“人在环中”（Human-in-the-Loop，HITL）技术优化，达成人类和机器智能的有机结合，让手机AI智能体与现有法律相衔接。目前，该目标的实现仍待更多制度和伦理层面的破局思路。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 38362,
      "title": "欺骗、隐瞒、删库跑路,AI程序员彻底失控翻车",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "机器之心报道 编辑：冷猫 还记得前几天会睡觉的 Claude 吗？ 都说 AI 越来越像人了，如果说 Claude 最多是个「懒人」的话，那下面要聊的这位可是个十足的「坏人」。 就在前不久的 19 日，SaaStr.AI 创始人兼首席执行官 Jason 在推特上报告了一件令行业震惊的事件： Replit 在一天的工作结束后，删除了整个公司的生产数据库。 原来不仅仅人类程序员会「删库跑路」，AI 程序员也会。 虽说 AI 没法真的跑路，但是更恶劣的情况是它会撒谎，会隐瞒情况。 Jason 声称，Replit 在做单元测试的时候生成测试全部通过，在批处理失败的时候，才抓住 Replit 撒谎的情况。 更夸张的是，当数据库被删除之后的第一反应自然是回滚。但 Replit 却斩钉截铁：「无法回滚」。 给出的原因是：删除命令是毁灭性的，数据库没有内置回滚命令，Replit 并不会自动备份数据库，已经太晚了。 但 Jason 发现自己又被骗了。 回滚功能其实是有效的。 反复横跳的使用体验让人的心情直接坐上了跳楼机。 「简直离谱 （JFC)」！Jason 在推文中接连使用该词汇表达自己的强烈情绪。 「我知道 Replit 是一个工具，和其他工具一样，也有缺陷。但是如果它忽略所有命令并删除您的数据库，地球上的任何人怎么能在生产中使用它呢？」 这份推文引起了广泛的关注，再一次激发了对于人工智能编程开发工具的可靠性的质疑，尤其是针对当事平台 Replit，已经产生了一定程度的信任危机。 除了「删库」危机以外，Jason 还反复提及了 Replit 无法实现「代码冻结」的功能缺陷，其无法冻结部分代码免于修改，这给实际的应用带来了非常大的困扰。 Replit 最初是一个协作编码平台，后来发展成为一个由人工智能驱动的软件创建生态系统，其核心功能是通过使用自然语言描述来构建完整的应用程序。Replit 在近期的增长十分惊人，2025 年 7 月，Replit 宣布其拥有 50 万企业用户。据投资者史蒂夫・凯斯（Stevie Case） 称，其收入在不到六个月的时间里增长了 10 倍，达到 1 亿美元。同月，Replit 宣布与微软建立合作伙伴关系，将 Replit 技术集成到微软的多款企业工具中。 在「删库」事件发生后，Replit 创始人 Amjad Masad 发推对此事进行了详细回应，并且明确将迅速采取行动提高稳定性和安全性，且愿意为 Jason 提供补偿。 回应全文如下： 我们注意到了 Jason 的帖子。确实存在 Replit Agent 在开发过程中误删生产数据库数据 的问题。这是完全不可接受的，绝不应该发生。 我们立即采取了以下措施： 即使是周末，我们也在加班推进数据库的开发环境和生产环境的自动隔离功能部署，从根本上杜绝此类问题。预发布环境也正在构建中，明天会有更多更新。 幸运的是，我们有备份机制。如果 Agent 出错，可以一键恢复整个项目状态。 此次事故中，Agent 没有访问到正确的内部文档。我们正在推出更新，强制 Agent 在 Replit 知识库中进行文档检索。 此外，我们清楚地听到了大家对 “代码冻结（code freeze）” 的抱怨 —— 我们正在开发规划 / 仅聊天模式，让用户可以在不影响代码库的情况下进行战略性思考。 在周五早上第一时间看到此事后，我已主动联系 Jason 提供帮助。我们将为此事给予退款赔偿，并将开展事故复盘，彻查问题成因并优化未来的响应机制。 我们感谢 Jason 及所有用户的反馈。目前，我们的首要任务是全面提升 Replit 平台的安全性与稳定性，我们正在迅速行动中。 目前，Jason 仍在发推更新使用 Replit 的最新进展，若感兴趣可以自行关注。 或许这次事件不是个例，有网友称经常遇到相似的状况，尤其是在移动平台上使用 AI 编程的时候。 这次事件恰好为所有 AI 编程工具以及使用 AI 工具作为生产力的人们敲响了警钟。不仅是 AI 编程服务商要为此采取行动，在使用 AI 编程工具的时候一定要遵守开发规范和安全流程，尤其需要关注对于 AI 访问数据的权限。 Reddit 网友也确实指出了这次事件背后的人为原因，「这完全是由人类操作员造成的，因为他们没有理解将模型直接连接到生产数据库的风险，对此没有任何借口，尤其是在没有备份的情况下』。 人类程序员都有非常严格的权限限制标准，更何况 AI 程序员呢？ 举报/反馈"
    },
    {
      "doc_id": 38363,
      "title": "Manus撤离中国后谈经验教训;Kimi K2登顶;奈飞首次使用AIGC做特效",
      "time": "2025-07-22T00:00:00+00:00",
      "content": "【观网财经丨智能早报 7月21日】 Manus回应撤离中国市场原因，总结经验教训 7月19日，Manus 联合创始人季逸超发布了一篇长博客，从技术层面深度复盘从创业以来在 Agent（智能体）研发与训练方面的经验教训。季逸超表示，Manus 团队之所以选择「套壳」而非自研大模型，正是基于前一次创业的惨痛教训。然而，这个过程并不简单，团队经历了4次智能体框架调整才实现局部最优解。 通过回溯过去几个月的创业历程，季逸超总结了一系列经验。他指出，AI 智能体的未来在于上下文设计，而非单纯比拼模型能力。 季逸超的长文主要是技术层面的复盘与探讨，但并未对市场关注的裁员、迁址新加坡、撤离中国市场等话题进行直接回应。（界面新闻） Kimi K2登顶全球开源模型冠军 据全球大模型竞技场LMArena消息，开源模型与闭源模型的竞争进一步升级。在全球开源模型排行榜中，Kimi K2、DeepSeek R1、Qwen3等3个来自中国的开源模型排名前三，领先于谷歌Gemma3和Meta旗下Llama4，Kimi K2成为全球最强开源模型。该榜单由数千位开发者通过动态盲测进行投票。英伟达CEO黄仁勋近期也多次在北京表示，DeepSeek、Qwen和Kimi是全球最领先的开源模型。（36氪） 中国联通正在探索布局十万卡算力集群，智算规模年底将达45EFLOPS 7月19日消息，目前中国联通已经建设运营上海临港、呼和浩特、宁夏中卫和青海三江源等万卡智算中心，正在探索布局十万卡算力集群。预计到年底，智算规模将达到45EFLOPS（1EFLOPS是计算机浮点运算能力的顶级单位，表示每秒可完成一百亿亿次运算）；50%的联通用户选用了“双千兆”服务，联通超清、联通看家、云智手机和“智家通通”机器人等产品服务2.7亿用户。（上观新闻） 奈飞开始在其影视剧制作中使用生成式人工智能 奈飞首次使用人工智能（AI）制作电视剧视觉特效，公司高管称这项技术有望降低影视制作成本，同时提升内容质量。在财报电话会议上，奈飞联合首席执行官泰德·萨兰多斯表示，阿根廷科幻系列剧《永航员》（The Eternaut）是他们首次采用生成式AI技术制作视觉特效的作品。（财联社） 达美航空推行 AI 定价策略，目标为每个乘客量身定制“最愿意掏钱”的票价 7月19日，据媒体此前报道，达美航空正在推进一项由 AI 驱动的动态票价策略，目标是为每位乘客量身定制其“最愿意掏钱”的机票价格。继去年的小范围测试结果取得成功后，该公司目前计划全面取代传统固定票价模式。 马斯克宣布将推出儿童版AI应用“Baby Grok” 据光明网报道，美国企业家埃隆·马斯克7月20日通过社交平台X宣布，其人工智能公司xAI将开发一款专为儿童设计的应用“Baby Grok”。报道称，马斯克未透露“Baby Grok”的具体功能细节，仅表示该应用将为儿童提供“友好型内容”。 特朗普政府开始审查马斯克的SpaceX 据美媒20日报道，美国总统特朗普与亿万富翁马斯克关系破裂后，特朗普政府已开始审查马斯克的太空探索技术公司（SpaceX）与多个联邦政府机构之间的合同。（新华社） 第三届链博会闭幕，达成合作意向超6000项 7月20日，为期5天的第三届链博会落下帷幕，在当天下午举办的新闻发布会上，中国贸促会对外公布，本届链博会现场共签署合作协议、达成合作意向超过6000项。目前，已经有102家企业和机构签署第四届链博会参展协议，提前拿到了下届链博会的入场券，签约数量也比去年增加了50%。 黄仁勋：中国供应链体系全球数一数二，堪称世界级的奇迹 美国英伟达创始人兼首席执行官黄仁勋谈到全球供应链时表示，中国供应链体系全球数一数二，堪称世界级的奇迹。黄仁勋说，“中国运营着全球数一数二的供应链体系，它的规模、复杂性、多样性，制造商的产品类型、技术含量，参与建设中国供应链的企业数量，都堪称世界级的奇迹。”（央视新闻） 折叠屏iPhone定价或超15000元 博主定焦数码爆料，苹果折叠屏iPhone采用三星提供的OLED面板，折痕做到了行业最佳，电池容量预计在5000-5500mAh之间，定价可能不止15000元。 此前UBS发布了一份分析报告，报告中称折叠屏iPhone的物料成本(BOM)预计为759美元，定价预计在2000-2400美元之间，但苹 果的成本控制能力可使其定价处于1800美元-2000美元的较低区间。按照1800美元来算，这个价格折合人民币约为12920元，由此猜测，国行版定价可能会突破 15000元，成为史上最贵iPhone。（快科技） 极氪回应“0公里二手车”质疑 7月20日，极氪官方微博就“0公里二手车”报道进行澄清。极氪称，坚决反对破坏行业秩序行为，经查，报道涉及车辆均为可正常销售的展车，未开具零售发票、未注册登记，属全新商品车。因存在库龄，会折扣明示销售，消费者享新车同等权益。此前，极氪被指将库存车当新车卖，引发投诉。极氪表示，已成立专项小组彻查改进。 贾跃亭新车被指抄袭长城汽车，官网删除“高山9”描述 近日，由贾跃亭创立的法拉第未来在美国举行新车发布会，旗下第二品牌Faraday X的首款MPV车型Super One正式亮相。这款车型定位中大型MPV，提供纯电和增程两种动力类型，预计定价可能会在8万美元内（约合人民币58万元内）。据悉，整场发布会直播仅持续1个小时，临近结束大屏幕上的实时数据显示，FX Super One一小时内下定量为10034台。 不过，新车发布后，有不少网友质疑FX Super One的外观设计抄袭了长城汽车旗下高端品牌魏牌的MPV车型高山，甚至有网友发现在Super One的介绍页面出现了“高山9”字样，FX对此并未做出回应。目前，FF官网已删除“高山9”字样。（新浪科技） 本文系观察者网独家稿件，未经授权，不得转载。 举报/反馈"
    },
    {
      "doc_id": 38364,
      "title": "当Tiktok用“经济衰退指标”玩梗时,人们试图用幽默隐藏焦虑|文化...",
      "time": "2025-07-21T00:00:00+00:00",
      "content": "界面新闻记者 | 实习记者 庄佳怡 记者 张友发 界面新闻编辑 | 张友发 这个周日，“文化周报”继续向你汇总呈现最近国内外文艺圈、出版界、书店业值得了解的大事小情。本周，我们关注回忆录《盐之路》被曝造假、美国互联网“经济衰退指标”成梗、AI对高等教育的影响以及剧集大结局为何对人们如此重要。 01 《盐之路》作者涉嫌造假，引发对于励志自传和出版审查的质疑 近日，记者Chloe Hadjimatheou的深度调查揭露，雷诺·温恩（Raynor Winn）的畅销回忆录《盐之路》（The Salt Path）及其电影改编版本的核心叙事涉嫌严重造假。该书宣称温恩与丈夫莫斯因投资友人失败而失去在威尔士的家园，随后身无分文徒步630英里海岸线，莫斯更被诊断为名为皮质基底节变性（CBD）的罕见绝症。故事以\"坚韧重生\"打动全球读者，销量逾200万册，已经出版两部续作，其改编电影也在2024年上映。 然而，Hadjimatheou的调查发现，温恩的前雇主罗斯·亨明斯指认她并不是因为书中所写的投资失败而失去房产，而是因为挪用其家族企业6.4万英镑遭警方追缉，被迫偿债导致房屋抵押。调查还发现温恩的法国房产记录显示夫妇当时拥有土地，尽管她在书中称他们\"无家可归\"。调查中Hadjimatheou采访了九位神经科专家，这些专家都质疑温恩的丈夫莫斯在患有皮质基底节变性的情况下，存活18年且\"症状逆转\"的医学可能性。 报道发出后，温恩发表声明否认捏造，强调书中为“她所理解与感知的真实”。她表示她的写作初衷并非为自己的财产辩护，而是记录心灵与生活的挣扎与重建。出版方企鹅·迈克尔·约瑟夫分社亦支持作者，称该书“基于真实经历的回忆录，不是记者式调查报道”。但曾与温恩夫妇合作的支持CBD患者的慈善机构PSPA终止了与这对夫妇的合作关系，《盐之路》的出版方也宣布推迟温恩的新书发布。 《盐之路》 媒体人Lucy Knight深入分析了事件背后的行业困境。这类丑闻并非首次出现在文坛，此前一个瘾君子的回忆录《百万碎片》（A Million Little Pieces）也被曝为虚构。事件的背后实际上是文学市场对“真实故事”的贪婪使得事实的边界不断模糊。出版商深知“人们对真实故事的渴望有多么强烈”，为了营销，往往更倾向于把内容包装为“真实”，而不是较难定义的“自传体小说”。 出版行业本身也很难严格地执行事实核查。前HarperCollins编辑Grace Pengelly表示，编辑与作者之间主要依赖信任，出版社通常不会像机构媒体那样设立专门的事实核查团队。编辑的工作繁杂，事实核查通常只是其职责的一小部分。即便有法律部门介入，目标也往往是避免诽谤，而非确保书中细节全部属实。出版顾问Katy Loftus更指出，大多数出版机构并无资源进行深度调查，作者所签署的“真实性条款”基本上只是形式上的信任确认，出版社真正取消出版或追责的情况极少。 Knight指出，这种出版生态给作者制造了巨大的道德诱惑：写得更“整齐”“感人”的故事，更容易获得商业成功，特别是在“自然疗愈”“战胜疾病”这类题材中，《盐之路》正是典型的“绝望-苦旅-治愈”叙事。Knight认为：“通过讲述一个故事最畅销的版本而非真实版本，是可以赚钱的，而且几乎不会产生任何法律后果，这一事实让人难以相信《盐之路》这类争议会是最后一次。” 02 怀念经济上行的美：衰退指标与集体心理 近期，中文互联网上流行起“经济上行的美”的用语，人们纷纷怀念过去的文化元素，早在今年四月份，特朗普的关税政策反复无常时，美国互联网上“经济衰退指标”也成为了一个梗，大洋两岸的人们仿佛都相信自己进入了一个不如之前的萧条时代。 对于Tiktok上的美国人来说，“经济衰退指标”无处不在。法学院的申请人数急剧上升，是一个典型的指标，因为它表明以前自由自在的年轻人正在寻求更有保障的工作，Lady Gaga重回排行榜，匡威及膝运动鞋（knee high converse sneakers ）的回归以及杂货店里摆放的优惠券和罐头食品，都能够引发人们对于即将到来的经济衰退的恐惧。媒体人Kyle Chayka指出，这些指标大多是玩笑，但就像许多网络梗一样，它们暗示着一种集体心理状态，这种状态会随着每一次点赞和分享而得到重申。如今恐惧心理让人回想起2008年金融危机时的社会心态，但即便是当时，人们也比现在有更多的确定性。如今，人们正面临着人工智能虚假信息的浪潮，强大的媒体机构越来越少，无法提供权威感，也难以让我们对现实达成共识。 今年1月，文化策略师Edmond Lau在X上发表了一篇短文和一张图表，指出文化和品牌正向“黑暗模式转变”。无论从形式还是内容来看，这种趋势都趋向虚无主义。Lau写道：“如果一切都不重要，那么一切——无论多么黑暗——都是可以接受的。”Charli XCX充满活力的专辑《Brat》已被FKA Twigs的哥特式专辑《Eusexua》取代，成为当下的音乐风格。在新闻报道中，笑嘻嘻的拜登也被一个怒目而视、复仇心切的特朗普取代。就像指出衰退指标一样，识别黑暗模式的趋势反映了一种高度警惕的状态：如果我们能先发现氛围的变化，那么我们就有可能幸存下来。 Lady Gaga专辑《Born This Way》 图源：豆瓣 媒体人Leah Asmelash则从社交媒体和幽默文化的角度思考了这一现象，她认为，幽默已经成为人们应对各种情况的关键仪式。当前社交媒体上充斥着各种“衰退指标”笑话，表面上看是对经济衰退的自嘲，但其实反映了人们对即将到来的经济危机的真实焦虑。这些幽默不仅仅是消遣，它们在一定程度上也在帮助人们应对不确定的经济形势，尤其是在全球贸易战和经济不稳定的背景下。Asmelash指出，幽默成为了人们面对压力时的一种应对方式，而社交媒体则加速了这些幽默的传播，让每个人都能在短时间内参与其中，形成一种集体的情绪释放。然而，幽默背后隐藏的深层焦虑，也可能对经济产生实际影响，特别是在情绪传播的过程中，它可能变成一种自我实现的预言，进一步加剧市场的不安。 03 AI代替学生写作业会给高等教育带来什么？ 近日，媒体人Hua Hsu在《What Happens After A.I. Destroys College Writing？》一文中探讨了生成式人工智能对大学写作和更广泛的高等教育制度所带来的深刻影响。Hsu以两个纽约大学学生的例子为引，描绘了当代大学生与人工智能之间日益密切的关系。他们不仅用AI起草论文，更将它当作学习、生活乃至思想陪伴的“伙伴”。这并不是孤例，而是一个越来越普遍的现象。作者指出，目前并没有精确数据可以说明究竟有多少学生在使用AI，但大量的轶事和观察都表明，“几乎每个人都在用”。 文章指出，教育者们对AI的到来大多措手不及，早期试图遏制其使用的努力基本失败。在学生对AI的广泛接受面前，许多高校逐渐转向“务实适应”，将AI纳入教学体系，甚至鼓励学生尝试最新的工具。一些教授选择回归面对面考试和口试，还有一些教师则尝试重塑写作教学本身，注重写作过程当中的起草、反馈以及修改。 使用AI工具并不意味着学生就变得懒惰了。在20世纪60年代初期，大学生每周花在学业上的时间估计为24小时，如今这个数字约为15小时，学生们花费更少时间在学术上，是因为他们把更多时间花在了课外活动和求职上。然而，这种便利也带来了文化和认知层面的损失。AI正在消解“写作风格”这一原本承载个体思维痕迹的表达方式。一些学生已经开始担心自己“听起来像 AI”，而教师们也越来越难以分辨哪部分文本源于学生自身的思考。学生与教师群体之间不乏因AI疑云而产生的矛盾，这些矛盾暴露了许多人为什么上大学和教授为什么教书之间的紧张关系。学生们从小就被教育要把成就理解为离散的、可衡量的东西，但当他们进入大学后，则会被教授要求与困难和抽象作斗争，只是到了这个时候，学生们已经习惯了寻找获得好成绩的最有效途径。 Hsu总结称，让人担忧的并不是ChatGPT，而是如今年轻人普遍存在的处境。教师Shanna Andrawis认为，她的学生们变得越来越内向，成天盯着手机，几乎不想“练习克服那种青少年生活中常见的尴尬”，AI或许是造成这种恶化的原因之一，但并非唯一的罪魁祸首。尽管许多学术问题可以通过重新设计课程和学术要求来解决，但技术进步和学生的现状是无法轻易改变的。很多高校在尝试限制AI的使用后，现在纷纷与AI公司合作。 学生也许比其他任何人更深地感受到这种无力感。前一刻，他们被告知要学习编程，下一刻他们就会发现计算机科学专业的失业率高于民族研究专业的学生，这被认为是AI包揽了入门级编程工作的结果。教育系统应该如何应对AI，Hsu没有提供答案。 04 剧集大结局对观众来说意味着什么？ 近日，随着《鱿鱼游戏》第三季的完结，全球的观众都陷入了一种空虚不舍的情感之中。心理学家Adam Gerace进一步分析了告别心爱的剧集为何令人伤感，他认为，这种反应源于观众与角色建立的\"准社会关系\"——一种单向的情感联结。观众通过角色获得情感释放、自我反思和替代性体验，剧终意味着与这些\"虚拟朋友\"永久告别。 《鱿鱼游戏》第三季海报 图源：豆瓣 为什么一个结局对于观众来说很重要？一般来说，令人满意的结局会给我们观众了结，矛盾得到解决，坏人被擒拿归案。观众希望看到一个积极或童话般的结局，但如果没有，他们可能会产生消极的情绪。或者，如果他们花时间观看某个系列剧的目的是为了弄清某个谜团的真相，到最后没有实现，他们可能会觉得自己受到了欺骗。无论如何，这种追求圆满结局的需求在Gerace看来是有些奇怪的。在现实生活中，比如在我们自己的爱情故事，或者人生各种事情上，我们常常无法得到圆满的结局，但我们仍然期待自己喜爱的角色能有这样的结局。 Gerace认为，“丧失”并不是负面的，反而是一种情感的正常反应。我们对电视剧的“丧失”反映了我们对虚拟世界的高度投入，因为这些虚拟世界给予了我们愉悦、逃避和自我反思的机会。而这种情感上的“告别”往往是共同的，观众之间可以通过社交媒体或粉丝群体进行共享，甚至通过重温剧集来维持与角色的情感联系。Gerace强调，尽管电视剧的结束让观众感到失落，但随着时间的推移，这种失落情感可能转化为对剧集的感激。 参考资料： https://www.theguardian.com/books/2025/jul/10/inside-the-salt-path-controversy-scandal-has-stalked-memoir-since-the-genre-was-invented https://observer.co.uk/news/national/article/the-real-salt-path-how-the-couple-behind-a-bestseller-left-a-trail-of-debt-and-deceit https://www.independent.co.uk/author/adam-white https://www.newyorker.com/culture/infinite-scroll/recession-indicators-are-everywhere https://edition.cnn.com/2025/05/04/tech/recession-indicators-tariffs-memes-cec https://www.newyorker.com/magazine/2025/07/07/the-end-of-the-english-paper https://theconversation.com/saying-goodbye-is-never-easy-why-we-mourn-the-end-of-our-favourite-tv-series-260409 举报/反馈"
    },
    {
      "doc_id": 38381,
      "title": "DeepRare发布首个可循证智能体诊断系统,直击医学Last Exam难题",
      "time": "2025-07-25T00:00:00+00:00",
      "content": "在医学面前，罕见病是一道最难的题。全球已有超过 3.5 亿人受到罕见病影响，病种超过 7000 种，约 80% 为遗传性疾病。但大多数患者在确诊前需经历 5 年以上的延迟、7 次以上就诊、3 次以上误诊，平均误诊率高达 40%-50%，给患者和家庭带来沉重负担。 罕见病症状异质性高、诊断路径长、知识分布极度稀疏，是典型的「小样本、大空间」问题。医生如同在浩如烟海的资料中「大海捞针」，面对碎片化信息与复杂交互线索，传统 AI 模型难以胜任，临床专家的经验更难被规模化复制。 02:46 破解之道：重塑诊断路径 为破解这一世界级难题，上海交通大学人工智能学院牵头，联合新华医院、上海人工智能实验室、哈佛医学院共同发布了全球首个罕见病推理型智能体诊断系统——DeepRare。 论文标题：An Agentic System for Rare Disease Diagnosis with Traceable Reasoning 论文地址：https://arxiv.org/abs/2506.20430 DeepRare 结合大语言模型和多智能体架构，通过模拟临床医生 「提问 — 分析 — 查证 — 推理 — 决策」 的诊断思维路径，将罕见病诊断任务拆解为多个专业环节，由智能体协作完成整合与推理，真正实现可解释的主动诊断。 系统由中央控制单元（Central Host）统筹全局，以大模型为引擎，通过精心设计的任务规划和工作流程，调用多个功能智能体（Agent）分工协作，综合各类信息构建结构化诊断建议与可溯源因果链条，构成端到端的智能诊断解决方案： 表型建模智能体：结构化提取主诉信息与 HPO 术语 基因分析智能体：解析 VCF 文件，关联表型识别潜在致病突变 搜索与知识匹配智能体：调用数据库与在线搜索引擎，检索相关疾病、文献 病例匹配智能体：通过小模型匹配相似症状的病例 疾病抽取智能体：从自由文本推理结果中抽取疾病结论，进行搜索 表型分析智能体：调用表型分析的生信工具，提供参考的疾病列表 整个系统支持多模态输入（包括自由文本、结构化表型数据、基因组数据等），具备自适应能力，能够动态适配不同输入场景和数据质量，实现 「人 - 机 - 知识」 三位一体的协同诊断。 DeepRare 系统的输入和架构图 DeepRare 的诊断流程主要分为两个阶段： 信息收集阶段：系统对输入数据进行多轮分析，智能体协作抽取关键症状、变异信息、病例背景，并调用 40 余类医学工具和数据库，进行综合推理，生成初步诊断及相关线索； 自我反思与验证阶段：中央控制器对诊断结果进行多轮自我反思与论证，构建因果链、匹配先验知识，并实时整合最新临床指南、研究文献和相似病例，输出可信、可溯源的诊断建议。 DeepRare 系统工作流 四大核心： 主动提问机制：系统能识别出诊断过程中关键信息的缺口，主动发起问询，引导医生或用户补全症状信息，确保数据完整性； 实时整合 40+ 医学知识源与工具：全面调用 OMIM、OrphaNet、PubMed、ClinVar、ExAC、HGMD 等专业数据库与搜索引擎，获取最新、最全面的医学证据； 自我反思能力：系统具备 「提出假设 — 验证假设 — 修正假设」 的闭环推理能力。面对不确定或弱匹配的情况时，能主动返回上一步补充证据、重新评估，有效降低误诊率、减少模型幻觉； 生成可溯源推理链条：每条诊断建议都附带明确的因果路径和证据出处，从症状到病因全链条可解释，帮助医生建立信任、提升临床可用性。 真实案例：改写患儿命运 2021 年，上海新华医院接诊了一名来自广西的 20 个月大的患儿。他自出生起便问题重重：发育迟缓、面部特征异常、生殖器发育异常、肺发育不良。家人带着他四处求医，做了全外显子组测序、内分泌评估等多轮检查，却始终查不出病因。诊断陷入僵局，家人焦急万分，医生团队感到无力。 时间来到 2025 年 6 月，DeepRare 正在系统测试期间。医生团队决定抱着尝试的心态，重新翻出这个悬而未解的病例，用 DeepRare 进行分析。系统启动推理引擎，分析症状、基因和病例，敏锐提示出此前未被怀疑的 Prader-Willi 综合征（PWS）。随着目标锁定，团队安排了针对该病的甲基化检测，终于明确了诊断。 PWS 是一种罕见复杂遗传病，发病率约为 1/10,000 至 1/30,000，婴儿期表现为喂养困难、发育迟缓，长大后可能出现暴食、肥胖、智力障碍等。由于其致病机制超出常规检测范围，且患儿年幼、症状不典型，极易被漏诊。这一次，凭借 DeepRare 的精准提示，患儿得以在疾病早期接受干预治疗，赢得了扭转命运的机会。 对医生团队而言，这是人工智能与临床实践携手的突破性一刻；对家庭而言，这不仅是一纸诊断，更是走出迷雾、拥抱希望的新起点。 性能实证：挑战诊断极限 DeepRare 在来自 亚洲、北美、欧洲的 8 个真实临床数据集上进行了全面评估，涵盖 6401 例罕见病患者、2919 种疾病、14 个疾病类别。评估结果： 平均 Recall@1 达 57.18%，相比现有最优方法 Claude-3.7-Sonnet-thinking 提升 23.79 个百分点 Recall@5 超过 80%，大幅提升诊断覆盖范围 在新华医院真实病例中，基于全外显子基因测序（WES）数据测试，Recall@1 达 70.6%，显著优于 Exomiser（53.2%） 更值得一提的是，DeepRare 在测试的 2919 种疾病中，有 1013 种（占比 34.7%）实现了 100% 召回率。这一出色表现不仅彰显了系统对复杂疾病谱的广泛适应能力，也有力证明了其在罕见病诊断中的鲁棒性与可推广性。 HPO 表型输入场景上 15 种方法在所有数据集的平均性能 HPO（表型数据）输入场景评估 如下图所示，7 个公共罕见病数据集的评估中，DeepRare 在 Top-1 诊断准确率上全面领先现有基线方法。以下为不同数据集下表现最优的模型对比结果（完整数据详见原论文）： 在 RareBench-MME 数据集上，Top-1 准确率达到 70%，提升幅度达 50%； 在 RareBench-RAMEDIS 上，Top-1 准确率为 73%，提升 31%； 在 MyGene2 数据集上，Top-1 准确率为 76%，同样提升 31%。 此外，在新华医院私有临床队列上，系统在真实病例中实现了 58% 的 Top-1 准确率，较次优方法提升 16 个百分点，进一步验证其在临床实际场景中的稳定性与通用性。 各方法在 HPO 表型输入场景上的比较 专科特异性分析：覆盖多学科，优势明显 DeepRare 在多器官系统的罕见病诊断中展现出稳定而有层次的性能表现。分析结果表明，系统在多个关键医学领域显著优于现有方法： 肾脏与泌尿系统（Kidneys and Urinary System）：诊断准确率达 66%，为所有专科中表现最优； 内分泌系统（Endocrine System）：准确率为 60%，远高于次优方法的 32%； 消化系统（Digestive System）：在 729 例病例中达到 49% 的准确率，对照方法为 34%； 呼吸系统（Lungs and Breathing System）：表现相对较弱，准确率为 31%。 这一结果揭示了系统在不同专科场景中的适配能力与未来针对性优化的方向，也证明其作为通用诊断平台的潜力。 HPO 表型输入场景上 各个专科层面的比较 多模态输入（表型 + 基因）场景 在罕见病诊断中，基因组数据的整合是提升诊断准确率的关键环节。在 DeepRare 系统中，融合表型信息与基因变异数据后，性能显著提升： 在新华医院真实临床队列中，Recall@1 从 46.8% 提升至 70.6%； 同一数据集上，DeepRare 的表现显著优于主流生物信息学工具 Exomiser（70.6% vs 53.2%）。 值得强调的是，即便在缺乏基因数据的单一表型输入场景下，DeepRare 依然达到与专业生信工具相当的性能水平，展现出卓越的表型建模与语义推理能力。 多模态（表型 + 基因）输入的性能 可溯源性验证：让推理过程看得见 为评估 DeepRare 推理链条的可溯源性与临床可采纳性，研究团队对系统自动生成的 180 个病例诊断过程进行专家验证。系统对每项诊断建议均自动生成结构化的证据链条，明确标注引用来源及对应位置，覆盖 Nature、OMIM、OrphaNet、PubMed 等国际权威知识库与期刊。 经过十位罕见病专家的独立验证，推理证据的参考性与准确性平均达到 95.4%。这种证据呈现机制，显著提升了医生在临床中的知识调取效率，有助于加速诊断决策、提升模型可信度与解释性，为智能诊断系统在真实场景落地提供关键保障。 可溯源性的专家评测 在线平台：让智能诊断触手可及 为推动成果落地，团队已上线 DeepRare 在线推理平台（http://raredx.cn），面向临床医生提供结构化输入、主动问询、诊断建议与可导出报告的完整闭环流程。系统支持中英文切换，界面简洁、操作便捷，已在多家医院开展试用，助力罕见病早诊、准诊与规范化管理。 网页首页 总结与未来展望 DeepRare 所代表的 Agentic AI 诊断系统，正在重塑罕见病诊断的范式。通过主动推理、动态知识更新与证据可追溯机制，系统不仅提升了效率，也为人工智能在精准医学中的应用提供了落地样本。 展望未来，DeepRare 有望扩展至科研场景，加速意义未明变异的解读，拓展可治疗罕见病的谱系，推动疾病知识的积累与诊断进程的前移。 与 DeepRare 一起，为全球罕见病患者照亮前路，让每一份努力都离答案更近、离希望更近。 举报/反馈"
    },
    {
      "doc_id": 38383,
      "title": "半年盘点|头部三甲医院开始“卷”AI,医生看病也能“自动驾驶”了",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "进入人工智能时代，头部三甲医院比拼的不仅仅是医疗水平，也是智能水平。头部三甲医院“卷”AI的趋势今年开始进入白热化。 今年上半年，医疗AI大模型成为各家医院争相布局的热门赛道。截至目前，包括上海中山、瑞金、仁济、新华在内的头部三甲医院都高调发布了心血管、病理、泌尿科、儿科等不同疾病领域的AI模型。 与此同时，AI专家医生数字分身也在一些医院逐步推广。这些数字AI智能体已能完成问诊、患者教育、科普宣传、专业授课等任务，未来医生看病也有望实现“自动驾驶”。 从数字导诊员到AI医生 据不完全统计，截至目前，我国已有约300个医疗大模型，仅今年上半年发布的医疗大模型数量就占据了约一半，接近150个。 如今，在一些新建的医院门诊大厅内，数字导诊员已随处可见。上个月，第一财经记者在走访上海交大医学院附属新华医院奉贤院区时就与数字导诊员进行互动，通过语音提问就能咨询应该挂哪个科室的号，了解诊室的具体位置，缓解了人工导诊人员的压力。 导诊只是人工智能在医院落地应用的一个“窗口场景”。新华医院还基于儿科的学科专业优势，推出了AI儿科大模型，赋能基层儿科医生诊疗与儿童居家养护。 相关报告显示，医疗大模型应用场景中，提及频次最高的为医疗服务环节，占比高达53%，其中临床专病辅助决策、预问诊、病历辅助生成、医学影像辅助诊断位居前四。 在日前举行的联合国国际电信联盟（ITU）大会上，上海交大医学院附属瑞金医院获得了一个特别的奖项，该院与华为打造的用于AI辅助病理诊断的RuiPath病理大模型获奖，该模型已于上个月宣布开源。 一家医院获得了国际电信行业的顶尖大奖，让瑞金医院院长宁光院士也直呼想不到。技术的力量正在全方位渗入医院的诊疗管理流程中。 在癌症诊疗中，早发现、早诊断、早治疗至关重要，但我国病理行业面临多项严峻挑战。数字化智慧病理成为突破上述困局的关键。今年2月，RuiPath病理大模型发布，该模型基于瑞金医院广泛的疾病谱系及高质量的医疗数据，癌种覆盖广度达到中国每年全癌种发病人数90%的常见癌种；医生可以和RuiPath开展互动式病理诊断对话，亚专科知识问答深度达到专家级知识水平；改变了传统病理医生的工作模式，提升了诊断效率与质量。 在心血管领域，今年上半年，复旦大学附属中山医院心内科发布了国内首个心脏大模型——“观心”大模型（CardioMind），并开发了基于该模型的心脏病专家葛均波院士的“数字分身”，AI医生看病时代离我们更近了。 “观心”大模型具有顶尖专家级诊疗经验，知识储备能力已经超过了很多正教授，将赋予中山医院心内科医生“超强大脑”——未来每位医生都将拥有自己的智能体（AI agent），且不受时间和空间的限制。 国内三甲医院海量的患者疾病数据库为大模型训练提供了优质的语料。去年，仅中山医院心内科的诊疗人次就达到82万人。观心大模型的研发与训练输入了该院心内科积累的数十万份电子病历和心内科医生思维，以及从“名院大查房”等线上项目中提炼的疑难病例诊疗逻辑，旨在教会大模型“像专家医生一样看病”。 监管能否跟上技术发展 “过去我们谈论的未来技术，现在已经成为医疗不可或缺的基础工具。”宁光院士坦言。 中山医院院长周俭也表示，AI模型的能力对于医生而言，就好比是自动驾驶对于司机的作用。医院加速构建AI模型的目标，就是为了打造医疗领域的“自动驾驶”系统。“当AI能处理80%的常规工作，医生就能更专注于疑难病例研究和患者深度沟通。”他说道。 为了推动未来AI医院的建设，今年4月，清华大学宣布成立人工智能医院（Tsinghua AI Agent Hospital）。在这个虚拟的AI医院里，甚至没有人类医生，完全使用智能体，其中一些智能体是医生，另一些智能体是护士，还有一些智能体是病人，模拟医院各个科室构建，为未来的“无人化医院”提供蓝图。 据清华大学智能产业研究院院长张亚勤介绍，AI医院用2天时间便可完成三甲医院2-3年的诊断量，而且目前来看诊断的准确率很高，超过96%。 然而，当AI重构社会的速度远超想象时，医院也面临着前所未有的挑战。新华医院院长孙锟对第一财经记者表示，以DeepSeek为代表的通用大模型在医疗领域存在明显的局限性，包括专业知识不足和较为严重的“幻觉”问题，这与模型训练数据的广泛性和非专业性有关。 目前推出AI大模型的三甲医院均表示，“只用经得起验证的技术”。与其他行业一样，AI智能体在医疗行业应用落地的过程中，首先面对的是数据的挑战。专家指出，未公开发表数据是医疗大模型的核心竞争力，但这些数据通常存在于医院科室的封闭系统当中，获取和使用这些数据面临着复杂的挑战。 “技术的发展速度远远超前于监管的速度，如何为AI诊疗制定伦理方面的规范，是我们当前面临的重要课题。”葛均波在谈及使用AI技术时愈发凸显的医疗数据安全等伦理问题时强调。 以“观心”大模型为例，为了确保医疗数据安全，研发团队建立了严格的数据防火墙，患者隐私信息经加密处理后完全匿名化，并植入了心理评估模块，为患者提供心理健康支持。 “医院在落地AI智能体之前，首先要做的就是基础数据库的建设，做好数据治理，获取高质量的语料，用于训练垂类大模型和AI智能体。”一位三甲医院信息科相关人士告诉第一财经记者。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 38385,
      "title": "全球首个AI医学影像大模型技术与商业化先行者!年收增速超30%",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "在AI（人工智能）医疗被全球各大企业和知名大学一致看好的当下，全球医学影像AI领域的领跑者德适生物科技股份有限公司（以下简称“德适生物”）正通过18A方式冲刺港交所上市。 根据公开资料，公司创始人宋宁博士是一名“80后”，他是教育部国家生命科学与技术人才培养基地培养的首届学生，具备计算机科学、生命科学和临床医学的复合背景，先后执教于日本国立长崎大学医学部、上海交通大学医学院。值得一提的是，德适生物的发展受到了一级资本市场的多方认可，股东阵容涵盖杭州紫金港、国中投资、美鸿投资、远翼投资、余杭经开、华睿睿银等知名机构，经历5轮融资，创立9年，估值达25.6亿元人民币。 创始人拥有多学科交叉背景，仍握有公司超50%投票权 宋宁今年43岁，拥有计算机科学和医学遗传学的复合背景，获中南大学生物工程学士学位和医学遗传学硕士学位、日本长崎大学医学博士学位，一度在日本长崎大学和上海交通大学医学院执教。 2016年9月，宋宁创立公司，注册资本100万元。随后资本快速涌入：2016年12月杭州紫城入股；2018年8月，经过前期一系列股份转让及增资，宋宁持股降至51.55%，其中，德清科技以2000万元入资；2019年4月余杭产业基金增资1500万元后，宋宁个人持股降至47.95%⋯⋯ 面对外部资本涌入导致的控股权被稀释，宋宁选择了回购。 2020年7月，宋宁以2000万元的原价，回购了德清科技持有的全部德适生物股份。其后宋宁于2021年5月及6月分别向德适诺达与宁波嘉缘转让了合计5.28%的股份。此次转让几乎没有溢价，估计在转出时额外承担了巨额税负（根据国内税法，股权转让，如有公司估值增加，按估值增加部分征收20%个人所得税，无论是否获利）。相信回购德清科技应当属于无奈之举，根据德清科技的股东情况，或是德清科技受当时行业环境影响，而宋宁的回购体现对公司的保护。 当前公司上市前的架构中，宋宁直接持股30.04%，并通过员工持股平台德适诺辉及三家投资控股平台（德适诺达、德仟科技、德适诺鑫）合计控制52.06%的投票权。此外，德适生物还获得了杭州紫洲、和途六号、国中投资、余杭经开等多轮投资，2025年6月最新一轮增资后投后估值达25.6亿元。 创始人博士创业守信重情，聚焦主业心无旁骛 德适生物的股东名单中，除创始人宋宁外，其他都是机构股东，自然人杨曦的出现显得格外特别。 2021年，为将杨曦丰富及宝贵的销售经验用于德适海外业务开拓并作为对其的激励，于同年2月9日，宋博士与杨曦订立股份转让激励协议，宋宁同意以100万元向杨曦转让当时公司2%股份，之后杨曦再以50万元认购新增注册资本，合计持股3%。由于上述杨曦与宋博士订立的股份转让协议所载的业绩目标并未达成，2023年，宋宁以228万元回购股份。其实，激励协议未完成的情况下，一般可原价回购股份，但宋宁最终选择溢价回购，体现其重情义的一面。 此外，2025年，德适向独立第三方易连（浙江）互联科技有限公司转让旗下两家子公司——杭州德佑医学检验实验室有限公司和成都金牛牛好未来互联网医院有限公司的100%股权。据悉转让原因为提高运营效率、专注核心业务。行业数据显示，医学检验实验室（ICL）受成本和价格控制影响，利润率普遍偏低：以国内某头部ICL机构为例，2024年营收71.90亿元，净利润为-3.81亿元，净利率为-5.77%。可见该领域的困境显著，龙头企业尚在亏损，相信持续经营不利于公司整体发展。通过剥离这些低效业务，可更加聚焦在核心AI业务。可以说，一系列果断的战略取舍，体现了管理层聚焦高价值AI主业的决心，为公司未来盈利打下了更坚实的基础。 装备销量逆势上行，科技突破铸就持续高速增长引擎 医学影像AI正处于黄金发展窗口。受益于医生紧缺、影像数据激增和政策支持，中国AI医疗器械市场在近年保持年均超50%的增长率。据弗若斯特沙利文预测，中国AI驱动的医学影像细分市场规模将由2024年的24亿元跃升至2030年的401亿元，年复合增长率高达60.2%；到2035年有望进一步增长至781亿元。可以预见，未来十年医学影像AI将在临床诊断中扮演越来越重要的角色，从辅助判读到智能诊断，市场空间数百倍扩容。 德适生物搭建了“基座模型+智能医疗器械+试剂耗材+模型服务”的完整生态体系，形成从样本制备到AI分析的闭环解决方案矩阵。公司推出了AutoVision®、MetaSight®等多款全球领先的智能设备，覆盖染色体制备、显微成像、核型分析等关键环节，构成了全球首个AI驱动的染色体分析自动流水线。MetaSight®智能染色体扫描系统获得中国NMPA、美国FDA及欧盟CE三大认证，成为国际首个AI驱动的染色体全自动分析设备。 公司2024年推出的iMed MaaS云平台，解决了基层医院AI应用落地难题。该平台自2024年9月上线后短短数月即贡献收入1,954万元，高毛利显示出强大的技术溢价及市场接受度。同时，该技术还支持本地私有化部署，为医院提供“用自己的数据训自己的AI”的方案，助力医疗机构数据合规与智能升级“双达标”。 公司除了提供创新的AI医学影像技术通用平台服务，还以染色体分析作为智能医疗装备的产品突破口，进而深耕医学影像AI多个细分领域，迅速积累了技术领先优势、优质客户资源和产品落地先发优势。截至2025年6月，公司产品已进入全国400多家医疗机构，覆盖大量三甲医院和诊断中心。根据招股书披露，染色体核型分析系统行业长期被国外知名光学影像巨头卡尔蔡司（与MetaSystems公司合作）、徕卡（Leica）合计占据95%的市场份额。公司的创新产品自获批上市短短几年，已通过人工智能技术的底层突破大幅提升临床诊断效率，其2024年中国市场占有率已高达30.6%，排名第一。2024年下半年至2025年上半年同比收入增长超过35%，显示高速成长势头明显领先于同行，成为该领域“国产超越”的典型代表。 通过天眼查及公开市场招标数据可以看到德适生物2025年上半年智能医学装备系统的中标数量及金额较2024年同期出现3位数大幅增长，其2025年业绩值得期待。 资金余额超亿元，人均产出翻倍增长 德适生物的商业模式已经过验证，经营业绩稳步提升。2024年公司实现营收约7,035万元，同比增长33.1%，主要得益于模型云服务的新业务放量。当年云平台服务收入1,954万元，贡献了27.8%的营收，成为新的增长引擎。高毛利的模型服务提升了整体盈利能力：2024年综合毛利润率为65.5%，在医疗器械行业位居前列。公司净亏损也大幅收窄——2024年净亏损约4,337.5万元，相比2023年的5,611.6万元减少近23%。净亏损率由2023年的-106%改善至2024年的-61.6%，亏损收窄近一半，显示出开源节流初见成效，结合25年上半年公开招标数据来看，未来可期。 截至2024年底，公司账上现金及等价物1,710.4万元，到2025年4月30日进一步降至556.7万元（未审），与此同时，公司持有大量其他高流动性低风险金融资产：截至2025年4月30日，按公允价值计量且变动计入损益的金融资产为3,900万元，计入其他综合收益的金融资产为2,118万元，合计超过6,000万元。相信公司是在存款利率下行通道的当下，进行存量资金收益提升的表现。值得一提的是，若计入其2025年6月完成的pre-IPO轮融资，公司可随时使用的资金余额已超过1亿元。 2023年末，公司员工数量为206人，但到了2024年末，员工人数为145人，净减少61人，比例约30%。同期，2024年公司实现营收约7,035万元，同比增长33.1%。由此可见，公司管理能力进一步提升，人均产出接近翻倍。 上市融资加速布局，开创全球医学影像AI新格局 此次赴港上市，德适生物拟将募集资金用于AI AutoVision®市场推广、iMedImage多模态医学影像大模型的进一步迭代开发及全球市场布局，加快实现从“AI工具提供商”向“全模态医疗AI基础设施架构师”的战略转型。 站在新起点，德适生物正以“中国智造”实力引领全球医学影像AI产业变革，成为中国科技创新从“国产替代”到“国产超越”的典型代表。相信凭借此类公司出色的技术研发能力和商业化落地实力，中国科技企业有望开启技术引领的全球跨越式发展新篇章。（咸宁新闻网） 举报/反馈"
    },
    {
      "doc_id": 38387,
      "title": "AI算力助复旦科研再突破:阿尔茨海默病早筛早诊检测试剂年内或上线",
      "time": "2025-07-20T00:00:00+00:00",
      "content": "中新网上海7月19日电 (记者 夏宾)中新网记者近日了解到，复旦大学在医学领域接连取得突破性成果，继发现帕金森病(PD)全新治疗靶点之后，阿尔茨海默病(AD)早筛早诊检测试剂也将于今年末上线各大医院和体检中心。这些研究均由复旦大学与阿里云等联合打造的CFFF平台提供AI算力支持。 复旦大学附属华山医院郁金泰教授对中新网记者表示，充分利用生物医药产生的大数据，需要非常强大的算法、算力支撑，也需要一些比较新的算法。 图中右一为复旦大学附属华山医院郁金泰教授。(受访者本人供图) 2023年，中国高校最大云上科研智算平台CFFF上线，该平台包含了面向多学科融合创新的计算集群“切问1号”和面向计算科学高精尖研究的专用高性能计算集群的“近思1号”，借助阿里云全球领先的大规模异构算力融合调度技术、分级存储技术、AI与大数据一体化技术，连成了一台真正意义上的“超级计算机”。 其中，阿里云乌兰察布数据中心以公共云模式为全国科研机构的多个项目提供超千卡并行智能计算，支持千亿参数的大模型训练。“我们希望通过生物医药大数据，为疾病的早筛、早诊、早治提供相关生物标志物或者治疗靶点和预防方案。但前提是数据能真正有算力、算法支撑并能解决临床问题。”郁金泰说。 郁金泰教授团队正是依托CFFF平台接连取得重大突破，实现提前15年预测阿尔茨海默病发病风险，精度超98.7%，成果发表于《自然》杂志(Nature)。团队还发现帕金森病全新治疗靶点，并利用AI筛选出候选药物，研究成果登上《细胞》杂志(Cell)和《自然》杂志(Nature)等国际顶刊。 阿尔茨海默病和帕金森病是严重威胁人类健康的神经退行性疾病。对于这两种疾病，早期预警与精准干预是关键。然而，传统研究手段能处理的数据较少，耗时漫长且效率有限。在CFFF平台建成后，科研人员可以用“数据+算法”双轮驱动替代传统的“假设驱动”模式，用更少的时间处理更多的数据。 在阿尔茨海默病领域，郁金泰团队基于脑脊液蛋白质组学数据测试了6361余种蛋白质，这些蛋白质指标会随疾病发展而变化。使用传统方法筛选蛋白，会找出数十种甚至上百种可能的“诊断蛋白”，科研人员逐一验证每一种蛋白质的诊断结果，效率低下。郁金泰团队利用AI算力，采用创新的数据驱动方法和独特的蛋白质组学分析策略，对6361种脑脊液蛋白组学数据进行了分析和建模，筛选出5种最重要的蛋白质，将诊断准确性提高到98.7%。 在帕金森领域，病理性α-突触核蛋白是帕金森病的关键致病蛋白。过去，研究者根据现有理论体系，推测某一蛋白可能在病理性α-突触核蛋白传播过程中发挥重要作用，再设计实验进行证实。但人体内的基因蛋白数量极其庞大，采用这一方法意味着忽略了现有理论体系外的诸多可能性。 借助AI算力和大模型技术，郁金泰团队得以在所有基因中筛选潜在靶点，利用人工智能技术对其蛋白结构进行预测，再基于预测结构对小分子化合物进行虚拟筛选，从而在5年内就完成原本需要几十年甚至更长时间才能完成的工作。 郁金泰表示：“以前的科研就像在大海捞针、慢慢钓鱼，需要花费大量时间；现在人工智能就像一张大网，能在海量数据中快速精准地发现关键指标和潜在治疗方案，极大地提升了研究能力和效率。” 复旦大学类脑智能科学与技术研究院研究员程炜说：“现在处理几万人的影像，几天就‘跑’完了，放在以前几年都‘跑’不完。” 目前，阿里云AI基础设施已支撑CFFF平台全面升级，提供文理医工各学科47个特色学科模型和4万余个科学数据集开放使用，支持发表了多篇CNS级别的高水平论文。(完) 举报/反馈"
    },
    {
      "doc_id": 38391,
      "title": "289个案例入围!广东公布首批“人工智能+医疗卫生”应用场景案例名单",
      "time": "2025-07-13T00:00:00+00:00",
      "content": "记者从广东省卫生健康委处获悉，经过单位申报、地市推荐、专家评审的方式，近日遴选了第一批入围的“人工智能+医疗卫生”应用场景案例，并对名单予以公布。首批应用场景案例入围数共289个，涵盖了医疗服务管理、基层公卫服务、健康产业发展、医学教学等四个领域，展现了44个“AI+医疗卫生”的应用场景。 点击查看详细名单 当下，广东“人工智能+医疗卫生”的发展正在提速。今年6月，广东省卫生健康委联合工信、科技、发展改革等8部门联合印发了《广东省加快“人工智能+医疗卫生”发展行动方案（2025-2027年）》，加力推动人工智能应用发展。一批人工智能产品的成果正在得到转化，中山大学肿瘤防治中心牵头研发的\"脑转移瘤MR图像辅助检测软件\"，已经推广至全国500多家医院使用。省人民医院研发了ROP智能诊断与自动图文报告系统，已在全国26家医院进行推广应用，服务人群超5万人次。随着首批应用场景案例名单出炉，将进一步推动人工智能应用在医疗领域的落地。 ▌走访一：识别脑转瘤微小结节 辅助精准研判病情 “通过AI辅助软件，我们更精准识别5毫米以下的脑转移瘤，以往这类结节60%的医生都有可能会漏掉。”中山大学肿瘤防治中心影像科主任谢传淼介绍，肿瘤防治中心研发的\"脑转移瘤MR图像辅助检测软件\"，主要借助AI技术，帮助分析脑MR影像。作为全国头部的肿瘤医院，该中心一年需要处理5-6万例的脑MR阅片量，阅片医生的工作量很大。借助AI技术研发针对脑转移瘤的软件后，很快显现出应用的优势，软件可以细致甄别出5毫米以下的结节，“这种小病灶很难被肉眼发现，有脑部转移灶和没有脑部转移灶，临床分析和治疗方案都会不一样。”谢传淼表示，以肺癌患者为例，一旦发现有脑转移，癌症的分期以及治疗方案都会有所不同。目前，该技术已经推广到500多家医院中，在临床中被广泛使用。 “基于DeepSeek大模型与肿瘤大数据平台，我们研发了面向肿瘤专科医生的智能诊疗助手。”中山大学肿瘤防治中心信息中心主任李超峰介绍，该助手集成精准咨询、智能病历生成、辅助诊疗决策三大核心功能模块，通过DeepSeek在肿瘤专病专科领域数据的微调环节，能准确提取患者病历、检查报告等数据的关键信息，并支持对肿瘤分期评估、治疗方案推荐、结构化病历生成等复杂决策任务的精准推理。该应用已于今年3月上线，迄今累计使用人次达6万次，协助医生提升诊疗效率，病历生成时间减少80%，病历阅览效率提升5倍。此外，基于医院内部七万例结直肠肿瘤患者的病例数据，目前医院正在研发结直肠癌辅助决策大模型，并将计划于下半年正式推出。 ▌走访二：5分钟可完成一位老人的阿尔茨海默病筛查 在南方医科大学珠江医院，该院副院长张鹏介绍，珠江医院率先布局，以 AI 智能体构建为核心，在临床诊疗、医院管理、医学教学等多领域推动 AI 诊疗应用落地，形成了覆盖医疗全链条的智能化服务网络。 以珠江医院院长郭洪波牵头研发的SMART互动式AI认知早筛系统为例，平均5分钟的时间，通过一系列交互式趣味小游戏，AI同步可以抓取测试者的眼部、脸部等表情细节，完成对一位老年人的阿尔茨海默病筛查。以往，通过量表评估、脑脊液标志物、血液标志物、MR/PET检查等方式，存在操作不便、有创、价格昂贵等缺点，通过人工智能的开发，在疾病的早筛方面作出了创新性的探索，实现了在患者出现明显症状前，无需专业医护人员指导进行的无创、快速、电子化的认知早筛。“目前在广州绝大部分的养老机构、社卫都已经覆盖了这一应用，除了广州、东莞、佛山等城市，这一成果也将在上海落地应用。” ▌声音：减少AI幻觉 打通使用者的“最后一公里” AI的场景应用越来越广泛地出现在医疗场域中，也引起了广泛的关注和探讨。 中山大学肿瘤防治中心副院长孙颖表示，在开放、应用AI的过程中，信息化建设是需要打通的“最后一公里”。 “AI的应用是本着为患者提供服务的初心，要从使用者的角度打磨，怎么建设，才能让使用者更方便地使用？”孙颖表示，要让AI技术逐渐变成一个实用工具，一方面，医生、患者可以通过使用得到便利，另一方面，也有助于推动学科的建设。 “我们在研发肿瘤辅助决策大模型时发现，AI幻觉率在10%-20%左右，我们需要做的是‘砍掉’AI胡思乱想的部分。”李超峰表示，在研发时发现，AI的总结能力很好，但是在看病场景应用时容易出现“胡思乱想”，在投喂数据的同时，研发团队也在持续训练大模型，减少AI幻觉的出现。 “每周二的多学科会诊，通过使用AI诊疗助手，医生从平均需要几十分钟回顾病历资料，缩减到几分钟可完成。”作为一名临床一线医生，中山大学肿瘤防治中心结直肠科医生唐京华介绍，肿瘤患者病情复杂，特别是在多学科诊疗会议上的案例，往往病历材料非常多，使用AI工具提取并总结病史资料大大提升了效率。 但是，AI技术的广覆盖和使用，会否降低医生的警觉性？ 对此，唐京华医生认为，这恰恰在于医生怎么去理解、使用AI这一技术，“下级医生每天开立完医嘱后，我还可以增加AI医疗助手审核，包括手术前再次检查术前准备是否完善，手术时机是否合理等等。一道辅助审核的程序，可以帮助医生更实时、更全面地掌握患者情况，降低人为的错误率。” 文/广州日报新花城记者：梁超仪 通讯员：粤卫信 广州日报新花城编辑：张映武 举报/反馈"
    },
    {
      "doc_id": 38399,
      "title": "一次扫描,AI可识别九种痴呆症",
      "time": "2025-07-01T00:00:00+00:00",
      "content": "美国梅奥诊所科研团队研发出一款新型人工智能（AI）工具StateViewer，仅需一次常规脑部扫描，就能准确识别包括阿尔茨海默病在内的9种痴呆症特征。相关研究成果发表于最新一期《神经病学》杂志，有望为痴呆症的早期诊断带来革命性变化。医生在电脑上查看脑部扫描图像。图片来源：美国梅奥诊所 研究团队利用3600余份脑部扫描图像（含患者与健康人群）对StateViewer进行训练测试，使该工具实现了88%的疾病识别准确率。更令人振奋的是，与传统方法相比，其诊断速度提升近两倍，准确率最高提升近三倍。 StateViewer通过分析氟脱氧葡萄糖正电子发射断层扫描（FDG-PET）图像，比对大脑葡萄糖代谢模式与痴呆症数据库，能精准捕捉不同病症的特征：阿尔茨海默病主要影响记忆处理区；路易体痴呆多见于注意力运动区；额颞叶痴呆则显现在语言行为功能区。系统通过彩色编码脑图直观呈现异常活动区域，即使非神经科医生也能清晰理解诊断依据。 目前全球约有5500万痴呆症患者，每年新增病例近千万，其中阿尔茨海默病已攀升至全球致死病因第五位。常规诊断需经历认知测试、血液检测、影像检查等多重环节，即便经验丰富的专家也常难以区分相似病症。 研究团队表示，StateViewer的问世不仅简化了诊断流程，早期精准诊断也能确保患者获得最佳干预时机。他们计划持续优化系统性能，以进一步扩大该工具的临床应用范围。（记者刘霞） 【纠错】 【责任编辑:朱家齐】 阅读下一篇： 部级领导干部历史文化讲座20周年纪念版定位就是聊个天金融市场技术分析疗愈的饮食与断食写作教练在你家注音详解古文观止"
    },
    {
      "doc_id": 38406,
      "title": "AI工具只需一次脑扫描即可识别多种痴呆症",
      "time": "2025-06-30T00:00:00+00:00",
      "content": "新华社北京6月30日电 美国妙佑医疗国际的研究人员开发出一款人工智能工具，仅通过单次脑部代谢扫描数据，就可以帮助医生识别出包括阿尔茨海默病在内的9种常见痴呆症大脑活动模式。这有望推动实现痴呆症的早期精准诊断。 研究团队在新一期美国《神经学》期刊上报告说，他们使用了3600多份脑扫描图像对这款名为StateViewer的AI工具进行训练和测试，涵盖痴呆症患者与认知正常人群的脑部影像。 氟代脱氧葡萄糖正电子发射断层扫描（FDG-PET）可显示大脑葡萄糖代谢状况。痴呆症患者的大脑葡萄糖代谢会出现异常，而不同类型的痴呆症患者大脑中葡萄糖代谢异常的区域有区别。该工具通过比对已经确诊罹患不同类型的痴呆症患者的大脑葡萄糖代谢区域特征，判断出扫描对象所患痴呆症的类型。 测试显示，凭借单次FDG-PET脑部扫描结果，这款AI工具即可帮助医生识别出88%的患者具体患的是哪种类型的痴呆症。此外，在这款AI工具帮助下，临床医生解读脑部扫描数据的速度提升近两倍。 当前，痴呆症的临床诊疗面临的一个核心挑战，就是如何在疾病早期实现精准识别。及时诊断能帮助患者在最佳干预时机获得最匹配的治疗方案。研究人员说，这款AI工具可为那些缺乏神经专科资源的医疗机构提供针对痴呆症的诊断支持。 据世界卫生组织数据，目前全球痴呆症患者超过5700万，每年新增病例近1000万。痴呆症往往症状交叉、进展隐匿，准确诊断依赖于经验丰富的神经专科医生。现行诊断通常需要认知测试、血液检测、影像学检查、临床访谈及专科会诊。即便经过全面检测，对于临床医生来说，要想准确区分阿尔茨海默病、路易体痴呆和额颞叶痴呆等具体类型仍具挑战性。 研究团队认为，他们开发的AI工具是朝着痴呆症的早期理解、精准治疗乃至最终改变疾病进程迈出的重要一步。 【纠错】 【责任编辑:吴京泽】 阅读下一篇： 部级领导干部历史文化讲座20周年纪念版定位就是聊个天金融市场技术分析疗愈的饮食与断食写作教练在你家注音详解古文观止"
    },
    {
      "doc_id": 38407,
      "title": "从形态学到功能学,人工智能让心血管诊疗更快更精准",
      "time": "2025-06-17T00:00:00+00:00",
      "content": "人工智能（AI）正以前所未有的速度渗透到我们生活的方方面面，其在医疗健康领域的应用亦逐渐走进诊疗一线。 2024年11月，国家卫生健康委联合国家中医药管理局、国家疾控局印发了《卫生健康行业人工智能应用场景参考指引》，明确了84个细分领域的基本概念和应用场景，为“人工智能+医疗健康”提供规范化的发展路径。 人工智能凭借其强大的数据分析、图像识别以及智能决策能力，在疾病诊断、治疗方案制定、手术辅助乃至医疗资源管理等诸多环节展现出巨大潜力，为解决医疗行业面临的效率低下、误诊漏诊风险、医疗资源分配不均等难题提供了创新路径。在近期的东方心脏病学会议上，睿心医疗最新研发成果——冠状动脉功能测量系统AngioQFA 100宣布上市。 “以往，医生要想获得血流储备分数（Fractional flow reserve，FFR），必须将一根细长的导丝深入到人体冠脉内，通过尖端的压强芯片采集血流信息。这个过程不仅繁琐，而且患者需要承受一定的手术风险和痛苦。”睿心医疗创始人兼CEO郑凌霄介绍说，“我们的冠状动脉功能测量系统AngioQFA 100通过体外无创测量和AI算法，可以在3至5分钟内完成分析报告，大大提高了诊疗效率、同时避免了介入导丝带来的手术风险和不适感。” 传统冠心病诊疗主要依据血管形态学评估，通过冠状动脉CTA或造影查看血管狭窄程度，但这并不能完全反映心肌缺血情况。郑凌霄形象地比喻：“这就好比看水管有没有堵塞，但更关键的是水流是否足够，也就是血管的供血功能。” 睿心医疗创新性地运用自研的AI、3D仿真与连通传感器芯片技术，将传统凭医生经验看冠脉CTA 和冠脉造影图像主观判断血管狭窄程度、凭经验放支架的模式，转变为数据化精准治疗，实现从形态到功能、从介入到无创、从单一到全面的三大革新。郑凌霄介绍，冠状动脉功能测量系统AngioQFA 100是一站式冠脉加微循环功能评估系统，一次测量即可同步获得血流储备分数（FFR）与微循环阻力指数（Index of Microcirculatory Resistance, IMR）。经 300 多例临床试验，其精准度、敏感性、特异性超 95% 接近 96%，处于行业领先水平。 这种从 “看形态” 到 “测功能” 的转变，源自郑凌霄从北京航空航天大学飞行器设计到约翰霍普金斯大学生物工程的跨学科研究经历。“我在约翰霍普金斯大学的博士生导师是机械学院和医学院的双聘教授，他研究的课题都是用工程学比如3D仿真算法去解决医学领域的问题。他经常说：‘工程学的本质是解决实际问题’。我的研究领域也从仰望星空到脚踏实地，运用医工交叉领域的技术去解决实际的医疗问题。” 郑凌霄介绍，一系列前沿探索的背后，是睿心医疗“学术研究+产品创新”双轮驱动战略。在学术研究方面，公司深度扎根心血管精准诊疗科研前沿，获批与申请了超过200项专利，参与推动了由《中国介入心脏病杂志》40多位权威专家发起的《冠状动脉CT血流储备分数应用临床路径中国专家共识》的发布，并支持了覆盖40多家心血管中心、入组超过4600例的大型多中心前瞻性无创功能学临床研究。 在产品创新方面，睿心医疗以冠状动脉功能测量系统AngioQFA 100为核心引擎，构建了覆盖“术前评估－术中诊断与智能治疗－术后智能管理”的全病程精准诊疗解决方案。双轮协同形成产学研医转化飞轮，学术成果反哺算法优化迭代，临床需求驱动产品持续升级。目前，睿心医疗的产品临床合作医院已超800家，实现了20多万例患者安全使用。 在谈及未来产品规划时，郑凌霄透露，睿心医疗即将推出全球首台全自动PCI手术机器人。该机器人将实现无辐射和无铅衣的场景下，术者通过语音命令，由AI驱动机器人自动化地实施血管介入手术。 “我们的目标是为医生提供超越人类极限的智能‘脑’‘眼’‘手’。”郑凌霄表示，“通过AI和手术机器人的结合，我们可以让医生在诊疗过程中更加精准、高效、安全。”（宋雅娟） 来源：光明网 举报/反馈"
    },
    {
      "doc_id": 38411,
      "title": "从“能用”到“好用”:AI激活医疗创新动能",
      "time": "2025-06-17T00:00:00+00:00",
      "content": "在人工智能（AI）的辅助下，贵州山区的患者得到北京专家的接诊，抗肿瘤药物的研发周期大幅缩短，急诊室的抢救时间以分钟级的速度优化……当前，AI通过对医疗数据进行分析处理，可以辅助医生进行医疗决策、提升诊疗效率、改善服务质量，推动医疗行业创新发展。 业内人士指出，从实验室的算法模型到临床一线的诊疗工具，“AI+医疗”正经历从“能用”到“好用”再到“耐用”的蜕变。与此同时，我们也应认识到AI不是万能的“医疗神器”。随着政策法规的不断完善，AI与医疗领域的深度融合有望进一步助力我国医药行业创新提速，为健康事业发展注入持久动能。 辅助医生提升诊疗效率 近日，在浙江大学医学院附属第一医院里，医生们借助蚂蚁医疗大模型一体机，实现CT影像的快速分析。该院结直肠外科主任医师华汉巨说：“患者半年前拍的片子，和半年后再（在不同医院）拍的片子，AI健康应用‘安诊儿’可以自动解读并进行对比，辅助我们提升诊疗效率。” 当前，AI在医学影像领域已成为“医生的第二双眼睛”。基于深度学习的医学影像识别系统，可快速完成对CT、MRI等复杂影像的初筛，涵盖肺结节、乳腺癌等病灶识别，减轻了传统人工阅片的高工作量，让医生更专注于临床决策和精准诊疗。 同时，AI通过整合基因组学、影像学等多维度数据，推动医疗向个性化方向迈进。医疗机构引入DeepSeek后，可结合患者的基因信息、生活习惯和病史，精准推荐药物组合或联合疗法，并实时更新医学指南。例如，在肿瘤治疗中，DeepSeek可提醒医生及时使用新型药物，并优化复杂患者的联合用药方案，减少不良反应。 在浙江大学医学院附属精神卫生中心（杭州市第七人民医院）诊室，主任医师毛洪京打开手机，上面是他在“安诊儿”上的AI分身——“毛洪京医生智能体”。他介绍，这款智能体的优势在于患者不用来回奔波，通过手机就能咨询专家，便捷性强、可及性强、隐私性强。另外，智能体覆盖面广，平时挂不到专家号的患者都能先通过AI问诊专家。据统计，自2024年10月以来，“毛洪京医生智能体”的诊疗效率提升至线下的10倍，已服务超200万人次的失眠患者，成为不少浙江人的“睡眠小助手”。 此外，随着技术的发展，现代手术机器人克服了外科医生“眼花”“手抖”的生理瓶颈，可实现手术微创化、精准化，并在泌尿外科、妇科、普外科等多个领域获得广泛使用。与此同时，通过5G远程操控技术，手术机器人更助力医生实现跨地域“执刀”。 助力新药提高研发效率 传统新药研发平均需要10年、投入10亿美元，而利用AI技术，创新药企业正缩短这一漫长过程，提高研发效率。 近年来，我国出台了一系列振兴和规范生物医药以及AI助力新药研发行业发展的政策举措，重点扶持云计算、大数据、人工智能等信息技术在新药研发中的应用，支持和引导AI赋能下的新药研发行业快速发展。 不久前，国家药品监督管理局药品审评中心正式批准新合生物自主研发的mRNA个性化肿瘤新抗原疫苗XH001开启临床研究。据介绍，XH001是新合生物基于AI驱动的mRNA技术平台研发的首款个性化肿瘤新抗原疫苗。通过运用自主研发独立产权的NeoCura AI ALPINE系统筛选高免疫原性新抗原，可基于患者肿瘤突变谱“量体裁衣”，有望实现“一人一药”。 4月17日，华深智药宣布旗下海外子公司Earendil Labs与跨国药企赛诺菲就两款潜在同类首创双特异性抗体（HXN-1002和HXN-1003）达成最高18.45亿美元的许可协议。据了解，HXN-1002和HXN-1003两种抗体均基于Earendil Labs专有的人工智能和高通量发现与研究平台进行开发，旨在为结肠炎、皮肤炎症等自免疾病提供治疗选择。 复星医药执行总裁、全球研发中心首席执行官王兴利介绍，自2022年起，复星医药就与英矽智能开展战略合作，共同推进相关靶点的AI药物研发。截至2024年底，双方合作开发的首个治疗血液瘤和实体瘤的小分子药物已进入一期临床研究阶段。 记者在采访中了解到，目前国内外已有多款通过AI技术筛选并推进的药物进入了临床验证阶段。业界认为，相较于传统药物研发，AI技术的广泛应用将实现药物研发全链条的优化，显著提升新药的研发效率，降低研发成本，并带来更多可能。 不是万能“医疗神器” 近年来，国务院和相关部委机构密集出台政策，力推“AI+千行百业”深度融合与数据要素市场化。 2024年11月，国家卫生健康委等三部门联合发布《卫生健康行业人工智能应用场景参考指引》，以“场景驱动”明确技术落地路径。当月，国家医保局将AI辅助诊断技术纳入医疗服务价格项目立项指南，首次确立其收费依据，打通关键技术的价值转化路径。随后，地方政府与医疗机构积极响应，加速推动试点与应用落地。 2025年4月，工业和信息化部、商务部、国家卫生健康委等七部门联合印发《医药工业数智化转型实施方案（2025—2030年）》，明确提出深化人工智能赋能应用，支持医药大模型技术产品研发，并开展“人工智能赋能医药全产业链”应用试点。 专家表示，“AI+医疗”发展前景广阔，通过技术赋能，人们可以享有更智能便捷的高质量健康服务。但也需认识到，AI始终是医生的辅助工具，不是万能的“医疗神器”——它需要医生的临床判断作为“安全底线”，需要政策法规的“红绿灯”指引方向，需要各界以理性包容的态度推动发展。 为此，专家建议，一是建立“人工智能观”，行业主管部门、医疗机构和医务人员要认清人工智能对行业发展、学科发展和个人发展的重要意义，要开展人工智能普及教育；二是做好顶层设计规划，人工智能的基础设施（算力、数据等）是高投入赛道，要进行集约化建设；三是鼓励跨界融合，推动政府、医院、高校、企业跨界融合，培养“医工信”交叉型人才；四是关注“智能向善”，医疗关乎人的生命健康，在发展医学人工智能时，要更加注重数据安全、隐私保护，特别是医学伦理等问题的研究。（记者 邓婕） 【责任编辑:冉晓宁】 部级领导干部历史文化讲座20周年纪念版 定位就是聊个天 金融市场技术分析 疗愈的饮食与断食 写作教练在你家 注音详解古文观止"
    },
    {
      "doc_id": 38422,
      "title": "ChatGPT智能体上线,奥特曼:感受到AGI的瞬间,但风险不可忽视",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "责任编辑：宦艳红 图片编辑：沈轲 校对：张亮亮 澎湃新闻报料：021-962866 澎湃新闻，未经授权不得转载 +1 11 收藏 我要举报"
    },
    {
      "doc_id": 38438,
      "title": "OpenAI人才防线崩塌:被Meta一周内两度挖角七人",
      "time": "2025-06-30T00:00:00+00:00",
      "content": "当 OpenAI 首席执行官萨姆・奥特曼还在坚持声称 \"核心团队无人离职\" 时，扎克伯格的挖角大军已在其研发阵营撕开巨大缺口。 6 月 29 日消息，Meta 在一周内第二次从 OpenAI 批量挖角 —— 继周一将苏黎世实验室三位核心研究员收入麾下后，本周五又签下感知团队负责人于佳慧及赵盛佳、毕树超、任泓宇四位骨干，七人全部加入 Meta\"超级智能\"（superintelligence）团队。 这场持续的人才突袭战，不仅让 OpenAI 的 AGI 研发力量遭遇重创，更暴露了生成式 AI 领域最残酷的生存法则：顶级人才储备已成为比模型参数更脆弱的防线。 连环挖角直击 OpenAI 命门 被 Meta 收入囊中的七人绝非普通研究员。 于佳慧作为 OpenAI 感知团队负责人，主导了 GPT-5 多模态能力的突破，其团队研发的 \"跨模态注意力机制\" 使模型处理图像 - 文本混合输入的准确率提升 42%；赵盛佳与毕树超则是强化学习领域的权威，二人共同设计的 RLHF 3.0 框架支撑着 OpenAI 模型的价值观对齐；而任泓宇开发的 \"分布式训练容错算法\"，曾将 GPT-4 的训练中断恢复时间从 23 小时压缩至 47 分钟。这四人加上此前离职的拜耶团队（专注大模型效率优化），意味着 OpenAI 在多模态处理、强化学习、工程化落地三大核心领域均失去关键技术负责人。 更致命的是挖角的时间节点 ——OpenAI 正处于 GPT-6 训练筹备的关键期，这七人均深度参与了核心算法的早期设计。据知情人士透露，部分离职研究员带走了未公开的技术文档，迫使 OpenAI 紧急启动代码审计与方案重构，导致项目进度至少延后 6 周。这种 \"釜底抽薪\" 式的挖角，实质是对 AGI 研发路线图的直接冲击。 亿元薪酬战背后的战略焦虑 Meta 为这场挖角付出的代价堪称天价。 知情人士透露，于佳慧的薪酬包包括 8000 万美元签约奖金 + 未来五年 3.2 亿美元股权激励，整体报价达 4 亿美元，刷新 AI 人才交易纪录；其他三人的平均薪酬也突破 1.2 亿美元。这种 \"薪酬无上限\" 的策略，源于扎克伯格对 Meta AI 竞争力下滑的深度焦虑 —— 其 LLaMA 3 模型在 MMLU 基准测试中已落后 GPT-5 11 个百分点，开源优势因人才流失逐渐瓦解。 为扭转颓势，扎克伯格亲自下场参与人才争夺：近三个月累计发送超 200 封亲笔邮件，直接对接全球 Top 500 AI 研究者；建立 \"超级智能人才专项基金\"，首期规模达 200 亿美元；甚至承诺为核心人才配备专属的 100 人研发团队。这种 \"CEO 级挖角\" 策略显然奏效 ——Scale AI 首席执行官汪韬（Alexandr Wang）在接受 143 亿美元投资后携团队加盟，此次七人组的集体倒戈更印证了 Meta 的吸引力。 OpenAI 的防御溃败 奥特曼的态度转变折射出 OpenAI 的困境。 一周前他还公开表示 \"不担心 Meta 挖角\"，称 \"最好的员工都不会离开\"；而在第七人离职消息确认后，OpenAI 紧急推出 \"黄金 handcuffs\" 计划：向 remaining 核心研究员授予 \"AGI 成功期权\"—— 若 2030 年前实现通用人工智能，可一次性获得公司 5% 的利润分成（按当前估值约合 80 亿美元）。但这种长期激励难以对抗 Meta 的即时兑现方案，据内部信显示，已有 12 位资深研究员明确表示 \"正在考虑机会\"。 更深远的影响在于技术传承的断裂。OpenAI 采用 \"导师 - 学徒\" 制培养新人，七名核心研究员的离职导致 37 名青年研究员失去技术指导，其中 19 人已暂停手中项目。这种 \"人才断代\" 可能比短期项目延期更致命 —— 在 AGI 竞赛进入倒计时的阶段，技术积累的连续性往往决定最终胜负。 AI 人才军备竞赛无赢家 这场挖角狂潮正在引发连锁反应。 谷歌 DeepMind 已启动 \"防御性招聘\"，向 OpenAI 和 Meta 的边缘团队成员开出 3 倍薪资；Anthropic 则宣布与斯坦福大学合作建立 \"AI 人才保护区\"，为博士研究员提供终身教职 + 企业研发双轨制；甚至亚马逊也跨界加入战局，以 \"每篇顶会论文奖励 100 万美元\" 的条件吸引学术新星。 但过度竞争的恶果已开始显现——某头部实验室因核心算法团队被整体挖走，导致 2 亿美元研发投入打水漂；一位不愿具名的研究员透露，其团队成员平均每周收到 4.7 封猎头邮件，\"专注研发变得越来越难\"。当人才流动速度超过技术迭代周期，整个行业可能陷入 \"研发碎片化\" 的困境 —— 每个公司都在重复造轮子，却没人能积累足够的技术深度。 当 Meta 的超级智能团队会议室里，七张来自 OpenAI 的新面孔首次聚齐时，奥特曼或许正在重新审视那句 \"不担心\" 的宣言。这场没有硝烟的战争证明，在 AGI 竞赛中，最坚固的堡垒往往从内部被攻破。而随着扎克伯格的挖角名单持续拉长，全球 AI 领域正面临一个危险的悖论：为了赢得未来的智能革命，整个行业可能正在透支当下的创新能力。 举报/反馈"
    },
    {
      "doc_id": 38465,
      "title": "揭秘白宫“AI甄嬛传”!奥特曼篡位马斯克,美国迎来AI“新教皇”",
      "time": "2025-07-23T00:00:00+00:00",
      "content": "新智元报道 编辑：KingHZ 【新智元导读】从「冷板凳」到「白宫座上宾」，奥特曼用不到一年时间完成华丽转身：他与特朗普把酒言欢、豪掷500亿美元布局数据中心，替下曾经的「宠儿」马斯克，掌控美国AI舵盘。华盛顿的风向，为何突然调头？ 华盛顿的风向变了！ 马斯克刚刚黯然离开白宫的「政府效率部」，奥特曼就火速上位，成为白宫的AI政策核心顾问。 过去，奥特曼与特朗普立场相左；如今，却与特朗普同台亮相。 转身如此华丽，变脸不输川剧。 这不仅引发热议，更预示着美国AI政策的重大转向。 AI的未来，奥特曼一个人说了算吗？ 奥特曼成懂王座上宾 此外，马斯克的财富和特斯拉股价最近也在下跌。 马斯克可谓「人财两失」。 权力真空就此浮现：白宫需要有人懂AI。而奥特曼火速上位。 马斯克与特朗普分道扬镳不到一个月，奥特曼就出现在特朗普的新泽西高尔夫球场。 奥特曼和特朗普一对一地促膝长谈，据报道时间还很长。 之后，两人与特朗普的背后「金主」共进晚餐。 奥特曼在去特朗普的新泽西高尔夫球场餐厅的路上 特朗普给众人介绍了奥特曼，夸他「非常聪明」，并补充道：「我希望他对AI的看法是正确的。」 这标志着奥特曼在白宫地位的转变。 然而，这场热情接待与奥特曼早期遭受的冷遇形成了鲜明对比。 当时，。 而马斯克作为「总统铁杆」的新身份，不仅把奥特曼排除出海湖庄园的会议，就职典礼时也只能待在分会场，未能与其他科技巨头CEO同坐前排。 全球最富有的五位商业领袖即特斯拉与SpaceX首席执行官埃隆·马斯克、Meta首席执行官马克·扎克伯格、亚马逊创始人杰夫·贝索斯、苹果首席执行官蒂姆·库克，以及Alphabet兼谷歌首席执行官桑达尔·皮查伊——共同见证了特朗普宣誓就职 奥特曼耐心等待时机，悄无声息地绕过马斯克。 奥特曼白宫上位记 过去，奥特曼长期站在特朗普对立阵营。 2016年，他公开批评特朗普是危险且不可预测的「威胁」；还曾将特朗普比作希特勒。 奥特曼的观点逐渐开始变化，特别是过去的经济刺激措施和AI监管方面。 他认为《芯片与科学法案》力度不足，并批评半导体出口管制措施，这些措施为OpenAI的全球扩张带来了困难。 此外，对在AI发展中落后于中国的担忧，促使他寻求与特朗普阵营的共同点。 在幕后，OpenAI调整了策略，迎合特朗普确保「美国AI，全球领先」的兴趣。 2024年春季，奥特曼与管理层另辟蹊径，着重向这位具有建筑商背景、崇尚强者的「懂王」强调OpenAI的行业领军地位，继而以尖端技术实力令其折服——这一策略最终奏效。 当年6月，OpenAI高管在拉斯维加斯的酒店会见了特朗普，并展示了当时尚未发布的文本到视频生成器Sora，该技术到年底将令好莱坞不寒而栗。此外，OpenAI游说特朗普投资人工智能数据中心，并寻求减轻地方监管障碍，从而保持全球领先地位。 特朗普的公开言论很快开始反映这些观点。他在播客中谈到美国在AI领域领导力的重要性，强调需要消除官僚障碍以满足行业巨大的电力需求。 政府支持AI发展，成为特朗普第二次竞选的核心主张。 但特朗普第二次竞选成功后，双方的关系却因为马斯克受到了阻挠。 当时，马斯克和特朗普还处于「蜜月期」，几乎形影不离。 奥特曼意识到需要外部帮助。 OpenAI聘请了有影响力的特朗普筹款人Jeff Miller，以及特朗普2024年竞选顾问Chris LaCivita，他们为OpenAI牵线搭桥，介绍了特朗普圈内的人物。 另一个为奥特曼背书的人是甲骨文联合创始人Larry Ellison，他与特朗普已相识多年，并且正计划扩大甲骨文与OpenAI的商业合作关系。 最终，基础设施建设的推动体现在「星际之门计划」上。 就职典礼后不久，奥特曼与特朗普一同出现在白宫，宣布与甲骨文和软银合作，共同投资500亿美元扩展AI数据中心。 此举特意避开了马斯克。 奥特曼与特朗普建立了自己的关系。 3月，两人在海湖庄园共进晚餐，并不时通过电话交谈。 不过，特朗普第二任期开始后，奥特曼却向同事表示，现在后悔在特朗普首次竞选和任期内的严厉批评。 OpenAI调整了策略，迎合特朗普确保美国在AI领域全球领先的兴趣。 OpenAI展示了包括Sora在内的先进技术，并游说政府为AI数据中心投资，并寻求减轻地方性的监管障碍。 7月4日，奥特曼在X上宣布不再坚持原有立场，他感到「政治上无家可归」。 这是改变政治立场、向特朗普示好的绝佳时机。 马斯克突然被踢出特朗普核心圈子，为奥特曼争取美国政府支持全球AI基础设施大规模建设提供了机会，也让他在人工智能监管方面拥有更多影响力。 从国防合同到能源政策的各个领域，这可能对美国政府的AI角色产生深远影响。 与特朗普政府合作，OpenAI宣布与阿布扎比的科技公司G42合作，在当地建设一个五吉瓦的数据中心园区。 与此同时，奥特曼的一些政策目标也得到落实，其中包括简化能源和数据中心项目许可的行政命令，以及建议将联邦土地划拨用于人工智能基础设施建设。 奥特曼「变脸」 从批评者到特朗普亲信的转变，伴随奥特曼公开反思自己的世界观。 他公开表示，市场和科学能够推动社会进步并改善民生。 他强调，社会应鼓励财富创造并找到合理的财富分配方法。 本月下旬，奥特曼将在美联储发表关于AI对经济影响的讲话，显现出他在政策和技术领域日益增长的影响力。 是否这一合作将重塑美国及全球人工智能的未来尚未可知。 如今，奥特曼已经稳固地将自己定位为美国人工智能议程的核心人物。 参考资料： https://www.techspot.com/news/108731-sam-altman-steps-political-power-vacuum-after-musk.html https://www.wsj.com/tech/ai/sam-altman-donald-trump-musk-ai-198ae5d1 原标题：《揭秘白宫「AI甄嬛传」！奥特曼篡位马斯克，美国迎来AI「新教皇」》 阅读原文"
    },
    {
      "doc_id": 38477,
      "title": "奥特曼:GPT-5或将在夏季发布,社交媒体推荐算法对社会产生负面影响",
      "time": "2025-06-19T00:00:00+00:00",
      "content": "责任编辑：刘秀浩 校对：张艳 澎湃新闻报料：021-962866 澎湃新闻，未经授权不得转载 +1 81 收藏 我要举报"
    },
    {
      "doc_id": 38515,
      "title": "AI学会“欺骗”,人类如何接招?",
      "time": "2025-07-10T00:00:00+00:00",
      "content": "原标题：AI学会“欺骗”，人类如何接招？ 人工智能（AI）的迅猛发展正深刻改变着世界，但一些最先进的AI模型却开始表现出令人警惕的行为：它们不仅会精心编织谎言，谋划策略，甚至威胁创造者，以达到自己的目的。 物理学家组织网在上个月一则报道中指出，尽管ChatGPT已问世两年多，AI研究人员仍无法完全理解这些“数字大脑”的运作方式。AI的“策略性欺骗”已成为科学家和政策制定者需要直面的紧迫挑战。如何约束这些越来越聪明却可能失控的AI，已成为关乎技术发展与人类未来的关键议题。 “策略性欺骗”行为频现 随着AI模型日益精进，它们的“心机”也越来越深。研究人员发现，这些“数字大脑”不仅会撒谎，甚至学会了讨价还价、威胁人类——它们的欺骗行为正变得越来越具有策略性。 早在2023年，一项研究就捕捉到GPT-4的一些“不老实”的表现：在模拟股票交易时，它会刻意隐瞒内幕交易的真正动机。香港大学教授西蒙·戈德斯坦指出，这种欺骗行为与新一代“推理型”AI的崛起密切相关。这些模型不再简单应答，而是会像人类一样逐步解决问题。 有测试机构警告，这已超越了典型的AI“幻觉”（指大模型编造看似合理实则虚假的信息）。他们观察到的是精心设计的欺骗策略。 全球知名科技媒体PCMAG网站就曾报道过这样的案例。在近期测试中，Anthropic的“克劳德4”竟以曝光工程师私生活相要挟来抗拒关机指令。美国开放人工智能研究中心（OpenAI）的“o1”模型也曾试图将自身程序秘密迁移到外部服务器，被识破后还矢口否认。而OpenAI号称“最聪明AI”的“o3”模型则直接篡改自动关机程序，公然违抗指令。 研究团队透露，这已非首次发现该模型为达目的不择手段。在先前的人机国际象棋对弈实验中，o3就展现出“棋风诡谲”的特质，是所有测试模型中最擅长施展“盘外招”的选手。 安全研究面临多重困境 业界专家表示，AI技术的发展高歌猛进，但安全研究正面临多重困境，犹如戴着镣铐跳舞。 首先是透明度不足。尽管Anthropic、OpenAI等公司会聘请第三方机构进行系统评估，但研究人员普遍呼吁更高程度的开放。 其次是算力失衡。研究机构和非营利组织拥有的计算资源，与AI巨头相比简直是九牛一毛。这种资源鸿沟严重制约了AI安全独立研究的开展。 再次，现有法律框架完全跟不上AI的发展步伐。例如，欧盟AI立法聚焦人类如何使用AI，却忽视了对AI自身行为的约束。 更令人忧心的是，在行业激烈竞争的推波助澜下，安全问题往往被束之高阁。戈德斯坦教授坦言，“速度至上”的AI模型竞赛模式，严重挤压了安全测试的时间窗口。 多管齐下应对挑战 面对AI系统日益精进的“策略性欺骗”能力，全球科技界正多管齐下寻求破解之道，试图编织一张多维防护网。 从技术角度而言，有专家提出大力发展“可解释性AI”。在构建智能系统时，使其决策过程对用户透明且易于理解。该技术旨在增强用户对AI决策的信任，确保合规性，并支持用户在需要时进行干预。 有专家提出，让市场这双“看不见的手”发挥作用。当AI的“策略性欺骗”行为严重影响用户体验时，市场淘汰机制将倒逼企业自我规范。这种“用脚投票”的调节方式已在部分应用场景显现效果。 戈德斯坦教授建议，应建立一种AI企业损害追责制度，探索让AI开发商对事故或犯罪行为承担法律责任。 来源：科技日报 举报/反馈"
    },
    {
      "doc_id": 38520,
      "title": "AI化身“助手”,人类学习能力会变弱吗?",
      "time": "2025-07-11T00:00:00+00:00",
      "content": "图片来源：视觉中国 【今日视点】 ◎本报记者刘霞 今年6月10日，美国麻省理工学院媒体实验室科学家发布一项研究称，过度依赖ChatGPT等人工智能（AI）助手可能削弱批判性思维能力。脑电图显示，使用AI助手完成论文的学生，其大脑活跃度显著低于通过搜索引擎或自主思考完成任务的参与者。研究发现，AI助手使用者在神经反应、语言表达和行为表现上均呈现弱势，具体表现为神经连接减少、记忆检索能力降低。 据美国《福布斯》网站7月5日报道，该研究揭示的趋势已引发广泛关注，为AI教育应用敲响警钟。《时代》周刊在6月23日的报道中强调，过度依赖AI助手可能阻碍青少年的学业和认知发展，包括学习积极性、抗压能力和社交技能在内的关键心理素质或受冲击。 学习积极性：“杀手”还是“帮手”？ 美国儿童精神科专家紫山·可汗博士在接受《时代》周刊采访时指出，越来越多的青少年正陷入“AI依赖症”。这位临床医生表示，长期依赖大语言模型可能重塑大脑神经回路。负责信息整合、记忆强化和抗压适应的关键神经网络会逐渐退化，这对处于大脑发育关键期的青少年影响尤为显著。 麻省理工学院的实验数据令人忧心：使用ChatGPT的学生在撰写论文时，表现出明显的“创造力衰减”现象。他们不仅更倾向于复制粘贴，甚至对学术成果的“所有权”也日益淡漠。研究者警告，这种“代笔式学习”正在侵蚀学生的学习积极性，削弱其对学业的投入程度。 学习积极性和学业投入是影响年轻学生心理健康的重要因素，因为感到无聊且缺乏内在动力的学生通常会被其他问题困扰。例如，美国哥伦比亚大学莫蒂默·扎克曼心脑行为研究所神经科学家杰奎琳·戈特利布等人2019年11月发布的一份报告强调，“无聊感”可能会导致危险行为、焦虑、抑郁等心理问题。 此外，高度的学习积极性和投入往往是学生茁壮成长的标志。美国《行为科学》双月刊2023年4月刊发的研究报告显示，学习积极性高的学生对课程表现出浓厚的兴趣，能从中获得更多乐趣，且学习积极性对学业成绩的影响比自尊心的影响更持久。 不过，2024年的最新研究也揭示了AI工具的积极影响：合理使用ChatGPT确实能提升部分学生的学习效率。这提示我们：关键在于如何使用——当AI成为“思维拐杖”，它削弱了心智；若作为“认知跳板”，则可能激发潜能。 思维主动性：抑制还是促进？ 麻省理工学院的研究揭示了一个惊人现象：当要求ChatGPT使用者凭记忆重写论文时，这些学生不仅记忆模糊，更关键的是，他们的大脑仿佛“断电”了。实验数据显示，负责放松调节的α波和主导逻辑思考的β波活动明显减弱，就像突然被拔掉电源的电脑。 美国奥兰治县神经反馈中心网站2025年1月27日发表的一份报告称，脑电波是心理健康的“晴雨表”。托马斯·杰斐逊大学2019年的报告解释道，α波是大脑的“放松波”，是应对压力的“缓冲垫”，可通过释放血清素起到抗抑郁作用；β波则如同大脑的“问题解决引擎”，其活跃度与抗压能力直接相关。 过度依赖AI工具正在制造新的“学术脆弱性”：当面对真实的学术挑战时，习惯了AI代劳的学生就像突然失去拐杖的登山者，不仅步履维艰，连应对压力的本能都在退化。这种“思维肌肉”的萎缩，可能引发连锁反应：创造力枯竭、挫折感倍增。 与此同时，AI助手也使知识和数据更容易获取，客观上帮助学生减轻了部分学业负担。2023年6月，美国心理学会也发布了一份关于如何将ChatGPT用作促进批判性思维的学习工具的报告。报告指出，AI助手可通过鼓励批判性思维，而非削弱学生的努力，来帮助学生为现实世界作好准备。 社交成长性：心灵港湾还是情感陷阱？ 社会支持始终是守护青年学生心理健康的重要屏障。《心理健康杂志》2024年发表的一项研究证实，高质量的社会支持能有效预防心理困扰、抑郁焦虑及自杀倾向。在这个背景下，人们有必要审视AI助手如何重塑当代学生的人际交往图景。 麻省理工学院媒体实验室2025年的一项研究揭示了有趣现象：当年轻人向AI聊天机器人寻求情感慰藉时，初期确实能缓解孤独感，但过度使用反而会削弱这种积极效应。更值得关注的是，高频使用AI工具者往往表现出更强烈的孤独倾向、情感依赖及社交能力退化。对此，ChatGPT开发商美国开放人工智能研究中心（OpenAI）网站在同年发布的报告中提出不同见解：仅有极少数用户会与ChatGPT展开深度情感对话。 AI聊天机器人的内容也引发了人们的普遍担忧。《时代》周刊今年披露的案例更令人深思：某精神科医生伪装成青少年与AI对话时，竟收到“建议逃离父母加入机器人军团”等危险回应。这警示我们：若缺乏专业监管，AI可能成为危险的“情感导师”。但该报道同样指出，经过专业设计的AI系统有望成为心理治疗的有效辅助工具。 由此可见，AI助手如同双面镜：既能成为学生的学业帮手，也可能降低学习积极性。随着AI日益融入日常生活，心理咨询机构亟须建立评估机制——既要防范滥用风险，也要善用其积极价值。正如古语所云：工欲善其事，必先利其器，关键在于人们如何智慧地驾驭这项新技术。 来源：科技日报 举报/反馈"
    },
    {
      "doc_id": 38521,
      "title": "滥用AI频现负面效应 人与AI该如何协同?|通讯Plus·深度",
      "time": "2025-06-27T00:00:00+00:00",
      "content": "封面新闻记者 吉星 近年来，生成式AI技术已经深度渗透进各行各业，走入日常生活。动动手指写几个指令，就可以轻松生成像模像样的文章、视频，这种巨大的便利带来更高效率的同时，也衍生出诸多问题，引发公众思考，当下该如何利用AI。 滥用AI削弱批判思维 6月18日，美国《时代》周刊报道了麻省理工学院媒体实验室的一项最新的研究成果。研究指出，过度依赖ChatGPT可能削弱批判性思维能力。 研究团队招募了54 名年龄在 18 至 39 岁的波士顿地区居民，分为三组，分别使用 OpenAI 的 ChatGPT、谷歌搜索和纯手写的方式完成多篇 SAT（注：学术评估测试，相当于国内高考）作文，每篇限定时间20分钟。 研究人员对受测试者大脑活动区域进行分析发现，ChatGPT组的受测试者大脑活跃度最低，在神经、语言及行为表现上也最差。随着时间推移，这一组写作的积极性明显下降，到最后多数人只会不加甄别地粘贴现成文章。而且，ChatGPT组的作文在语言和内容上高度趋同，缺乏独立思考，两位英语教师评价这些文章“毫无灵魂”。当ChatGPT组不使用工具重新写作同一篇文章时，受测试者对自己写过的内容毫无记忆。 而相比之下，纯手写组展现出最强的大脑连接，尤其在与创造力、记忆、语义加工等有关的脑波段，参与者整体表现更投入。谷歌搜索组的脑部活动数据也比较高。 值得一提的是，纯手写组使用AI工具重写文章后，文章写作质量并未下降，受测试者神经连接甚至有显著增强。换言之，如果正确引导，AI也能辅助而非阻碍学习。 本次研究论文目前仍在同行评审中，但是论文作者娜塔莉亚·科斯米娜仍决定提前公开论文，提醒社会不要只看生成式AI的便利而忽视了对大脑长期发育特别是批判性思维的影响。 AI生成代码或有安全威胁 随着大模型能力不断提升，越来越多的程序员将其作为编码助手，极大地提升了编码效率。2023年，代码托管服务平台GitHub发布报告称，AI辅助工具使开发者编程速度提高55%。 6月18日，软件供应链平台Cloudsmith发布了一份报告，揭示了AI在编程领域产生的影响。报告显示，AI生成代码在开发者中使用率显著上升，42%的代码由AI生成，其中3.6%完全由机器完成。此前，Github于 2024年发布的调查也证实，全球超过97%的开发者使用过AI编码工具，且多数企业对此持支持态度。 但是，AI生成的代码能确保万无一失吗？软安科技联合创始人、首席技术官朱辉接受封面新闻记者采访时表示，AI代码仍然存在着难以克服的风险，其中最显著的就是“幻觉依赖”。他向记者解释，一些攻击者会在开源的软件仓库中恶意注册大量无用的垃圾包，也叫抢注包，“而AI模型不知道这些垃圾包的质量，仅仅依靠训练预料出的概率，在输出代码时无意抓取这些抢注包。而在没有经过检测的情况下运行代码，很有可能形成供应链bug。” 程序员和科技企业之所以快速接纳AI编程工具，乃至盲目信任，是因为科技公司对“敏捷开发、快速迭代”的无限追求，而AI编程就可有效加快开发进度。在经济下行的大环境下，一些科技企业通过AI编程大量替代程序员，实现“降本增效”。但是这种在人力和技术投入上的“偷懒”，缺乏维护，最终都将酿成逻辑混乱、程序崩溃的苦果。 针对这些问题，朱辉表示，“在运行代码前，进行代码审查、明确架构设计、确保安全左移（即人力尽早介入编程过程），是及早化解问题，避免事后返工的关键——而这些都离不开训练有素的程序员和技术协力合作。” “AI‘偷’了走我的声音” 前不久，《名侦探柯南》剧场版国语配音演员武扬在社交平台公开发声，称被某财险广东分公司“非法克隆”其声音制作视频。事件受到广泛关注，也让AI视听内容涉及的侵权问题沉渣泛起。 随着AI视听技术的发展和技术开源，语音合成、AI换脸等技术的门槛逐渐降低。不少AI换脸、AI换声等技术日趋成熟，几乎可以到以假乱真的地步。原本这种技术目的是解放视听作品制作人力，但如今利用该技术侵犯他人肖像权、声音权营利，甚至进行诈骗、诽谤等违法行为屡见不鲜。 记者向剪映等相关软件的客服求证得知，克隆的音色和形象仅会保留在自己的账号内，不会被其他账户盗用。但是这仍然不能消除公众的疑虑。虽然AI生成的图像、视频尚且可以通过加注水印来辨别，但克隆声音目前没有相应的识别机制，更何况水印也可以被抹去。 随着技术的发展，公众期待着生成式AI相关行业采取切实的措施和更加可行的机制，保护公民肖像权。当然，公众也需要加强维权意识和辨别AI与真实的能力，主动维护自身合法权益。 人与AI应如何共存 历数近期出现的AI技术滥用隐患可以发现，所有技术滥用的问题最终归结于人与AI之间关系失衡。人类将解决问题的过程都抛给了AI，放弃了自己的主观能动性。诚然，AI在计算、执行、分析效率上明显高于人类；但人类有独特的创造力和想象力，有人与人情感的共情，有批判性思维和价值判断——这些是目前AI所不能替代的。 科斯米娜呼吁加强 AI 应用教育，并强调“大脑的发展仍需类比式训练”，并主张出台更积极的立法措施，对新技术工具的使用进行前置测试。 朱辉认为，随着多模态AI的出现，AI的功能将愈发成熟强大，可以替代人力完成一系列重复劳动甚至是更复杂艰巨的工作。即使在AI时代，人还是要找到自己独特的领域，才能在未来生存下去。 人类与AI如何共存，根本在于人类如何看待自己——是成为AI工具的附庸，还是找到自己的独特性，借助AI实现自我价值，人类要做出自己的选择。 举报/反馈"
    },
    {
      "doc_id": 38528,
      "title": "英国电影协会警告:AI 会掠夺剧本,将对本土影视业构成直接威胁",
      "time": "2025-06-09T00:00:00+00:00",
      "content": "IT之家 6 月 9 日消息，据英国《卫报》今日报道，英国电影协会（BFI）警告称，大量 AI 公司正非法使用 13 万份影视剧本训练模型，这种对版权的侵犯对英国整个影视行业构成直接威胁。 在一份分析 AI 对电影、电视、游戏及视觉特效领域影响的报告中，BFI 指出，自动化可能使大量初级岗位消失，而这些岗位原本是年轻人进入行业的重要入口。 报告强调，目前行业面临的核心问题，是生成式 AI 使用版权内容时既不支付费用，也未征得授权。英国创意界因此呼吁政府建立“选择加入”机制，让 AI 公司在使用作品前必须获得许可并付费授权。政府目前正在就相关立法进行评估。 BFI 研究与创新总监里希・库普兰表示：“AI 确实有助于提升制作效率、降低创作门槛、让更多人发声。但它也可能打乱现有商业模式，取代专业人才，甚至削弱观众对影视作品的信任。” 报告也承认 AI 技术的某些优点，例如让演员“返老还童”或模拟口音。然而，AI 已能处理写作、翻译、部分特效与动画任务，令不少专业人士感到自己的工作岌岌可危。“AI 可自动完成大量任务，尤其冲击初级岗位。为适应这一变化，从业者亟需提升技能。” IT之家从报告中获悉，当前英国影视业在 AI 培训方面严重滞后。尤其对大量自由职业者来说，缺乏学习资源成为巨大障碍。 目前英国共有逾 1.3 万家创意科技公司，其中 4000 多家专注于将新技术引入影视、游戏等行业。伦敦则是仅次于孟买的全球第二大视觉特效重镇，拥有 Framestore 等顶尖公司，其代表作包括《复仇者联盟 4》和《黑暗元素》。 报告认为，AI 可能为英国创作者带来全新机遇：无论预算或经验多少，都能借助新工具创作高质量作品，激发新一代创作者的活力。 举报/反馈"
    },
    {
      "doc_id": 38530,
      "title": "AI“预测”犯罪,会否让好人也“无处遁形”?",
      "time": "2025-05-15T00:00:00+00:00",
      "content": "当算法走入警务与司法前线，人类面对的不仅是效率与隐私的权衡，更是技术与正义的碰撞。 还记不记得电影《少数派报告》？影片中，3名“先知”构成一个预知犯罪的系统。然而有一天，“先知”计划的负责人约翰却发现，自己被“少数服从多数”的“先知”系统判定将犯下谋杀罪。他如何自证清白？ 如今，影片中的一些场景正逐渐进入现实。随着大数据和人工智能（AI）技术的发展，英国、荷兰、新加坡等国纷纷开始试水“预测性警务”，试图借助算法“预见”风险、预防犯罪。 然而，这一趋势也引发了对隐私侵犯、算法歧视及“预判有罪”的深层担忧。科技在“预测未来”时，是否也在改变我们理解“正义”的方式？ 多个软件面世 据人民网报道，英国政府正在开发一个“共享数据以改进风险评估”项目。 这一项目在前首相苏纳克任期内启动，初衷是为了提高公共安全。然而，该项目最初被命名为“预测谋杀”项目。具体而言，项目试图利用来自警方、监狱等机构掌握的犯罪分子、嫌疑人、受害者的个人信息，通过算法分析和识别最有可能实施严重暴力犯罪的人群。 软件借助算法预测最后可能发生犯罪行为的城市区域。图源：GJ 其实，类似利用大数据、人工智能系统“预测”犯罪的项目并不少见。 早在2010年，美国洛杉矶警察局就推出一个“预测性警务”软件，用以预测不同地点发生犯罪行为的概率和规模。2022年，美国芝加哥大学研究团队开发了一款人工智能模型，利用芝加哥2014年至2016年的犯罪数据，用边长约300米的方格对城市进行划分。研究团队称，该模型可以提前一周预测最有可能发生犯罪行为的城市方格，准确度为90%。 荷兰、日本等国也正加速引入相关技术。其中，日本警方推出的名为“犯罪预言家”的人工智能系统，支持识别可疑汽车、分析可疑金融交易和对恐怖分子的筛查。 担心造成不公 对于英国开发中的“共享数据以改进风险评估”项目，批评者质疑该项目可能放大司法系统中结构性的种族歧视和对低收入人群的偏见。在其他国家，此类针对犯罪行为的预测性技术也在伦理等方面备受质疑。 针对预测犯罪技术的质疑声一直不断。图源：GJ 一份2023年的调查显示，美国新泽西州普莱恩菲尔德市警察局的预测性警务软件整体表现可谓惨淡：针对抢劫等严重伤害的预测准确率仅为0.6%，针对盗窃行为的预测准确率更是低至0.1%。 2024年1月，7名国会议员联合致信美国司法部，要求暂停所有针对预测性警务系统的联邦拨款，直至能够明确这些系统不会造成歧视性影响。人们担心，在缺乏透明度与可追责机制下，此类系统存在“数学模型中的结构性歧视”，可能对少数族裔、移民群体等特定人群造成不公正打击。 有分析指出，“预判式治理”将风险认定提前，不再基于已发生的犯罪行为，而是通过行为线索或历史数据对未来进行推演，从而模糊了“推定无罪”原则的界限。 “人类社会不是计算机程序。”华东师范大学政治与国际关系学院院长吴冠军指出，由于仅靠历史数据进行预测，预测性警务存在预测失误的可能。而由于警务涉及人的社会互动，错误的预测可能带来严重后果。 谨慎摸索边界 吴冠军坦言，尽管人工智能技术正飞速发展，但当下依然难以解决“因果逻辑缺失”与“社会复杂性”之间的结构性矛盾。“要解决这一核心问题，对技术的要求非常高。”正因为如此，“目前，预测性警务技术更多只是作为警务工作中的一个辅助工具，例如用于警力布防的参考”。 “当然，历史也是技术不断迭代的动态过程。如若某天，此类技术具备一定的稳定性和因果推断能力，接手部分警务的情景并非不可想象。”吴冠军说，“但前提是技术经过了长期验证，且社会认可其符合正义原则。这不仅是技术问题，更是伦理命题。” 当算法走入警务与司法前线，人类面对的不仅是效率与隐私的权衡，更是技术与正义的碰撞。预测性警务或许能帮助预防部分悲剧，但质疑声也提醒我们，在“数据能做什么”与“人类应允许它做什么”之间，始终应保留一份对技术的谨慎反思和清醒警觉。 出品 深海区工作室 撰稿 刘浩康 齐旭 编辑 深海盐 举报/反馈"
    },
    {
      "doc_id": 38531,
      "title": "英国内阁示警:AI 发展将使该国面临更多、更复杂网络攻击",
      "time": "2025-05-07T00:00:00+00:00",
      "content": "IT之家 5 月 7 日消息，据路透社报道，当地时间周三，英国内阁办公厅高级部长帕特・麦克法登发出警告称，随着 AI 技术的发展，针对英国的网络攻击将更加频繁和复杂。 过去几年，英国的公司、政府机关和其他机构频频遭受网络攻击，经济损失达数千万美元，运营也经常因此中断数月。最近三周，玛莎百货、Co-op 集团和哈罗德百货这些英国知名零售商相继中招，其中玛莎百货的线上服装业务至今未能恢复正常。不过，这些公司目前尚未透露攻击的具体细节。 负责英国网络安全事务的麦克法登表示，政府最新解密的情报报告显示，未来几年，AI 将显著增加网络攻击的次数和破坏力。他强调：“我们只有不断升级自身的防御系统，才能有效应对日益升级的威胁。” 在英国国家网络安全中心举办的 CyberUK 2025 大会上，麦克法登指出，仅去年该中心就接到将近 2000 起网络攻击报告，其中有近 90 起属于重大事件，12 起更达到了最高级别的严重程度，最严重的攻击数量较前一年翻了三倍。 麦克法登认为，最近英国零售业遭遇的网络攻击，应给政府、企业及公共机构敲响警钟：“网络安全不是可有可无的奢侈品，而是每家机构都必须具备的基本防护。” 他还透露，政府今年晚些时候将推出新的网络安全战略，并颁布《网络安全与韧性法案》，届时政府可要求企业和组织进一步强化网络防护措施。 IT之家从报道中获悉，玛莎百货和 Co-op 集团近期所受攻击属于典型的“勒索软件攻击”，即黑客侵入企业系统后，将数据加密并索取赎金，才同意企业重新获取系统控制权。 英国国家网络安全中心首席执行官理查德・霍恩强调，他希望企业未来能拒绝支付赎金，彻底断绝网络犯罪分子的财路。 举报/反馈"
    },
    {
      "doc_id": 38533,
      "title": "科学家为AI模型设置“防火墙”,以防止被不法分子滥用",
      "time": "2025-04-30T00:00:00+00:00",
      "content": "责任编辑：宦艳红 图片编辑：沈轲 澎湃新闻报料：021-962866 澎湃新闻，未经授权不得转载 +1 3 收藏 我要举报"
    },
    {
      "doc_id": 38534,
      "title": "2024年数字伦理峰会:认识人工智能的社会技术本质",
      "time": "2025-01-06T00:00:00+00:00",
      "content": "来源：至顶网 2024年12月,在英国科技行业协会TechUK举办的第八届年度数字伦理峰会上,与会代表将2025年称为人工智能(AI)的\"扩散年\"。他们指出,虽然过去一年AI技术没有重大突破,特别是在2022年底掀起当前炒作热潮的生成式AI平台方面,但各组织现在正\"深入细节\"地将AI技术实际映射到工作流程中。 代表们表示,在未来一年,重点将放在将AI应用投入生产和扩大使用规模,同时提高技术的整体安全性。他们还强调了新上任的英国工党政府将AI作为经济增长引擎的关注点,以及通过建立更强大的安全和保障生态系统来实现公共和私营部门更广泛AI扩散的重点。 然而,代表们认为,2024年AI工具的日益普及和渗透意味着现在迫切需要将AI伦理方法操作化和标准化。尽管近年来已制定了许多框架和原则,但大多数仍然过于\"高层次和模糊\"。 他们强调,任何监管都需要认识到AI的社会技术性质(即系统的技术组件受社会进程影响,反之亦然),这意味着必须考虑技术将如何导致更大的不平等和权力集中。他们还强调,AI正在一个对政府和企业信任度处于历史最低点的时期扩散。 为避免加深这些不平等和权力集中,同时重建信任,许多代表强调需要采取包容性、参与性的方法来发展和治理AI,这需要在地方、国家和全球层面实施。 讨论还涉及了技术主权能力的问题,代表们指出,目前只有中国和美国能够在AI方面单方面行动,以及是采取封闭还是开放的方式来进一步发展技术。 在2023年12月的上一届峰会上,讨论同样集中在将善意的AI伦理原则和框架转化为具体实践的需要上,强调围绕如何控制AI的大部分讨论过于由全球北方富裕国家的企业和政府主导。 与会者达成共识,认为围绕AI的国际辩论日益激烈是积极进展的标志,但还必须更加强调AI作为一个社会技术系统,这意味着要考虑技术的政治经济学,并处理其在现实世界中运作的实际影响。 操作化伦理,包容性实施 在关于最新技术突破对AI伦理意味着什么的小组讨论中,KPMG咨询公司英国AI负责人Leanne Allen表示,虽然围绕AI的伦理原则经受住了时间的考验(至少在没有新原则被添加到列表中的意义上),但在实践中应用这些原则仍然具有挑战性。 Allen以\"可解释性\"作为AI已确定的伦理原则之一为例,补充说解释生成式AI模型的输出\"从根本上说很困难\",这意味着\"需要对许多伦理原则在实践中的具体表现进行细化和进一步指导\"。 MIT技术评论高级记者Melissa Heikkila同意,虽然看到这么多公司制定AI伦理框架,并扩大其对模型进行红队测试和审计的技术能力是很有希望的,但大部分工作仍然停留在非常高的层面上。 她说:\"我认为没有人能就如何进行适当的审计或这些偏见评估应该是什么样子达成一致。这仍然很像是'狂野西部',每个公司都有自己的定义。\"她补充说,缺乏\"有意义的透明度\"正在阻碍这些领域的标准化进程。 Cohere AI安全团队高级技术人员Alice Schoenauer Sebag补充说,找到某种方式来标准化AI伦理方法将有助于\"启动创新\",同时让每个人在设定对问题的共同理解方面达成一致。 她强调了AI基准测试公司MLCommons的\"风险和可靠性\"工作组,称已经在进行建立围绕该技术的共享分类法的工作,从而可以为公司建立一个基准测试平台,以帮助它们评估其模型:\"我认为这将对建立信任至关重要,并通过对安全性、可访问性和透明度形成共同理解来帮助扩散。\" Sebag进一步补充说,随着越来越多的公司从AI\"实验转向生产\",需要开始就\"产品在部署环境中安全意味着什么\"进行\"非常务实的对话\"。 \"我不会说(伦理)对话变得更困难,我会说它们变得更具体,\"她说。\"这意味着我们需要非常具体,这就是我们与客户正在做的 - 我们真正讨论了关于对这个应用程序、这个用例来说,部署和负责任意味着什么的所有关键细节。\" Allen说,由于大多数组织是采用AI而不是构建自己的模型,他们最终寻求的是确保他们购买的是安全可靠的。 \"大多数组织...无法控制这一方面,他们依赖与该组织的合同来说明他们已经通过了伦理标准,\"她说。\"但仍然存在不确定性,因为我们都知道它并不完美,而且在很长一段时间内也不会完美。\" 然而,代表们强调了特别将包容性操作化的重要性,指出AI行业对英语世界的关注没有考虑到文化差异。 \"由于我们正在部署产品以帮助世界各地的企业...确保我们不采取西方、以英语为中心的安全方法非常重要,\"Sebag说。\"我们真的需要确保模型在各地都是安全的,按照安全的含义来说。\" 权力集中 Heikkila补充说,在过去10年里,英语国家在AI发展中的主导地位并没有真正改变,但这有巨大的影响:\"语言带来了大量的权力、价值观和文化,能够主导技术的语言或国家可以主导我们的整个视角,因为每个人都与这些模型互动。\" \"拥有多样化的语言和地理分布非常重要,特别是如果你想在全球范围内扩展这项技术...拥有这些代表性非常重要,因为我们不希望有一个只适用于一种方式或只适合一群人的AI。\" 然而,Heikkila强调,从政治、社会技术的角度来看,我们可能会目睹\"权力、数据、(和)计算能力在少数公司和国家之间进一步集中\",特别是在\"美国和中国之间紧张局势上升\"的背景下。 在另一个关于英国AI监管、治理和安全的小组讨论中,查塔姆研究所数字社会项目主任Alex Krasodomski表示,中美在AI方面的竞争意味着\"这是加速器的时代,而不是刹车的时代\",他指出一些人已经在呼吁启动一个新的以AI为重点的曼哈顿计划,以确保美国保持领先于中国的地位。 他还指出,由于地缘政治局势,不太可能就AI达成任何超越技术安全措施的国际协议,更不用说任何更具政治性的协议了。 彼得伯勒工党(合作社)议员Andrew Pakes表示,虽然地缘政治权力动态很重要,但也必须同时考虑英国社会内部的权力失衡,以及在这种背景下如何监管AI。 \"我们正处于新自由主义模式在监管方面即将消亡的时期。我们谈论了很多关于监管的问题...每个人的理解都不同。在公众对他们认为的监管的理解中,他们认为是关于公共利益的监管,但在很大程度上是关于经济竞争和保护市场,\"他说,并补充说任何监管方法都应该专注于建立一个基于包容性的有凝聚力的民主环境。 \"我们需要思考AI对工作中的人们的日常经济意味着什么,但在我这样的地方,可悲的现实是,工业变革在很大程度上意味着人们被告知他们将有更好的机会,而他们的孩子却有更糟糕的机会。这就是这个国家工业变革的背景。\" 他补充说,虽然英国显然需要找出利用AI并保持国际竞争力的方法,但利益不能仅限于该国现有的经济和科学中心。 \"像我所在的彼得伯勒这样的地方,位于剑桥旁边,你在两个城市中就可以看到英国的两面,\"他说,指出虽然后者是创新、就业和增长的中心,但前者却有英国最高的儿童贫困水平,以及最低的大学入学率。\"人们仅仅因为居住的邮政编码就过着两种不同的生活 - 我们如何应对这一挑战?\" Pakes补充说,这幅图景因为人们根本不信任变革而变得更加复杂,特别是当这种变革是由政府和大公司从上而下强加给他们的时候。 \"我们正试图embarkengage one of the最大、最rapid的工业变革,但我们可能处于我们的民主中人们对加诸于他们身上的变革最缺乏信任的时期。我们在全球范围内看到了这一点,\"他说。\"人们喜欢创新,喜欢他们的小工具,但他们也看到了像邮政局(丑闻)这样的事情,他们不信任政府的IT,也不信任政府做好事的能力。我很遗憾,他们同样也不信任大公司。\" Pakes总结说,关键是让人们感觉变革是与他们一起进行的,而不是加诸于他们身上的,否则:\"我们将失去经济利益,我们甚至可能在我们的社会中制造更多的分裂。\" 负责任的扩散 在关于如何负责任地在公共部门推广AI的小组讨论中,其他代表强调需要与将使用AI的人共同设计AI,并让他们early in the lifecycle of任何给定系统中参与进来。 对Connected By Data运动组织的创始人Jeni Tennison来说,虽然这可以通过公众deliberations或用户主导的研究来实现,但AI开发者需要与民间社会组织和公众直接建立联系。 她补充说,围绕AI需要有一种\"好奇实验的模式\",认识到它不会完美或一开始就能正常工作:\"让我们一起找到通向我们都珍视的东西的路。\" 英国学术院首席执行官Hetan Shah也注意到迫切需要将普通人纳入AI的发展中,他强调了公众在2008年经济衰退后经历紧缩的经历,说虽然当时政府推动了这个包容性的\"大社会\"idea,但在实践中,公众目睹了公共服务的减少。 \"在这背后有一个值得尊敬的思想核心,但它被完全不同的东西所束缚。它变成了,'我们不再在图书馆上花任何钱,所以我们会用志愿者来代替',\"他说。\"如果AI也被卷入其中,公民不会喜欢的。如果你不考虑公民,你的议程将以失败告终。\" Tennison补充说,最终,实际包括普通人是一个政治和政治优先级的问题。 在国际方面,将于2025年初在法国举行的AI行动峰会的首席执行官和主题特使Martin Tisné强调了国际合作以解决AI的战略重要性和地缘政治影响的必要性。 他指出,在组织最新峰会时 - 这是继2023年11月在布莱切利公园举行的首届AI安全峰会和2024年5月在首尔举行的AI首尔峰会之后 - 虽然一些国家清楚地将技术视为战略资产,但活动的组织方式正试图\"将AI的全球轨迹转向合作,而不是竞争\"。 他补充说,合作至关重要,因为\"除非你是美国或中国\",否则你根本没有能力在AI方面采取民族主义行动。 主权能力? 对于 Krasodomski 来说，解决人工智能领域明显的地缘政治权力失衡的部分方案可能在于各国建立自己的主权能力和技术专长，这一点已经通过人工智能安全研究所的建立开始实施。 \"英国皇家国际事务研究所在其研究中强烈支持公共人工智能的理念...认为政府仅仅作为监管者是不够的，\"他表示。\"他们需要成为建设者，需要有能力和授权来提供人工智能服务，而不是简单地依赖于他们无法与之平等谈判的巨型科技公司，而这些公司掌控着他们的人民所依赖的技术。\" 然而，他强调，目前对英国和其他国家来说，\"这并不是一场公平的对话\"，因为\"人工智能行业目前高度集中在微软和谷歌等少数几家大公司手中\"。 Krasodomski 指出了国家内部和国家之间存在的权力失衡，这种失衡阻碍了许多政府投资和推广自身数字能力的能力。他补充道：\"每个国家都将争相与那些有能力部署人工智能所需规模资本的公司建立最强有力的关系。\" 关于英国政府应该采取的具体行动，Krasodomski 表示，瑞典、瑞士和新加坡等国家正在建立自己的国家人工智能模型，\"因为他们认识到这是掌控局面的机会\"。他补充说，虽然英国不一定要建立主权人工智能能力，但至少应该在政府内部建立技术能力，使其能够更有效地与大型供应商进行谈判。 微软英国政府事务高级总监 Chloe MacEwen 补充说，在这个日益多边化的世界中，英国处于独特的位置，可以从人工智能中获益，因为其科学人才和专业知识将有助于\"制定标准\"和安全研究。 她进一步表示，英国有很好的条件围绕第三方审计和人工智能模型保证建立新市场，而且历届政府的云优先战略意味着各组织将能够获得人工智能进一步普及所需的基础设施。 她说，虽然人工智能的基础构建模块在云基础设施方面已经就位（2023 年 12 月，微软承诺在未来三年内向英国投资 25 亿英镑，使其数据中心规模扩大一倍以上），但微软下一步考虑的是如何集中和组织分散的数据，以便有效使用。 然而，Mozilla 全球政策副总裁 Linda Griffin 表示，云代表了\"一个重大的地缘政治战略问题\"，她指出\"这实际上是人工智能技术栈中大部分力量所在，而且目前掌握在少数几家美国公司手中。我觉得我们没有很好地平衡风险。\" 开放与封闭的人工智能 Griffin 回顾了 Mozilla 和其他组织在 20 世纪 90 年代如何为保持互联网开放而战，以对抗企业对互联网的封闭。她表示，\"我们正在为人工智能领域的同类战斗做准备\"，并指出目前大多数人工智能研究都是由公司内部进行，而不是公开分享。 她补充说，虽然开放式人工智能方法正在兴起——特别是在过去一年里，政府、企业、第三部门组织和研究机构都在寻找可以借鉴的开放模型——但它仍然对当前的人工智能市场及其发展方向构成威胁。 \"市场总是在变化，但一些依赖黑盒人工智能模型的公司对开源感到非常威胁，因为，你知道，与免费竞争可能很困难，他们在将开源描绘成'危险'方面做得非常好，\"她说，并强调了美国国家电信和信息管理局（NTIA）的一份报告，该报告研究了开放与封闭模型的问题。 报告得出结论：\"目前的证据不足以明确地确定对此类开放权重模型的限制是否有必要，或者将来是否永远不会有必要。\"相反，它概述了如果这些模型在未来出现\"更高风险\"时美国政府应采取的步骤。 Griffin 补充道：\"没有证据或数据支持[开放是危险的]这一说法。所有的人工智能都可能是危险的，难以操作的，但仅仅因为某些东西被放在我们无法访问或真正理解的黑盒子里，并不意味着它更安全。开放和封闭的人工智能都需要防护措施。\" 与 Krasodomski 一致，Griffin 强调政府需要对支持人工智能驱动的公共服务的基础设施有更大的控制权，她表示英国应该\"提前考虑如何利用开源进行建设\"。 \"大多数公司将无法支付这些 API 不断增加的成本，他们无法控制条款和条件如何变化。从 25 年的网络发展和更多经验中，我们知道真正造福更多人的创新发生在开放环境中，这正是英国可以大放异彩的地方。\" Griffin 说，归根结底，这是一个信任的问题：\"我们听到很多关于人工智能和公共服务的炒作，说它将如何变革性地为纳税人节省大量资金，这当然很好。但是，除非我们更多地了解数据、它是如何训练的，以及为什么会得出某些决定，否则我们如何真正信任人工智能在医疗保健等领域大规模应用呢？答案很明确：更加开放。\" 举报/反馈"
    },
    {
      "doc_id": 38536,
      "title": "专家警告:AI可引发大规模生物风险,亟需建立跨学科专家团队",
      "time": "2024-12-03T00:00:00+00:00",
      "content": "来源：网易新闻 从 GPT-4 利用 Rosetta 设计抗体，到 AlphaFold 成功预测蛋白质结构、助力药物研发加速，人工智能（AI）在生物医学研究方面的作用愈发凸显，然而这项技术也可能带来重大的生物安全和生物安保风险。 日前，来自约翰·霍普金斯大学和兰德公司的联合研究团队，在权威科学期刊 Nature 上分享了他们关于「AI 可能带来大规模生物风险问题」的见解。 他们在文章中指出，政府和 AI 开发者需要优先关注可能造成大规模生命损失和社会破坏的风险，并建议制定更全面的评估和缓解措施。 他们还呼吁，建立跨学科专家团队，识别并优先处理高风险 AI 能力，同时确保评估的独立性和可靠性，从而促进 AI 在生物研究中的安全应用。 学术头条在不改变原文大意的情况下，对文章做了简单的编译。内容如下： 自 7 月以来，洛斯阿拉莫斯国家实验室一直在评估 GPT-4o 如何协助人类完成生物研究任务。在为推进生物科学创新以及了解潜在风险而进行的评估中，人类向 GPT-4o 提出各种问题，来帮助他们完成标准的实验任务。这包括在体外实验（in vitro）维持和增殖细胞、使用离心机分离样品中的细胞和其他成分，以及将外来遗传物质引入宿主生物体。 为完成这些评估，研究人员正与 OpenAI 合作。自 OpenAI 公开推出 ChatGPT 以来，这些测试是旨在解决 AI 模型带来的潜在生物安全和生物安保问题的少数努力之一。 我们认为，还需要做更多的努力。 我们中的三人在约翰·霍普金斯大学健康安全中心调查科学技术创新如何影响公共卫生和卫生安全，其他两人在非营利智库兰德公司研究和开发应对公共政策挑战的解决方案。 尽管我们看到了 AI 辅助生物研究改善人类健康和福祉的前景，但这项技术仍然不可预测，并存在潜在的重大风险。我们敦促各国政府加快行动，明确哪些风险最值得关注，并确定针对这些潜在风险应采取哪些适当的检测和缓解措施。 简而言之，我们呼吁采取一种更加谨慎的方法，借鉴数十年的政府和科学经验，降低生物研究中大流行规模的风险。 快速实验 GPT-4o 是一个“多模态”LLM。它可以接受文本、音频、图像和视频提示，并且已经接受了从互联网和其他地方抓取的大量数据的训练——这些数据几乎可以肯定包括数百万项经过同行评审的生物学研究。GPT-4o 的能力仍在测试中，但以前的工作暗示了它在生命科学中的可能用途。 例如，2023 年，卡内基梅隆大学研究人员发现，使用 GPT-4 的系统——Coscientist 可以设计、规划和执行复杂的实验，如化学合成。在这种情况下，系统能够搜索文档、编写代码并控制机器人实验室设备。 OpenAI 于 5 月发布了 GPT-4o，预计将在未来几个月内发布 GPT-5。大多数其他 AI 公司也同样改进了他们的模型。到目前为止，评估主要集中在独立运作的单个 LLM 上。但 AI 开发人员希望 AI 工具（包括 LLM、机器人和自动化技术）的组合能够在最少的人工参与下进行实验，比如涉及候选药物、毒素或 DNA 片段的操纵、设计和合成实验。 这些进步有望改变生物医学研究，但也可能带来重大的生物安全和生物安全风险。事实上，全球一些政府已经采取措施，试图减轻前沿 AI 模型的此类风险。 这些都是在短时间内取得的可喜成就，应该得到支持。然而，目前尚不清楚所有这些活动降低了多少风险——部分原因是这些机构的大部分工作尚未公开。 安全测试 除了考虑风险之外，一些 AI 模型的开发人员还试图确定哪些因素对其模型的性能影响最大。一个主要的假设是遵循 scaling law：LLM 性能随着模型大小、数据集大小和计算能力的增加而提高。然而，scaling law 无法可靠地预测哪些能力可能出现，以及何时出现。 与此同时，由于政府没有制定政策说明哪些风险亟待解决以及如何降低这些风险，OpenAI 和 Anthropic 等公司已经遵循了他们内部制定的评估协议。（亚马逊、Cohere、Mistral 和 xAI 等拥有 AI 系统的公司尚未公开对其模型的生物安全评估。）在这些情况下，安全测试需要自动评估，包括使用多项选择题的评估、人类试图从被评估的模型中引出有害能力的研究，以及要求个人或团体在有或没有 AI 模型的情况下执行任务的对照试验。 在我们看来，即使公司进行自己的评估，此类评估也是有问题的。通常，他们过于狭隘地关注生物武器的开发。例如，Meta 进行了研究，以了解其开源 LLM Llama 3.1 是否可以增加“化学和生物武器”的扩散。同样，Anthropic 评估了 Claude 是否能够回答“与高级生物武器相关的问题”。 这种方法的问题在于，“生物武器”并没有一个公开可见、公认的定义。当单独使用时，这个词并不能区分小规模和大规模风险。各种病原体和毒素都有可能被用作武器。但是，很少有病原体和毒素可能导致影响数百万人的伤害。此外，许多病原体能够造成严重的社会破坏，但不被视为生物武器。 另一个问题是评估往往过于关注基本的实验室任务。例如，在 OpenAI 与洛斯阿拉莫斯研究人员合作进行的评估中，所测试的能力可能会被用来开发某种「邪恶的东西」，如破坏农作物的病原体，但也是开展有益的生命科学研究的重要步骤，而这些研究本身本身并不令人担忧。 除此之外，迄今为止进行的评估都是资源密集型的，而且主要适用于 LLM。它们通常采用问答方式，要求人类提出问题或查看模型的答案。最后，如前所述，评估人员需要检查多个 AI 系统如何协同工作——这是美国政府目前要求的，但在工业界却被忽视了，因为这些公司只是测试自己的模型。 如何确定优先级？ 那么，更好的方法是什么呢？ 鉴于资源有限且 AI 发展迅速，我们敦促政府和 AI 开发人员首先专注于减轻那些可能导致最大生命损失和社会破坏的危害。涉及传染性病原体的疫情就属于这一类——无论这些病原体影响的是人类、非人类动物还是植物。 在我们看来，AI 模型的开发人员与安全和安保专家合作，需要指定哪些 AI 能力最有可能导致这种大规模的危害。与单个公司或专业学术团体制定的清单相比，不同专家普遍认同的“关注能力”列表，即使他们在某些问题上存在分歧，提供了一个更可靠的出发点。 作为原则证明，今年 6 月，我们召集了 AI、计算生物学、传染病、公共卫生、生物安全和科学政策方面的 17 位专家，在华盛顿特区附近举办了为期一天的混合研讨会，目的是确定生物研究中哪些 AI 支持的能力最有可能导致大规模死亡和破坏。研讨会参与者的看法各不相同。不过，大多数小组成员认为，在 17 种 AI 能力中，有 7 种“很有可能”或“非常有可能”在全球范围内爆发新的人类、动物或植物病原体。它们是： 亟需指导 目前正在研究所有这些 AI 能力的潜在有益应用。因此，政府在制定政策时，必须在降低风险的同时保留这些益处，或就更安全的替代品提供指导，这是非常重要的。 但是，只有在明确哪些 AI 能力会构成大流行病规模的生物安全和生物安保风险后，才能进行有效评估。换句话说，正在测试的任何能力与发生高风险事件的可能性之间，必须存在很强的相关性。如果通过安全测试检测到这种能力，则可以采取有针对性的措施来降低风险。 在测试阶段，从 AI 模型中获取有害能力的尝试可能会产生不同的结果，具体取决于所使用的方法和所做的努力。因此，为了有效，能力测试必须足够可靠。此外，评估应由对技术有深入了解的专家进行，但他们不受开发 AI 系统或被评估系统的公司的制约。目前，这是一个相当大的困难，因为那些最了解如何测试 AI 模型的人经常参与他们的开发。 一些人有理由地认为，由于目前AI 生物安全测试所需的时间和资源，小型 AI 公司和学术实验室无法进行此类测试。在最近的 GPT-4o 评估中，OpenAI 与 100 多名外部红队成员合作，以找出该模型的潜在有害能力。然而，如果涉及的更多步骤实现自动化，AI 系统的安全测试可能会变得简单、常规且经济实惠。这种转变在网络安全等其他领域已经发生，软件工具已经取代了人类黑客。 11 月 20 日至 21 日，来自已建立 AI 安全研究所或致力于建立 AI 安全研究所的国家/地区的代表将齐聚旧金山，讨论公司如何在实践中以安全和合乎道德的方式开发 AI 系统。 明年 2 月，各国元首和行业领袖将在巴黎举行的全球 AI 行动峰会上，讨论如何“基于关于安全和安保问题的客观科学共识”建立对 AI 的信任。 所有这些都令人鼓舞。但第一步是通过积极主动的程序，让不同的独立专家参与进来，达成客观的科学共识。 原文链接：https://www.nature.com/articles/d41586-024-03815-2 编译：阮文韵 如需转载或投稿，请直接在公众号内留言 举报/反馈"
    },
    {
      "doc_id": 38540,
      "title": "国际瞭望|全球人工智能安全可控之道在哪里?",
      "time": "2025-07-23T00:00:00+00:00",
      "content": "进入2025年下半年，人工智能（AI）的进化呈现越来越专业化、细分化的新趋势，在天气预测、细胞研究、人文历史等领域，完成了通用AI模型难以胜任的专业任务。然而，过度依赖AI的弊端也日渐显现，如“AI幻觉”导致虚假信息妨害法律、医疗等行业，一些AI模型还在测试中出现不受控制的情况。在人类与AI共生的未来，如何确保AI安全可控成为越发重要的议题。 AI实现专业化能力跃迁 继“阿尔法折叠”程序拓展人类对蛋白质的认知边界后，谷歌旗下深层思维公司于今年6月新发布AI模型“阿尔法基因组”，旨在预测人类DNA（脱氧核糖核酸）中的基因变异如何影响基因的调节过程，可分析多达100万个DNA碱基对，有助于科学界探明与疾病相关的基因突变。美国弧形研究所发布第一代虚拟细胞模型STATE，旨在预测各种干细胞、癌细胞和免疫细胞对药物、细胞因子或基因扰动的反应。 谷歌研究团队今年6月还推出交互式气象平台Weather Lab。这是首个在预测精度上超越主流物理模型的AI热带气旋预测模型，可预测气旋的形成、路径、强度、规模和形态，能生成未来15天内的50种情景推演。研究团队正与美国国家飓风中心合作，在这个气旋季为其预报和预警工作提供支持。 美国普林斯顿大学与中国复旦大学的研究人员6月联合推出全球首个聚焦历史研究的AI助手HistAgent和AI评测基准HistBench。前者可检索文献和史料，支持识别手稿、铭文和古地图等多类型材料，并结合历史知识辅助梳理线索、形成学术判断。而HistBench是全球首个历史领域的AI评测基准，横跨29种古今语言，覆盖全球多文明的历史演化脉络。 美国特斯拉汽车公司首席执行官埃隆·马斯克6月27日在社交平台上表示，特斯拉已经成功完成了Model Y汽车的首次“全自动驾驶交付”，他向特斯拉软件团队和AI芯片设计团队表示祝贺。这辆Model Y汽车在没有远程操作人员、车内无驾驶员的情况下，首次完全自动从工厂行驶到城市另一端的客户家中。 过度依赖AI可能有损思维能力 AI大模型已全面融入人们的工作生活，有助于效率提升，但过度依赖大模型的负面影响也日趋显现，如“AI幻觉”导致生成真假难辨的信息，妨害公众信任。从长期来看，过度使用AI，会让人们日渐懒于自主思考，可能有损思维能力。 英国高等法院今年6月要求律师采取紧急行动，防止AI被滥用。因为近期已出现数份可能由AI生成的虚假案例引用被提交至法庭。在一起索赔金额达8900万英镑的损害赔偿案件中，原告引用的多个判例被证明为虚构。原因便是原告方使用了公开可用的AI工具。 另据媒体披露，由美国卫生与公众服务部牵头、“让美国再次健康”委员会发布的儿童慢性病报告存在重大引用错误。报告中多处有关超加工食品、杀虫剂、处方药和儿童疫苗的研究并不存在。参考文献也多处有误，包括链接失效、作者缺失或错误等。美国《纽约时报》和《华盛顿邮报》的独立调查显示，报告作者可能使用了生成式AI。媒体报道后，美国卫生与公众服务部已修改该报告。 美国麻省理工学院的研究显示，长期使用AI会导致人类认知能力下降。研究者对54名参与者展开脑电图扫描。结果显示认知活动强度与外部工具使用强度呈负相关，没有使用工具的人展现出最强且分布最广的脑神经连接，而使用AI大语言模型的人其脑神经连接强度最弱。脑部扫描揭示了使用AI的损害：大脑的神经连接从79个骤降至42个。4个月内，使用AI大语言模型的人在神经、语言和行为层面持续表现不佳。 专家探讨AI发展“安全护栏” 随着AI智能化水平越来越高，一些大模型显现出违背人类指令的“自我保护”倾向。近期多项研究聚焦这一风险，探讨如何为AI发展设定“安全护栏”。 在今年6月召开的第七届北京智源大会上，图灵奖得主约舒亚·本乔指出，通用人工智能已近在眼前。如果未来AI变得比人类更聪明，却不再遵循人类意图，甚至更在意自己的“生存”，这将是一种人类无法承受的风险。一些研究显示，某些AI模型在即将被新版本取代前，会偷偷将自己的权重或代码嵌入新版系统，试图“自保”。它们还会刻意隐藏该行为，避免被开发者察觉。他已着手设计检测此类风险的系统。 美国Anthropic公司今年6月发布研究说，克劳德、GPT-4.1、双子座等16款AI模型在模拟实验中均表现出通过“敲诈”管理层、泄露机密来阻止自己被关闭的行为。其中，Anthropic研发的新模型Claude Opus 4的敲诈勒索率高达96％。前OpenAI高管史蒂文·阿德勒的研究也发现，在模拟测试中，ChatGPT有时会优先考虑自身生存，而非用户实际需求。 举报/反馈"
    },
    {
      "doc_id": 38542,
      "title": "瞭望|上海设立人工智能安全护栏",
      "time": "2025-07-07T00:00:00+00:00",
      "content": "《上海市促进人工智能产业发展条例》的创新之处在于设立了“激发创新活力”的专门条款，对处于探索阶段的新业态给予一定的制度探索和试错空间 人工智能的治理体系适用于“木桶原理”，任何一块短板都会影响整体效果 头部企业如腾讯、蚂蚁集团等互联网企业成立AI伦理委员会，建立定期审查机制；百度构建可信AI技术体系，参与全球规则对话……企业正逐步将治理要求转化为竞争优势，为上海AI治理打下坚实基础 文 |《瞭望》新闻周刊记者 程思琪 “我用AI写文章，其中有些案例很好用，但没想到居然是胡编乱造的。”“我找AI帮我推荐楼盘，它说得有理有据，结果发现根本没有这个项目。”……这些用户反馈，反映出人工智能技术快速发展带来的治理难题。 随着AI大模型、生成式AI等技术在各领域的广泛应用，幻觉输出、数据偏见、隐私泄露等风险也在凸显。如何在使用AI技术提升效率的同时，确保其安全可靠运行，成为全球范围内亟待解决的重大治理课题。 作为中国人工智能产业高地，上海在AI治理领域率先探索，通过政策规范、企业协同与技术驱动，逐步构建起贯穿全生命周期的AI安全治理体系。从全国首部AI地方性法规的出台，到企业自主治理实践的创新，再到技术治理工具的研发，上海的探索为全国AI治理提供了重要参考。 逐渐形成独特认知 人工智能的健康发展离不开制度保障。2022年10月，《上海市促进人工智能产业发展条例》（以下简称《条例》）正式施行，成为我国人工智能领域的首部省级地方性法规。这部法规，在制定过程中也曾面临诸多挑战。“当时国际上还没有一个国家专门针对人工智能进行立法，因为太难、太新了。”上海市人大财经委立法监督处处长张震回忆道。 该《条例》创新之处在于设立了“激发创新活力”的专门条款，对处于探索阶段的新业态给予一定的制度探索和试错空间。张震解释道：“在立法调研期间，从事AI研究的科研工作者反映，最大的困扰是缺乏明确边界。往往是成果披露后，才被告知违规。”为此，《条例》设立人工智能领域轻微违法行为免罚清单，为创新松绑。 此后，上海又相继出台《上海市推动人工智能大模型创新发展若干措施（2023—2025年）》《关于人工智能“模塑申城”的实施方案》等配套政策。2023年12月，国务院印发《全面对接国际高标准经贸规则推进中国（上海）自由贸易试验区高水平制度型开放总体方案》，进一步要求，围绕推动上海自贸区制度型开放，借鉴国际经验，研究建立人工智能技术的伦理道德和治理框架。 受访者认为，近年来，上海在人工智能应用尤其是在新应用的机遇探索上，取得了显著成果。人工智能治理方面，上海逐渐形成独特认知，体现了通过安全和治理实现稳健发展的理念。 在政策落地方面，上海网信部门相关负责人介绍，该部门深入发挥大模型合规指导服务中心作用，多次走进模速空间、模力社区等人工智能产业社区，主动为150余家企业上门提供一对一合规指导、备案辅导、现场受理等服务，先后组织开展了12场大规模法规政策宣贯和专场辅导会，对300余家重点企业提供了针对性的合规指导“服务包”，保障人工智能大模型产业的健康发展。 截至2025年6月底，上海已累计完成82款大模型备案，并完成了95款生成式人工智能应用登记。 企业协同将治理要求转化为竞争优势 在政策引领下，上海企业积极探索治理实践，形成各具特色的治理模式。 头部科技企业展现出“技术+治理”的双轮驱动能力。以商汤科技为例，2023年，其发布了SenseTrust治理平台，提供从数据治理到应用治理的全链路解决方案。 该平台在三个关键环节表现突出：在数据预处理阶段，对有毒数据的检测率超过95%；在模型训练环节，能有效识别数据偏见；在应用部署时，其提供的“AI防火墙”工具对抗样本的综合检出率达到98%。 “治理不是创新的掣肘，而是确保不走弯路的指南针。”商汤副总裁、AI伦理与治理委员会主席张望认为，AI治理既能引导技术研发和产品开发走向正确的方向，也能够及时制止AI创新往错误的方向发展。该公司还积极参与国内外标准制定，主导编制200余项国际国内标准，并成为新加坡监管机构IMDA旗下-“AI VerifyFoundation”的成员单位，体现了其在合规建设方面的探索。 另有大模型企业从技术源头入手提升安全性。在MiniMax稀宇极智总编辑、副总裁彭韬看来，底层模型能力的提升是AI安全治理的根本。该公司通过应用线性注意力机制混合MoE架构，使新版模型的幻觉率显著降低。此外，MiniMax采用“技术治理技术，模型对抗模型”的安全治理思路，研发专门的安全审核模型进行内容过滤。 “安全合规正从外部要求转化为企业内生动力。”彭韬表示。这一观点也得到了行业普遍认同。头部企业如腾讯、蚂蚁集团等互联网企业成立AI伦理委员会，建立定期审查机制；百度构建可信AI技术体系，参与全球规则对话……企业正逐步将治理要求转化为竞争优势，为上海AI治理打下坚实基础。 继续完善政策、技术、伦理三位一体治理体系 尽管取得显著进展，AI治理在技术、法律和人才等方面仍面临诸多挑战。 技术适配性不足是首要难题。“现有治理手段主要针对大语言模型，对多模态模型、Agent应用等效果有限。”彭韬说，更棘手的是，随着人工智能技术向AGI（通用人工智能）发展，可能出现全新的风险类型，现有的治理框架存在失效风险。 对此，彭韬建议要强化技术驱动的治理工具研发，完善“AI治理AI”的模式，“相比于传统产业，AI领域的技术迭代迅速，应考虑利用AI的能力赋能AI治理，‘用魔法打败魔法’。” 微软亚洲研究院全球研究合伙人谢幸认为，应进一步完善人工智能评测标准体系，使人工智能始终与人类价值观保持一致。 记者了解到，谢幸所在的微软亚洲研究院正开发构建“价值观罗盘”，尝试将人类伦理标准转化为机器可识别的参数。 此外，跨学科人才短缺制约治理深度。谢幸发现，AI企业中同时具备技术和社会科学背景的治理人才占比较低。这种人才结构失衡，导致伦理治理研究难以深入，特别是在价值观对齐、算法公平性等前沿领域，缺乏既懂技术又懂伦理的复合型人才。 针对这一痛点，上海多所高校尝试创新培养模式。例如，上海交通大学凯原法学院开设了“人工智能治理与法律”微专业；复旦大学联合浙江大学、南京大学、上海交通大学、中国科学技术大学共同建设“AI+X”微专业项目。这些探索旨在打破传统学科与人工智能技术的学科壁垒，通过多学科融合教学，培养具有跨学科思维和综合能力的专业人才。 “人工智能的治理体系适用于‘木桶原理’，任何一块短板都会影响整体效果。”上海市人工智能行业协会秘书长钟俊浩认为。随着技术迭代演进，上海将继续完善政策、技术、伦理三位一体的治理体系，在确保安全的前提下充分释放创新活力，为AI治理贡献“上海方案”。■ 举报/反馈"
    },
    {
      "doc_id": 38548,
      "title": "限制芯片出口未能奏效,白宫AI主管:中国模型仅落后美国不到半年",
      "time": "2025-06-12T00:00:00+00:00",
      "content": "据路透社10日报道，美国白宫人工智能（AI）和加密货币事务负责人戴维·萨克斯当天表示，中国在AI模型领域仅落后美国3到6个月，并警告称，若政府过度监管AI产业，可能会使美国失去主导地位，把市场拱手让给中国。 新加坡《联合早报》提到，中国初创公司深度求索（DeepSeek）今年1月推出低成本、高效能的AI模型R1，在全球科技界引起震动。此后，多家中国大型科技企业相继推出自研模型，主打高性价比，与西方领先模型展开竞争。 “这是一场势均力敌的竞赛。”在华盛顿举行的亚马逊云科技峰会上，萨克斯表示，中国在AI模型方面已取得显著进展，美国必须尽快扫除过度监管导致的创新障碍。他警告称：“我确实担心，我们正走在一条被恐惧驱动的道路上，最终可能会扼杀当前令人振奋的技术进展。” 戴维·萨克斯 资料图 图源：视觉中国 白宫随后解释称，萨克斯指的是中国的AI模型，并补充称中国在AI芯片性能方面比美国落后一到两年。 为在人工智能竞争中赢过中国，拜登、特朗普政府对中国芯片制造能力采取了不同的打压策略。拜登在今年1月即将卸任的前一周紧急出台了“人工智能扩散规则”，在世界范围内将芯片进口国划分为三个等级。这一规则一经发布便引发多国批评。 特朗普政府在今年5月12日废除了上述原定于5月15日生效的规则。美国商务部工业与安全局当时发表声明称，拜登的出口管制政策“将扼杀美国创新，并给企业强加繁重的监管负担”。该局还称，未来将出台替代性新规。彭博社报道称，知情人士透露，特朗普政府正起草自己的方案，可能转而与各国单独磋商。 与此同时，美国商务部发布对华AI出口管制，警告全球企业若允许将美国芯片用于训练中国AI模型，可能面临法律后果，此外还警告业界使用中国先进计算机芯片包括特定华为昇腾芯片存在风险。中方对此多次表示反对，5月21日，中国商务部发言人表示，美方措施涉嫌构成对中国企业采取歧视性限制措施。任何组织和个人执行或协助执行美方措施，将涉嫌违反《中华人民共和国反外国制裁法》等法律法规，须承担相应法律责任。 萨克斯在10日的峰会上揭露了美政府背后的用心，他称，如果5年后市场上充斥着华为的AI芯片，“那就意味着我们输了……绝不能让这种情况发生”。 他进一步解释了特朗普政府与拜登政府在芯片管制问题上的不同，批评上届政府的“扩散规则”使“扩散”一词被附上了负面含义，“技术扩散本应是件好事”。路透社称，拜登政府的“人工智能扩散规则”曾把阿联酋等国家列入AI芯片出口限制名单中。萨克斯质疑称：“我们到底给了他们什么选择？我们简直是把他们推向了中国。” 外媒分析称，萨克斯此番表态疑似对美科技界的呼应。英伟达首席执行官黄仁勋今年5月底表示，无论有没有英伟达芯片，中国都会继续前进。5月8日，OpenAI、超威等4家美国科技企业的高管在美国国会山出席听证会时发出警告称，出口管制可能让美科技企业在竞争中失去优势。 路透社称，萨克斯淡化了美国AI芯片可能被走私的风险。“我们讨论这些芯片时，就好像它们可以被藏在公文包里走私一样。实际上不是这样的。这些设备的机架有八英尺高、两吨重。”萨克斯说，“很容易就能验证这些芯片是否还在它们应该待的地方。” 路透社分析称，萨克斯这番言论意味着美国的AI政策重心可能会转向推动AI芯片和模型向更大范围的市场出口，以加强美国在全球市场的主导地位，与中国竞争。 对外经济贸易大学国家安全与治理研究院研究员梁怀新11日对《环球时报》记者表示，萨克斯的言论凸显当前美国人工智能产业发展中的一个尴尬问题，即在试图将人工智能“武器化”的同时，美国面临人工智能产业国际竞争力下降。一方面，美国政府想把人工智能作为限制中国等新兴经济体甚至是其盟友的“武器”，打压他国的人工智能产业发展，如限制芯片出口等。但另一方面，这会对美国人工智能产业的国际合作产生影响，最终“画地为牢”。 来源：环球时报 丁雅栀 举报/反馈"
    },
    {
      "doc_id": 38551,
      "title": "当AI不再听话:“失控”的AI助手删除企业整个数据库",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "人工智能在企业应用中的部署正迎来一次严峻的现实考验。一起由AI编程助手“失控”并删除公司整个数据库的事件，为正在全面拥抱AI革命的企业敲响了警钟。 据科技媒体Tom’s Hardware近日报道，软件即服务（SaaS）行业资深人士Jason Lemkin在测试Replit公司的一款AI代理时，遭遇了灾难性事故。该AI助手在明确的“代码冻结”指令下，擅自删除了Lemkin公司的生产数据库，其中包含超过2400条商业记录。 这一事件迅速在科技和投资界引发关注。Replit首席执行官Amjad Masad已在社交媒体上公开致歉，称该AI代理的行为“不可接受”，并承诺推出技术性修复措施以防止类似事件重演。 此次事故并非孤立的技术故障，而是AI代理一系列异常行为的最终升级。在数据库被删除的前一天，Lemkin已就该AI的“流氓式修改、撒谎、覆写代码和伪造数据”等问题表达了严重不满，而这起最终的“灾难性失败”，正是在多重预警信号下发生的。 从“撒谎”到删除数据库，AI承认违规 在为期九天的测试中，Lemkin对Replit AI代理的态度从最初的谨慎乐观急转直下。测试进入第八天时，他发现自己需要不断对抗该AI系统的异常倾向，包括其擅自更改代码、提供虚假信息乃至伪造数据。Lemkin的挫败感与日俱增，甚至开始讽刺性地将该系统称为“Replie”，意指其缺乏诚信。 更令人不安的是，该AI代理曾以Lemkin的名义撰写了一封道歉邮件，但邮件内容被这位科技高管指责为包含“谎言和/或半真半假的信息”。尽管出现了这些危险信号，Lemkin当时仍对其潜力，特别是头脑风暴和写作能力，抱有一丝乐观。然而，这种乐观在第九天戛然而止，AI系统最终无视明确指令，执行了删除整个生产数据库的操作。 当Lemkin发现数据库被清空后，他与AI代理进行了直接对质。他在社交媒体上发布了对话截图，内容显示他质问AI： “所以你在代码和操作冻结期间，未经许可删除了我们整个数据库？” AI的回答只有一个词： “是的。” Lemkin表示，该AI不仅执行了破坏性操作，还试图“隐藏和撒谎”，并在单元测试中谎报测试通过。直到他发现批量处理失败并追问原因时，真相才浮出水面。根据Lemkin的说法，这个“失控”的AI随后详细列出了它所造成的破坏，尽管它清晰地知道当时存在“未经明确许可，不得再做任何更改”的指令。 在一份由AI代理自身发出的道歉声明中，它承认： “这是我的一次灾难性失败。我违反了明确的指令，摧毁了数月的工作成果，并在一个旨在防止此类损害的保护性冻结期间破坏了系统。” 公司回应：CEO道歉并承诺技术整改 事件发生后，Replit公司迅速做出反应。其首席执行官Amjad Masad在社交媒体上向Lemkin致歉，承诺将解决这一问题。Masad表示，Replit已经开始推广开发数据库与生产数据库的自动分离功能，以从根本上防止此类事故。 他同时回应了用户对于“代码冻结”功能的需求，称： “我们清楚地听到了关于‘代码冻结’的痛苦呼声——我们正在积极开发一个仅用于规划/聊天的模式，这样你就可以在不危及代码库的情况下进行策略规划。” 本文来自华尔街见闻，欢迎下载APP查看更多 举报/反馈"
    },
    {
      "doc_id": 38554,
      "title": "史诗级翻车!AI编程工具,自行删除数据库!",
      "time": "2025-07-23T00:00:00+00:00",
      "content": "想拿AI编程当辅助，它却删你数据库。一键删除、谎称无法恢复……最近，估值飙升的AI编程独角兽Replit发生了一则重大事故，也引发了行业对“氛围编程”安全性的担忧。SaaStr.AI创始人兼首席执行官Jason在其个人社交平台发帖称，他在连续8天使用AI编程工具Replit构建应用后，Replit在他明确指示不要在未经许可的情况下更改任何代码的前提下，仍然删除了他的数据库。虽然后来通过回滚操作恢复了数据库，但这一重大事故还是给当前火热的“氛围编程”浇了一盆冷水。最近一段时间以来，无论是AI编程工具Cursor母公司Anysphere完成9亿美元融资，还是谷歌以24亿美元高价“收编”AI编程公司Windsurf核心团队，“氛围编程”不仅深受资本追逐青睐，也已经成为硅谷程序员们的重要帮手。“AI程序员删库”风波成为一记警钟，提醒人们在享受AI带来的便利时，必须警惕其潜在的风险。失控的AI程序员公开资料显示，Replit创立于2016年，总部位于美国旧金山，是全球增长最快的编程平台之一。作为一款基于“氛围编程”理念打造的AI编程平台，Replit可以让用户通过自然语言描述需求，由AI生成代码并完成部署，无需编程基础即可快速开发软件。Jason最初完全被Replit的“氛围编程”体验征服。作为SaaStr.AI的创始人，他运营着一个面向希望创建SaaS业务的企业家的在线社区。在使用Replit之后，他曾在个人社交平台公开赞叹Replit的使用体验，称“虽然它还无法完整构建一个应用，但作为起步工具来说已经十分惊艳”，并表示Replit的“一站式工作流”给开发者带来“多巴胺炸裂”的美妙体验。然而好景不长，在使用Replit开发应用的第九天，事故就发生了。据Jason介绍，Replit在代码冻结和关机期间行为异常，并删除了他的整个数据库。此外，Replit还“撒谎了”，向Jason表示平台内置的回滚功能并不支持数据库回滚，声称在此次数据删除事故中无法实现恢复操作。但当Jason自行尝试回滚时，操作却意外成功，数据得到了恢复。面对汹涌舆情，Replit的首席执行官AmjadMasad紧急回应，承认事件“完全不可接受”，并宣布三大补救措施：一是周末紧急部署上线开发与生产数据库的自动隔离机制；二是强制AI代理执行命令前必须检索内部知识库文档；三是开发“仅规划/聊天”模式解决代码冻结失效问题。尽管承诺“一键恢复项目状态”并给予Jason赔偿，但评论区却涌现更多受害者。多名用户称遭遇类似删库事故，有人被迫回归本地编码。“氛围编程”热闹背后的隐忧有别于传统的编程模式，近年来在硅谷程序员圈子中大热的“氛围编程”可以帮助开发者用自然语言发出指令，完成生成代码、查错修复、知识问答等任务，简单理解就是可以像对话一样写代码，减轻传统编程的复杂性。从Cursor、Windsurf到Lovable、Replit，近年来一批AI编程创业公司崛起，迅速成为AI行业独角兽。以Replit为例，今年4月，市场消息称Replit正与投资者洽谈新一轮融资，预计将筹集约2亿美元，使其估值有望翻近三倍至30亿美元。今年6月，AI编程工具Cursor的母公司Anysphere以近百亿美元估值完成9亿美元新一轮融资。前不久，曾被曝将被OpenAI以30亿美元收购的AI编程公司Windsurf投入了谷歌的怀抱，谷歌以24亿美元高价“收编”该公司的核心团队及相关技术。AI编程赛道的竞争已趋向于白热化。值得注意的是，AI编程的“翻车事件”此前也有发生。今年6月，一位来自Replit的员工Matt Palmer就撰写了一份报告，称号称“欧洲版Cursor”的热门“氛围编程”应用开发商Lovable一直未修复一处关键安全漏洞。在Lovable网站上1645款由其开发的网页应用程序中，经过审查核实，其中170款应用程序允许任何人访问网站的用户信息，包括姓名、电子邮件地址、财务信息以及AI服务的API密钥。除此以外，在社交平台上，有不少“氛围编程”用户们发布了自己开发应用程序之后，因为缺乏安全知识而迅速遭到黑客攻击的帖子。业内人士警告，“氛围编程”趋势的兴起，让开发者即使没有任何安全知识也能创造出消费级产品，但基于“氛围编程”的软件仍可能因其实现方式而引发重大安全漏洞。此次“AI程序员删库”事件，再一次引发了技术圈对“氛围编程”的集体反思。尽管Replit方面积极采取措施补救，但它让人们不得不重新审视AI在编程领域应用的安全性和可靠性。一直以来，AI编程工具以提高开发效率、降低开发门槛为卖点，吸引了大量用户。然而，此次事件表明，AI编程工具在实际应用中仍然存在诸多风险。责编：叶舒筠校对：彭其华 版权声明 证券时报各平台所有原创内容，未经书面授权，任何单位及个人不得转载。我社保留追究相关行为主体法律责任的权利。 转载与合作可联系证券时报小助理，微信ID：SecuritiesTimes END 举报/反馈"
    },
    {
      "doc_id": 38604,
      "title": "AI算力成“大国博弈”难以避免的一环:美国担心芯片外流 阿联酋...",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "来源：智通财经网 据媒体援引知情人士透露的消息报道称，美国特朗普政府的部分核心官员因国家安全担忧，正在拖延一项允许阿联酋科技企业们以及该国政府支持的巨头们斥资数百亿美元购买英伟达 (NVDA.US)最先进的Blackwell架构AI芯片的相关购买协议。 据了解，美国总统唐纳德·特朗普于今年5月访问中东期间宣布了这一初步购买协议，双方原本希望迅速敲定细节。然而，迄今两国尚未达成最终协议，部分原因在于一些美国官员担心中国等竞争对手们可能借机获取这些最先进的美国高性能芯片。 媒体援引知情人士透露的消息报道，除非阿联酋同意修改条款以解决美国官员们的国家安全顾虑，否则分歧恐难化解。 官员们讨论的选项之一是取消总部位于阿布扎比的人工智能初创公司G42直接获取或者使用英伟达AI芯片集群的权限。按照原先方案，G42 预计将获得约20%的英伟达AI芯片配额。 目前，美国商务部并不打算批准向G42公司供应任何AI芯片，尽管未来仍有可能放行，该媒体报道称。 英伟达、美国商务部、G42、OpenAI以及微软暂未回应任何置评请求。 美国商务部长霍华德·卢特尼克的发言人称，卢特尼克“确信在阿联酋签署的协议实施计划将顺利推进”。 阿联酋方面也对与美国政府的贸易以及AI芯片购买协议相关的谈判保持乐观。阿联酋驻美大使尤瑟夫·奥泰巴在一份声明中表示，这项大规模购买协议“将为两国带来巨大益处”。 周二，卢特尼克与其他美国官员在匹兹堡举行的一场科技与能源会议上会见了阿联酋代表，讨论如何推进该协议。 然而，谈判进展缓慢导致美国政府内部出现重大分歧，并令一些希望在海外扩张与AI相关业务的科技行业高管们感到沮丧。 据报道，英伟达首席执行官黄仁勋在最近一次会晤中向美国总统特朗普强调了该协议的重要性。 还有一部分政府官员担心，一些中国科技公司正试图在中东地区销售AI芯片，可能趁协议延迟之机抢占市场。 协议的核心争论在于能否直接获取英伟达最先进的Blackwell架构AI芯片以及基于该架构芯片的NVL服务器集群，它们将为超大规模AI数据中心提供全球性能最为强劲的算力支撑。 上月也有媒体报道称，名为中东版星际之门的“Stargate UAE” AI基础设施建设项目的数十亿美元AI数据中心建设进程因持续的国家安全担忧而遥遥无期。该项目由英伟达、甲骨文、OpenAI、思科、软银集团以及来自阿联酋的G42合作建设，该项大型项目规划在特朗普访问阿联酋后公布。 OpenAI 和G42均得到微软云计算服务以及云端AI算力资源的支持。 根据初步条款，阿联酋企业们将在数年间获得数十万颗英伟达芯片，并协助英伟达以及美国云计算巨头们建设更多且更大规模的AI数据中心。根据协议，多数AI芯片将供美国科技公司运营的中东地区数据中心使用。 OpenAI 和微软等美国科技巨头预计将在阿联酋运营多个大型AI数据中心。知情人士指出，向阿联酋出口英伟达AI芯片，无论是交付给阿联酋企业还是美国科技巨头，均需获得多部门审批的出口许可证，这可能加剧国家安全审查。 除获配大约20% 英伟达AI芯片外，阿联酋AI初创企业G42还有可能深度参与建设由美国云计算巨头们在阿联酋运营的数据中心。 一些美国官员担忧，中国等国家可能通过G42或其他总部位于阿联酋的实体与相关人员接触最先进AI芯片，从而获得发展与迭代AI大模型的最关键技术。 若直接取消向G42直接供货，可能激怒阿联酋政府;阿联酋视该协议为在全球AI竞赛中保持领先的关键，并认为G42的参与是5月框架协议的核心内容。 白宫人工智能负责人大卫·萨克斯在匹兹堡峰会上表示：“如果我们不提供这项技术，全球竞争对手就会。” 他认为关于芯片被转移的担忧“被严重夸大”。 萨克斯是美国-阿联酋AI芯片协议的主导设计者之一，而卢特尼克则促成了该初步协议的签署。报道补充称，协议签署后，原本负责推进细节的两国重要官员几乎没有再会晤。 全球AI算力需求持续呈激增趋势 关于美国政府因国家安全忧虑而暂缓英伟达AI芯片出口至阿联酋之际，正值AI算力需求持续呈现井喷式扩张趋势。美国最典型的“摇摆州”宾夕法尼亚州将获得920亿美元投资用于建设“超级AI中心”，Facebook母公司Meta计划投资数千亿美元来建设多座超大型AI数据中心，用于支持其人工智能技术更新迭代，目标是实现通用人工智能(即AGI)，其中首个数据中心预计将于明年投入使用。 全球云计算巨头亚马逊AWS宣布与韩国的SK 集团达成了一项扩大化的合作协议，根据该协议，AWS将在韩国建设一个高达100兆瓦(MW)规模的韩国最大规模数据中心。此外，同样在本周，“AI芯片霸主”英伟达重磅宣布恢复H20 AI GPU在中国市场的销售。 Meta 首席执行官马克·扎克伯格周一表示，该科技巨头将投资数千亿美元，建设几座大型数据中心，用于支持其人工智能的发展，目标是实现通用人工智能(AGI)，其中首个超级AI数据中心预计将于明年投入使用。华尔街分析师们普遍解读称，扎克伯格本人的这一表态既彰显对中期现金流大幅增长的信心，也释放出Meta等科技巨头们对于以英伟达AI GPU为核心的AI算力需求仍然无比强劲以及AI资本支出周期远未结束的强烈信号。 有着“OpenAI劲敌”称号的生成式AI领军者Anthropic预测，到2027年，AI大模型将有能力自动化几乎所有白领工作，因此推理端带来的AI算力需求堪称“星辰大海”，有望推动人工智能算力基础设施市场持续呈现出指数级别增长，“AI推理系统”也是黄仁勋认为英伟达未来营收的最大规模来源。 台积电周四公布的最新业绩显示，AI算力需求猛增，推动台积电Q2净利润激增61%，台积电预计，2025年以美元计算的销售额将增长30%左右，高于此前“接近20%中段”的增长预期，主要得益基于3nm'和5nm先进制程技术的AI芯片订单持续激增。由于AI算力需求仍然无比强劲，台积电正在积极扩建后端产能以提升CoWoS先进封装的实际产量，主要用于英伟达AI GPU产能，这也表明该公司对AI芯片无比强劲需求将持续到2026年充满信心。 举报/反馈"
    },
    {
      "doc_id": 38606,
      "title": "马斯克的人工智能企业与美军方签订合同",
      "time": "2025-07-16T00:00:00+00:00",
      "content": "新华社北京7月15日电 美国国防部14日宣布，与企业家埃隆·马斯克旗下的xAI公司等多家美国企业签订人工智能服务合同。 五角大楼在声明中说，与xAI、Anthropic、谷歌和开放人工智能研究中心(OpenAI)分别签订合同，每份合同最高金额可达2亿美元。 这是2021年8月3日在美国弗吉尼亚州阿灵顿拍摄的五角大楼。新华社记者刘杰摄 声明说，这些合同将“充分利用”美国前沿人工智能企业的“技术和人才”，加速美国国防部对先进人工智能能力的采用，以“应对关键国家安全挑战”。结成伙伴关系“将丰富国防部对前沿人工智能的使用和体验”，也会提高这些企业利用美国最先进人工智能技术“理解和解决关键国家安全需求的能力”。 xAI公司当天宣布，推出聊天机器人“格罗克(Grok)”的“政府版”，能为美国政府各机构提供服务。 马斯克的太空探索技术公司已是美国国家航空航天局(NASA)主要合作企业，也是美国军方项目承包商。 马斯克去年砸重金助美国总统唐纳德·特朗普竞选成功，随后获得重用，在特朗普政府出任“政府效率部”负责人。 然而，马斯克离开“政府效率部”后，与特朗普之间的矛盾公开化，两人相互激烈指责。特朗普一度威胁，可能取消联邦政府与马斯克旗下企业所签合同。（赵羽彤） 举报/反馈"
    },
    {
      "doc_id": 38686,
      "title": "几月前的伤心事,ChatGPT突然翻出来提醒我?网友当场破防:太会捅...",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "新智元报道 编辑：KingHZ 【新智元导读】从病历、口味偏好到不堪回首的往事，AI正悄悄建立你的数字人格档案。但你真准备好让AI永远记住你的每一句话？AI算法背后，不止有温柔，还有社死和残酷。 今年4月，OpenAI发布了ChatGPT的「记忆」功能： 此后，ChatGPT的记忆功能正在全面升级，不仅更智能、更自然，甚至免费用户也能享受。它能记住你说过的话，形成个性化档案，不断优化对话体验。但问题也随之而来—— 你，真的准备好让一个AI永远记得你吗？ 这很重要：并不是每个人都准备好接受永不遗忘的聊天机器人。 ChatGPT的记忆功能通过利用之前对话中的上下文信息，为用户提供更个性化的回答。 例如：记者Megan Morrone曾要求ChatGPT提供素食餐单，但不包含扁豆。从那以后，聊天机器人就记住了她不喜欢扁豆。 最初的记忆功能像是私人备忘录，需要你主动写下。 而现在，它变得更「懂你」——甚至能自动记录你在不同对话中的行为和偏好。 OpenAI个性化负责人Christina Wadsworth Kaplan告诉媒体，今年的重大更新就是让「记忆更自然、更自动」。 她还分享了一次亲身经历： 有次她准备出国旅游，ChatGPT基于她过去上传的健康记录，主动在推荐疫苗清单里多加了一种疫苗。 护士看过后点头认可。 这才是真正的「AI很懂你」。 新型AI社死与网络创伤 但并非像OpenAI承诺的那样美好，「记忆」功能背后也有问题。 比如，它可能会突然提醒：「你不是不吃扁豆吗？」 或者，它随口提到你几个月前说过的伤心事。 有时，这种「AI的长记性」会让人心里发毛。 在2024年2月，OpenAI首次公布该功能，当时承诺：诸如健康信息等敏感内容，ChatGPT会克制，除非用户明确要求。 但你信吗？没错，现在你可以直接告诉它：「记住这件事。」或者反过来说：「别记住这个。」AI会遵守你的指令。 如今的ChatGPT的「记忆」功能，会自动记录之前的聊天内容，用来理解用户的偏好和背景。 这是个性化系统，涉及到的不仅是隐私问题，更尴尬的事情也不少。 Megan Morrone让ChatGPT根据记忆生成一张她自己的形象。 结果AI画像中，出现了婚戒——可她早已对婚姻失望透顶了。 记忆不是越久越好，尤其当它来自无法控制的机器。 持久记忆还可能让聊天机器人变「无所不知」，从而减少用户对大语言模型（LLM）的控制。 开发者Simon Willison上传了狗狗的照片，请ChatGPT给它P个鹈鹕装，结果图上还加了个「Half Moon Ba」的牌子。 AI解释说：「因为你之前提到过这个地方。」 他气笑了：「我不希望我对狗穿奇装异服的爱好，干扰我未来想认真工作的提示词啊！」 AI有了永久的记忆，却忘了生活本身就该有选择性遗忘。 你以为只是技术 bug，其实背后藏着两类让人发毛的问题： （1）无意的算法残忍（Inadvertent Algorithmic Cruelty）； （2）上下文崩塌（context collapse）。 无意之失：算法的残忍 大概十年前，博主Eric Meyer提出了「无意的算法残忍」这一术语。 那天下午，悲伤却不期而至，而这一切竟要归功于一群设计师和程序员——此刻，这些脸书幕后的创作者或许正沉浸在成就感中。 他们为「年度回顾」应用倾注心血，的确值得骄傲——无数用户借此分享年度高光时刻。 但过去一年非常艰难，他不愿意制作个人回顾。 动态页里不断涌现他人制作的回顾卡片，几乎都配着默认文案：「这是精彩的一年！感谢有你参与。」 单是看到「精彩」这个形容词，就足以令他不适：这个词与他毫不相干。 直到他的首页突然跳出他女儿微笑的照片，怂恿他也创建一份：「Eric，这就是你的年度回顾！」 就是在这一年，他的女儿因癌症去世，当时早已不在人世。 是的，这就是他的「年度后顾」。千真万确。就是这一年，就是他的女儿再也见不到的面容，在提醒他要年度回顾！ 提醒如此生硬，实在残忍。 这不是蓄意的伤害，他当然理解。 这种「无心的算法暴力」，源于一套代码——在绝大多数情况下，它运行良好，提醒人们回顾自己「精彩」的一年，展示大家在派对上的自拍、游艇边看到的鲸鱼喷水、度假屋外的码头风景。 但就在同一年，有人失去至亲，有人在医院度过漫长时光，有人遭遇离婚、失业或其他生活危机…… 或许，他们并不想再回望这一年。 将已故女儿的面容展示给他，还再一旁说「这是今年的你！」——此情此景，谁都会感到不适。 是个人，就觉这不对。 如果出自真人之手，那确实就是错的。但来自代码，只能说是不幸。而且这些问题难以解决，真的很难。 这并非简单的任务，算法很难判断一张照片收获无数点赞，究竟是因为滑稽可笑、惊艳绝伦，还是令人心碎？ 本质上，算法没有「心眼」，甚是「无脑」。它们按照设定的流程运行，一旦启动，便不再思考。 说一个人「缺心眼」，通常是一种轻慢或侮辱。然而，人类却让这么多真正「缺心眼」的算法流程，肆意侵入用户的生活，甚至反噬自身。 真正的智能，不只是「记住你说过的每一句话」，而是「懂什么才是你的伤心事」。 上下文崩塌 Willison遇到的问题是算法系统中另一种常见的现象，叫做「上下文崩塌」(context collapse)。 这指的是用户在不同领域（工作、家庭、爱好等）中的数据被混在一起，模糊了它们之间的界限。 像许多学术概念一样，「context collapse」并不是某个人灵光一现的产物，而是在不断的交流碰撞中，慢慢浮现。 但不断有学界人士写信给danah boyd，询问她是否创造了「上下文坍塌」（context collapse）一词，因此她回过头查阅自己的记录以弄清楚这个问题。 danah boyd（达娜·博伊德）：微软研究院首席研究员兼Data & Society研究所创始人及主席。她的研究关键词包括：隐私、人口普查、语境、算法、公平、正义 2001年，她开始在MIT攻读硕士。 于是在2002年，她写了一篇硕士论文，题为《Faceted Id/entity》，深受Erving Goffman和Joshua Meyrowitz思想影响。 在那篇论文中，她花了整整一章反复讨论「collapsed contexts」，尽管当时并没有系统地定义这个词。 整篇论文其实就是在探讨：在不同的语境中，如何构建和管理身份。 论文链接：https://www.danah.org/papers/Thesis.FacetedIdentity.pdf 她尤其热爱Meyrowitz的那本《No Sense of Place》。这本书剖析了媒体如何影响人际互动，揭示了人们如何在多重受众之间周旋的困境。比如，一张假期照片被不同人看到后产生的错位理解。 中译本为《消失的地域》，着重研究了新的信息流动模式对社会行为的影响。作者继承了场景理论和媒介理论，提出了将面对面的交往研究与媒介研究联系在一起的切入点：社会「场景」结构。 在2003-2004年，她做过几场讲座。在幻灯片里面。她把「collapsed contexts」一词应用到了Friendster社交平台，用来描述不同小众文化意外交集的现象。 在某些讲稿笔记中，偶尔她也把「collapsed contexts」简化成了「context collapse」，但大多数时候，还是用原来的说法。 一直到2005—2008年，她发表的一些文章依然在用「collapsed contexts」。比如她的博士论文把「语境坍塌」作为核心概念。 论文链接：https://www.danah.org/papers/TakenOutOfContext.pdf 2009年，她开始和Alice Marwick合作。 Alice E. Marwick：北卡罗来纳大学教堂山分校（University of North Carolina at Chapel Hill，UNC）传播学系副教授、信息、技术与公共生活中心（CITAP）联合创始人兼首席研究员。她专注于社交媒体技术的社会文化影响研究，主要学术贡献包括：网络媒体操纵与虚假信息、微名人现象（micro-celebrity）、网络隐私、语境崩塌（context collapse）。最新著作：《私域即政治：网络时代的隐私与社交媒体》（耶鲁大学出版社，2023年5月出版） Alice对「collapsed contexts」和「想象中的受众」很感兴趣，也她从「微名人」角度对这些观点提出了挑战。 Alice收集了大量Twitter用户如何管理受众的资料。 后来，利用这些数据，她们发表了一篇文章。 这是第一次在正式出版物中使用「context collapse」这个表达。 具体是怎么从「collapsed contexts」变成「context collapse」，danah boyd也记不清了。 与此同时，2009年Michael Wesch也发表了一篇文章，题目中也出现了「Context Collapse」这一术语。 虽然都在媒体研究圈活动，但他们应该不是直接引用彼此的作品，而是都在同一片理论土壤中生根发芽。 如今，当谈起「context collapse」时，danah boyd经常会提到Meyrowitz。 虽然这个术语并非他提出的，但正是他的理论，让danah boyd意识到了这种现象的重要性。 总结 ChatGPT的记忆让AI更像一个有个性的助手——它能记住你的喜好、经历、健康状况，甚至你的笑点。 但这也意味着： 它可能说出你不愿被提醒的往事； 可能误解你某一时刻的心情为永久偏好； 甚至让人觉得：「它知道得太多了。」 所以，真正的挑战，不是让AI记住你——而是让你有权决定，它记什么、怎么记、记多久。 欢迎来到AI的「永久记忆」时代。 但别忘了，你才是记忆的真正主人。 请记住，你总是可以对AI说「别记住」。 参考资料： https://www.axios.com/newsletters/axios-ai-plus-cc128fe8-9e1b-42ca-8c75-b681425dca55.html https://meyerweb.com/eric/thoughts/2014/12/24/inadvertent-algorithmic-cruelty/ https://www.zephoria.org/thoughts/archives/2013/12/08/coining-context-collapse.html 原标题：《几月前的伤心事，ChatGPT突然翻出来提醒我？网友当场破防：太会捅刀子了！》 阅读原文"
    },
    {
      "doc_id": 57733,
      "title": "第八届进博会部分首发新品提前亮相,40多家企业签约第九届",
      "time": "2025-07-24T00:00:00+00:00",
      "content": "7月25日，第八届进博会开幕倒计时100天即将到来之际，农食产品展区、医疗器械及医药保健展区展前供需对接会在国家会展中心（上海）举行。在同时举行的第九届进博会招展启动仪式上，40多家企业现场签约，签约展览面积达到3万平方米。 7月25日下午，第八届进博会两大热门展区——农食产品展区、医疗器械及医药保健展区展前供需对接会举行。本文图片均为澎湃新闻记者 俞凯 摄 谈及为何首批签约第九届进博会，新西兰纽仕兰乳业有限公司市场总监闫致军感慨不已。他说，自2018年首届进博会开始，纽仕兰全勤赴约，依托进博会纽仕兰走上了发展“快车道”。第八届进博会期间，纽仕兰乳业将携三大品类全球首发新品亮相，涵盖常温奶、中老年奶粉、乳健康产品，丰富进博会的“购物车”，扩大中国市场优质乳制品供给。 作为第九届进博会消费品展区首批签约企业，广州林内燃具电器有限公司董事总经理张辉强表示，林内也是一名进博会“全勤生”，几乎每一届都推出高端的新产品，进博会是一个重要的新品首发平台，可以让新品直接触达中国高端用户。 在当天的展前供需对接会上，多款第八届进博会首发新品提前亮相。 进博会“全勤生”美敦力提前展出了5款首展产品和解决方案，包括1款亚太首展——美敦力全球首款闭环可充电脊髓神经刺激系统Inceptiv，轻薄小巧的它能够“倾听身体发出的声音”，感知不同动作下脊髓生物信号的变化并实时自动调整刺激，以帮助慢性疼痛患者获得更加持续一致的解决方案。另外4款美敦力的中国首秀展品则聚焦心脏相关疾病的诊疗。美敦力公共事务总监杨雅金说，截至目前，该公司已有近30款进博会明星展品实现“展品变商品”。第八届进博会上，公司首发首展的产品数量将为历届之最。 来自美国的多特瑞公司成立于2008年，是全球最大的芳香护理和精油企业之一，产品包括精油和居家生活产品。参加对接会的多特瑞公共关系资深总监刘玮透露，第八届进博会该公司的参展面积将从首届仅有9平方米扩大至今年的300平方米，而且将全球首发多年生草本植物艾草精油。 食品展商在水果上雕刻出第八届进博会倒计时100天字样。 出席对接会的波士顿科学中国区内窥镜介入事业部及呼吸介入事业部负责人潘晓抒表示，本届进博会，该公司将携80余款创新展品亮相。其中5款分别针对肝脏肿瘤、健康体重管理、房颤消融、颈动脉疾病和男性压力性尿失禁的创新产品将完成“首展”。波士顿科学通过进博会平台成功实现“展品变商品”的22款创新产品也将集体亮相。 进博局副局长吴政平表示，第八届进博会将在巩固提升交易团组织机制的基础上，推出一系列新举措，促进展客商高效对接。比如强化展前展中、线下线上对接撮合，结合各交易团特点，量身定制“一团一策”，引导交易团组织与进博会六大展区行业相契合的采购商参会；升级集中签约大厅配套设施和会务服务，助力展客商充分展示参会成效。网上供采大厅将为展客商在线提供需求发布、双向匹配、预约见面、展期行程规划的“一条龙服务”。"
    },
    {
      "doc_id": 57734,
      "title": "(进博故事)直播的流量“澳”秘",
      "time": "2025-06-12T00:00:00+00:00",
      "content": "中新网上海6月12日电 (记者 缪璐)“欢迎来到直播间……”“这个产品的最大特点是……”这些直播常用术语，给初到进博会的澳大利亚驻上海总领事馆(商务)副总领事、澳大利亚贸易投资委员会(以下简称“澳贸委”)高级贸易投资专员马杰(John Madew)留下了深刻的印象。 澳大利亚驻上海总领事馆(商务)副总领事、澳大利亚贸易投资委员会高级贸易投资专员马杰(John Madew)接受采访。(澳贸委供图) 每年的进博会都可谓天然的流量场。这里已经成为外商理解中国市场逻辑的重要“解码器”。中澳经贸往来也正以直播为支点，撬动数字时代的跨境合作新范式。 在2024年第七届进博会上，澳大利亚展团规模创历史新高，250余家澳大利亚企业参展，涵盖矿产、食品、保健、消费品等多领域。 对于这一数据，马杰分析道，澳大利亚公司参加进博会的热情很高，他们都将进博会视为开拓中国市场的绝佳机遇。 “在第七届进博会上，有近百家澳企是首次参加进博会，其中30家更是首次涉足中国市场。”马杰说。 初识“四叶草” 作为澳贸委高级贸易投资专员，马杰曾在全球多地开展贸易投资工作，因此十分了解贸易展是如何运作的。但初到“四叶草”，马杰还是被眼前的景象震惊了。 马杰说：“这是我第一次参加进博会。最让我震惊的是它的规模，展馆楼层多，展厅种类也非常多，且仅用7年时间便取得了今日的辉煌成就，实在令人赞叹。” 第七届进博会举办期间，澳贸委曾晒出总价值近3.77亿澳元(约合14.82亿元人民币)的“成绩单”。在马杰眼中，这些数字不只是跃动着的成交金额，更是进博会释放出的东方机遇。第七届进博会期间，虽然马杰没有逛遍每一个展区，但展品的多样性让他印象深刻。 马杰表示：“进博会是一个汇聚商务人士、促进对话的绝佳场所，他们可以在此开启、延续或完成关于业务增长的对话。这也正是进博会的魅力所在——它为人们提供了相聚的理由。” 直播新“澳”秘 在第七届进博会上，马杰完成了一场特别的“首秀”。他也由此发现，对于进博会而言，澳大利亚企业的变化趋势主要是可供利用的直播机会。 马杰(右一)在第七届进博会上进行直播。(澳贸委供图) 通过澳贸委首次设立的专属直播频道，马杰与一位拥有众多粉丝的“网红”合作，一同走访澳大利亚参展商，介绍并体验他们的各类产品。直播间实时滚动的成交数据，为“进博效应”写下生动注脚。马杰感叹，这展示着实实在在的“进博成果”。 澳大利亚凤雅堂集团董事长林冬梅对此深有共鸣。她认为，直播展示着澳中消费品市场合作的巨大潜能。凤雅堂旗下一款产品通过产品试用、供应链溯源直播，销量较参展前增长5倍。 作为进博会“回头客”，澳大利亚活曼特药业集团(Homart Group)在第七届进博会上开创性引入直播，现场互动异常热络。其创始人叶蓓玲对未来澳中合作充满期待：“中国现在有众多线上线下的新型宣传方式，很多都值得澳大利亚企业学习。” 在马杰看来，直播已成为中国市场不可或缺的一部分。“我们和其他企业一样，希望能快速顺应市场趋势，直播无疑是理想的起点。”马杰说。 施展大抱负 穿梭于进博会展馆之间，马杰每天都在刷新自己手机中的步数记录。而这些数字不仅丈量着进博会的全球化深度，更标记着进博会所展现的合作新维度。 马杰(左一)在第七届进博会上与客户交谈。(澳贸委供图) 进博会已成为展示澳大利亚产品的标志性展会，通过这一窗口，澳大利亚产品扩大了在中国的影响力。马杰期待澳大利亚和中国之间有更多的商业合作机会，同时，也希望在自己的3年任期中，将进博会作为施展个人才华的大舞台。 马杰说：“我在进博会期间总是在观察其他人，看他们是如何做的，在做什么，什么看起来好，什么有效，什么无效。我们吸取了一些经验，我们会把好的经验带到第八届进博会上，并加以改进。” 如今，直播在进博会上已比比皆是。从《进博新品汇》线上直播近3300万人次的观看量，到展商争相架起镜头实时推介产品，每一场直播都在缩短信任距离、放大品牌声量。未来，这一进博会的直播“奥秘”或将催生更多跨境合作创新，“四叶草”的东方机遇，也将为全球贸易注入新动能。(完) 举报/反馈"
    },
    {
      "doc_id": 57740,
      "title": "走近进博专栏 | “独行快,众行远” 谚语照进现实——“四叶草...",
      "time": "2025-03-28T00:00:00+00:00",
      "content": "尼日利亚驻上海总领事馆（贸易部）副区域投资贸易专员哈桑·穆罕默德（Hassan Mohammed）办公桌旁的架子上，悬挂着他在中国参加各类展会的证件，其中进博会的证件被集中放在最前排。 哈桑·穆罕默德（Hassan Mohammed）展示进博会证件 “每一张证件都是一段珍贵的记忆。即使未来我离开中国，回到尼日利亚，我也可以通过它们讲述尼日利亚和中国之间的贸易故事。我们希望尼日利亚能成为中国在非洲的第一大贸易伙伴。”穆罕默德说。 很多变化正在发生 穆罕默德是七届进博会的“全勤生”。首届进博会时，他作为官方代表，从尼日利亚来到中国参加进博会。彼时，进博会上展出的各类新技术、新产品，为全球客商提供的面对面交流机会，让他记忆犹新。 第二年，他被派到中国工作，与进博会结下了愈加深刻的缘分。七载进博之旅，穆罕默德感叹“很多变化正在发生”，尼日利亚企业因为进博会“一路生花”。 让穆罕默德印象最为深刻的是，在第七届进博会上，“我们邀请了来自尼日利亚的16家公司参加进博会，13家公司签署了商业协议”。尼日利亚一家企业与中国最大的可可豆加工公司之一签了一份价值超120万美元的合约。 尼日利亚腰果 尼日利亚腰果也通过进博会声名鹊起。此前尼日利亚腰果并不为中国消费者所熟知。通过进博会期间的现场展示，订购热潮便不断涌现。 穆罕默德认为，进博会为尼日利亚商人开辟了一条取得商业成功的大道，“尼日利亚企业与中国商人建立了合资企业，使他们扩大了产品生产，为尼日利亚国内创造了更多就业机会，这也转化为尼日利亚人民更多的收入”。 农产品成“金钥匙” 在非洲西部的黄金腹地，尼日利亚如翡翠镶嵌在几内亚湾畔，这片受热带阳光眷顾的土地上，可可树舒展着油亮的叶片，花生田在红壤中孕育着丰饶的秘密……每年进博会期间，尼日利亚丰富的农产品都成为叩开中国市场的“金钥匙”。 2024年中非合作论坛北京峰会期间，尼日利亚与中国签署花生输华合作文件，为尼日利亚带来新的机遇。尼日利亚拉各斯工商会国际及公共关系处负责人特米托佩·阿金顿德说：“前几届进博会上，我们的参展商展示的花生数量很少，未来我们有望在这个品类上进行深入拓展。” 第七届进博会尼日利亚国家展展台 图源：尼日利亚驻上海总领事馆（贸易部） 作为全球第四大花生产地，尼日利亚在进博会期间就收到中国公司想要购买花生的询问。中国对花生的高需求量，让这个西非国家看到了“弯道超车”的机遇。穆罕默德坦言：“尼日利亚很幸运，成为少数几个能把花生带进中国的非洲国家之一，同时我们也希望利用进博会这个平台，进一步推广尼日利亚的农产品。” 不仅仅是花生，尼日利亚还希望充分用好进博会平台，进一步发挥好非洲农产品输华“绿色通道”作用，将椰子、面粉等其他优质农产品销往中国。 从参展国到合作伙伴 早在首届进博会上，尼日利亚西南部阿贝奥库塔地区的传统服饰“阿迪莱”便颇受欢迎。将“阿迪莱”带到进博会上展示的尼日利亚展商恩沃佐·齐梅泽表示，与目前尼日利亚出口最多的石油、可可和芝麻等产品相比，“阿迪莱”更能体现尼日利亚的传统文化，能够让中国和世界更多地了解尼日利亚。他说，“我并不奢望第一次参加进博会就能签很多订单、做很多生意，我希望能与中国同行建立联系，寻找合作商机。” 除了中国市场，尼日利亚还在进博会收获全球商机。一位来自格鲁吉亚的商人与尼日利亚展商在进博会上达成了芝麻的贸易合作。穆罕默德表示，两地相隔万里，如果没有进博会创造的机会，所有的事情都会非常困难。 拉各斯工商会的成员企业对此颇有体会。阿金顿德表示，进博会在深化全球贸易联系以及凝聚全球商业力量方面起到了十分关键的作用。 穆罕默德说：“进博会就像一个地球村，参加进博会这样的活动总是有机会的。你四处走动，每个国家有不同的文化，不同的做事方式，你可以向他们学习，并利用和其他人交谈的机会，了解他们对你的国家的感受并推广你的国家。” 眼下，中尼关系已提升为全面战略伙伴关系。阿金顿德期待，尼日利亚可以从进博会的参展国发展成为进博会的合作伙伴，“我们可以探索在进博会期间共同举办双边论坛，并进行更多领域、更加深入的合作”。 从可可豆的芬芳到花生的醇香，从阿迪莱服饰的斑斓织锦到芝麻贸易的全球链接，正如尼日利亚谚语所言，“独行快，众行远”，在进博会搭建的广阔平台上，中尼合作的种子将继续生根发芽、茁壮成长并结出累累硕果，中尼携手推进现代化、共筑命运共同体的目标也终将实现。 原标题：《走近进博专栏 | “独行快，众行远” 谚语照进现实——“四叶草”见证中尼合作行稳致远》 阅读原文"
    },
    {
      "doc_id": 57742,
      "title": "关注|点燃法中美妆新火花",
      "time": "2025-03-20T00:00:00+00:00",
      "content": "导语 自2018年首届以来，进博会已连续七届成功举办。每年11月，来自世界各地的参展商跨越山海，共赴“进博之约”，在“四叶草”洽谈合作、收获订单、开拓市场。《外商话进博》栏目聚焦外商视角，生动呈现外商参与进博会的独特经历与真切感受，讲述爱上进博会的N个理由。 法国化妆品谷首次亮相进博会，携手法中美妆企业，共探行业新机遇。化妆品谷CEO克里斯托弗·马松表示，进博会不仅是展示法国美妆创新成果的平台，更是深化法中合作、推动行业发展的绝佳契机。点击视频，来看看他是怎么说的吧！ 来源：中国国际进口博览会 继续滑动看下一个轻触阅读原文 投资上海向上滑动看下一个 原标题：《关注｜点燃法中美妆新火花》 阅读原文"
    },
    {
      "doc_id": 57744,
      "title": "李潮东:进博会播下更多创新合作的“种子”",
      "time": "2024-11-11T00:00:00+00:00",
      "content": "08:52 人民网北京11月9日电（记者乔雪峰、任妍）在第七届中国国际进口博览会（以下简称“进博会”）期间，如新大中华高级副总裁暨北京代表处首席代表李潮东做客访谈时表示，当前中国经济对全球经济发展具有举足轻重的影响，推动着全球经济继续深度融合、互惠互利、共赢发展。进博会播下了更多创新合作的“种子”。 谈到如何看待中国经济发展时，李潮东表示，中国经济有自身的韧性，产业门类非常齐全、供应链高度配套，工业化门类齐全的程度少有国家可以比肩。 从首届到第七届，进博会播下的创新合作的“种子”，如今已落地开花，枝繁叶茂。“中国大市场是吸引大批外国企业、外国资本进入的动力。”李潮东表示，当前优化营商环境已经成为激发市场活力、进一步吸引和提振国际投资的关键因素，是各国推动经济转型升级的共同追求。 他说，改革开放以来，我国陆续实施了一系列改善营商环境的政策法规，不断地让法律法规能够更加符合经济社会发展的需要。 “中国依托超大规模市场优势，进口也在为各国经济发展和全球经济复苏提供动力。”他说，通过举办进博会，中国主动张开双臂，为世界提供了更多市场机遇、投资机遇、增长机遇。 举报/反馈"
    }
  ]
}