{
  "query": "字节阿里腾讯大模型价格战",
  "id": "qGFq56",
  "granularity": 23,
  "time_range": [
      "2024-05-21",
      "2024-06-03"
  ],
  "articles": [
    {
      "doc_id": 640,
      "title": "百度最新发布",
      "time": "2024-11-22T00:00:00+00:00",
      "content": "【导读】百度披露三季度财报，将于2025年初发布新版大模型 中国基金报记者 忆山 11月21日，百度发布2024年第三季度财务报告，三季度总营收为336亿元，核心营收为265亿元；归属于百度核心的净利润为75.4亿元，同比增长17%，超出市场预期。 在当晚的财报电话会上，百度创始人、董事长兼首席执行官李彦宏透露，百度将于2025年初发布文心大模型的新版本，以巩固其在基础模型上的领先优势。 李彦宏指出，百度坚持以人工智能为核心的战略，提升AI能力是百度的长期战略重点，亦是由人工智能驱动转型的基石。这一战略将使百度抓住长期的重大增长机会。 智能云营收为49亿元 AI收入占比超11% 三季度，百度智能云业务持续增长，营收为49亿元，同比增长11%，Non-GAAP经营利润率同比提升。AI贡献的收入占比超11%，对比去年四季度的5%，增长超6个百分点。 据介绍，报告期内，百度智能云进一步提升数万卡集群的管理能力，实现了99.5%的有效训练时长。同时，百度与闪送、金蝶和途虎养车等企业建立了合作。 百度方面指出，三季度，百度智能云的增长主要由互联网、教育、金融等行业对模型训练和推理的高需求带动。其中，来自腰部企业客户的增量收入环比增长170%。根据IDC报告，在中国AI公有云市场，百度智能云已连续五年位居第一位。 新版大模型将于2025年初发布 三季度，百度推出ERNIE Speed Pro和ERNIE Lite Pro两款增强的轻量级模型，进一步扩展文心系列模型的丰富性。 同时，百度持续迭代文心大模型的能力，优化模型效率。基于自研的四层人工智能技术栈优化，旗舰模型文心4.0 Turbo的推理效率显著提升，自6月发布以来，模型性能提升48%。 数据显示，11月，飞桨文心生态开发者数量达1808万个。文心大模型日均调用量达15亿次，相比去年四季度披露的5000万次，一年内增长30倍。 “文心大模型日益增长的调用量，证明我们强大的人工智能能力，正在获得更广泛的市场认可。”李彦宏表示，百度坚持以人工智能为核心的战略，并对长期发展充满信心。 据介绍，百度将于2025年初推出文心大模型的新版本，以巩固其在基础模型上的领先优势。 百度App AI功能已覆盖近七成月活用户 今年9月，百度App月活用户达7.04亿个，同比增长6%。随着AI对搜索的持续重构，当前，百度App的AI功能已覆盖近七成月活用户，用户与AI每日总互动次数可达数千万次。 目前，文心智能体平台已汇聚15万家企业和80万个开发者，涵盖公司、工具、职场、角色、娱乐等各类场景。以比亚迪官网智能体为例，上线后，其销售线索转化率提升119%。 百度文库也通过AI重构实现转型。今年9月，百度文库AI功能的月活用户（MAU）突破5000万个，同比增长超300%；用户付费意愿不断增强，第三季度订阅收入同比增长23%。 近期，百度发布了无代码开发工具“秒哒”，进一步降低了AI应用开发门槛。据了解，“秒哒”已吸引超过5000家企业排队测试。 李彦宏表示：“我们相信，将人工智能的能力拓展至程序员人群之外，将推动下一轮创新浪潮，释放出巨大的社会价值。” 编辑：舰长 审核：许闻 版权声明 《中国基金报》对本平台所刊载的原创内容享有著作权，未经授权禁止转载，否则将追究法律责任。 授权转载合作联系人：于先生（电话：0755-82468670） 举报/反馈"
    },
    {
      "doc_id": 641,
      "title": "百度的明天与中国AI下半场",
      "time": "2024-03-06T00:00:00+00:00",
      "content": "来源：网易新闻 十年磨一剑，百度AI终迎“花开”。 “10年间，百度研发支出超过1100亿元，增长了15倍。”去年百度发布2022年第四季度及全年财报时，媒体曾如此描述百度对AI巨额投入。 但时隔一年，在近几日百度发布2023年第四季度及全年财报之后，业内开始思索的问题却变成了： “AI将为百度贡献多少价值？” 在国内互联网巨头中，百度创始人、董事长兼首席执行官李彦宏似乎一直是“最疯狂的掌舵人”。“有1块钱的时候，会投进技术里；有1个亿，会投进技术里；有100个亿，还是会投进技术里。”曾有人如此形容他的执着。但时至今日，他率领的百度，终究用亮眼的业绩证明了“十年磨一剑，出鞘必惊人”的古朴哲理。 得益于抢占AI制高点，百度去年第四季度及全年的营收与利润均实现增长；同时，AI技术已全面重构百度生态，为百度创造出了新的增长动能。 可以说，在2023年AI技术席卷全球之时，已积累十年的先行者百度，的确是为数不多的、牢牢抓住这一波富贵的企业；且在AI技术革命的浪潮下，百度也是最有希望参与全球竞争的企业之一。 1、营收利润双增长，AI成新动能 从财报数据看，百度2023年第四季度及全年均取得良好增长：其中，第四季度，百度营业收入为349.51亿元，同比增长6%；净利润为77.55亿元，同比增长44%。放到全年来看，百度也实现了营收与净利润的双增长，具体为全年营业收入为1345.98亿元，同比增长9%；净利润为287亿元，同比增长39%。 ▲图：财报截图 从本次业绩来看，百度单季度与全年的均取得了较高的净利润增幅。而在如今互联网公司多出现净利润下降的情况，作为行业巨头的百度，依然有能力打破“增长天花板”取得高比例的增长，确实非常难能可贵。 与此同时，过去一年，百度全面推进旗下产品及服务的“AI原生化重构”，推出百度新搜索、百度新文库、文心一言App等AI原生应用，以及轻舸、品牌智能体等AI营销工具。一系列AI技术应用的成果也开始显现。 其一，百度核心呈现强力向上增长势头。财报显示，2023年百度核心（即搜索服务与交易服务的组合）营业收入1034.65亿元，同比增长8%；归属百度核心的净利润274亿元，同比增长38%。在线营销收入为751亿元，同比增长8%；非在线营销收入为284亿元，同比增长9%；爱奇艺收入为319亿元，同比增长10%。 ▲图：财报截图 其二，百度生态粘性不断增强。如财报中释放的两个信号：移动生态系统方面，2023年12月，百度App的MAU（月活跃用户）达到6.67亿，同比增长3%；第四季度，托管页（Managed Page）营收占到了“百度核心”在线营销收入的51%。 其三，百度真正成为AI驱动未来的企业，AI技术为其带来增长新动能。如李彦宏在财报电话会上就透露，百度智能云去年四季度总营收84亿元，其中大模型为云业务带来约6.6亿元增量收入。 在多模块的商业化方面，本次财报发布时百度也给出了喜人的成绩。在百度智能云方面，截至2023年底，百度飞桨（PaddlePaddle）开发者社区已增长到1070万人，为23.5万家企业提供服务，开发者已在飞桨上创建了86万个模型。 万众关注的文心一言大模型，它使用量与API调用量也均保持了高速增长。公开数据显示，截至2023年12月底，文心一言用户数超过1亿，累计完成了37亿字的文本创作，输出3亿行代码。 在TO B企业合作方面，文心一言大模型也实现了较为出色的商业化成果。如去年四季度内，中国三星、荣耀、汽车之家等头部企业均与百度达成合作。以三星为例，其最新旗舰手机Galaxy S24系列，就将会集成文心大模型多项能力，包括通话、翻译、智能摘要等。 多业务开花之下，曾不被看好的自动驾驶出行服务——萝卜快跑，也正在迎来它的“曙光”。财报显示，截至今年1月2日，萝卜快跑在开放道路提供的累计单量已超500万单；去年四季度，萝卜快跑服务单数同比增长49%至83.9万单，在武汉地区全无人驾驶订单比例达到45%，高于2023年第三季度的40%。 2、十年磨一剑，为AI“孤注一掷” 营收超千亿，百度做对了什么？虽然这一成绩背后有无数的构成，但找到自己的“长坡厚雪”——AI，绝对是百度在当下及未来制胜的关键因素。 自2013年百度开始布局AI，便开始了“漫长”的孕育之路。2013年全年，百度研发投入达人民币41.07亿元，同比增长78.2%，占全年总营收的比例接近13%。自此开始，百度在研发方面不断加大投入。而在其成为“技术驱动型公司”的同时，十年来也不乏不少质疑之声。 在外界看来，十年来互联网业态不断推陈出新，新玩法新产品层出不穷，百度除了坚守AI之外，没有新的故事可以拿出来吸引眼球，已经落后于时代。 但似乎只有百度自己，并不着急于没有搭乘上O2O、出行、社交、短视频、直播等快车，依然埋头坚持AI技术的投入。经济观察网去年11月报道中提到：目前在国内公司中，百度对AI投入最多，迄今已有1462亿元。 这一数字无疑是惊人的，特别是在2017年，在百度首届AI开发者大会上，百度喊出了“All in AI”口号之后，对AI技术的投入更坚决力度也更大了。例如，2022年，百度全年营收1236.8亿元，净利润为206.8亿元，同时研发投入高达214.16亿元。换句话说，当年百度挣的钱，全部都投入到了研发中。 但在过程中，外界对百度的决策也多有不解。曾几何时，人们对百度做“无人驾驶”的看法是“天方夜谭”；而今，它的自动驾驶出行服务却已经在全国多个城市遍地开花，众多消费者在惊讶中体验到了无人驾驶成为现实。 在去年OpenAI突然推出“ChatGPT”之时，国内大模型率先亮相的也只有百度的文心一言。虽然在当时，对文心一言的能力能否与“ChatGPT”抗衡亦是众说纷纭。但归根结底，在这场席卷全球的AI浪潮中，国内企业当时只有百度和OpenAI坐到了一张牌桌上；李彦宏也终于在发布会当天自豪地说出了：“百度是全球大厂中首个做出对标ChatGPT产品的企业”。 去年，作为一家全球为数不多的提供AI芯片、软件架构和应用程序等全栈AI技术的公司, 百度也被《财富》杂志评为全球四大AI公司之一，另外3家为微软、谷歌和Facebook。 3、AI下半场，百度仍有增长潜力 2024年，或将成为百度起势腾飞的一年。目前，包括高盛、大摩在内的20余家知名国际投行都看好百度，纷纷给出了“买入”评级，他们认为，AI已成百度增长新动力，百度未来市值增长空间巨大。 而这一结论也并非凭空论断，百度目前确已在AI方面占据诸多优势：比如，稀缺性。虽然目前做AI的公司很多，但是能实现商业化的公司却很少。但百度则相反，它是在国内AI商业化能力领先的模版。 正如李彦宏所说，“我们一定要去卷AI的原生应用，要把这个东西做出来了，模型才有价值。”李彦宏认为大模型对于绝大多数人来说都不是机会，“AI原生时代，我们需要100万量级的AI原生应用，但是不需要100个大模型。” 所以，百度最得天独厚的优势在于，其一它本身拥有庞大的流量和丰富的应用生态，大模型落地提效商业化的场景足够丰富。AI技术的施用，已让百度多业务领域均产生商业价值。 如财报中业绩亮眼的在线营销，之所以得到业绩增长就与其AI工具密不可分。去年10月百度推出的AI Native营销平台轻舸，就可以为客户提前布局投放，以突破获客瓶颈等。文心一言对百度智能云的加持也带来诸多效果，招银国际就预测，人工智能云业务的增加，有助于恢复百度智能云在2024年的收入增长，预估百度智能云收入在2024年同比增长12%。 其二，得益于自身AI技术深厚的积累，百度AI软硬件在TO B业务方面有更大的想象力。李彦宏在去年11月的演讲中就透露，国内有200多家大模型，“文心大模型一家的调用量比这200多家大模型调用量加起来还要多。” 随着文心一言大模型推理成本的降低，它的商业化价值未来预期还可以得到更大提升。在财报电话会上，李彦宏提到，百度不断降低文心大模型的推理成本，目前已降低至去年3月版本的1%。他还表示，文心大模型的日调用量已超过5000万次，约有2.6万家企业调用文心大模型。 4、写在最后 如今，无论是荣耀、三星、汽车之家等企业合作文心一言，还是北京市门头沟区、芜湖江北新区等政府部门合作百度智能云，都表明了政企客户对百度AI能力的认可。 但是，对于众多科技企业来说，更多的发展过程往往都是“十年窗下无人问，一举成名天下知”。这就需要企业能耐得住默默无闻的岁月，同时，也需要市场和用户给予其更多的鼓励和支持。如能做到众人拾柴，我们的科技之火必能烧的更旺。 作者｜吴南南 编辑｜胡展嘉 举报/反馈"
    },
    {
      "doc_id": 642,
      "title": "百度版ChatGPT来了,AI竞赛中国胜算几何?",
      "time": "2023-02-07T00:00:00+00:00",
      "content": "【文/观察者网 吕栋】 今天早上（2月7日），百度方面向观察者网确认，该公司“类ChatGPT”项目将在3月份完成内测，并面向公众开放，目前这一项目正在做上线前的冲刺。 受此消息影响，百度港股早盘大幅拉升，截至发稿涨超14%。 在过去两个月里，全球AI领域最出圈的应用非美国公司OpenAI推出的聊天机器人服务ChatGPT莫属。无论懂不懂技术，全球网友都在或多或少地谈论ChatGPT。 在发布短短五天内，ChatGPT的用户就已突破百万；发布两个多月后，ChatGPT的用户暴增至1亿人，成为人类历史上最快用户破亿的软件产品。 遗憾的是，由于国内手机号无法注册ChatGPT，让很多想登陆体验的网友颇为失望，他们迫切希望中国能做出类似ChatGPT的产品，来满足对AI的好奇。 但在满足网友的猎奇心态外，中国科技公司需要思考的是，ChatGPT到底能带来哪些商业价值。另外，掌握主动权不是简单模仿和盲目跟风，而是要结合自身特点做出独特优势。 “中国版”何时推出备受关注 在网络上众多的讨论中，ChatGPT被传出不仅能像人类一样进行聊天交流，还能完成邮件、文案、翻译等内容创作任务，甚至还有分析师尝试用它写研报。 如此现象级的产品，也彻底引爆了AIGC（AI Generated Content，AI生成内容）概念，带动起全球人工智能领域的第二波热潮。 在ChatGPT火遍全球之后，谁能率先推出中国版的ChatGPT，成为市场关注焦点。 2月7日，在对传言保持数日沉默后，百度方面向观察者网透露，该公司“类ChatGPT应用”将在3月份完成内测，该项目名称已被确定为“文心一言”（ERNIE Bot）。 作为国内首家透露“类ChatGPT”项目的公司，百度方面还表示，目前文心一言在做上线前的冲刺。按照谷歌和微软节奏，文心一言开放内测还有可能提前。 这一消息也在一定程度上佐证了彭博社等外媒之前的报道。但网友好奇的是，中国拥有众多的AI公司，为何百度会成为关注焦点。 这就不得不提一下ChatGPT诞生的相关技术背景：大算力支持、AI大模型、自然语言处理能力（NLP）和充足的资金。 在市场看来，ChatGPT是一次AI技术的“暴力式”突破，通过大算力的堆叠，全球大数据集不计成本的训练，最高性能硬件的支持，以及顶尖人才等因素共同实现。可以这么讲，如果说AI投入是一个吞金兽，那ChatGPT就是一个超级吞金兽。 这些因素也共同决定了一般的AI公司并没有能力去开发ChatGPT。而百度方面向观察者网透露，该公司拥有ChatGPT相关技术。在人工智能四层架构中，百度有全栈布局，包括底层的芯片、深度学习框架、大模型以及最上层的搜索等应用，而文心一言，位于模型层。 2019年，百度开发了AI大模型“文心”，该模型具备跨模态、跨语言的深度语义理解与生成能力，是一种与ChatGPT所基于的技术类似的深度学习模型，已被用来使其搜索结果更具相关性。后来，百度又开发了多个模型，并拓展它们的能力以纳入图像和艺术生成。 在此之前，虽然百度未对“国产ChatGPT”有任何官方回应，但资本市场已开始用脚投票，百度股价连日拉升，这也在一定程度上表明了投资者们对“中国版”ChatGPT的期待。 市场上近期有消息显示，“类ChatGPT”项目在百度内部由搜索（MEG）和技术中台（TPG）团队牵头，呈现形式将会是生成式搜索，也就是将搜索和ChatGPT结合。 目前来看，ChatGPT最显著的几个关键词——AI、NLP、搜索，都是百度的标签。联系去年9月，百度CEO李彦宏判断人工智能发展在“技术层面和商业应用层面，都有方向性改变”。据推测，百度那时候就开始做文心一言。 考虑到ChatGPT的爆火，未来觊觎这一市场的中国公司，肯定不止百度一家。抛开股市上炒作概念的上市公司，阿里、字节、腾讯等互联网巨头也均在相关领域有所布局，并在很多具体业务上都利用了AI加持。 近期有媒体报道称，字节正悄悄准备重启已经关停了两年的悟空搜索，联想到ChatGPT产品与搜索工具的关系，不难看出字节隐秘的想法。而工商信息显示，腾讯申请的“人机对话方法、装置、设备及计算机可读存储介质”专利获授权也正式浮出水面。 商业落地依然很难，但AI竞赛中国不能输 虽然在ChatGPT爆火后，很多人提到了谷歌和百度的焦虑。但不可否认的是，目前ChatGPT最主要的意义还是引发人们对AI的热情。在ChatGPT具体商业落地上，依然有很多难点。 以搜索引擎应用为例，不少国内行业人士认为，目前ChatGPT还是一个对AI技术范式的探索，它并不能代替搜索。ChatGPT当下一个很大的弊端是无法实时获取互联网信息。由于它只是一个端到端的生成模型，能够自我构造虚假答案，这些都是它替代搜索的障碍。而如果以目前每一条几美分的成本来看，它会让商业搜索引擎公司入不敷出。 眼下，国内业界对ChatGPT的共识是，它更善于“一本正经地胡说八道”。有AI行业研究人士指出，ChatGPT是一个黑盒计算，当下在内容的可信性和可控性上有一定局限，要给它足够正确的知识，再引入知识图谱这类知识管理和信息注入技术，还要限定它的数据范围和应用场景，使得它生成的内容更为可靠，这是业界需要做的。 但实事求是地说，ChatGPT确实代表了未来AI的发展趋势。 与传统的语音交互、图像识别等AI应用类似，ChatGPT也是一种人机交互。人通过文字和机器对话，获得内容。但ChatGPT的突破之处在于，它可以基于大数据集自己生成内容，而不是简单的比对和匹配。这意味着AI掌握了一定的自学习能力，技术迭代的速度大幅提升。 在所谓的AI 1.0时代，人们使用语音交互时，获得的内容是技术人员提前预设的，AI只是在海量数据库中做快速比对，如果数据库中并没有对应内容，AI无法自己生成内容。因此，ChatGPT的诞生也被市场认为是AI 2.0时代到来的象征，未来会影响到各行各业。 事实上，在满足网友好奇心和产业意义外，ChatGPT背后其实还暗藏着大国之间的AI战略竞争。2021年，美国政府曾明确提出，美国要想保住超级大国地位，必须在人工智能、量子计算、生物技术、半导体以及自主系统等五项关键技术上保持领先地位。 众所周知，人工智能事关国家安全，中国同样不能落后。早在2018年，中央政治局就曾定调，人工智能是新一轮科技革命和产业变革的重要驱动力量，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。 令人欣慰的是，过去5年，中国在人工智能领域的专利申请量比第二名及第三名申请量的总和还要多出一倍多，这意味着中国在人工智能领域的创新非常活跃。 第三方数据显示，2018年1月至2022年10月， 全球超过50个国家和地区共申请了115万件人工智能领域相关专利。分国家来看，专利申请数量最多的3个国家分别是中国、美国和韩国，专利申请数量分别是64.8万件、19.1万件和5.28万件。 随着“中国版”ChatGPT的推出，国内AI市场肯定会再掀起一波新的热潮。 本文系观察者网独家稿件，未经授权，不得转载。 举报/反馈"
    },
    {
      "doc_id": 643,
      "title": "内部腐败吓死人?!李彦宏讲话刷屏:马化腾说的问题,百度都有!要做...",
      "time": "2023-01-06T00:00:00+00:00",
      "content": "点蓝字关注，不迷路~ 2022年底，中国科技互联网公司仿佛有默契地一起释放调整信号，强调新一年要降本增效、更看重稳健经营。 据36氪，一篇题为“简单之约：谈机会谈挑战，新思考新要求”的文章发布在百度内网，其内容取自2022年12月末，李彦宏面向全体员工的一场内部直播，执掌百度人力资源体系的百度集团资深副总裁崔珊珊主持了这场直播。 “简单之约”，是百度管理层与全体员工沟通公司理念与战略的固定机制，由员工提问，高层答疑，每季度举行一次。 直播中，有员工问及Robin（李彦宏）是否关注到马化腾的内部讲话。此前马化腾在2022年内部员工大会上，谈及了业务部门改革表面、追求大数字营收、内部贪腐“触目惊心”等问题。 “腾讯的那些问题，百度也都有。”李彦宏答道，崔珊珊也补充：反腐的例子百度也经常看到，也是“吓死人”。 在内部讲话中，李彦宏还谈及技术投入、商业本质、公司管理以及百度未来的机会等多个话题。他表示，有些业务短期亏损是可行的，但长期来看就不行。对于他长期关注的话题“技术和创新”，他指出，“要做市场真正需要的技术，否则就是自嗨”。 李彦宏这份7000字讲话在6日引发市场关注。 股价方面，截至1月6日港股收盘，百度股价报收127.3港元。百度2022年第三季度财报显示，公司实现营收325.4亿元，同比增长2%；归属百度的净利润（non-GAAP）达到58.9亿元，同比增长16%。由于各项业务都取得不错的增长，2022年四季度以来，百度公司股价涨幅近七成。 谈技术：要做市场真正需要的技术，否则就是自嗨 对于李彦宏长期关注的话题“技术和创新”，他表示，百度依然非常看重技术投入和创新的，希望通过创新带动增长。与以往不同的是，他还强调了技术与市场的匹配，让技术专家不要“自嗨”，做市场真正需要的技术。 事实上，这并不是2022年李彦宏第一次在公司内部会议上谈起的技术和创新。2022年10月在公司内部总监会上，李彦宏完整讲述了百度的创新理念——“创新驱动增长，反馈驱动创新”。他要求各个业务“闭环化”思考问题。他说百度是全球为数不多、全栈布局的人工智能公司，从芯片（昆仑芯）、框架（飞桨）、模型（文心大模型等）、应用（搜索、自动驾驶等）都有覆盖。这是百度的优势和根本，如果每一层之间都有反馈，借助反馈，就可以实现端到端优化。 李彦宏还指出百度技术研发存在的问题，说做的技术市场不需要就是自嗨。他分享了自己对当前备受关注的人工智能问答程序“chatGPT”的看法。在李彦宏看来，“把这么酷的技术变成人人需要的产品”才是最难的。 谈商业：有些业务短期亏损可以长期不行 2021年在香港二次上市，百度在招股书中提出公司三个增长引擎，面向公司内部称为“三个增长曲线”。 第一个增长曲线是搜索为基础“移动生态”，有百度App、好看视频、百度贴吧等多个应用程序。这是百度的核心收入来源，2022年第三季度百度收入325亿元。 第二增长曲线是智能云，第三曲线是智能驾驶和其他的增长计划，比如芯片、造车、小度等。根据百度财报，第三季度百度广告收入之外的业务营收增长25%，推动公司收入增长。 李彦宏说，百度更加注重技术的投入，更加注重第二增长曲线，第三增长曲线。在第二、第三增长曲线上的投入，占整个百度的收入、利润比例可能更大一些，百度的研发强度，研发占总收入的比例是比许多科技公司更高。“我们也信这个，虽然现在亏钱亏得很厉害，但未来它会有相应的回报。” 但是，李彦宏也发现，“百度很多新业务都在亏钱，那么时间长了之后，大家觉得亏钱是理所应当的”。对此，他表示百度已经开始调整，毛利比收入更加有质量。他还要求关注经营利润：“有些业务虽然有毛利，但把研发和各种什么费用一减掉，还是亏的。短期说亏是因为高速成长是行的，但是长期来讲是不行的。” 谈AIGC：这是百度的机会，但技术还有不确定性 2022年11月底，美国人工智能机构OpenAI推出聊天机器人应用chatGPT，人们只需要输入问题，chatGPT就能给出看上去准确且有意义的回答。 chatGPT上线不到五天，就吸引了100万人用它写代码、回答问题、创作剧本、做游戏设定等等。一度有人提出搜索引擎将会受到重大冲击，存在价值会大打折扣。在全员会上，李彦宏也被员工问到如何评价引发巨大关注的chatGPT，百度有什么部署。 他认为，不论是AIGC（人工智能生成内容，比如输入一句话生成图片），还是chatGPT，都是技术、尤其是AI技术，发展到一定地步产生出来的新的机会。“这其实就是属于百度的机会，我们技术准备程度上是最好的。” 技术前景诱人，但李彦宏在全员会中透露着谨慎。他提醒，现在这个机会还不是很清晰，技术能做到这一步，它会变成什么样的产品、满足什么样的需求？“在这个链条上，其实还有很多不确定性。” 附讲话全文： 简单之约：谈机会谈挑战，新思考新要求 时间川流不息，来到新的起点。几天前，在2022年的末尾，Robin和同学们相聚“简单之约”直播间，用一个小时的时间，和大家一起回顾2022、展望2023，回答同学们提出的问题。面对时刻处在变化中的大环境，Robin也真诚地分享了很多自己思考过和正在思考的内容。 整场下来，干货满满，直播氛围虽轻松，聊的内容却挺烧脑，知识密度很高，就像一堂宝贵的认知课，值得同学们多看回放，细读报道。相信学习之后，大家对新的一年怎么打，如何才能实现更好的成长，会有新的体悟。 Part1回顾2022，展望2023 回顾2022 特殊的年份，难得的经历 珊珊：回顾2022年，我做了一张拼图。北京的同学一看就很熟悉，一张是12月初的西单，没有车、也没有人。一张是前天的国贸桥，车水马龙，非常漂亮。 Robin：2022年是大家非常想不到的一年。在我看来，这些都是人生经历。我活了50多岁，说实话也觉得2022年是一个特殊的年份，一生中有这么一种经历也挺难得。发生了没想到的事情，再想办法去应对，再进一步能够找到其中可以做得更好的地方，对于人的成长也是有好处的。 展望2023 想干事儿是中国人的特性 珊珊：再来看看对2023年的展望。也给大家看几张图，第一张是12月6号的中央政治局会议，第二张是12月15到16号的中央经济工作会议。一句话来概括会议内容，就是“明年是全力抓经济的一年”，第三张是总监群内分享过的一篇文章，讲的是有个人去了趟东南亚，看到那边有不少机会。在这种宏观形势下，Robin对宏观形势有怎样的判断，觉得可能有哪些新机会？ Robin：我其实非常推崇我们中华民族的文化。中国人是很想干事儿的，非常勤奋、努力。中央经常说我们的经济韧性十足，这其中有一个非常关键的因素，就是中国的民族文化就是“我想干事儿、想赚钱、想生活得更好，哪怕吃点苦”。一旦有机会，很多人真的会冲上去。 面对挑战，要抢机会、讲创新 珊珊：从整个宏观角度来说有很多机会，具体对于百度有没有哪些机会？ Robin：既有机会，也有挑战。更重要的是，我们还是要抢机会、讲创新。 增长从哪里来？从创新来，创新驱动增长。过去这几百年，不光是中国，整个世界的增长全部都是因为创新、因为效率的提升。百度这样的公司，还是依然非常看重技术投入和创新的，希望通过创新带动我们的增长。 把技术变成市场需要，就是属于百度的机会 Robin：过去这么多年，我们在人工智能技术上的投入，现在也逐步能看到各种各样的新机会。我们过去讲第一曲线、第二曲线、第三曲线，其实即使放到第一曲线这样一个比较成熟的业务来看，过去一年也仍然有很多新机会出来。 例子：AIGC。我们做了这么多年的AI之后，发现过去AI试图理解人、模仿人，现在AI可以生成内容。其实在这个领域，我们在过去很多年都有技术的积累。 产品也好，功能也好，怎样把技术转化成市场需要的东西，这就是属于百度的机会，我认为我们在准备度上是最好的。当然，我们对于市场的敏感度是不是最好的，这存疑。这需要我们更敏感，能更快、更准确地抓住到底用户和客户的需求在哪里，这方面我们还是有很多功课要做、很多课要补。 Part2多元问题，答疑解惑 Topic1谈要求 看到第三季度财报中也有明确提出“有效的降本增效带来了公司运营效率的提升”，感觉今年很多要求都放在了效率提升上。明年公司在运营效率上还会有什么样的导向？对员工来说，有什么要求？ Robin：我们更加注重技术的投入，更加注重第二增长曲线、第三增长曲线。我们在第二、第三增长曲线上的投入，不管是在百度收入中的占比、还是利润占比都可能更大一些，我们的研发强度、研发占整个收入的比例是比腾讯高的。我们信这个，虽然也觉得现在亏钱亏得很厉害，但相信未来它会有相应的回报。 重申商业本质，细究收入质量 Robin：在践行“降本增效”理念的过程中，我说一说我碰到的一些问题，以及一些自己没有想到的情况。 我在10月份总监会上也讲过，很多人对商业的本质理解是不深的。由于我们很多新业务都在亏钱，所以时间长了以后，大家觉得亏钱是理所应当的，不会去想这个业务是再过三年能赚钱、还是再过五年能赚钱、还是再过一百年也不会赚钱。 这些新业务在设置OKR的时候，最长的维度就是年度，年度OKR里写收入的增长目标是多少。可是这个收入是怎么来的，质量怎么样？这个问题，不要说普通的员工，即使是很高级别的管理者思考得也不多。我们的一个明星业务、一个高增长业务，仔细一看，自研产品只占收入的20%多，70%多的东西都是转售。那你跟贸易公司有什么区别呢？贸易也是从这儿买回来，从那儿卖出去。我们那么多人在做研发，一万多的工程师，研发投入占收入的20%多，跟我们业绩实际获得的效果却有这么大的反差，这个问题有多少人意识到了？有多少人意识到了其实这个收入质量不高？ 毛利、运营利润、现金流是更有质量的信息 Robin：如果不看收入，应该看什么？上次总监会我讲过，比收入更加有质量的东西，实际上是grossprofit，不是毛利率，是毛利。 公司在大概二十年前，就有grossprofit的概念。我们早年做搜索业务，有一部分收入来自联盟，联盟的流量其实是买来的，挣的钱要和这些流量的伙伴来进行分成。所以不管是对整个公司的考核，还是对相应业务负责人的考核，我在说收入的时候，都叫做revenuenetofTAC（TrafficAcquisitionCost，流量获取成本）。因为你加上买量的成本算出来的收入，不能说明什么。把买流量的成本减去之后的收入，才更说明我们这个搜索业务的本质。 但是到后来做各种各样新业务的时候，大家慢慢忘了：为什么我要做这个新业务，为什么我一年要亏10亿、50亿去做这个东西。grossprofit是一个质量高的信息，比它质量更高的是operatingprofit，也就是你的运营利润是多少。你虽然有grossprofit，但是把你的研发和各种费用一减掉，可能还是亏的。短期说“亏是因为高速成长”是行的，但是长期来讲是不行的，从运营水平上也要能够有profit，这才是一个好的业务。这些标准，我们早期的搜索业务都是满足的。正是由于它太满足，以至于我们每一级的员工、每一级的管理者早就忘了这件事情。 珊珊：或许因为有些年互联网就是这样的，都亏，但是仍然可以被估出值。 Robin：要看到这背后为什么亏还能被估值——因为相信你有一天会赚。这些业务即便是在亏的时候，grossprofit也是很高的，之所以会亏，是因为花了好多钱去做广告、做研发，也就是业务的nature其实是非常高毛利的。比如像淘宝，不算净利，就看收入，它绝大多数的收入能够转化成它的毛利。由于大多数的互联网业务都是这种业务，所以我们早就忘了收入到底是什么意思，以及为什么要关注grossprofit、为什么要转成grossprofit。 其实operatingprofit也不是最后一步，最后一步是cashflow。即使账面上有这么多收入，但实际上那些钱没收回来，都是客户欠你的钱，过两天客户倒闭了或者赖账，那还是不行。很多toB公司不是没有profit，也不是没有operatingprofit，而是没有cashflow，没有现金流，最后资金断裂死掉了，这样的公司有很多。 “层层递减”不可取，提高站位看长期 Robin：我们对这套逻辑不熟悉，大家在那儿玩命地打，公司要GMV我就做GMV，公司要DAU我就做DAU，公司要收入我就想办法把流水变成收入。有时候我们对于业务的理解变成了“层层递减”。当我把这些理念去跟我们的VP、总监对齐的时候，他们也同意，但是当落到一个总监的OKR里头的时候，有些人的OKR里可能会有收入，有些可能连收入都不体现，OKR里只写时长需要增长到多少。这样当他再往下传递的时候，下一级就变成说“老板要的多少时长，其他的我们不管”。 我们这个公司可能有五级甚至六级，传到最基层、传到真正干活的一线员工的时候，他根本不理解“我为什么要干这个事”，或者他虽然理解了，但是不觉得“这东西跟我有什么关系”。这就导致大家越往下做，就越在做短期的事，做了很长时间后突然回头说“哦，有可能做错了，这不是我们想要的东西”，这是很糟糕的，尤其是当我们愿意花很多钱去投入的时候。高层愿意为长期的结果去投入，你今年不赚钱可以，三年不赚钱可以，五年不赚钱也OK，但我希望你七年之后赚钱。可实际上当我们在执行的时候，有人去看七年后的事情吗？ 我希望我们每一级的人，尤其是当你想要往更高级别走的时候，你要站在一个更高的角度去思考这个问题。我们现在用的是OKR，但是一旦分解下去，大家就去看那些数，不管是O里的数，还是KR里的数。甚至有时不管O是什么，如果O里没数，就不看O只看KR，只去完成一个数，很多时候都变成了这样。但更多的时候，我们做事情除了满足所谓的OKR，也应该跳出这些数，去看一看我拿来的这个数，对于业务长期的成长、长期的健康性到底有没有用，是有正面作用还是有负面作用。 反复对齐，对抗惯性 珊珊：今年ACG、IDG的员工，其实是可以看到业务的负责人实际上是被要求了毛利的提升的。 Robin：对，这个话已经说了很多遍了，但是要把大家这种做事的惯性或者思维的惯性改过来，真的是不容易。我在会议室里，不知道对同一批人说过了多少遍，我说明年我不看收入了，就看毛利，但下次开会，他们又照样跟我说我们的收入是这样，别人的收入是那样，我们对比下来是怎样。 我每遇到一次这样的情况，就会再讲一遍，同一批人可能得讲个五六遍之后，这种惯性才能够改过来。你问他懂不懂这些道理，都懂，实际做，却是说“过去都是这么做的呀，所以我现在还这么做呀”。Humannature就是这样，“习惯了”。所以今天我们又花这么多力气在这对齐，讲一遍可能还不够，但总比不讲要强。 Topic2谈战略 Q3、“新十条”发布以后，百度上线了疫情指数，用信息流动对抗未知恐惧。京通小程序的上线，百度也是首发。这些贴合热点的迅速反应，体现了我们的社会责任。想问问Robin，在后疫情时代，百度怎样进一步体现责任和担当，还可以贡献哪方面的价值，什么是属于我们的机会？ 让人们平等便捷地获取信息、找到所求，是一件了不起的事 珊珊：“新十条”发布后，像是每天的新增发病数字，卫健委发布的跟大家的切身感受完全对不上，而我们的疫情指数当时还是很管用的。 Robin：这种时候恰恰是百度能够发挥作用的时候。我那几天其实挺兴奋的，我们的数据、我们的服务能够让更多的人更及时地看到真相，获得他们在其他地方不能获得的信息，这是一件很伟大的事情。我们以前的使命也是这么说的，“让人们平等便捷地获取信息，找到所求”，这种作用在一个充满巨大不确定性的环境中，越发显得重要。 搜索其实是无数人用他们的行为，告诉我们现在的情况是什么样子。如果我们能够把这样的情况综合起来，并且呈现给每一个人，他就没有那么慌了——不是他的周边有多特殊，而是整个大环境就是这个样子。尤其当他看到一些预测，说到了多少天后趋势就会平静下来，那他就会觉得说，“我可能不需要囤一年的食物吧”。历史上出现过好多次这样的情形，在大家比较懵圈、不知道该怎么办、不知道下一步会发生什么的时候，我们尽量让大家获得及时准确的信息。 一般出现这种情况，对百度来说其实没什么钱赚，就是流量涨、收入降。但我觉得不光是我，每一个参与到这个工作的人、每一个百度人，都会觉得我们能在这个时候起到这样的作用，能够被别人所依赖，是一件很了不起的事情。 当别人很依赖你时，机会总会有的 Robin：当别人很依赖你的时候，机会总会有的。整个搜索业务这么多年，最本质的东西，就是当别人想知道什么是事实，当别人想知道对方说的是对还是错的时候，他来百度一下，他说“百度说的是这样的，所以我信”。 HCG的同学那些天也一直在做需求，当时面对的就是“需求太多，做不过来”，因为很多人在找药、找医生。但大家不管多忙多累，都在坚持工作，因为有太多人需要我们。这种感觉也挺好。 Q4、最近一段时间，AI领域也有很多进展，比如AI作画，AI对话（ChatGPT），AI写作……Robin怎么看待这些AI应用方向，百度未来又会在这些方向有什么规划或部署？ AI技术的产品化，很兴奋、有责任 Robin：很多人问过我这个问题，不光是周边同行业同领域的朋友，好多不同领域、跨界的人都在问我怎么看ChatGPT。我很高兴这么一个我们天天在琢磨的技术方向，能够引起这么大的舆论场，能够让这么多人关注，确实是挺不容易的。 无论是AIGC，还是ChatGPT，都是新东西，都是AI技术发展到一定地步后产生的新机会，虽然现在这个机会还不是那么清晰。技术能做到这一步了，但是它会变成什么样的产品，这个产品能满足什么样的需求，在这个链条上还有很多不确定性。所以一方面，我们很兴奋，另一方面，我们也觉得责任挺大的。作为一个公司、一个商业机构，我们有这么酷的技术，那我们能不能把它变成人人需要的产品？这一步其实才是最难的，也是最伟大、最能够产生影响力的。 四种类型的创新 Robin：我最近在看一些有创新的资料，它总结了四种类型的创新。 第一种是从左到右的创新。从科学、从基础理论开始推演，一步步变成技术，技术再变成产品，产品再推向市场。 第二种是从右到左的创新。产生了一个需求，再往回推，看能不能做一个demo、做一个产品；产品再往回推，看能不能实现这样的技术；技术再往回推，看技术背后的理论到底是什么，能不能实现这样的事情。 第三种是manufacturewiththeinnovation。也就是你生产的产品不断扩大制造规模的过程当中，自然而然产生出来的那些创新。我认为中国作为制造业大国，在这种创新上是有优势的，比如生产新品，比如说台积电，大家以前觉得是个代工，现在发现门槛很高、不容易，这种创新就是生产制造带出来的创新。 第四种是机构式的创新。整个机构就是一个创新机器，它的目的或者说作用就是想尽一切办法去产生各种各样的创新。 在百度，这几类创新我们多多少少都沾点边。但是怎么真正产生出来大的创新，怎么让我们的机制能够更高效地产出创新，这是一个非常有意义的课题，也是我最近在琢磨研究的事。 AIGC商业化，虽难必做 珊珊：如果说AIGC，你对百度有什么期望的话，你是希望我们能够率先在商业化上摸索出来？ Robin：当然。创新不是说一个技术过去没有，真正的创新是说，这个过去没有的技术到底产生了什么样的社会影响，而这个影响一定得通过产品、通过商业化应用才能够产生，这一步其实是最难的，但也是我们必须要去做的事情。 Topic3谈导向 Q5、总监会讲到的“端到端优化”占篇幅挺多，但不太好懂。怎么理解这里的“端到端”？怎么定义“端”？落到具体业务上，怎么做是“真端到端”，怎么做是“假端到端”？ 讲透“端到端”，平台化or纵向整合 Robin：这个概念确实比较难理解，因为它涉及到战略层面的思考和发展理念的问题。“端到端”并不是放之四海皆准的，有些公司就非常明确地说，“我就做平台，不做端到端，我更相信横向分工”。 其实，不光是在IT产业，我们看汽车产业，也是这样的。在汽车领域，早期的福特就是做端到端的，什么零件都做，只不过它是用流水线把效率提升了。最后颠覆福特的是一种横向的、精细化的分工。丰田就说，“很多东西我都不做，我都靠供应商，供应商去做汽车配件的话，会比我自己做成本更低、效率更高。”最终依靠这个颠覆了福特。在IT领域，苹果是在做明显的“端到端”，什么都做，所以它做出来的手机最高端、体验最好。而安卓的理念就完全不一样，他的理念就是：手机做不出来或者卖不出去都OK，我照样是一个非常成功的平台。 Robin：所以，当我们在讲“端到端”的时候，其实是在思考：从整个百度大的业务线条上来看，我们到底是走平台化道路，还是走纵向整合的道路。 规模足够大，“端到端”的效率才最高 Robin：我们要搞清楚，一定要有足够的规模，“端到端”才是效率最高的。如果你这个业务很小，其实不一定要做“端到端”，效率也不一定是最高的。 不管是针对MEG、ACG还是IDG的业务，大家在思考“端到端”的时候，一定要想：我能不能把规模做得足够大？在规模足够大的情况下，我们把芯片层、框架层、模型层和应用层串联起来之后，有意为这个东西做优化，最终达成效率的提升。如果我能够给每个客户节约50万，但需要的研发投入是5000万。这就意味着，如果客户数目小于100个，就不划算了，还不如不做这种“端到端”的优化。 要不要做“端到端”，就看是不是“真提效” Robin：我以前也在不断地讲“创新的本质是提升效率”，如果你做的这个创新使得效率提升了，这才是好的创新。如果你做的事情让效率下降了，那就不叫创新，或者说不是好的创新。所以当大家把自己的具体业务和“端到端”结合起来看的时候，一定要具体问题具体分析，最终还是落在“创新的本质是效率提升”上，看是不是真的提升了效率。 对于很多其他公司来说，做平台是没错的，甚至对于百度某些业务来说，做平台也没错。因为对于他们来说，做“端到端”不是最高效的做法。 如果你做了这个判断，就想做个平台，认为做平台效率更高，能够为公司赚更多的钱，那也没问题。只是当我去分析我们最主要的几个业务，比如ACG云业务，从规模上讲，我们既不是NO.1，也不是NO.2。而NO.1的理念就是做平台，搭一个台子，让所有人来这儿唱戏就好了。如果我们也同样说：我就搭个台子，你们都来这儿唱戏。那人家凭什么都到你这儿来唱戏？但是我们可以做“端到端”优化——假如你做的是生物计算，你可以跟客户说来我们这儿得到的服务一定是最高效的、质量最好的、反应最快的；假如你是做自动驾驶的，你可以跟客户说把云放到我这儿，我这儿高精地图、仿真服务、昆仑芯片什么都有，你就应该来我这儿。 珊珊：也就是说，如果没那么多生态依赖你，你就不要觉得自己还能做一个平台。 Robin：是的，如果你做了半天，没有人给你付费，没有人愿意为你这个平台来开发产品、开发应用，那其实也不叫平台。还是需要好好想想我们能解决什么问题。但我一开始为什么说这个问题难呢，是因为它不是一概而论的，要好好思考手头的业务到底和这个理念契合在哪里。 Q6、Robin说要找准大盘、选择合适的指标，总监会上也强调有些没有利润的指标难以反应业务的实质。现在正在制定年度规划的时候，能不能指导一下怎么才能看到业务的实质，找准合适的大盘和指标？ 认清业务本质，才能找准大盘 Robin：刚才回答的两个问题，无论是“创新就是效率的提升”，还是“端到端”，多多少少都跟这一题有关系。 刚才说创新效率是从收入到毛利、到纯利、到现金流，整个过程都是在帮助大家理解业务的本质是什么。而“端到端”是更进一步去分析你所做的这件事的本质是什么。当你看到本质以后，再去制定你的OKR、再去往里放“数”的时候，你才知道：为什么要放这个数，为什么看重这个数，用什么手段做到这个数就是做对了，用什么手段做到这个数就没做对。 每一个业务都不太一样，我们很难有一个统一的规则，所以这也需要发挥大家的分析、判断能力来做。但是我知道过去我们有很多做错的时候，我们放一个数在这儿，过了很长时间以后发现说“哎呀，这个数做对了没什么作用，并不能真正地达到我们当初想要达到的目的”，这时候就是对标错了大盘。比如，他要资源的时候总是说“我们要对标小红书，你看小红书一年要投多少广告费”，但是让他做一个小红书这样的东西，他又说“哎呀，小红书有一万人在做，我们只有一百人在做，所以我做不到那样子”。这是经常能见到的思维方式。 提升认知高度，做市场真正需要的技术 珊珊：第5、6两个问题和第1、2两个问题，实际上是跟业务或者说商业的本质有关联的，可能一线同学们不太接触这些东西，但是懂点总是好的。有很多高T的知识范畴实际也很窄，他们不了解这些，但了解一下也是有好处的。 Robin:你了解了，才能更加知道我们为什么要做这个事，甚至判断出我们该不该做这个事。不光是高T，所有做技术的人，都希望他做的技术能够产生影响力，他做的技术是市场真正需要的技术、是无数人依赖的技术，但是很多时候不管是出于个人能力的局限，还是体制机制的局限，导致我们这些技术同学做的事其实离市场很远，很多时候是自嗨，自以为做得很不错，“我发了顶会的论文，我申请了专利，我打了哪个榜”，但是过了一两年之后发现这东西没有被用，或者虽然表面上被用了，但当你去问这些业务同学“你愿意为这个技术付多少钱”，他会说“白用可以，让我出预算，我不愿意出”。 这种问题对于技术人员其实是很大的打击，他过了挺长时间才明白“我做的技术不是市场真正想要的技术”。这很糟糕，对公司是资源浪费，对这些同学是很大的时间和精力的浪费，如果我们早一点告诉他“你做的不行、做的不对，你得做成那样才是市场需要的”，那该多好。 我们经常看到有些人写周报用三种颜色，绿色是好消息，红色是坏消息，黑色是正常内容。有些人的周报永远是好消息，这儿又提升了多少，那儿又超过了谁谁谁，永远看不到我们哪些进展不符合预期。但是他负责的那些事儿，真的永远都是符合预期的吗？如果你不说哪些东西不符合预期，在哪儿遇到了困难，你的上级怎么帮你？反而你的上级都被你蒙住了，他以为你做得特别好，不需要任何帮助。有时候这些同学也不是“成心”，就是个认知问题，没有站在那个高度去看，所以我要把这些东西说出来，来帮助他站到那个高度上去。 责编：叶舒筠 校对：廖胜超 直播预告 版权声明 王锦程 证券时报各平台所有原创内容，未经书面授权，任何单位及个人不得转载。我社保留追究相关行为主体法律责任的权利。 转载与合作可联系证券时报小助理，微信ID：SecuritiesTimes END 举报/反馈"
    },
    {
      "doc_id": 645,
      "title": "用大模型“百度一下”,是种什么体验?",
      "time": "2022-12-05T00:00:00+00:00",
      "content": "金磊 发自 凹非寺量子位 | 公众号 QbitAI 百度最擅长、最知名的搜索，要“变味”了。 因为这一次，他们决定把大火的大模型也丢进去做成产品了。 这个大模型，就是百度自家的“最强兵器”——文心大模型。 AI大模型应用在搜索场景，带来的新产品则叫做文心百中。 好奇的小伙伴肯定要问了，那它跟我们传统搜索会有什么不同呢？ 举个例子。 针对“山城是指的哪个城市”这个问题，传统基于关键词搜索的结果可能会是这样的： （注：“相关度”采用ES默认计算方式，分值为0～1区间，分值越高说明模型认为结果越符合检索需求） 但很显然，传统搜索的结果并不是我们想要的那个答案。 而这个问题到了文心百中手里，得到的答案就通灵了： （注：置信度由百中搜索模型计算得出，分值为0～1区间，分值越高说明模型认为结果越符合检索需求） 这只是文心百中在“知识搜索”里的能力展现，它对于开发者还制定了特定的搜索功能。 例如在“开发者搜索”里输个“Java”，会得到这样的结果： 可以说搜索的结果是相当垂直、相当“技术流”的那种了：清一色都是概念介绍、热门GitHub项目、官网介绍等。 但纵观文心百中所涵盖的其它领域，一个非常明显的特点就是很To B。 换言之，它的发力点不单是普通用户、开发者，还聚焦在了许多产业领域之中。 这一点，在近期WAVE SUMMIT+ 2022深度学习开发者峰会上百度对它的介绍不谋而合——大模型驱动的产业级搜索系统。 文心百中的特点可以总结为三点：“极简的系统”、“强大的语义理解”和“极低的人力成本”。 百度CTO、深度学习技术及应用国家工程研究中心主任王海峰还提到： 具有算法、算力和数据综合优势的企业，可以将模型生产的复杂过程封装起来，通过低门槛、高效率的生产平台，为千行百业提供大模型服务，从而形成一条大模型产业化路径。 这也正是百度文心大模型产业化路径的一个缩影，而铺设这么一条路百度已有数载时间。 那么站在现在这个时间节点，大模型的产业之路，或者更广泛的来说是AI的产业化之路，都有啥新进展？ 我们不妨一同来看下。 百度的大模型之路：越发亲民、易用 “亲民”、“易用”，是纵观整场WAVE SUMMIT后，对百度大模型最为直观的感受。 这里可以从两个方面来理解。 其中之一便是越发接地气，“文心一格”的能力升级便是很好的体现。 文心一格是百度今年8月推出的AI艺术与辅助创作平台，用户只需要往里面丢自然语言，就能生成风格多变的画作—— 把“凤凰”相关的表述输入进去，再选择相应风格，就能得到下面这张恢弘绚丽的作品： 而这一次，百度把文心一格变得更加亲民、功能更加丰富。 例如可以“以图生图”，通过用户输入的图，可以生成按用户指定要求风格的一些新图。 还可以“文字编辑图片”，只需要简单描述下文字，就可以极简地对图片进行编辑。 不仅如此，还可以让图片一键生成视频。 这便是文心大模型“接地气”产品化的其中一面。 而另一面，则是在固有大模型的“根节点”基础上，以“产业级”、“知识增强”为路径，不断向下繁衍出更多“叶节点”——聚焦产业的大模型。 整体而言，这次文心大模型又发布了11个全新大模型： 5个基础大模型 1个任务大模型 5个行业大模型 五个新基础大模型 首先是在NLP大模型方面。 这次推出了知识增强轻量级大模型ERNIE 3.0 Tiny，它是以ERNIE 3.0千亿参数大模型为“教师”，通过多任务知识蒸馏手段，将“毕生所学”浓缩到了一个轻量级模型（10亿级、亿级和千万级）。 ERNIE 3.0 Tiny一大特点就是具备较强的泛化能力，相对于超大参数模型而言，推理速度提升数十倍到百倍，能够显著降低超大参数模型落地的成本。 跨模态方面，新增了3款大模型。 跨模态理解大模型ERNIE ViL 2.0，采用多视角对比学习方法，同时构建模态内部与模态之间的表示对齐，在中文、英文效果上均超越业界最优模型。 据了解，ERNIE-ViL 2.0已在飞桨企业版EasyDL上线，支持一站式的精调训练、推理，可用于多种图文匹配应用场景。 跨模态生成大模型ERNIE ViLG 2.0，属于知识增强的混合降噪专家模型。 它的训练过程引入了视觉知识和语言知识，可以提升模型跨模态语义理解能力与可控生成能力。 在扩散降噪过程中，ERNIE ViLG 2.0通过混合专家网络建模，增强了模型建模能力，提升了图像的生成质量。 文档智能大模型ERNIE-Layout，它是以文心多语言ERNIE为基础，融合了文本、图像、布局等信息进行跨模态联合建模，还引入了布局知识增强，提出阅读顺序预测、细粒度图文匹配等自监督预训练任务，并最大支持96种语言。 它所擅长且已应用的领域包括金融、保险、能源、物流、医疗等行业。 最后是在生物计算大模型上，推出了单序列蛋白质结构预测大模型HelixFold-Single，它是业界首个开源的、基于单序列语言模型建模的蛋白质结构预测大模型。 从近3亿的无标注蛋白质数据中提取信息，建模蛋白质之间的关系，从而将MSA同源信息隐式的学习在预训练大模型中，进而有效地替代MSA信息检索模块，使得模型推理速度提升数百倍。 从效果上来看，HelixFold-Single在抗体蛋白结构预测上比AlphaFold2更优，更有助于抗体药物的设计 。 一个新任务大模型 代码大模型ERNIE-Code，它是在海量代码和文本数据基础上进行预训练，采用多语言多代码联合学习。 由于ERNIE-Code基于中间语言的翻译语言模型，因此它还具备跨多种自然语言和编程语言的语义理解和生成能力。 据了解，ERNIE-Code在代码生成任务、代码搜索任务，多语言代码摘要和代码文档翻译等多个公开的评估基准上取得领先效果。 5个行业大模型 在此之前，文心行业大模型已经发布过6个，而这次，又有5位成员被涵盖了进来。 它们分别是： 深燃-百度·文心：知识增强的燃气行业大模型 吉利-百度·文心：知识增强的汽车行业大模型 泰康-百度·文心：知识增强的保险行业大模型 TCL-百度·文心：知识增强的电子制造行业大模型 辞海-百度·文心：知识增强的社科行业大模型 …… 除此之外，在工具与平台层面上，百度还将大模型的开发套件全面升级，开箱即可用的建模、定制、精调和可信学习工具。 再如飞桨企业版EasyDL零门槛AI开发平台和BML全功能AI开发平台，升级提供全流程开箱即用的大模型能力。 这就是此次百度在大模型上的最新动作，也是大模型应用的最新风向标。 不难看出的一点是，百度的文心大模型产业味道非常浓厚，它的“叶节点”正在向千行百业蔓延开来。 或许对于百度而言，大模型和行业大模型之间的关系，也展现出面向产业开放和赋能的一面。 好比武林至尊把自家的兵工厂、铸剑池，对外开放，帮助需要的任何产业方打造趁手兵器。 如果说文心大模型是百度自家打造的“独门宝剑”，完全是基于自身的武功、特点、需求打造的工具，主要为自己服务。 那么产业大模型，就是百度给产业各方提供了铸剑服务，帮助打造所需的工具，来自产业需求，用于产业痛点，而且产业方完全不需要掌握大模型这样的高门槛技术，借助百度就能完成符合自己需求的大模型。 而如此能力背后，还离不开大模型背后更为底层的一个东西，那便是深度学习平台飞桨。 在这次的WAVE SUMMIT中，飞桨同样也有了较大的升级。 飞桨升级2.4版本，“产业味”更重了 用王海峰的话来说，飞桨这个深度学习平台是基础共性平台，下接芯片，上承应用，相当于智能时代的操作系统。 其在AI技术应用、AI产业化进程中的重要性可见一斑。 而且飞桨作为一个深度学习平台，虽与文心大模型“异曲”，但从出发点和目标来看，却又有着“同工”之妙——加速AI的落地。 为此，时隔半年之后，飞桨已经步入到了2.4版本的阶段。 若是将这次的升级提炼出三个关键词，它们分别是技术、功能和生态。 首先是在技术方面的“三部曲”： 开发：新增稀疏计算、图学习API；升级高阶自动微分能力，支持科学计算应用；动态图转静态图技术升级，支持复杂模型导出和部署。 训练：业界首个同时支持复杂算法+超大图+超大离散模型的大规模图学习训练技术，单机即可支持百亿节点、数百亿边的采样和训练，并可通过多机扩展支持更大规模 部署：高扩展、自动化、高性能推理技术助力大模型应用；新发布AI部署工具FastDeploy。 这是在技术层面上的能力提升，也是飞桨每年在WAVE SUMMIT上必秀的一块肌肉。 其次是在功能体验方面，可以说是“产业味”越发浓郁。 例如飞桨这次发布了业界首个一站式开源大模型开发套件PaddleFleetX，可以全流程支撑大模型生产落地。 不仅如此，从百度透露出来的几组数据，也能够体现飞桨越发浓重的产业味： 产业级模型库开源低代码模型新增至600+个 产业级特色PP系列模型新增至42个 发布飞桨产业级模型库一站式入口 产业实践范例即产业落地全流程“样板间”新增至68个，覆盖金融、工业、交通、互联网等重点行业。 最后是生态建设方面，可以分为三个方面。 在产业生态上，飞桨已经联合了行业众多龙头企业，包括国家能源集团、中国工商银行、中国联通、中国石油、中国铁道科学研究院、中国移动、中国一汽，发布产业范例征集计划。 在硬件生态上，飞桨硬件生态共创计划”硬件伙伴由13家增至28家。 其中12家（包括英伟达、英特尔、昆仑芯、Arm、天数智芯、清微智能等）已经发布飞桨生态发行版，为开发者提供软硬一体化体验。 在人才生态上，“飞桨AIStudio人工智能学习与实训社区”新增了“企业实训”与“生态异构算力中心”。 二者同样是已经与国家电网、OPPO、英特尔、英伟达和曙光等龙头企业展开了合作。 …… 由此可见，无论是大模型亦或是飞桨，它们现在所聚焦的内容无不在围绕着“产业”二字在展开。 那么接下来，就要回到最初我们提到的那个问题： AI产业化之路，现在什么阶段了？ 要回答这个问题，我们不妨先将四年来的Wave Summit铺开来看下。 在2019年第一届峰会中，王海峰就提到： 深度学习正在推动人工智能进入工业大生产阶段。 王海峰当时认为，正因深度学习具备通用性，以及深度学习平台在不断发展，所以它们正在推动AI步入一种新的模式。 这种模式可以归结为“三化”，即标准化、自动化和规模化，这也就意味着人工智能在进入工业大生产阶段。 到了2020年，“企业版平台”被纳入到了飞桨的全景图之中，并且还发布了预训练模型的开发模式。 这也就迈出了通过预训练大模型来降低AI门槛的重要一步。 而在去年，百度集团副总裁吴甜在峰会中提出企业AI应用三阶段：AI先行者探路、AI工作坊应用、AI工业大生产。 并且针对每一个阶段分别阐述了企业将面临的困难和挑战，以及相应的解决方案。 与此同时，在同年的12月份，文心大模型也随之正式亮相。 就在今年5月的峰会中，吴甜还提到“今年是大模型产业落地的关键年”，并给出了她认为的一种解法： 要做好落地，需要解决的关键问题是，前沿的大模型技术如何与真实场景的方方面面要求相匹配。 而到了今天这个时间节点，在AI产业化这条道路上，百度正在发出一个非常明显的信号—— 框架、模型不仅要用起来，更重要是要打出去，用吴甜的话来说就是“生态太重要了”。 对于这一点其实并不难理解，正如历史中每一次的工业大革命，都是有通用技术的普及一样，例如机械技术、电气技术和信息技术。 而要做人工智能时代下的普及，就需要先让框架、大模型在企业，尤其是龙头企业铺展开来；而后通过反馈和优化，逐层向下更深入的应用起来。 这或许也是百度不遗余力降低AI技术使用门槛，并且把自家“最强兵工厂”对外营业，与产业众多企业强强联手的原因了。 那么在如此发力之下，AI产业化又走到了什么阶段？ 或许借鉴更为大众所熟悉的移动通信发展史，可以更好得出结论。我们知道，智能手机之前，有过最初的大哥大、小灵通、功能机，最后才是我们所处的智能手机时代。 有人认为即将来到功能机，也有人认为一切才刚开始。 换个角度来说，历史性的一页才刚刚拉开序幕，广阔的产业化机遇才刚刚开始。就像瓦特完成蒸汽机改良时，没有人能意识到，会进入一个生产力大爆炸的新时代。 举报/反馈"
    },
    {
      "doc_id": 646,
      "title": "百度的Q3:坚持的红利",
      "time": "2022-11-22T00:00:00+00:00",
      "content": "今天（2022年11月22日）百度如期发布了Q3未经审计财报，总体表现如下： Q3，百度实现营收325.4亿元，同比增长2%。归属百度的净利润（non-GAAP）达到58.9亿元，同比增长16%。 百度核心经营利润（non-GAAP）66.5亿元，同比增长14%，实现自2021年第二季度以来的首次同比增长；核心经营利润率（non-GAAP）26.3%。 百度第三季度录得自由现金流66亿元。 可以看出百度的盈利能力在逐季修复。 而落到具体业务中，百度移动生态、智能云和智能驾驶都有不俗表现： 一是虽然广告大盘低迷，行业整体业绩不佳，但百度移动生态更赚钱了。9 月，百度App MAU达到6.34亿，同比增长5%，经营利润也保持了同比增长，仍旧是百度的现金牛。 二是百度苦盼多时的“云+AI+产业”智能云业务线逐步看到了盈利曙光，百度智能云营收同比增长24%； 三是百度长期巨额投入的智能驾驶业务，不仅行业领先身位拉大，商业化也有了新进展。 百度移动生态，逐渐变得不一样了 在百度提出把“智能搜索+智能推荐”作为拉动移动生态增长的双引擎，持续增强对“人+信息+服务”的连接能力后，百度移动生态在丰富C端用户的信息和服务获取体验，提升百度创作者内容创作能力和收入多样性，并持续为B端客户营销赋能等方面都有了新的举动。 一是内容生态更加丰富。百度APP内视频化内容增加，通过更多引入第三方文章、短视频、直播等内容，百度APP内搜索结果丰富度也有所提升。内容的丰富给用户带来了更好使用体验，9 月，百度App MAU达到6.34亿，同比增长5%。第三季度，移动端搜索查询次数同比实现两位数的增长，百度App信息流内容分发量同比增长23%。9月，百度搜索结果页面 (SERP) 点击次数中有23%为短视频，预计视频在搜索结果中的流行度将继续快速发展。 二是更加注重对商家营销的赋能、重视互利与开放。电商SaaS托管页降低了中小商家使用成本，同时也改变了搜索引擎只能做“中转站”的模式，让百度也能持续发掘和释放流量价值，Q3托管页收入同比增长13%，在百度核心在线营销收入中占比达到 51%。另一方面，以智能小程序为核心载体，百度和第三方共建包括电商、生活服务在内的闭环服务，以更好满足移动生态内用户对标品的、通用化的服务需求。在电商领域，用户到百度App进行产品搜索的意愿进一步提升，产品相关搜索查询持续增加。第三季度，百度搜索促成的季度 GMV 同比增长52%。 其三是更多服务接入带来更多交易机会。商家为营销付费意愿提升仰赖平台的生态优化——这也是为什么百度希望让用户在移动生态内实现从获得信息、获得服务到完成交易闭环的完整体验，也让作者和商家都能享受到流量精耕的红利。 在单纯的流量分发逻辑下，百度移动生态最重要的收入来源一定是广告；但当逻辑改变为智能化的信息+服务推荐，多元化收入模式会为百度的移动生态带来新的增长机会。 虽然广告大盘在收缩，但百度移动生态的“弹性”也在增强，经营利润持续上升，仍旧是目前百度最坚定的现金牛。 坚持“云+AI+产业”，百度智能云看到盈利曙光 2022年7月，中国信通院第七次发布《云计算白皮书》，其中指出2021年全球公有云市场规模达到3307亿美元；中国云计算总体依然处于快速发展期，2021年市场规模达到3229亿元，较2020年增长54.4%——超快的增速说明了中国云计算市场还远未饱和，大量传统产业对云的需求正逐步被释放。 2019年9月，李彦宏在一封内部信中宣布百度将进一步升级“云+AI”战略，并提升百度智能云的战略地位。李彦宏认为，百度智能云将人工智能技术与云基础设施服务相结合，承载着百度正在把人工智能输送到千行万业的使命。在那之后，百度智能云的发展明显提速。 在今年3月由 Canalys 发布的《2021年中国云计算市场报告》中，中国云基础设施市场规模已达274亿美元，比2020年增加85亿美元，阿里云、华为云、腾讯云和百度智能云占据80%的中国云计算市场，其中百度智能云全年同比增速55%，超过了45%的行业平均水平，市场份额明显提升。 在22年Q3的百度财报中，面对云计算领域的激烈竞争，百度智能云营收同比增长24%，推动百度核心非广告收入同比增长25%，本季度实现经营利润环比、同比双提升。其进步不仅源于百度智能云不断扩大的运营规模、及时从低利润项目转移并推动标准化的解决方案，更与百度智能云选择以AI为核心的“云+AI+产业”差异化竞争策略关系匪浅。 在“云+AI+产业”方面，云服务是基础，传统产业改造是目的，能够深度学习的AI才是导致质变的根本力量，也是百度提供云服务中的核心竞争力。从2016年百度宣布PaddlePaddle国产开源深度学习平台诞生，到2019年这一平台全面升级为“飞桨”，现在飞桨已经逐步变成一个有千亿特征、万亿参数、数百节点的开源大规模训练平台，超过150万开发者逐步聚集在此共创各种人工智能模型，而百度的AI能力也得以随之下沉进入产业经济和生产一线。 飞桨平台的一大特色就是与产业结合紧密，其上已积累了数千个与制造业、农业、能源等产业匹配的人工智能模型：通过AI识别卫星遥感数据，获得精准的农耕地块信息，飞桨可以助力农作物全生命周期监管，让每亩地节省成本100元，农民收入提高10%；飞桨上也有优化铸造熔炼程序的智能模型，每年为企业节省原材料10%，配料计算时间节省90%；通过飞桨控制的智能巡检机器人，可以使变电站设备仪表识别准确率提升90%以上，人工巡检工作量降低90%。 百度飞桨（宁波）人工智能产业赋能中心 也正是由于飞桨平台上聚集了众多可用的产业AI模型，让百度智能云既能为各产业客户拿出相对成熟、标准化的云+AI解决方案，又可以按个性化需求用短时间做针对性调整。今年9月，百度智能云宣布基于“云智一体，深入产业”的新战略，升级为“云智一体3.0”架构。3.0架构会从行业核心场景切入，通过打造行业标杆应用，带动和沉淀AI PaaS层和AI IaaS层的能力，打造高性价比的异构算力和高效的AI开发运行能力，进而向上可以优化已有应用、孵化新应用，向下改造数字底座，使基础云更适合AI应用，形成螺旋上升、不断进化的效果。 可以说，百度智能云正在将传统云计算市场的竞争，带入AI云服务竞争的阶段。而伴随云计算市场的高速增长，百度智能云已经毫无悬念将成为百度增长的第二曲线。 百度智能驾驶，越来越大的领先身位 2021年底，百度CEO李彦宏在接受彭博社采访时表示：“我们都低估了自动驾驶研发的投入。百度去年已经投入了200亿造车。”要知道2021年，百度全年营收为1245亿元，几乎用收入的1/6投入研发自动驾驶。而根据摩根大通研究分析，2019年—2025年，中国L1到L5级的辅助驾驶和自动驾驶市场规模将实现33%的年均增长率，并于2025年达到约71亿美元，约合500亿人民币——相对于2025年的市场规模预期，百度的投入令人咋舌。更何况李彦宏还在接受采访时表示，对自动驾驶技术的大规模投入将持续10年甚至20年。 之所以自动驾驶发展没那么快，原因不难理解： 1、自动驾驶目前存在技术难点，在大部分使用场景想100%不犯错很难，这不仅与自动驾驶车辆技术有关，也来自道路交通； 2、做测试车容易，但是要商品化、低成本却很难。从研发到制定成熟标准、试验到商用，需要3—5年时间；如果想真正实现L4（高度自动化）、L5（完全自动化）级别的自动驾驶，则需要10年或更久。 不过百度在自动驾驶方面的打法虽然投入巨大，却颇有讲究。 在技术与安全性上，根据《北京市自动驾驶车辆道路测试报告（2021年）》显示，2018年-2021年底，北京道路测试安全行驶里程已累计超过390万公里。其中载人测试车辆达到170辆，百度和萝卜快跑占据其中128辆，累计道路测试里程数更是稳居榜首，占北京总测试里程数的93%，是其他所有玩家加起来的15倍。 针对自动驾驶的“犯错问题”，百度不仅在加强车辆自动驾驶技术，也大力投入到对“车路同行”的改造中。今年8月，百度联合多方发布全球首个路侧软件和服务开源系统“智路OS”，为智能网联、高级别自动驾驶和交通数字化管理等全场景应用提供统一的车路协同开发环境。 在降低自动驾驶车辆成本方面，今年7月21日，百度发布了第六代量产无人车Apollo RT6，不但具备城市复杂道路的无人驾驶能力，且成本仅为25万元，低至业界的1/10。 从百度Q3财报来看，百度的智能驾驶业务板块再次取得突破，也在拉大自己的领先身位。 根据Q3财报，百度Apollo汽车智能化解决方案近期累计定点及签约金额预计达到114亿元，证明了市场对其日益增长的需求。第三季度，百度与中国最大的汽车科技公司之一深化了合作关系，将在其一款流行车型上应用ANP（Apollo领航辅助驾驶）、AVP（自主泊车）和高精地图。 百度自动驾驶出行服务平台萝卜快跑市场份额持续增长，运营规模持续扩大，继续保持其全球最大自动驾驶出行服务提供商的地位。第三季度，萝卜快跑共提供47.4万次乘车服务，同比增长311%，环比增长65%。截至2022年第三季度末，萝卜快跑向公众提供的乘车次数累计达到140万。2023年，百度预计将把Apollo RT6 投入在萝卜快跑上使用，使打无人车的成本比现在打车更加便宜。 在智能交通场景，截至第三季度末，以累计合同金额超过千万元人民币订单计算，百度ACE智能交通解决方案已经被63个城市采用，覆盖范围较一年前的24个城市持续提升。 继移动生态、智能云之后，智能驾驶作为百度的“第三增长曲线”已经若隐若现。 写在后面 当我们看到百度的财报的时候，最关注的仍旧是他做为 “搜索公司”的固有印象——更关注百度的在线营销增长，搜索用户还多不多，APP日活、月活是否有增无减。 但百度已经变了，至少处在和AI共同变化的过程中。这种改变不会一蹴而就，也不仅是一个虚拟人或是全屋家电控制那般简单——正如前文所述，百度的AI是一个平台指导2000万亩的农耕生产，也是用10个人实现对19个城市变电站7*24小时的实时监管，未来更可以是对驾驶员的全面解放，通过车载电脑的感知和运算来全天候、全地域的自动驾驶车辆。 当我们更多关注百度智能云和智能驾驶方面的进展，会对百度产生新的认知。在Q3财报发布后，包括中金公司、中信证券、瑞银、汇丰银行、摩根大通等多家头部券商机构给出“买入”评级。 在线营销业绩的好坏已不再成为判定百度价值的最主要标准。现在的百度打开了移动生态、智能云和智能驾驶这三个引擎，正在开始加速。 举报/反馈"
    },
    {
      "doc_id": 650,
      "title": "百度Q2财报:营收341亿元实现加速增长 净利润高速增长44%",
      "time": "2023-08-22T00:00:00+00:00",
      "content": "北京时间8月22日，百度发布了截至2023年6月30日的第二季度未经审计的财务报告。第二季度，百度实现营收341亿元，同比增长15%；归属百度的净利润（non-GAAP）达到80亿元，同比增长44%。营收和利润双双实现大幅增长，超市场预期。 得益于在线营销业务的稳健表现和经营杠杆推动，百度核心营收和利润增长加速。第二季度，百度核心收入264亿元，同比增长14%。百度核心经营利润（non-GAAP）同比增长27%至65.1亿元，经营利润率为25%，相比2022年第二季度的22%和2023年第一季度的23%有所提升。百度核心的在线营销收入为196亿元，同比增长15%。百度核心在经营中产生了约97亿元净现金流。 “生成式AI和大语言模型在许多行业具有巨大变革能力，为我们提供了重大的市场机会。百度不断升级模型，生成更具创造性的回答，提高训练速度并降低推理成本，保持行业领先。”百度创始人、董事长兼首席执行官李彦宏表示，“文心大模型3.5得到了云客户、AI开发者和行业专家的广泛认可。百度正在用AI原生思维重构产品和服务，为用户提供创新体验，并支持企业抓住机遇。百度致力于围绕生成式AI和大语言模型构建新引擎，推动长期增长。” 百度首席财务官罗戎表示：“百度已经在AI领域投资了十多年，完全有能力抓住生成式AI和大语言模型带来的机遇。我们将继续坚定投资AI，在未来几个季度加大对大语言模型和生成式AI的投入。” 基本盘强劲：智能云蝉联AI公有云市场份额第一，萝卜快跑领跑全球无人驾驶 除了实现营收和利润大幅增长，百度智能云、智能驾驶、用户产品等基本盘业务也在二季度持续高速增长，迎来突破性进展，领跑行业。 作为经过AI调优的云基础设施，百度智能云为大模型训练提供强大的算力，并迅速扩展合作客户群。百度智能云推出的千帆大模型平台，不仅提供包括文心一言在内的大模型服务及第三方大模型服务，还提供大模型开发和应用的整套工具链，能够帮助企业解决大模型开发和应用过程中的所有问题。在第二季度，百度智能云签约客户数量持续增加，包括兴业银行、南网总调、汉得信息、金蝶、软通动力等外部企业。 近期，《IDC中国AI公有云服务市场份额，2022》报告显示，百度智能云市场份额占比第一，这是百度智能云连续四年、第八次排名第一。 智能驾驶方面，百度自动驾驶出行服务平台萝卜快跑快速拓展运营规模。第二季度，萝卜快跑提供了71.4万次乘车服务，同比增长149%。截至2023年6月30日，萝卜快跑累计向公众提供的乘车服务数量达到330万次。 今年6月，萝卜快跑获得深圳市坪山区颁发的首批全无人商业化试点通知书。目前，萝卜快跑已获批在武汉、重庆、北京和深圳四个城市向公众提供全无人自动驾驶出行服务。今年7月，萝卜快跑获得上海市浦东新区发放的首批牌照，允许在公开道路上开展全无人自动驾驶测试。 6月，百度App月活跃用户达6.77亿，同比上涨8%，百度用户基本盘稳健。此外，根据IDC和Canalys的数据，小度在2023年第一季度位居中国智能屏和智能音箱出货量第一。 用AI原生思维彻底重构产品线：提升用户体验和广告变现，推动长期增长 在基本盘业务强劲增长的同时，百度正在用文心大模型和文心一言构建AI原生应用，彻底重构产品线，带来全新增长动力，在未来获得更多增长空间。 百度搜索正在内测“极致满足”“AI伙伴”“AI BOT”等功能，当前百度搜索每天已有的问答需求中，首条满足比例已达到70%，百度搜索日均新增问答需求超过5000万次。5月，百度文库宣布内测“AI文档助手”，借助大模型等AI技术实现对传统学习办公模式的重构。百度智能工作平台如流，基于大模型能力打造了AI助手“超级助理”，可将小时级工作压缩为分钟级甚至秒级完成，例如自动总结会议纪要、创建会议邀请、请假、申请出差等均可一键完成。 同样被大模型重构的还有百度的营销产品，百度营销AIGC商业创意平台“擎舵”，通过多模态内容生成，突破创意生产力瓶颈，2分钟生成100条创意文案，3分钟生成一个数字人建模，5分钟即可制作一支完整的数字人口播视频，为广告商带来了转化率的提升，从而带来更好的变现效果。 AI原生应用的快速落地得益于底层大模型性能的提升。第二季度，百度推出文心大模型3.5，飞桨与文心协同优化，训练速度达到原来的3倍，推理速度达到30多倍。据IDC发布的《AI大模型技术能力评估报告，2023》显示，文心大模型3.5拿下12项指标的7个满分，综合评分、算法模型、行业覆盖均为第一。 8月16日，在WAVE SUMMIT深度学习开发者大会2023上，百度发布文心大模型、飞桨平台、AI原生应用如流等一系列技术、产品及生态成果。目前，飞桨生态已凝聚800万开发者，服务22万家企事业单位，基于飞桨创建了80万个模型。 此外，为了进一步推动大模型生态的健康发展，今年5月，百度宣布启动“文心杯”创业大赛，并设立10亿投资基金。“文心杯”最高奖项为价值 1000 万元早期投资，在1个月内吸引了近1000项目参与。 举报/反馈"
    },
    {
      "doc_id": 16581,
      "title": "大模型商业化进入淘汰赛,赢家正在变少",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "作者｜西梅汁 编辑｜星奈 媒体｜AI大模型工场 在今年百度Create开发者大会上，李彦宏直言：“没有应用，芯片和模型都无法发挥价值。” 这句话背后，是产业正在迅速达成的一个共识：AI价值必须通过商业化实现闭环。从两年前OpenAI掀起技术热潮以来，大模型行业快速跃升成为全球科技焦点，但伴随而来的，也是一场从理想到现实的快速降温。 模型训练所需的高昂成本、C端应用的不确定性、ToB市场的复杂交付，以及持续烧钱的高压运营，让“钱难赚、屎难吃”这类行业黑话，成为现实困局的凝练表达。 此刻的AI产业，正经历一轮深度的分化。一方面，百度、阿里、腾讯、字节等平台型巨头以饱和式投入对抗技术拐点，通过自研、收购、云平台能力将AI全面纳入主营生态；而另一面，哪些没有树大根深的母系家族依赖的初创公司在技术与商业之间徘徊，一旦无法建立营收模型或稳定现金流，就会迅速从风口中滑落。 01 大厂承压，多元化变现，生态协同为王 从“跑模型”到“跑营收”，这条路并不好走。 在大模型的商业化赛道上，巨头拥有更强的抗压能力，根系足够发达，可以承接多元的商业化探索。从百度到阿里，再到腾讯，这些大厂拥有庞大的生态体系，它们的AI业务并非单纯地依赖某一块应用或场景，而是通过将AI能力嵌入到现有的产品、服务和云平台中，来实现跨界赋能和收入协同。 比如，百度通过文心大模型，把AI能力嵌入到搜索、地图、网盘等核心产品中，不仅提升了这些产品的智能化，还通过“千帆平台”对外提供AI服务，打入政务、金融等垂直行业，构建起了一个全方位的AI商业化闭环。 而其AI驱动的自动驾驶平台“萝卜快跑”也已经积累了千万级别的订单量，智能云业务也逐步盈利。这样，百度不仅实现了技术与产品的协同，还为自身在AI领域的生态扩展打下了坚实的基础。 阿里在通过将通义千问融入到钉钉、天猫精灵等高频应用中，借助阿里云“百炼平台”加速向B端市场输出模型和技术能力，构建了云服务+AI能力的双引擎。 腾讯则在自身强大的社交和办公生态内植入混元大模型，并通过腾讯云为各行业提供定制化的AI解决方案，进一步扩展其商业化边界。 这些大厂的共同特点在于，AI已不再是单一的技术项目，而是被作为基础设施嵌入到现有业务中，推动着营收的多元化发展。它们的AI战略更像是一种“平台化”的思维，借助现有流量和用户基础，快速实现从技术到商业的落地。因此，大厂的AI商业化，往往具备更高的市场抗压能力和更多的成长空间。 而字节跳动和快手在AI大模型的商业化上，虽然采用了不同的策略，AI主要用于提效主业或打造爆款应用，但都在各自的赛道上找到了突破口。 字节通过剪映、飞书、番茄小说等产品矩阵渗透不同场景，形成“流量+工具+服务”的协同效应。进入AI时代，字节以豆包大模型为核心，布局C端AI应用和B端工具链，如Coze平台，结合抖音的庞大生态深入Agent商业化。 从营收情况来看，虽然字节目前未上市，没有具体财务数据，但其旗下应用矩阵已实现月活跃用户超40亿，企业服务业务主要由飞书、火山引擎等承担。火山引擎2024年营收就已突破120亿元，2025年目标更是定为250亿元。 此外，据报道，字节跳动正低调研发一款“护目镜”形态的轻量级混合现实设备，更是体现字节跳动在AI硬件方面的诸多布局。 相比之下，快手通过视频生成大模型可灵AI等技术创新，成功提升了内容生态与商业化效率。截至2025年4月已累计收入1.8亿元，企业API调用量超4000万次，估值达到80亿美元。 同时，其AI能力深度整合至电商与广告核心业务，C端通过AI试衣、智能客服提升用户体验，B端为商家提供AI工具，如直播切片生成，可见AI已成为快手电商增长的关键驱动力。 可以看到，字节一方面打造AI应用，另一方面用AI给自身业务提效，而快手则依赖于垂直场景的深耕，逐步形成了自己的盈利模式。虽然两者的路径不同，但都依托于技术与生态的协同，成功打破了各自行业的商业化困局。从市场趋势来看，谁能在技术创新和场景渗透中找到平衡，谁就能在这场AI商业化的赛道中占据先机。 02 小厂负重，变现难 那么，与这些拥有自有流量或平台优势的巨头不同，一批以技术起家的模型创业公司，必须以更具辨识度的策略寻找路径。 相比于资源充裕、业务多元的大厂，创业公司的流量和平台红利更加有限。在这种情况下，它们往往选择了在ToB或者ToC的垂直赛道上深耕，试图通过专业化和技术优势来赢得一席之地。 智谱、阶跃星辰和商汤等公司，主要集中在ToB市场，面向政府、金融、制造等领域提供定制化的AI解决方案。它们虽然在技术能力上积累了显著优势，但缺乏大厂的资金支持和生态体系，普遍依赖政府订单和企业客户。 ToB市场本身回款周期长、项目转化门槛高，导致商业化进程缓慢。即便如商汤这样自建SenseCore AI大装置、承接大额项目，也仍要面对高额的前期投入和不确定的回报周期。 与之对应，Minimax和月之暗面等公司则多选择ToC市场上的路径，多是直接面向消费者进行AI应用的落地。这些公司在产品上进行了创新，例如Minimax通过推理模型的开源和低价API吸引开发者，并凭借星野AI、海螺AI等产品迅速吸引了大量C端用户。 月之暗面则在过去一年通过Kimi抢占了用户心智，持续推出面向写作、搜索、知识整理的轻量化工具，形成了一定的用户付费习惯。最近发布的Kimi K2，更是在推理性能、上下文长度和生成速度上进一步强化了产品竞争力。 但在ToC市场，尽管用户基数庞大，留存和变现依旧艰难，如何将短期的规模化增长转化为长期、稳定的收入，依旧是这些小厂必须面对的挑战。 另外，除了大厂的多元布局和上面的创业公司垂直深耕之外，DeepSeek的路径稍显不同。年初通过开源DeepSeek-R1模型快速积累了巨大的开发者社区，建立起独特的技术生态，也由此吸引了大批C端用户。在短短一年内，它已经成为国内C端用户最多的AI平台，月活用户接近1.7亿。 然而，据Semianalysis报告，用户使用率从年初峰值7.5%回落，官网流量降至3%，近期其官网流量和用户活跃度出现明显下滑，面临着巨头追赶和用户留存的双重压力。 但与其他AI创业公司不同，DeepSeek似乎并不急于盈利，而是将重点放在技术的深耕和生态的扩展上，未来的商业化路径可能会随着技术的不断进步和市场需求的变化而逐步清晰。 无论是大厂还是小厂，AI商业化的核心挑战始终在于：如何从单纯的技术创新，转向能够持续盈利的闭环模式。大厂凭借强大的资源优势，在广泛布局和多元化收入中找到了自己的节奏，而小厂则必须通过专注细分市场和不断深耕技术，寻找自己的突围路径。 对创业公司而言，商业化过程中的变现难题仍然没有解决，如何有效连接技术、用户与商业，是它们能否生存下去的关键。而像DeepSeek这样的“特例”则表明，在大模型行业中，并非所有公司都必须迅速变现，有些公司可以通过建立技术生态、积累用户口碑，为未来的商业化奠定基础。最终，AI赛道上的“赢家”不仅仅是那些技术最先进的公司，更是那些能够在“技术”与“商业”之间找到平衡的团队。 03 没有现金流的模型，终将死去 不过，无论是大厂还是初创公司，最终都要回答同一个问题：如何建立起健康的现金流闭环。 在C端市场，虽然潜在用户庞大，但要真正穿透流量、留住用户并实现营收，仍然面临巨大难度。AI应用如写作、娱乐、社交、教育等场景虽然有潜力，但要实现闭环需要较高的产品体验、留存机制和成本结构的协同，这对团队的打磨能力要求极高。即使是拥有庞大用户基数的DeepSeek，也面临用户活跃度下滑的挑战，凸显了C端留存与变现的普遍难题。 如今，在App Store和安卓市场持续占据下载前列的AI应用几乎都依托于大厂渠道或工具属性，这进一步说明独立跑通C端模型商业化的困难。 对于没有母公司支撑的初创公司，资金链的稳定性至关重要。尽管AI技术的开源给了许多公司展示技术能力的机会，但许多初创企业未能在市场上找到足够的盈利来源，导致它们的运营压力巨大，最终无法承受亏损而退出市场。尤其是对于没有强大资本背景的公司，如何在短期内找到稳定的现金流成为关键问题。 尽管ToB市场提供了较为稳定的客户群体和订单来源，但B端的客户教育成本高、转化门槛大，尤其是对于初创公司而言，如何与传统企业建立合作并进行深度定制，依然是一大挑战。此外，大厂在ToB市场中的布局愈加完善，形成了强有力的竞争，进一步加剧了初创公司在这一赛道中的压力。 AI的技术能力固然强大，但它能否真正落地到应用中并解决实际问题，才是其商业化的关键所在。许多公司尚未能够将AI技术与具体行业需求结合，导致其技术虽然先进，但无法形成真正的应用场景，从而无法产生可观的收入。 训练和推理都需要算力支撑，GPU 成本仍居高不下。一些初创公司盲目堆参数，结果上线一个模型，光推理就烧光融资。DeepSeek 能跑出来，靠的是极致成本控制和标准化输出。 同时，大模型的商业化的过程中，最难的部分就是如何将技术转化为现实中的商业价值。技术本身的复杂性和应用场景的多样性，使得AI产品的落地应用变得尤为困难。尤其是在没有稳定现金流的情况下，很多初创公司无法承受运营压力，最终不得不退出市场。 像很多AI App虽然短期用户增长快，但真正能沉淀高复购的产品很少。内容生成、写作、娱乐等场景看似火爆，但要实现真正闭环，需要产品体验、留存机制和成本结构三者协同，这对团队产品打磨能力提出了极高要求。或许只有像可灵、星野这类深入细分场景的产品，才能把用户变成现金流。 而目前在App Store和安卓市场持续占据下载前列的AI应用，几乎都附着于大厂渠道或具有极强的工具属性，进一步说明独立跑通C端模型商业的难度不容小觑。 另一方面，To B 和 To G 市场虽然单价高，但交付周期常常超过半年，审批、招标、定制都耗时。没有稳定现金流撑着，很容易断粮。 此外，AI技术的商业化需要巨大的投资和长期的技术积累，而这些初创公司往往缺乏这样的资源。这使得他们在竞争中处于不利地位。对于这些公司来说，如何找到可持续的盈利模式，将是决定它们生死存亡的关键。 04 穿越AI周期 要穿越这一周期，也许要回到一个起点：模型不是全部。 真正的产品，不在于参数有多强，而在于能否解决一个具体问题。高考志愿填报、医疗问诊、办公自动化等场景中，都已经出现高频、刚需的AI能力嵌入。用户并不在意底层模型有多少层Attention结构，而是关心能否节省时间、降低成本、减少错误。在这个逻辑下，AI产品的核心将从模型通用性走向任务完成力，从泛智能向垂直刚需收敛。 与此同时，生态协同正在成为关键变量。一个模型即便能力强大，若无法接入业务流程，依然无法落地。百度的“文心+千帆”、腾讯的“混元+微信”、字节的“火山引擎+API”策略，实质上都是在构建“平台-模型-产品”的联动闭环，提升模型在不同层级中的适配能力。初创公司若不能进入这种生态协作体系，势必面临更高的客户教育成本与转化门槛。 在全球视角下，中国AI公司也在探索开源与出海的组合路径。DeepSeek、月之暗面等公司在GitHub的开源项目持续积累开发者口碑，而MiniMax、智谱等也在新加坡、中东等市场布局多语种版本与本地化部署。 技术竞速阶段已经过去，如今的大模型行业不是谁的参数最多，也不是谁的演示最惊艳，而是谁最能将模型能力嵌入到真实业务中，形成可持续的现金流，熬过资本降温后的淘汰期。 最终留下的玩家，不一定是最先锋的探索者，而是那个最早找到客户、最早形成收入、最能调整方向并活下来的团队。这场赛跑的终点，不属于浪漫主义者，而属于在冷静中构建价值闭环的现实主义者。"
    },
    {
      "doc_id": 16583,
      "title": "大厂的2025,在AI上砸钱、抢人、争地盘",
      "time": "2024-06-13T00:00:00+00:00",
      "content": "2025年将近过半，恒生科技指数已震荡近两个月，市场又在重新审视互联网大厂们的价值了。 这两个月，也是一季度财报披露的时间。从表面的数字看，有一些大厂的利润和营收不及此前的市场预期。这也是指数徘徊的的一个诱因。 投资人们最关心的就是，如何预期业绩的拐点，大厂未来能否突破增长的瓶颈？ 破解这一谜题的关键，在于厘清大厂资金流向及其投入是否有效性。 当前观察显示，互联网巨头正加速向AI领域倾斜资源。从研发投入到生态布局，从算力基建到场景落地，AI，特别是大模型，已成为资本配置的核心赛道。 01、谁在AI上投入 “用户为先，AI驱动。” 阿里眼下的这个战略，可以说，也是国内所有互联网科技公司战略的概括。 在这种战略的驱动下，大厂们都加大了对AI的投入。 比如，腾讯在财报中就明确表示，“加大了对元宝应用与微信内的 AI 等新AI机遇的投入。”百度首席财务官何俊杰表示，“展望未来，我们将坚定投资于AI”。而阿里集团CEO吴泳铭此前就明确表示，未来三年将投入超过3800亿元用于AI和云计算基础设施建设。 具体来看，截至3月31日，阿里2025财年，全年研发费用571.5亿元，占总收入5.7%。2025年第一季度，研发费用为149.3亿元，营收占比为6.3%。阿里早在‌2023年4月首次发布了通义千问模型，目前的最新版本为今年4月份发布的Qwen3系列。同时，阿里也在大力推广夸克浏览器，希望将其打造成集多种功能于一体的“AI 超级框”，使其成为阿里AI布局中至关重要的C端流量入口。 腾讯2025年第一季度研发支出189.10 亿元，同比增长了21%，占收入10.5%。腾讯于2023年9月推出自研大模型混元，到2024年5月，基于混元大模型的AI助手应用元宝正式上线。腾讯总裁刘炽平表示，2025年腾讯将加大AI投入，“预计资本支出将占收入的低两位数百分比”。按腾讯2024年营收规模与增速估算，相关投入可能接近千亿元。 百度2025年第一季度研发费用45亿元，占收入7.2%。百度也是国内最早发布自研大模型的大厂，在2023年3月启动了文心一言的正式邀测。今年3月，百度又发布了首个具备多模态能力的旗舰基础模型，文心4.5，以及推理模型文心X1。 阿里、腾讯、百度作为互联网时代的三大科技巨头，重金押注AI顺理成章。然而，AI时代必将重塑格局，促使另一些公司悄然加码布局。 比如快手，2025年第一季度研发支出为32.98亿元，占营收的10.1%，并在财报中特别强调了4月份升级的自研视频声称大模型可灵AI 2.0。 还有美团，也在财报中明确表示，研发开支则由2024年第一季度的50亿元，增加至58亿元，占营收的6.7%，增加的原因是对AI的投入增加。虽然美团没有在财报中刻意提到大模型，但美团创始人王兴提到，美团的基础大模型能力已接近GPT-4o的水平。目前，美团已经上线一款AI编程类工具NoCode，另据悉，其自研基座模型叫龙猫。 除了上述几大上市公司外，还有两家未上市的巨头，其在AI和大模型上的投入，也是有目共睹，那就是华为和字节跳动。 其中，早在2020年11月，华为云内部就立项了盘古大模型，近日，华为推出了参数规模高达7180亿的准万亿MoE模型——盘古Ultra MoE。 而字节跳动在2024年5月的火山引擎原动力大会上，正式发布豆包大模型。自发布后，豆包就长期占据国产大模型APP下载榜的前列，并推动了云服务市场的价格下调。 此外，抖音旗下多个团队还推出了不同的AI应用产品，包括内容创作类的即梦AI、即创、海绵音乐等，试图形成一个“工具+内容+社交”全链条布局。 可以说，目前，所有有野心的大厂，都在自研基座大模型。 但在2024年之前，许多大厂还没有这样的想法。当时的腾讯、阿里、字节更多的是把重心放在了云服务上。彼时，他们的战略思维，更倾向于“卖铲子”——让别人去研发大模型，自己提供云服务。为什么仅仅一年的时间，大家的想法就变了呢？ “不转变能怎么办呢？DeepSeek都给掀翻了桌牌。”某大厂的相关人员对《商业与生活》感慨。 02、转变，挖人 DeepSeek的出现，给业界带来了两个非常大的冲击。第一个，它确实在学术研究层面有一个比较惊喜的突破。第二个，它推动了大模型的快速应用。 2024年，豆包砸下巨额的广告投放，将日活跃用户规模推到了3000万。但是，DeepSeek只用了一个多月的时间，凭借着各个应用伙伴的主动接入，就自然增长到了差不多的规模。这给整个行业带来了巨大的焦虑。 “被挑战了。之前，大模型在智能水平层面的进展，一直处于一个相对可以预期的状态，所以大家开始把精力放在了应用侧的产品创新上。但DeepSeek的出现，让大家发现，智能能力才是最根本的东西，模型的能力决定了应用的智能化上线。因此，一下就把行业趋势给扭转过来了。”阿里云的一位员工对《商业与生活》说。 DeepSeek出现之前，业内的玩家普遍认为，有了模型能力的基础之后，更多的机会还在应用侧的优化。但现在，大模型产品的设计能力、交互能力更加重要。因此，大模型的竞争又变成了技术的竞争。而技术竞争的一个关键，就是人才。 腾讯的财报显示，2025年第一季度研发支出中，仅员工薪资福利就占了150.12亿元。就是因为，腾讯在AI领域大肆招兵买。最近，腾讯推出了“青云计划”招聘专项，将大模型作为投入力度最大的关键领域，为入选人才提供全面定制化的培养方案。 另一个疯狂抢人的，则是字节跳动。 早在2024年11月，阿里决定对“通义大模型前员工周畅违反竞业协议”申请仲裁的消息，就在 AI 圈迅速传开。公开报道称，字节跳动为周畅提供的合同极为优厚，包括4-2的职级和8位数的年包工资，相当于在阿里的职级体系中连跳两级且薪资翻倍。 “字节去年突然要砸几十亿去做大模型，跟他内部的文化基因有很强的关系。”有接近通义千问的知情人士对《商业与生活》说。 互联网三巨头时代，人们常说，运营看阿里、腾讯看产品、技术看百度。这是三家的特长，也是三家的文化。过去七八年里，字节创造了众多的显像级产品，它的文化也是偏产品的。 但云和AI时代的到来，让各个大厂的文化向技术文化转变，原来文化中的商业基因被逐渐剥离。 阿里因为阿里云的缘故，打下了技术文化的基础，也因此比腾讯、字节更早地进入了大模型战场。 对于腾讯和字节来说，要从产品文化骤然转向技术文化，捷径只有一个，那就是豪掷高薪挖人。而在AI大模型领域起步更早的阿里，自然也就成了被挖角的对象。 阿里也没有闲着。“510”阿里日上，吴泳铭发布内网帖，重申电商、AI+云计算、互联网平台产品三大核心战役，并将针对组织机制调整和人才考核提上日程。吴泳铭号召扶持年轻人，年仅32岁的林俊旸被提拔为阿里通义千问（Qwen）技术负责人。不久前，通义实验室招聘官网，还悄悄更新了“世界模型”的相关岗位。“世界模型算法工程师”职位描述则写着，“Foundation Model要想真正实现AGI，需要实现理解生成一体化而打造出世界模型，达成‘交互’和‘创造’两大目标”。 根据人才解决方案提供商翰德发布的《2025人才趋势报告》，目前国内AI人才的供需比仅为0.5，这意味着每两个AI岗位仅能匹配到一位合适的候选人。大厂高薪抢人的激烈程度也就不言自明。 而除了，抢人，另一件事就是抢地盘。 03、砸钱，抢市场 “现在的基本情况就是，大家都死守自留地，其他家的地盘，你也投不进。”一位大厂的相关人员对《商业与生活》透露，大厂在大模型上的竞争，已经到了非此即彼的程度。 有心的人可能已经发现，过去几个月，在微信朋友圈，刷几下就会出现“元宝”的广告，但不会见到“豆包”“夸克”。同样，在字节的产品里，比如抖音，也刷不到元宝的广告，豆包成为独占资源的明星产品。 这是因为，几家大厂都牢牢把控着自家地盘上的广告位，几乎屏蔽了其他AI应用的投放。 这种竞争，表现在财务数字上，就是销售和市场费用的增加。 其中，阿里2025年第一季度的销售和市场费用为361.79亿元，占营收的15.3%，同比增加了73.73亿元。阿里在财报中解释，增加的主要原因为电商业务的投放增加。但是，对比市场上的其他数字，AI大模型的投放也应该占了不小的比例。 比如，腾讯在财报中就明确提到，为支持AI原生应用发展而加大了推广力度，2025年第一季度的销售和市场费用为79亿元，同比增长4%。 根据AppGrowing数据，截止至2024年11月，Kimi、豆包、星野、元宝等国内十款AI应用合计投放广告数量超过625万条，换算金额超过15亿元。其中，豆包和Kimi最激进，分别投入5.4亿元和4亿元。 要庞大的算力支持，要高薪挖人，还需要花费巨资抢占市场，这也让业内越来越确信，基础大模型是大厂的游戏，不适合创业型公司。 猎豹创始人傅盛在最近的采访中透露，2024年初，国内“大模型六小虎”（智谱AI、月之暗面、百川智能、MiniMax、阶跃星辰、零一万物）风头正盛时，他们也曾提议自研千亿参数模型。但因为发现市场竞争过于激烈，三个月后，就果断叫停。 但DeepSeek V2.5和阿里的 Qwen 70B 推出来后，国内大模型创业公司就普遍放弃训练基础大模型，“六小虎”也纷纷调整策略，甚至放弃基础模型研发，转向“小而美 ”。因为他们发现，资源上拼不过大厂，技术上又找不到优势，差距越来越大。 据QuestMobile数据，2025年2月，AIGC APP月活跃用户规模方面，DeepSeek排名第一，达1.8亿，豆包为1.01亿，腾讯元宝2636万，Kimi为2451万，纳米AI搜索为1688万，文小言为1024万。 到3月份，AIGCRank发布中国AI应用排行榜则显示，阿里的夸克（通义千问）、DeepSeek、字节跳动的豆包、腾讯的腾讯元宝，稳居前四，日活用户总和达8473万，占TOP20总量的68%。而kimi已经掉到了第6，月活跃用户只有元宝的四分之一了。 至此，夸克、DeepSeek、豆包、元宝也正式形成了“AI四大天王”格局，头部生态壁垒进一步加深。 市场份额有了，但投资人最关心的还是，如何赚钱？ 04、是个赚钱的生意吗？ 傅盛在最近的采访中表示，未来大模型就是个基础设施，大模型的token就跟自来水和电一样，要么由开源社区提供，要么由某一些大公司提供，总会有人填补这个战略生态位。 不久前，OpenAI又把自己变成了营利性公司，并任命了一个应用CEO。 基于模型出来的应用，可以变成挣钱的东西。而一个产品、一个技术，一旦被定义为“基础设施”，从挣钱角度看，就不怎么挣钱，或者不应该有暴利。 3月1日，DeepSeek官方披露了一个数据，按照DeepSeek-R1的token定价水平，公司一日之内总收入为562027美元（404万元），成本利润率高达545%。 看起来，利润率好像很高。但是，按照这个日均收入，一年营收也只有约14.8亿元。与各个大厂动辄几十、上百亿的研发和市场费用相比，实在不是一个乐观的数字。 大厂在AI上到底赚不赚钱，又如何赚钱？ 从财报上来看，全球企业AI需求的飙升，让各大售卖AI大模型服务的云计算巨头们拿出了不错的业绩。 2025年第一季度，阿里云智能营收 301.27亿元，同比增長18%。增长势头主要来自公共云业务，包括AI产品采购量的提升。腾讯金融科技及企业服务营收549亿元，同比增长5%。百度智能云收入为136.5亿元‌，同比增长42%，智能云业务也成为公司整体营收的重要驱动力。 另据媒体报道，火山引擎2024年营收规模超过120亿元，2025年营收目标超过250亿元。 大厂赚钱的一个渠道，还是“卖铲子”——云服务。 日前，国际数据公司（IDC）发布《中国公有云大模型服务市场格局分析，1Q25》报告显示，2024年中国生成式AI基础设施规模达356亿元，其中公有云大模型调用量达114.2万亿Tokens（不包含出海群体使用的MaaS平台的调用量，也不包含各大模型APP上的调用量），同比增长近10倍，市场规模与增速远超预期。 从数据上看，上半年日均调用量仅为963亿Tokens，但至12月已飙升至9522亿Tokens，半年内增长近10倍。不过，今年2月，百度智能云事业群总裁沈抖直言“国内大模型去年‘恶意’的价格战，导致行业整体的创收相较于国外差了多个数量级。 对比来看，2024年四季度谷歌云营收119.55亿美元，微软智能云（含Azure）2025年一季度达255.4亿美元，亚马逊云科技同期收入288亿美元。 在应用层面，从产品类型看，通用AI助手仍占据主导地位，AI四大天王均为通用型产品，凸显了“超级入口”的战略价值。其中，阿里巴巴、字节跳动、腾讯三大巨头均试图通过“大模型+生态流量”构建护城河。比如，腾讯透露已在内部接入超过700个产品和业务场景。 虽然大厂都加大了对C端用户的投放，但效果一般。字节内部评估也认为，豆包等对话类产品可能只是过渡形态，用户付费订阅模式在中国尚未成熟，而用户时长和交互轮次的低迷也制约了广告变现空间。 因此，更多的商业机会还是来自ToB的应用。有数据显示，80%的企业计划在未来18个月内增加生成式AI投入。IDC预计，2025年生成式AI在企业端的渗透率将突破30%，金融、零售、制造等行业的智能化改造将释放万亿级市场空间。 目前，大厂都在加紧拓展自家大模型的应用行业。腾讯称其“腾讯混元+开源模型”多模型行业方案，覆盖30多个垂直行业。基于通义千问大模型，阿里的AI合作已扩展到多行业，包括与宝马、中国联通、中国移动等众多行业头部客户都达成了AI领域战略合作。百度的AI大模型也在内容创作、企业服务、金融、医疗、教育等领域探索应用场景。 市场最关心的莫过于，这些合作，是在真金白地的赚钱，还是只赚吆喝呢？快手可灵AI的验证了AI的赚钱能力。财报显示，可灵AI在广告、营销、短剧和智能终端等多个行业的应用，一季度为公司带来了超1.5亿元的收入，其中，AIGC营销素材的日均广告消耗约为3000万元。 中国AI应用市场，已经进入了头部固化、垂类爆发的新阶段。通义千问、DeepSeek、豆包、元宝四大巨头依托技术、流量与资本优势，占据了用户心智与大部分市场份额。垂类AI应用则通过场景专业化挖掘增量市场，在教育、生成工具、情感陪伴等赛道进入高速发展期。比如，作业帮旗下教育AI应用产品快对AI就以1293万日活、489万月下载量，挤进了3月榜单的第五名。 包括腾讯等在内的多家大厂都相信，现在仍是在AI战略的投入阶段，但这些AI战略性的投入，将会发挥杠杆效应，在未来能撬动长期、可观的增量回报，成为大厂新的增长引擎"
    },
    {
      "doc_id": 16587,
      "title": "2025AI中场战事:谁在撤退,谁在进攻?",
      "time": "2024-05-21T00:00:00+00:00",
      "content": "文 | 新摘商业评论 ，作者 | 南一 目前，国内AI大模型市场由“百模大战”逐渐进入淘汰整合的中场阶段。 历经2023年以来的“百模大战”和资本狂热，行业格局正逐步清晰。曾经百家争鸣的局面已经洗牌，今天的舞台由新老巨头与新晋独角兽两大阵营主导。 在头部技术路线和商业化落地上，老牌互联网巨头和“新BAT”——以百度、字节跳动、阿里、腾讯、为代表，抢占先机；同时涌现出的“基模五强”——字节跳动、阿里、阶跃星辰、智谱AI、DeepSeek等也在全线发起进攻。 这些巨头与独角兽们在模型创新、算力投入、生态布局、开源策略等方面各有打法。与此同时，“AI六小龙”的处境却出现分化，有的已开始收缩阵脚。 距离ChatGPT发布仅过了2年，从巅峰时期的300家大模型同台竞技到洗牌至以月之暗面、MiniMax、智谱、阶跃星辰、零一万物、百川智能为代表的“大模型六小龙”。他们曾雄心勃勃追赶OpenAI的脚步。 然而当前，随着巨头势力全面加持，技术门槛和成本壁垒不断攀升，“小龙们”的生存空间正在被挤压。同样重要的是，新一轮AI攻势还催生了一批规模巨大的玩家。 字节跳动、阿里为代表的巨型互联网公司纷纷在大模型领域加大投入，各自布局了大型AI中台和应用生态。和他们并肩作战的，还有新崛起的阶跃星辰、智谱AI、DeepSeek等明星级创业团队。这些“新基模五强”为主的玩家各显神通，掀起了又一轮技术与市场竞争。如今战线已从前沿算法逐步向商业化与生态落地转移，价格战与应用场景争夺成为新的焦点。 一、高筑墙，广积粮，新老BAT凶猛 在这场AI博弈中，巨头阵营的攻势格外凶猛。 字节跳动在这一轮洗牌中保持了稳扎稳打的进攻态势，近年推出的“大模型家族”，如豆包系列模型，在多模态理解与生成上持续升级。最新的豆包通用模型（Doubao-Pro）在公开评测中已与GPT-4系列看齐。字节还针对不同应用场景不断优化模型结构，今年公布的视觉理解模型和种子级文本、语音、音乐等专用模型，使其在语言、视觉、声音等多模态任务上都保持行业领先。 更重要的是，字节对AI商业化投入巨大，豆包系列在公司内部50多个业务场景中大规模上线，日调用量已突破4万亿tokens，7个月增长33倍之多。 不仅如此，为了抢占市场，字节还大胆降价，力推“厘时代”。2024年5月，豆包通用模型首度对外发布时定价仅0.0008元/千token，比行业均价低99.3%；年底再推视觉理解模型，价格仅0.003元/千token，比行业价低85%。这一轮降价风暴在火山引擎AI大会上一举打响，字节相关负责人透露：“5月豆包日调用量1200亿，此前已飙升到4万亿”。 同时，跌价带来的正向循环迅速显现，底层算法实力加上亿级用户生态（抖音、头条、飞书等），使豆包迅速形成覆盖千行百业的闭环。 字节还通过开放开发平台“扣子”集聚开发者，目前已有百万活跃开发者参与构建了200万智能体，全面铺开AI应用生态。综合技术实力、资金、生态三者，字节已成为AI赛道的领跑者之一，其打法可总结为“更强模型+更低价格+更易落地”。 阿里作为开源最早、最完整的大公司，在AI的投入上也最坚决。 截至目前，通义团队累积开源200多款模型，涵盖了千问（Qwen）大语言模型和万相（Wan）视觉生成模型两大基座系列。在4月底，阿里发布的最新“千问家族”Qwen3 系列模型，包含 0.6B 至 235B 规模的多款模型（包括两款 Mixture-of-Experts 大模型），并选择将模型完全开源。在性能方面，Qwen3 小模型（4B 参数）可以达到上一代 Qwen2 大模型的效果，而 Qwen-3 系列整体在多模态和推理上有显著提升。整体布局，正如马云所言，“AI 不是选择题，而是阿里的必答题”。 配合新模型，阿里还在云服务端积极降价抢市场，2024 年，阿里已将多款大模型推理价格砍至原价的3% 左右，并在 2025 年继续降价。阿里通过开放模式与巨额补贴双管齐下，一方面开放底层模型以吸引全球开发者关注，另一方面下调成本激发生态活力，反映了持续投入的决心。 腾讯在大模型领域的战略和部署同样持续进化。 4月份，腾讯对其混元大模型研发体系进行了全面重构，围绕算力、算法和数据三大核心板块，刷新团队部署，加码研发投入。调整后，腾讯成立两个新的部门：大语言模型部和多模态模型部，分别负责探索大语言模型和多模态大模型的前沿技术，持续迭代基础模型，提升模型能力。腾讯官方人士表示，此举旨在优化研发流程、整合资源，以应对大模型时代日新月异的挑战。 此前，腾讯已经将元宝、ima、QQ浏览器、搜狗输入法等几大AI产品线整合，提出“核心自研+拥抱开源”的AI策略。具体来看，腾讯自研的混元模型多模态性能强劲。今年推出的“快思考”Turbo S模型和“深度思考”T1模型，在公开基准上均达业界领先水平；在视觉、3D生成领域，腾讯也开源了多款模型（如混元3D生成、混元视频生成、文生图DiT、千亿参数混元MoE模型等），这些模型在GitHub上收获了近3万星标。混元模型已深度嵌入微信、QQ、腾讯会议、腾讯文档等产品，提高了用户端的智能化体验，同时通过腾讯云向外输出能力，助力合作伙伴创新提效。 值得注意的是，据腾讯2024年四季度及年度财报显示，腾讯研发投入再次创下历史新高，达到707亿元，这为其大模型技术攻关提供了雄厚后盾。在持续的中场博弈中，腾讯凭借底层算法实力、开源影响力和全域生态的输出，构筑了独特的防线和进攻点。 同样，作为老牌互联网巨头，百度在2025年上半年持续加码大模型研发与开源，以“文心大模型”4.5系列为核心，先后推出并免费开放 ERNIE 4.5 和深度思考 X1，其性能在多模态理解和推理能力上已全面超越同级竞品，且通过 Turbo 版本将推理成本分别降低至 0.8 元和 1 元/百万 Token。 市场应用层面，文心一言平台自4月全面免费后，用户规模迅速攀升至 4.3 亿，日均调用量突破 15 亿次。未来 ERNIE 5.0 的推出，预计在多模态融合与推理效率上进一步革新。 在产品与生态层面，百度已将大模型能力深植搜索与智能助手，先后上线“AI搜”智能检索服务和通用智能体 App“心响”，覆盖知识问答、文档处理、旅游规划等百余场景，并通过开放 API 吸引开发者创新。 二、新锐突围，基础大模型格局再洗牌 除了“新老BAT”外，一些大模型初创企业同样展开全面进攻。 上海独角兽阶跃星辰作为新兴力量，今年来动作频频。2024年末该公司完成B轮融资数亿美元，由上海国资领投、腾讯等战略投资者跟投。官方披露，融资将继续用于核心大模型的研发，特别是强化多模态和复杂推理能力，并通过产品生态进一步渗透C端市场。 今年2月，阶跃星辰开源发布了其性能最强的两款多模态模型：其中“Step-Video-T2V”拥有300亿参数，能生成204帧、540P高质量视频；“Step-Audio”在多项公开语音评测中超越业内同类开源模型，尤其在汉语六级水平考试中表现突出。 据了解，成立不到两年、团队500余人的阶跃星辰，在迭代了11个模型后跻身“AI六小虎”行列，并被《麻省理工科技评论》评为“中国值得关注的四家AI创业公司之一”。公司高管透露，团队中算法和技术人员占比接近八成，创始人姜大昕为微软前高管、IEEE Fellow入选者，首席科学家张祥雨则为ResNet论文合著者。这些“高密度人才”正支撑阶跃星辰在多模态技术上的狂飙突进。 与此同时，来自清华学府的智谱AI也高速扩张，并已启动上市进程。今年4月，智谱AI正式在证监局备案辅导（中金公司为辅导机构），标志着其成为国内首家进入IPO流程的大模型创业公司。 智谱AI自2019年成立以来，一直专注认知智能大模型研发。该公司与学术机构合作打造了中英双语千亿参数预训练模型GLM-130B，并基于此推出了对话模型ChatGLM及其开源版本ChatGLM-6B。 除通用模型外，智谱还推出了多模态和行业应用组件：包括AI助手“智谱清言”、高效代码生成模型CodeGeeX、视觉语言理解模型CogVLM、文生图模型CogView等。商业模式上，智谱主张“模型即服务（MaaS）”，已建成AI开发开放平台，为政府和企业提供私有化部署和智能体解决方案。 据官方介绍，其MaaS平台已支持百万量级开发者，与全球多家车厂、终端厂商合作，将大模型从“聊”引向“行”。凭借深厚学术背景与产业合作，智谱AI正力图成为“基座模型”领域的领军企业。 在这阵营中，DeepSeek的声音当然也不容忽视。DeepSeek团队非常低调，但技术打法极具冲击力。他们专注于语言模型、尤其是数理逻辑能力，并秉持坚定的开源策略。今年农历春节期间发布的DeepSeek-R1模型，以远低于常规的算力投入，实现了与GPT-4等顶级模型媲美的性能。 业内分析认为，DeepSeek在训练方法上的创新才是关键：其采用的Mixture-of-Experts架构使模型参数总量达6710亿，但运行时只激活37亿参数，大幅降低计算需求；多Token预测和“潜注意力”等技术也极大提升了效率。 简言之，DeepSeek走的是偏科研的路线，不急于变现，团队以顶尖新秀为主、规模精简，将更多资源投入算法优化。正因如此，一度被忽视的DeepSeek一经开源便引爆关注，据报道，其App已突破3000万日活，成史上最快登顶的AI应用之一。投资者与同行也纷纷围拢，例如新浪财经报道，“DeepSeek-R1开源后，众多业内人士重新审视DeepSeek的技术实力，私募纷纷尝试接触其创始人梁文锋”。DeepSeek通过极致的工程优化与开源创新，已悄然建立起自己的竞争优势。 总体来看，以字节跳动、阿里巴巴、腾讯为代表的新BAT，以及阶跃星辰、智谱AI、DeepSeek等新兴主力，构成了当前中国AI“大模型”赛道的进攻重兵。他们在技术研发、人才储备、资金投入和市场开拓上全面发力，推动着AI技术不断向世界前沿靠近。在这种格局下，大公司的优势在于资源与生态整合，而创业公司则更强调创新与专注，各有千秋。 三、退守与聚焦，AI六小龙瓦解 相比之下，“AI六小龙”——曾被寄予厚望的创业小企业，则出现了明显分化。 以李开复创办的零一万物为例，2025年伊始便曝出要将预训练团队出售给阿里的传闻。尽管李开复辟谣称并非出售，但他已承认“目前只有大厂能持续投入超大规模模型训练”。公司大幅调整方向，主动与阿里云合作成立“产业大模型联合实验室”，将预训练算法团队和基础设施团队交给阿里，专心做小参数高性价比模型。他坦言：“我们不再做超大模型，不是因为不相信 Scaling Law，而是把这件事交给能做的大公司来做，我们跟他们合作，这才是生存之道”。 零一万物开始放弃自行训练万亿参数模型，转向针对电商直播、会议等场景的行业智能应用，推出 AI 数字人和“Yi”系列服务。虽未立刻倒闭，但其已清晰地从“造基座”往后撤步，调整为聚焦落地应用。 同样，百川智能也显示出战略调整迹象。2024 年 7 月宣布完成 50 亿元人民币 A 轮融资，估值约 200 亿元，投资方包括阿里、腾讯、小米等互联网巨头。百川主打医疗方向，大模型“百川-53B”于 2023 年底问世，AI 助手“百小应”上线，曾在 2024 年 WAIC 展台展示医疗问诊应用。 而今年3 月中旬就有媒体爆出，百川两位联合创始人已经确认离职。股权回购与融资并购也传出争议。此外，王小川在内部信中提到了成立两年来百川智能的不足，称公司“两年来战线拉得太长、不够聚焦”，公司前后已经裁撤部分 ToB 金融部门，将重心回归医疗专家模型和百小应产品。可见百川虽依然获得资金支撑，维持产品更新和生态拓展，但内部正在精简业务以求聚焦。 月之暗面近期明显收紧打法，缩减烧钱战略。春节后有媒体披露，在DeepSeek攻势之下，月之暗面决定大幅压缩市场推广预算，暂停多款安卓渠道投放并解除第三方广告合作。公司内部将此归因于“外部环境变化和战略调整”，表明其营销打法将更加谨慎。 此前，月之暗面曾以广撒网的方式重点推广AI助手Kimi，也在海外推出Ohai、Noisee等产品。但根据晚点财经报道，月之暗面今年9月已决定停止Ohai和Noisee的运营，将资源集中在核心产品Kimi。有两位负责海外产品的高管离职创业，创办了定位于AI编程的公司。这些动向与资本市场的谨慎形成对照，不难看出，这家曾估值近25亿美元的独角兽在战术上更加聚焦，降低了非核心业务拓展的投入。 而MiniMax的路径选择就显得既谨慎又富有张力。这家曾因创始团队出身商汤而备受瞩目的公司，早期凭借Talkie这类情感陪伴类应用快速打开海外市场，日交互量一度突破30亿次，但如今却面临用户增长乏力、留存率下滑的困境。当赛道瓶颈逐渐显现，MiniMax继而调整策略，逐渐淡出同质化严重的情感陪聊红海，转而将资源向视频生成、音乐创作等更具技术壁垒的领域倾斜。 MiniMax作为国内首个自主研发MoE混合专家架构的团队，他们早已不满足于单一模态的较量，而是构建起覆盖文本、语音、图像、视频的全矩阵模型体系。 产品布局上，MiniMax采取To B与To C双线并进的策略。To B端通过开放平台接入3万家企业，覆盖客服、教育等标准化场景以降低边际成本；To C端则依靠星野、Talkie等情感陪伴应用积累日均30亿次交互数据，但面临用户增长放缓、付费能力有限及海外监管风险。近期推出的海螺AI试图以文生视频、音乐生成等特色功能突破同质化竞争，但渗透率仍需提升。 今年3月，MiniMax虽获6亿美元A + 轮融资，旗下Talkie应用日交互量超30亿次，却仍未找到稳定盈利模式。尽管有大量资金注入且产品有一定用户活跃度，但MiniMax在盈利模式上尚未取得突破，目前仍在不断尝试和调整，以在竞争激烈的市场中找到可持续发展的道路。 总的来看，AI创业“小龙们”的走势已有显著差异，但是，这种趋势并非败退，而是行业成熟期必然的理性回调，最终目标是在巨头夹缝中守住“小而美”的生存空间。 相反，以字节、阿里、腾讯为首的重量级玩家由于资金、人才、生态和数据积累优势，正处于中场竞赛的主动位置。未来谁能在“智能上限”和“多模态能力”上取得突破，还有待考验。 但可以肯定的是，这场“中场战事”已经由此前的狂飙突进转向稳扎稳打的比拼，各路玩家都在砥砺技术、优化策略，一方面力图保留优势，一方面寻求新的成长路径。要知道，“大模型的路要跑得清楚，最终还得落到产品上”，谁能走得更久、更稳，将决定这场AI竞赛的下一阶段格局。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 16596,
      "title": "「财经分析」大模型迎来“降本增效”年 “独角兽”们应对冲击...",
      "time": "2024-01-15T00:00:00+00:00",
      "content": "新华财经上海1月15日电（记者杜康、朱程）岁末年初，国内外主流大模型再次降价。DeepSeek-V3因其训练成本之低引发国内外热议，让行业开始反思，无限追逐更大算力集群、更多数据量是否是大模型优化唯一道路。伯克利大学NovaSky 团队Sky-T1-32B-Preview开源模型的发布，再次印证了高水平AI研发不需要天价预算。行业也由单方面的性能角逐，转向性能与实用性并重的发展趋势，更加注重性价比。 成本的降低，无疑将进一步加快大模型的场景落地。这同时也对大模型创业公司提出挑战。在与大厂的“价格”比拼中不具备优势的创业公司们，迫切需要寻找到一条差异化道路，避开互联网厂商的“射程”将是关键。 训练成本降低 效率成为行业关键词 日前，DeepSeek-V3因其训练成本之低引发行业热议。从其正式发布的技术报告来看，DeepSeek-V3完整训练只需2.788M H800 GPU小时，包括预训练、上下文长度外推和后训练。假设H800 GPU的租金为每GPU小时2美元，其总训练成本仅为557万美元。Deepseek也透露，上述成本不包括与架构、算法或数据相关的先前研究或精简实验的成本。 美国人工智能公司Anthropic的CEO达里奥·阿莫迪曾透露，GPT-4o这样的模型训练成本约为1亿美元。这意味着DeepSeek的成本只有GPT-4o的1/20。 训练成本降低的同时，DeepSeek-V3保持了高性能。根据其公告，DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲。 为什么DeepSeek-V3能够实现低成本、高性能？“包括模型架构、基础设施优化、数据优化在内，我们看到DeepSeek-V3从端到端都进行了工程优化，叠加后呈现出很好的效果。”Gartner研究总监闫斌介绍，大模型进入公众视野大约时间尚短，只有两年多时间。期间，行业模型训练相对粗放，通过尽量多收集数据，建设更大的数据中心，以获得更好的训练结果，行业也用“Scaling Law”总结这一过程。 “DeepSeek-V3证明了，通过更好的工程化能力，我们可以通过相对较少的算力资源、较小的模型，也可以达到不错的训练效果。”闫斌说。“目前行业在数据和算法方面仍有优化空间，低成本的训练和高效推理应用或将是下一阶段大模型发展的方向之一。” 值得关注的是，伯克利大学NovaSky 团队也刚刚发布了Sky-T1-32B-Preview开源模型，在常见的推理和编码基准测试中，与OpenAI的o1-preview“平分秋色”。据称，其训练成本不到 450 美元，展示了以经济高效的方式复制高水平推理能力的可能性。 NovaSky 团队之所以能够以如此低成本进行模型训练，其关键之处包括使用了数据筛选机制，如通过QwQ-32B-Preview生成初始数据，通过GPT-4o-mini重写数据格式等。此外，NovaSky 团队选择了Qwen2.5-32B-Instruct作为基础模型进行训练。“这个项目证明了，高水平AI研发不需要天价预算。”行业人士评价道。 “效率是2025年大模型行业的关键词之一。除了少数公司有能力、有愿景用万卡，乃至十万卡继续追求顶级大模型，大多数公司未来要降本增效。事实上，优化注意力机制、采用MOE架构、降低模型激活的参数量等，都已经是很主流的降本方式。我们相信这会带来AI门槛的降低，以及技术的普及化，不仅体现在应用侧，还有研发侧。”瑞银证券中国软件分析师张维璇表示。 行业再降价 大模型创业公司将直面冲击 伴随着训练成本的降低，DeepSeek-V3 的API 价格目前为每百万输入tokens 0.5元（缓存命中）/ 2元（缓存未命中），每百万输出tokens 8元。同时，DeepSeek提供了45天优惠价格体验期，在2025年2月8日之前，所有用户使用 DeepSeek-V3 API 的价格分别下降了 80%（输入命中）、50%(输入未命中）、75%(输出）。 事实上，2024年上半年中国大模型“价格战”的发起者，正是DeepSeek。 2024年5月，DeepSeek率先宣布降价，其发布的第二代MoE大模型DeepSeek-V2定为0.001元／千tokens的输入价格与0.002元／千tokens的输出价格。随后，智谱 AI、火山引擎、 阿里云、百度、科大讯飞、腾讯云等国内主要大模型厂商迅速跟进。DeepSeek甚至获得了一个新称号——AI界“拼多多”。 可以看到，2024年年底，除了DeepSeek-V3 新版本的推出以及API 价格调整，国内大模型其他厂商也在降价。2024年12月31日，阿里云宣布2024年度第三轮大模型降价，通义千问视觉理解模型全线降价超80%，其中，Qwen-VL-Plus直降81%；更高性能的Qwen-VL-Max降幅高达85%。此前，在12月18日举办的火山引擎Force大会上，字节跳动推出的豆包视觉理解模型也宣布进行降价。 “大模型不断降价，无疑有利于吸引更多企业使用新的技术，为大模型创业公司提供了更大的市场。同时，这也对大模型创业公司构成了挑战。‘独角兽’们仅仅做到提升大模型能力还不够，还要不断优化算法，快速降低模型的推理成本。只有真正做到为用户提供更有性价比的大模型服务，才能赢得市场份额。”MiniMax副总裁刘华对记者表示。 经过一年多来的行业竞争，中国人工智能大模型的行业格局不断清晰，主要玩家从“百模大战”时代不断收敛。MiniMax与智谱AI、百川智能、月之暗面、阶跃星辰、零一万物6家行业“独角兽”企业估值均超10亿美金，被行业称为国内“大模型六小虎”；再加上关注度较高的幻方和面壁智能，以及互联网大厂中的字节、阿里、百度和腾讯，行业主要玩家缩减到十来家。 API接口调用付费是大模型企业B端重要商业化实现路径之一。不过，ToB业务中，由于互联网大厂可以将AI功能绑定算力和云服务业务，二者叠加商业推广上效率更高。因此，在“价格战”中，大厂因为业务复合、资金雄厚，也更有优势。面对“价格战”，创业公司只能化压力为动力，从加快迭代模型、不断优化算法中寻找解法。 “如果要拼低价和资源，创业公司肯定不如大厂。下一步，大模型创业公司可以聚焦在提供个性化服务，比如提供情感类大模型的API接口。”行业人士对记者表示。 “独角兽”们需差异化发展 避开互联网厂商“射程” 无疑，大模型训练成本、推理成本的下降，将进一步加快行业场景应用落地。事实上，寻找更合适的大规模落地场景、更好的商业闭环模式，已经成为大模型企业下一阶段发展的当务之急。 在接受采访时，多位行业人士提到上述提到的“大模型六小虎”开始出现分化，并表示有独角兽企业出现“掉队”的势头。“这也说明，大模型行业发展遇到了瓶颈。”行业人士评价道。 “从全球来看，大模型企业都面临一定的融资压力。大模型出现之初，大家对它的预期很高，后面又经历了预期的回调。与此同步，行业融资热度稍降。当然这也符合一项新技术的发展曲线。单纯通过讲故事已经很难找到投资人。”闫斌表示。 从B端应用来看，Gartner一份最新调研结果显示，截至2024年6 ⽉目前只有8%的中国企业将生成式人工智能部署在生产环境中。对此，闫斌解释称，目前大模型在中国企业生产场景中小规模落地已出现，但大规模企业落地仍然较为少见。“如果把最终落地应用比作一场考试，那么大模型能力、数据、工程化、产品设计将是几门关键课程。根据我们观察，国内很多大模型能力已经不错，目前落地短板更聚焦在其他几个方面。” 再来看C端落地。根据AI产品榜数据，目前用户量排名靠前的应用分别为抖音的豆包、MiniMax的Talkie AI、月之暗面的Kimi智能助手、百度的文小言，全球12月份的月活分别为7117万、2977万、1669万、1347万，在全球主要C端产品榜单中，分别位列第2位、第4位、第15位、第20位。 与创业“独角兽”们相比，“大厂”在C端应用推广上，展示出了流量和资本方面的巨大优势。字节2024年5月才推出AI对话助手“豆包”，凭借投流买量后来居上，成为过去半年增长最快的移动应用。“一些创业公司此前通过投流买量的方式迅速扩大了用户量。但随着‘大厂’下场，这种做法就显得不那么划算了。”有行业人士对记者表示。 “目前国内大模型企业的C端产品存在‘同质化’的问题，很多企业都推出了AI对话助手类产品，功能大同小异。但是，大模型技术在不断迭代。各家企业需要基于大模型能力的提升趋势，去探索新的AI产品形态，去满足客户们尚未被满足的需要。尤其是创业公司，更是要把资源聚焦于技术和产品的创新，而不是通过投流买量进入变成‘红海’的赛道。”刘华说。 编辑：王媛媛 声明：新华财经为新华社承建的国家金融信息平台。任何情况下，本平台所发布的信息均不构成投资建议。如有问题，请联系客服：400-6123115 举报/反馈"
    },
    {
      "doc_id": 16597,
      "title": "OpenAIo1炸场!价格战未停 AI大模型五大内幕|年中盘点",
      "time": "2024-10-04T00:00:00+00:00",
      "content": "文丨胡璞心 编辑丨张睿 【亿邦原创】2024年，大模型行业开始大起大落。 模型层突破迟迟未至——GPT-5难产，Sora现货变期货，技术曲线放缓，开路者优势岌岌可危。 应用层陷入价格战，大厂争相降价 ，百万Token收费从2元、1元、0.8元、0.5元一路跌到免费；明星创业公司艰难突围，套壳抢跑公司则批量倒下。 视频模型成为难得亮点，快手可灵AI在全球范围内一骑绝尘，美图、智谱AI、阿里云、MiniMax、生数科技等视频模型，均在运动控制、镜头控制、人物一致性方面取得长足进展。九月底，火山引擎DiT架构视频模型发布，头号玩家终于入场。 机器人被热捧——在所有科技展会上，机器人、机器狗、灵巧手都是最吸睛的展品。有人认为这又是一个超级大风口，有人则认为该泡沫将在一年之内破裂，就像过去两年的元宇宙、AR/VR。 在Q3即将结束的时候，Open AI终于向市场扔出“深水炸弹”。9月13日发布的OpenAI o1，号称首个具有“推理”能力的大模型，能通过推理过程逐步分析问题，直至得出正确结论。至此，大模型领域再次一扫颓势，继续创世野心。 本文将梳理2024年到目前为止AI大模型领域最值得关注的五大看点，共同期待接下来的新产品和新应用。 01 最期待：Open AI新模型炸场，万众一心为Scaling Law续命 今年模型层的入场券已经从万卡集群向着十万卡集群演进，但迭代速度依然不如人意，GPT-4发布一年多，GPT-5迟迟不能面世，Sora从现货变成期货，应用落地仅能稍稍提效，远达不到重塑商业模式的效果。 从年初开始，对大模型的唱衰之声不绝于耳，OpenAIo1的发布无疑有“挽狂澜于既倾”的效果。 o1 就是此前OpenAI一直在宣传的“草莓大模型”，它拥有真正的通用推理能力，不用专门训练就能直接拿到数学奥赛金牌，甚至能在博士级别的科学问答环节上超越人类专家。 奥特曼表示，虽然 o1 的表现仍然存在缺陷，不过你在第一次使用它的时候仍然会感到震撼。 不少人实测中发现，o1 上线之后，ChatGPT在回答问题前会花更多时间进行思考而非直接回应，具有改善和调整策略的能力。这是因为OpenAI o1在模型推理侧同样满足scaling law，即模型推理时间越久模型处理复杂问题能力愈强，通过不断的思维树检索和反复自我博弈，o1呈现出类人的逻辑思维潜力。 强化学习指的是，智能体在与环境的反复交互过程中持续学习，不断最大化其奖励。 “强化学习是过程监督而不是结果监督，每一步的思考过程都需要被标注，这类数据的获取非常困难，需要专业人士生成高价值的数据。”生数科技首席科学家朱军指出，“但效果也十分明显，这是时隔多年，大模型再次有算法层面的巨大更新。GPT是predict next token，从2018年GPT-1出来一直到GPT-4，除了加了一个MoE（混合专家模型）以外，没有什么太多的很新的东西。” “决定这一代AI技术的上限很核心还是文本模型的能力上限，如果文本模型能持续提升智商，就是能做越来越复杂的任务。”月之暗面CEO杨植麟则认为。他指出，有了强化学习， 新的PMF（产品市场匹配）机会可能会出现。o1可以分拆人物、自我回溯，做出高质量输出，在更高价值的场景，特别是生产力场景中，会率先出现应用场景。 更重要的是，o1成功给Scaling Law续命。“我预计未来18个月里，智能体的进展将非常令人兴奋。比如世界模型的创建和生成、虚实融合，尤其是在特定场景下决策能力的提升。它会利用推理、感知等能力来取得突破。”朱军补充。 02 最精彩：视频模型大混战，快手拔得头筹 自从2月Sora炸场，视频生成模型就成了AI的主战场。这一年Sora迟迟不见踪影，而冲击Sora的视频模型则如雨后春笋。 值得注意的不是模型数量的多少，而是视频模型的能力升级——经过半年迭代，视频模型从曾经的PPT动画，到如今可以基于提示词，生成4s-16s连贯视频，生成过程中可以保持人物一致性、场景一致性、风格一致性，可以进行镜头控制、运动控制。 视频能力的增强让创作者仅需三张定妆照完成一部短片；基于一张商品图，做一支广告片。视频可控性的增强则让视频模型广泛应用于电商、短剧、电影等行业。 生数科技CEO唐家渝告诉亿邦动力，视频模型改变了传统视频制作的步骤。比如，Vidu可以摒弃了传统的分镜头画面生成步骤，通过“上传主体图+输入场景描述词”的方式，直接生成视频素材。 图片来源：生数科技 7月，抖音和快手各自上线纯AI生成的短剧《三星堆：未来启示录》与《山海奇镜之劈波斩浪》，完成视频模型在短剧领域的首秀。青年导演李宁正在打造中国首部AIGC院线电影《玄宇》，他利用Vidu预创作了一段男主的视频片段，其中所有人物画面仅通过男主近景、中景、远景三张定妆照生成。 来源：《三星堆：未来启示录》 可控性的增强也在商业广告片方向展现了强大的潜力。 广告片的一大关键在于要保证多个镜头、不同场景下品牌物形象的一致性。而主体一致性功能能够很好的实现，仅通过一张商品图，便生成所有视频画面，无论是不同角度、背景，还是动态表现，跑步鞋的形象在整个视频中都保持了高度一致。 从更长远的视角来看，一旦实现了全面的可控性，视频创作行业将经历一场颠覆性的变革。当然，视频模型的生产力才初见端。 03 最激烈：价格战打到负毛利，大厂还不收手 大模型最激进的战场，当属价格战。 从4月各个云厂商的春季峰会开始，字节高调“起头”，阿里“击穿底价”，百度直接“掀桌子”……不到一周时间，大模型厂商针尖对麦芒，每百万token的输入价格，先后从2元、1元、0.8元、0.5元跌到免费。Token降价潮就将所有参与者卷了进来。 经过半年价格战，大厂把Token价格打到负毛利仍然没有收手，以9月份的云栖大会为起点，大厂又开始新一轮降价。 《财经》披露，今年5月以前，国内大模型推理算力毛利率高于60%，和国际同行基本一致。今年5月各大厂接连降价后，推理算力毛利率跌至负数。 这场价格战主要集中在大厂之间，尤其是有云业务的大厂，大模型创业公司并未跟进。 最激进的当属阿里云。据悉，阿里云内部将2024的AI类比为2012年的移动支付和2017年的短视频——2012年到2013年，3G过渡到4G过程当中，中国的移动支付两年增长了 800%；2017年到2018年，短视频增长爆发，整个短视频行业呈现8.5倍的增长。 降价的效果也立竿见影。今年8月，百度二季度财报电话会披露，百度文心大模型5月API日均调用次数是2亿，8月增长到了到6亿次；5月日均Token消耗量是2500亿，8月增长到了1万亿。 火山引擎披露，截至9月，豆包语言模型的日均tokens使用量超过1.3万亿，相比5月首次发布时猛增十倍，多模态数据处理量也分别达到每天5000万张图片和85万小时语音。随着AI渗透率提升，预期2027年豆包每天Token消耗量会超过100万亿，是现在的100倍以上。 更大的算力支出，更低的模型价格，更高的技术门槛，大模型的竞争尽管还没来得及取得太多商业化成绩，但已经开始进入淘汰赛。 吴泳铭在云栖大会提到，全世界先进模型竞争的投入门槛，将达到数十亿、数百亿美元的级别。过去一年，阿里云投资新建了大量的AI算力，但还是远远不能满足客户的旺盛需求。 从以CPU为核心，到以GPU为主的计算范式和市场需求的转变，成为云厂商以前所未有的强度投入升级AI大基建的主要原因。而云厂商为此要保持每年百亿元级别的算力资本支出。 怪不得王小川认为创业公司要活在大厂的射程之外，“我也是看热闹，和大家的心态一样。” 04 最有钱：百度、科大讯飞、智谱AI领跑行业 随着诸多大模型获得备案许可，围绕大模型的商业化进程需要进一步提速。 C端商业化目前处于探索阶段，不管是聊天、配音、视频还是数字人，大都提供免费服务，厂商看中的是MAU与留存数据。 B端是大模型商业化的重心，教科、金融、能源、政务成为重点领域，采购方主要为央国企、政府部门和科研院所，以项目招标为主。 据智能超参数统计，截止8月底，大模型相关中标项目551个，其中Q1有50个，Q2有187个，7月112个，8月127个，数量显著增长。同时上半年统计中标项目披露金额9.39亿元。 大模型公司在部分标杆项目的争夺中“短兵相接”。 在岚图汽车科技有限公司的AI大模型应用项目中，智谱AI报价约为348.81万元，腾讯云报价1334.10万元，科大讯飞报价758.96万元，智谱AI中标。 在中广核海上风电机组辅助诊断AI大模型研究采购项目中，智谱AI、科大讯飞、拓尔思直接竞标，智谱AI中标，报价比其他两家低200多万元。 在上海人工智能创新中心的项目中，更是出现0元中标情况。 在所有厂商中，百度、科大讯飞、智谱AI的中标数量领跑行业。 其中百度延续了在AI领域的先发优势，无论在云计算还是大模型，百度的早期AI布局都在本轮换挡期抢到先手；科大讯飞深耕政企领域多年，竞争力强；智谱AI商业化迅猛，技术强认可度高，中标项目多，但中标行业较为分散，有价格让利。 据了解，目前围绕大模型相关的招投标项目，大致可分为4 个大类：算力、数据、模型、应用。其中应用类占比超70%，算力类项目紧随其后，智能客服助手、辅助编程、数据分析类是需求最多的应用场景。 05 最五花八门：机器人花式整活儿 今年最热闹的大模型应用，当属具身智能。 在7月5日的2024年世界人工智能大会，一进世博展览馆的正门，18款列队站好的人形机器人向游客招手。H1会场内，蹦跶着各种尺寸各种形态的机器人，宇树科技的机器狗翻着跟头到处卖萌，逐际动力双足机器人摇头晃脑到处溜达，达闼的美人鱼机器人翩翩起舞，穹彻智能的机械臂在叠衣服、削黄瓜。 在8月21日的世界机器人大会，人形机器人毫无意外地成为全场焦点，不仅会摆摊磨咖啡、摊煎饼果子、打冰激凌，还会多才多艺写毛笔字。 几乎所有人都对人形机器人发展抱有热切期待。 中国科学院院士毛明表示，人形机器人正在迅速成为智能制造、医疗、家庭服务等行业的变革力量。全球市场年增长率超 20%，预计 2025 年达数百亿规模。 宇树科技CEO王兴兴认为，最迟明年年底之前，全球范围内一定会出现比人跑得快的人形机器人，“比如说100米跑进10秒，在体育项目和文艺演出上，人形机器人比做家务应该更得心应手。” 不过人形机器人热度虽高，落地依然困难。多位参展的人形机器人厂商表示，人形机器人目前主要出口欧美，使用场景为科研场景。开普勒机器人则计划今年下半年量产先行者K1人形机器人，预计售价在3万美元左右，用于科研。 由于特斯拉的示范性作用，也有厂商将汽车主机厂当作主要落地场景。 王兴兴也认为，人形机器人距离真正大规模应用的主要限制在于机器人人工智能方面尚未突破临界点，随着近年来在人工智能取得快速进步，可能在1-2年内会有一些小突破，3-5年内，有足够潜力实现实质性突破。 举报/反馈"
    },
    {
      "doc_id": 16604,
      "title": "寻求IPO或被收购,大模型创业企业步入收敛进程",
      "time": "2024-10-23T00:00:00+00:00",
      "content": "10月22日，有媒体报道称，大模型公司杭州波形智能科技有限公司（下称“波形智能”）将被手机厂商OPPO收购，“95后”CEO姜昱辰将入职OPPO。澎湃科技向波形智能求证，波形智能回复“目前不方便回应，暂时没有消息可以分享”。 从“百模大战”卷性能，到大模型降价、被收购，国内大模型企业正在经历洗牌。“有洗牌是正常的，行业发展比较快，企业需要快速适应变化。”某科技投资人10月22日对澎湃科技表示，目前国内大模型企业已经进入收敛进程中，国内大模型数量庞大，只有最头部的企业才能生存。 最好的结果是卖给大厂？ 此次被传收购的波形智能成立于2023年，CEO姜昱辰出生于1998年，本科毕业于浙江大学，在苏黎世联邦理工大学攻读博士，从事自然语言处理研究。2023年回到家乡杭州，去年3月创办了波形智能，Pre-A轮融资由蓝驰创投领投，西湖科创投、老股东藕舫天使等跟投。今年1月，该公司发布中文创作垂域大模型Weaver，及由其驱动的面向用户写作类Agent（智能体）产品“蛙蛙写作1.0”。 对于收购传闻，波形智能回复，“目前不方便回应，暂时没有消息可以分享。”OPPO方面则表示“目前暂无更多信息”。 早在去年11月，金沙江创投管理合伙人朱啸虎就曾预判，200多个大模型很快就会进入收敛期，大部分大模型现在很难差异化和商业化。没有商业化落地的AIGC（生成式人工智能）都是讲故事，投资人很难有兴趣。对于大模型公司的出路，朱啸虎今年在接受媒体采访时表示，大模型创业公司最好的结果是卖给大厂。但他表示，“在国内来说，你到底有没有一些额外的人才是大厂没有的？这是每个投资人都要思考的问题，大厂会不会为了这些人才花这么多钱去并购？” 积极融资，也力争上市？ 一方面是模型创业公司被传收购，另一方面，头部大模型公司频频融资，甚至寻求上市。 当前，国内大模型行业中，MiniMax、智谱AI、百川智能、月之暗面、零一万物、阶跃星辰被称为大模型公司“六小虎”，企业估值飞升，进入200亿估值时代。据北京市海淀区国资委旗下的中关村科学城公司今年9月5日发布的消息，该公司以投前200亿元估值领投智谱新一轮融资，用于支持智谱国产基座大模型的技术创新与生态发展。 今年7月，百川智能证实完成A轮融资，金额达50亿元人民币，A轮投资方有阿里、小米、腾讯、亚投资本、中金等头部大厂和市场化投资机构，也包括北京市人工智能产业投资基金、上海人工智能产业投资基金、深创投等国资背景产业投资基金。同时百川智能将以200亿元估值开启B轮融资。 此外，有明星大模型创业企业管理层日前告诉澎湃科技，业内有大模型公司“着急IPO”。上述科技投资人则告诉澎湃科技，头部模型公司肯定会尽快上市。 上述科技投资人也对澎湃科技表示，由于中国的融资环境，国内大模型企业面临的困境是“弹药”不够，“如果‘弹药’更充足，它们的生存会更好。本质是中国的创新生态不够，不敢冒风险，不敢在这种未来很有前景当然也有风险的事情上砸更多的钱。” 价格战对创业公司影响很大 对于大模型创业公司来说，一方面缺乏足够的弹药，另一方面还要面对来自市场的竞争。有业内人士表示，目前字节跳动和阿里都在打大模型价格战，“这两家降得比较狠，价格战对创业公司影响很大。” 今年5月，阿里云宣布通义千问GPT-4级主力模型Qwen-Long降价，输入价格从0.02元/千 tokens降至0.0005元/千 tokens，直降97%。4个月后，阿里云在9月宣布通义千问三款主力模型再次大幅降价，最高降幅85%，百万tokens价格低至0.3元。 字节跳动5月份宣布，豆包主力模型在企业市场的定价只有0.0008元/千 tokens，0.8厘就能处理1500多个汉字，比行业便宜99.3%。 但阿里云首席技术官周靖人不认为这是大模型价格战，大模型现在的价格还不够低，“对于未来庞大的应用来说还太贵了”。字节跳动旗下火山引擎总裁谭待8月份也表示这不是价格战，大模型原来的价格太贵了，现在是价格回归到应该回归的地方。 “现在创业公司的成本都比大厂高，售价也高，你根本就没法竞争。所以大厂打价格战，创业公司都不能跟进的，没法跟进。”朱啸虎今年在接受媒体采访时如此表示。 上述科技投资人也向澎湃科技表示，如果一个小企业只能跟大厂拼价格，就说明它走错路了。“大厂有大厂的优势，初创企业有初创企业的优势，初创企业更容易创新，如果大厂什么都能做成，就没有OpenAI的事了。但初创企业的劣势在于资源不如大厂多，所以初创企业必须做更创新、更冒风险的事，创新企业往往是最有前途的企业。” 澎湃新闻记者 张静 (本文来自澎湃新闻，更多原创资讯请下载“澎湃新闻”APP) 举报/反馈"
    },
    {
      "doc_id": 16607,
      "title": "国产大模型“标王”争夺战 AI生产力革命引爆",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "21世纪经济报道记者雷晨 北京报道 2025年，中国大模型技术迎来爆发式增长与结构性优化的关键转折点。 随着多模态理解、智能体（Agent）技术及推理引擎的突破，大模型从辅助工具跃升为核心生产力，深度渗透政务、金融、制造、医疗等实体经济领域。 公开信息显示，上半年招投标市场以64亿元规模、1810个项目刷新纪录，火山引擎、百度智能云、科大讯飞（002230.SZ）等头部厂商竞逐行业标杆。 而政策合规、资本共振与区域特色布局正共同塑造一个技术驱动、场景落地的产业新生态。 这场由技术革命引领的效率变革，如何重构商业逻辑与竞争格局？ 本期21世纪经济报道“中国龙”系列研究围绕数据、技术、政策、产业等维度，拆解大模型市场的爆发逻辑与未来挑战。 规模爆发 结构优化 大模型的角色已从此前的辅助性效率工具，向着主导性生产力主体转变，被视为推动企业生产力转型的重要工具。 技术突破正加速转化为商业价值。2025年上半年，中国大模型招投标市场呈现出“规模爆发与结构优化”的双重特征。 据智能超参数统计，上半年大模型累计中标项目达1810个，总金额突破64亿元，不仅中标项目数量已超过2024年全年的1521个，中标金额也接近去年全年的64.69亿元水平。 市场爆发的核心驱动因素，在于2025年成为央国企大模型落地成果验收的重要窗口期，企业用户更倾向于选择具备AI工程化落地经验的厂商，推动需求端持续扩张。 在市场竞争格局方面，百度智能云取代科大讯飞成为上半年“标王”，以48个中标项目和5.1亿元中标金额稳居项目数量与金额“双第一”，并在金融、能源、政务、制造等重点行业持续领跑。 此外，科大讯飞以3.7亿元、火山引擎以3.6亿元紧随其后，阿里云、智谱、腾讯云位居第四至第六名。 从季度数据看，2025年第一季度中标项目数量和金额同比2024年同期均实现近9倍增长，单季度中标总额（24.67亿元）已超越2024年前三季度累计金额（21.28亿元），市场动能强劲。 2025年第二季度大模型中标项目中，应用类项目数量占比已超过50%，显示市场重心从基础设施建设逐步转向实际业务场景的应用落地。 2024年大模型中标项目主要集中在运营商（行业前五）、政务等领域；2025年上半年行业覆盖扩展至金融能源、制造、医疗教育等更多传统行业，传统行业（政务/央国企/金融等）项目占比显著高于泛互联网领域，反映出大模型技术正从互联网企业向实体经济深度渗透。 采购主体方面，2025年央国企成为主要采购方，进一步推动行业应用向规模化与专业化发展。 从市场结构来看，行业正处于“算力基建向应用落地过渡”的关键转折点。在当前阶段，技术实力与实际落地能力成为衡量企业竞争力的关键标准。 技术突破 场景深化 2025年上半年，大模型行业在技术融合层面呈现显著突破，多模态能力与智能体（Agent）技术的协同发展，推动产业形成“技术-场景-商业”的正向循环。 在这一过程中，行业呈现出三大趋势，标志着大模型应用从通用化向深度行业定制化的加速演进。 首先，在多模态技术领域，大模型实现从单一文本交互到“图文音视频”全模态融合的跨越式发展。 Gartner预计，到2027年，40%的生成式AI解决方案将采用多模态技术，较2023年的1%显著提升。 国内厂商中，火山引擎今年6月发布豆包大模型1.6、视频生成模型Seedance1.0pro等新模型，其中豆包1.6系列模型支持多模态理解和图形界面操作；商汤日日新大模型从1月推出原生融合模态版本，到4月升级V6实现多模态推理突破，技术不断迭代；快手可灵AI构建多模态创意生产力平台，上线一年多以来，已累计生成1.68亿个视频和3.44亿张图片。 其次，智能体（Agent）快速普及。如果说多模态技术拓展了感知维度，那么智能体技术则重塑了业务执行的深度。 智能体技术实现从辅助决策向全流程自动执行的跨越，通过任务拆解、工具调用与流程编排，重构行业业务链条。 例如，国家电网“营销供电方案智能体”，可自动识别用户需求、拆解任务并生成供电方案，完成“用户需求-方案生成-工单流转”闭环。 中指研究院联合小冰科技开发的“AI招投标Agent”，聚焦物业招投标场景，通过本地化部署，实现3分钟自动完成标书撰写、5倍提升参标数量、废标率降低100%、中标率提升300%。 Gartner将AI智能体列为2025年十大战略性技术趋势，全球市场规模预计从2024年的51亿美元增长至2030年的471亿美元，年复合增长率达44.8%。 三是效率革命来临。推理引擎技术突破推动大模型应用成本显著下降，加速中小企业与长尾场景渗透。 京东云JoyBuilder推理引擎通过自研云海AI存储与负载感知调度，将推理成本降低90%，多轮对话响应时延压缩60%；AWSSageMaker通过“听”“说”分离并行处理优化，推理吞吐量提升30%以上。 此外，低代码/零代码工具降低应用门槛，阿里云百炼平台通过MCP协议支持企业快速接入大模型服务，首批覆盖生活信息、浏览器等领域的50多款应用，推动技术落地从“试点”向“规模化复制”迈进。 政务下沉 实体融合 进一步来看，大模型行业应用呈现显著的“从政务向实体经济渗透”特征，技术落地从政策驱动的政务场景逐步转向市场驱动的制造业、医疗健康、农业等核心实体经济领域。 其中，制造业作为实体经济的核心，大模型与工业软件的融合成为主流应用模式。 中国钢研基于昆仑芯、百舸算力平台及千帆模型开发，完成钢材表面缺陷检测等核心场景应用。 此外，中国电信杭州分公司的视觉大模型在工业质检领域通过数据回流优化，布料瑕疵检出率从85%提升至90%，已推广至全国10余家龙头纺织企业。 市场规模方面，2024年中国制造业数字化转型市场达1.55万亿元，预计2025年增至1.76万亿元，未来5年将以14%左右增速稳步增长。 医疗健康领域，大模型应用从单一辅助诊断向全流程渗透，覆盖病历管理、质控、诊疗决策等关键环节。兰州市第一人民医院部署的DeepSeek大模型集成至电子病历系统核心模块，支持电子病历结构化生成（自动生成处方、检查、治疗方案等）和病历内涵智能质控（智能纠错、用药冲突监控等），预计病历书写效率提升超50%，质控问题检出率提高40%。 农业领域则形成“AI+物联网+无人机”的技术闭环，以数据驱动农业全产业链数字化转型。茂名市“荔枝AI助手”接入病害防治知识库、气象数据等超500万条，将平均诊断时间从数小时缩短至5秒以内，准确率提升至95%以上，生产效率提升30%；广西产研院研发的农业物流与监测机器人，在500亩火龙果果园应用中可节省搬运人工和时间，其物联网低代码开发平台已在物流园区管理、能耗监测等领域试点。 整体来看，大模型在实体经济领域的渗透已从“试点验证”迈向“价值创造”。 数据显示，2025年上半年招投标市场中，政务、央国企、金融、医疗、教育等传统行业项目占比，显著高于泛互联网领域，其中央国企项目占比超六成，能源、金融、制造等行业成为落地主力，标志着大模型技术正深度融入产业核心生产环节。 合规筑基 政策赋能 从政策面来看，我国大模型行业国家层面政策框架已形成“合规-激励-基建”三位一体的系统性布局，通过制度规范、资源倾斜与基础支撑的协同发力，引导产业健康有序发展。 在合规体系构建方面，备案制成为行业规范化发展的核心抓手。依据《生成式人工智能服务管理暂行办法》《互联网信息服务算法推荐管理规定》等法规，面向公众提供服务的生成式AI企业需完成大模型备案，备案材料涵盖安全评估报告、拦截关键词库、语料标注规则等关键要素，以确保模型安全性与数据来源合法性。 截至2025年6月30日，累计有439款生成式人工智能服务完成备案，233款生成式人工智能应用或功能完成登记。 同时，立法进程持续推进。《人工智能法草案》于2023年、2024年连续被列入国务院立法工作计划，重点完善伦理规范、安全标准与治理规则，针对大模型训练中的知识产权合理使用等问题，探索通过法律解释或地方先行先试机制破解实践难题。《全国人大常委会2025年度立法工作计划》提出，人工智能健康发展等方面的立法项目，由有关方面抓紧开展调研和起草工作，视情安排审议。 内容安全标准同步提升，如地方层面已推行拦截关键词库建设要求，从源头筑牢内容风险防线。 激励措施聚焦技术研发与场景落地双轮驱动。资金支持方面，多部门联动设立专项基金，如科技部等七部门设立总规模1万亿元的国家创业投资引导基金，重点支持人工智能等领域种子期、初创期企业，通过“母基金+参股+直投”模式带动社会资本近1万亿元；工信部联合财政部设立600亿元国家人工智能基金，培育400余家人工智能领域国家级专精特新“小巨人”企业。 场景落地方面，“人工智能+”行动全面推进，2025年政府工作报告明确支持大模型在工业、农业、服务业等垂直领域应用，工信部通过“揭榜挂帅”机制攻关制造业重点场景，组织“十大行业、百大场景、千家标杆”赋能活动，加速通用与行业大模型在智能制造、智能工厂中的深度融合。 资本市场支持同步强化，证监会推出18条措施加大对人工智能等战略性产业的支持，优化私募股权创投基金退出机制，为科技型企业并购与融资提供便利。 算力供给方面，工信部强调统筹布局通用大模型和行业专用大模型，强化算力基础设施建设，地方通过“算力券”政策降低使用门槛，如上海对算力服务按30%给予补贴。 数据要素方面，《“数据要素×”三年行动计划(2024—2026年)》推动高质量行业数据集建设，《中小企业数字化赋能专项行动方案（2025—2027年）》支持建设公共数据集与垂直行业大模型，为中小企业应用提供数据支撑。 普惠服务方面，多地推行“模型券”与专项奖励，如武汉对备案大模型给予100万元奖励，降低企业技术应用成本，推动大模型技术向中小企业渗透。 总体来看，国家层面既明确了行业发展的“红线”与“底线”，又提供了资源支持与落地路径，为大模型产业从技术研发向规模化应用转型奠定了制度基础。 区域特色 多元布局 从地方来看，我国地方大模型政策呈现区域差异化特征，京津冀、长三角、珠三角等核心区域依托产业基础与资源禀赋，形成各具特色的发展路径，同时其他区域亦结合自身优势探索创新模式。 京津冀地区以北京为核心，聚焦技术攻关与产业升级。北京市将技术突破与新型工业化深度融合，出台《北京市人工智能赋能新型工业化行动方案（2025年）》，推出16条支持措施，包括对国内一流、国际领先水平的大模型算力成本给予最高3000万元支持，对工业仿真软件、中试平台等关键环节提供最高5000万元资金扶持。 在具体领域，北京重点布局具身智能机器人、工业大模型等前沿方向，通过“人工智能+”行动计划明确目标：2025年底形成3-5个自主可控基础大模型、100个行业大模型及1000个成功案例，标杆工程涵盖机器人性能验证、医疗辅助服务优化（如“北京医生”平台）、交通信号灯智能控制等场景。此外，北京在监管层面实施严格标准，要求大模型拦截关键词库规模达20万个，为行业合规发展树立标杆。 长三角地区以上海为枢纽，侧重场景创新与生态培育。上海市以场景驱动技术落地，通过“算力券+模型券”组合政策降低中小企业应用门槛，同时建设医疗服务管理大模型，推动检查检验结果互认与医疗风险预警，提升民生服务智能化水平。在基础研究领域，上海发布2025年“通用人工智能大模型”专项指南，聚焦具身自主学习算法、多模态生成内容鉴定等9个前沿方向，采用“阶梯追加支持”模式，单个项目一期资助最高50万元，优秀项目可获二期追加资金。长远规划上，上海目标2026年形成算法模型评测指标体系，2027年吸引不少于100家大模型生态企业集聚，构建协同发展的产业生态。 珠三角地区以广东为龙头，突出产业融合与终端落地。广东省聚焦大模型与实体经济的深度融合，2023年底即提出研发千亿级参数通用大模型，构建自主可控技术体系。在制造业领域，深圳作为核心节点，计划2026年实现人工智能终端规模冲击万亿，推出50款爆款产品（如AI手机、全屋智能设备），2027年突破机器人核心零部件技术，培育10家百亿估值企业。农业领域则探索“数据+模型”驱动模式，推动荔枝等特色农产品全产业链数字化转型，形成产业升级样板。 此外，其他区域实践各有特色。海南省依托自贸港政策优势，采用“政府主导、企业运作、多方参与”机制建设三医联动监管项目，推动技术方案与人才经验向周边国家辐射。重庆市实施“模动山城”计划，目标2027年智能终端产业规模破万亿，2025年底建成超大城市治理大模型V2.0。科技金融创新试验区（如安徽、苏州）通过“创新积分制”匹配金融资源，苏州元禾控股发行6亿元科创债定向支持高端装备领域基金，为区域大模型产业发展提供资金保障。 资本共振 产业协同 在内生创新与政策驱动下，大模型厂商的中标订单数量激增。 而通过构建“短期情绪-中期业绩-长期价值”分析框架，可揭示头部厂商股价与中标业绩的联动关系。 短期事件驱动层面，重大中标项目往往引发市场情绪快速反应。 2025年上半年，百度智能云以48个中标项目和5.1亿元中标金额稳居行业“双第一”，受此利好影响，百度（BIDU.US）股价在7月7日交易中上涨5%，收报90.68美元。 中期业绩验证环节，中标转化为营收的能力及盈利水平成为关键。 以科大讯飞为例，2025年第一季度公司营收实现27.74%的同比增长，达到46.58亿元，主要得益于大模型技术对G端、B端招投标评分的正向作用；然而，同期净利润仍为-2.28亿元，尽管同比亏损收窄35.68%，但“高研发投入-低盈利转化”的行业共性问题依然显著。长期价值分化趋势则更为明显。云厂商凭借全栈技术能力构建了“中标-营收-股价”的正向循环：百度智能云依托招投标领先地位，2025年第一季度业务同比增长率高达42%；阿里云因集团宣布“未来三年云与AI基础设施投入将超越过去十年总和”，带动中恒电气、浙大网新等概念股一度涨停，万国数据、世纪互联等合作商股价阶段上涨。 此外，企业资本运作通过并购重组、战略投资及产业链联动三大路径，与招投标市场形成协同效应，加速大模型技术商业化落地与产业生态构建。 在并购重组方面，科技创新企业借助资本整合实现快速上市，进而推动招投标市场突破。智元机器人于2025年7月通过协议转让、股权受让及部分要约收购（计划以每股7.78元收购1.49亿股，最高金额11.61亿元），合计持有上纬新材66.99%股权，成功借壳上市。 该案例成为新“国九条”和“并购六条”实施后的标杆，体现政策对科技创新企业资本运作的支持。 产业链联动方面，阿里算力订单放量消息传出后，曾带动海南华铁、中科曙光等企业股价上涨；腾讯大模型算力升级，亦需求推动浪潮信息、华勤技术等服务器龙头股价躁动。 当前，大模型技术的规模化落地，标志着人工智能从“试验场”正式迈入“深水区”。2025年的爆发式增长背后，是技术突破、政策赋能与市场需求的三重共振：政务与实体经济成为主战场，智能体重构业务流程，而区域差异化布局则催生多元生态。 这场生产力革命的下半程，不仅关乎技术迭代，更是一场关于商业本质、产业协同的全面竞争。 注：文中数据均来源地方政府，企业官网，行业报告等公开信息。 更多内容请下载21财经APP 举报/反馈"
    },
    {
      "doc_id": 16609,
      "title": "大模型商业化进入淘汰赛,赢家正在变少",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "文 | AI大模型工场，作者 | 西梅汁，编辑 | 星奈 在今年百度Create开发者大会上，李彦宏直言：“没有应用，芯片和模型都无法发挥价值。” 这句话背后，是产业正在迅速达成的一个共识：AI价值必须通过商业化实现闭环。从两年前OpenAI掀起技术热潮以来，大模型行业快速跃升成为全球科技焦点，但伴随而来的，也是一场从理想到现实的快速降温。 模型训练所需的高昂成本、C端应用的不确定性、ToB市场的复杂交付，以及持续烧钱的高压运营，让“钱难赚、屎难吃”这类行业黑话，成为现实困局的凝练表达。 此刻的AI产业，正经历一轮深度的分化。一方面，百度、阿里、腾讯、字节等平台型巨头以饱和式投入对抗技术拐点，通过自研、收购、云平台能力将AI全面纳入主营生态；而另一面，哪些没有树大根深的母系家族依赖的初创公司在技术与商业之间徘徊，一旦无法建立营收模型或稳定现金流，就会迅速从风口中滑落。 大厂承压，多元化变现，生态协同为王 从“跑模型”到“跑营收”，这条路并不好走。 在大模型的商业化赛道上，巨头拥有更强的抗压能力，根系足够发达，可以承接多元的商业化探索。从百度到阿里，再到腾讯，这些大厂拥有庞大的生态体系，它们的AI业务并非单纯地依赖某一块应用或场景，而是通过将AI能力嵌入到现有的产品、服务和云平台中，来实现跨界赋能和收入协同。 比如，百度通过文心大模型，把AI能力嵌入到搜索、地图、网盘等核心产品中，不仅提升了这些产品的智能化，还通过“千帆平台”对外提供AI服务，打入政务、金融等垂直行业，构建起了一个全方位的AI商业化闭环。 而其AI驱动的自动驾驶平台“萝卜快跑”也已经积累了千万级别的订单量，智能云业务也逐步盈利。这样，百度不仅实现了技术与产品的协同，还为自身在AI领域的生态扩展打下了坚实的基础。 阿里在通过将通义千问融入到钉钉、天猫精灵等高频应用中，借助阿里云“百炼平台”加速向B端市场输出模型和技术能力，构建了云服务+AI能力的双引擎。 腾讯则在自身强大的社交和办公生态内植入混元大模型，并通过腾讯云为各行业提供定制化的AI解决方案，进一步扩展其商业化边界。 这些大厂的共同特点在于，AI已不再是单一的技术项目，而是被作为基础设施嵌入到现有业务中，推动着营收的多元化发展。它们的AI战略更像是一种“平台化”的思维，借助现有流量和用户基础，快速实现从技术到商业的落地。因此，大厂的AI商业化，往往具备更高的市场抗压能力和更多的成长空间。 而字节跳动和快手在AI大模型的商业化上，虽然采用了不同的策略，AI主要用于提效主业或打造爆款应用，但都在各自的赛道上找到了突破口。 字节通过剪映、飞书、番茄小说等产品矩阵渗透不同场景，形成“流量+工具+服务”的协同效应。进入AI时代，字节以豆包大模型为核心，布局C端AI应用和B端工具链，如Coze平台，结合抖音的庞大生态深入Agent商业化。 从营收情况来看，虽然字节目前未上市，没有具体财务数据，但其旗下应用矩阵已实现月活跃用户超40亿，企业服务业务主要由飞书、火山引擎等承担。火山引擎2024年营收就已突破120亿元，2025年目标更是定为250亿元。 此外，据The Information报道，字节跳动正低调研发一款“护目镜”形态的轻量级混合现实设备，更是体现字节跳动在AI硬件方面的诸多布局。 相比之下，快手通过视频生成大模型可灵AI等技术创新，成功提升了内容生态与商业化效率。截至2025年4月已累计收入1.8亿元，企业API调用量超4000万次，估值达到80亿美元。 同时，其AI能力深度整合至电商与广告核心业务，C端通过AI试衣、智能客服提升用户体验，B端为商家提供AI工具，如直播切片生成，可见AI已成为快手电商增长的关键驱动力。 可以看到，字节一方面打造AI应用，另一方面用AI给自身业务提效，而快手则依赖于垂直场景的深耕，逐步形成了自己的盈利模式。虽然两者的路径不同，但都依托于技术与生态的协同，成功打破了各自行业的商业化困局。从市场趋势来看，谁能在技术创新和场景渗透中找到平衡，谁就能在这场AI商业化的赛道中占据先机。 小厂负重，变现难 那么，与这些拥有自有流量或平台优势的巨头不同，一批以技术起家的模型创业公司，必须以更具辨识度的策略寻找路径。 相比于资源充裕、业务多元的大厂，创业公司的流量和平台红利更加有限。在这种情况下，它们往往选择了在ToB或者ToC的垂直赛道上深耕，试图通过专业化和技术优势来赢得一席之地。 智谱、阶跃星辰和商汤等公司，主要集中在ToB市场，面向政府、金融、制造等领域提供定制化的AI解决方案。它们虽然在技术能力上积累了显著优势，但缺乏大厂的资金支持和生态体系，普遍依赖政府订单和企业客户。 ToB市场本身回款周期长、项目转化门槛高，导致商业化进程缓慢。即便如商汤这样自建SenseCore AI大装置、承接大额项目，也仍要面对高额的前期投入和不确定的回报周期。 与之对应，Minimax和月之暗面等公司则多选择ToC市场上的路径，多是直接面向消费者进行AI应用的落地。这些公司在产品上进行了创新，例如Minimax通过推理模型的开源和低价API吸引开发者，并凭借星野AI、海螺AI等产品迅速吸引了大量C端用户。 月之暗面则在过去一年通过Kimi抢占了用户心智，持续推出面向写作、搜索、知识整理的轻量化工具，形成了一定的用户付费习惯。最近发布的Kimi K2，更是在推理性能、上下文长度和生成速度上进一步强化了产品竞争力。 但在ToC市场，尽管用户基数庞大，留存和变现依旧艰难，如何将短期的规模化增长转化为长期、稳定的收入，依旧是这些小厂必须面对的挑战。 另外，除了大厂的多元布局和上面的创业公司垂直深耕之外，DeepSeek的路径稍显不同。年初通过开源DeepSeek-R1模型快速积累了巨大的开发者社区，建立起独特的技术生态，也由此吸引了大批C端用户。在短短一年内，它已经成为国内C端用户最多的AI平台，月活用户接近1.7亿。 然而，据Semianalysis报告，用户使用率从年初峰值7.5%回落，官网流量降至3%，近期其官网流量和用户活跃度出现明显下滑，面临着巨头追赶和用户留存的双重压力。 但与其他AI创业公司不同，DeepSeek似乎并不急于盈利，而是将重点放在技术的深耕和生态的扩展上，未来的商业化路径可能会随着技术的不断进步和市场需求的变化而逐步清晰。 无论是大厂还是小厂，AI商业化的核心挑战始终在于：如何从单纯的技术创新，转向能够持续盈利的闭环模式。大厂凭借强大的资源优势，在广泛布局和多元化收入中找到了自己的节奏，而小厂则必须通过专注细分市场和不断深耕技术，寻找自己的突围路径。 对创业公司而言，商业化过程中的变现难题仍然没有解决，如何有效连接技术、用户与商业，是它们能否生存下去的关键。而像DeepSeek这样的“特例”则表明，在大模型行业中，并非所有公司都必须迅速变现，有些公司可以通过建立技术生态、积累用户口碑，为未来的商业化奠定基础。最终，AI赛道上的“赢家”不仅仅是那些技术最先进的公司，更是那些能够在“技术”与“商业”之间找到平衡的团队。 没有现金流的模型，终将死去 不过，无论是大厂还是初创公司，最终都要回答同一个问题：如何建立起健康的现金流闭环。 在C端市场，虽然潜在用户庞大，但要真正穿透流量、留住用户并实现营收，仍然面临巨大难度。AI应用如写作、娱乐、社交、教育等场景虽然有潜力，但要实现闭环需要较高的产品体验、留存机制和成本结构的协同，这对团队的打磨能力要求极高。即使是拥有庞大用户基数的DeepSeek，也面临用户活跃度下滑的挑战，凸显了C端留存与变现的普遍难题。 如今，在App Store和安卓市场持续占据下载前列的AI应用几乎都依托于大厂渠道或工具属性，这进一步说明独立跑通C端模型商业化的困难。 对于没有母公司支撑的初创公司，资金链的稳定性至关重要。尽管AI技术的开源给了许多公司展示技术能力的机会，但许多初创企业未能在市场上找到足够的盈利来源，导致它们的运营压力巨大，最终无法承受亏损而退出市场。尤其是对于没有强大资本背景的公司，如何在短期内找到稳定的现金流成为关键问题。 尽管ToB市场提供了较为稳定的客户群体和订单来源，但B端的客户教育成本高、转化门槛大，尤其是对于初创公司而言，如何与传统企业建立合作并进行深度定制，依然是一大挑战。此外，大厂在ToB市场中的布局愈加完善，形成了强有力的竞争，进一步加剧了初创公司在这一赛道中的压力。 AI的技术能力固然强大，但它能否真正落地到应用中并解决实际问题，才是其商业化的关键所在。许多公司尚未能够将AI技术与具体行业需求结合，导致其技术虽然先进，但无法形成真正的应用场景，从而无法产生可观的收入。 训练和推理都需要算力支撑，GPU 成本仍居高不下。一些初创公司盲目堆参数，结果上线一个模型，光推理就烧光融资。DeepSeek 能跑出来，靠的是极致成本控制和标准化输出。 同时，大模型的商业化的过程中，最难的部分就是如何将技术转化为现实中的商业价值。技术本身的复杂性和应用场景的多样性，使得AI产品的落地应用变得尤为困难。尤其是在没有稳定现金流的情况下，很多初创公司无法承受运营压力，最终不得不退出市场。 像很多AI App虽然短期用户增长快，但真正能沉淀高复购的产品很少。内容生成、写作、娱乐等场景看似火爆，但要实现真正闭环，需要产品体验、留存机制和成本结构三者协同，这对团队产品打磨能力提出了极高要求。或许只有像可灵、星野这类深入细分场景的产品，才能把用户变成现金流。 而目前在App Store和安卓市场持续占据下载前列的AI应用，几乎都附着于大厂渠道或具有极强的工具属性，进一步说明独立跑通C端模型商业的难度不容小觑。 另一方面，To B 和 To G 市场虽然单价高，但交付周期常常超过半年，审批、招标、定制都耗时。没有稳定现金流撑着，很容易断粮。 此外，AI技术的商业化需要巨大的投资和长期的技术积累，而这些初创公司往往缺乏这样的资源。这使得他们在竞争中处于不利地位。对于这些公司来说，如何找到可持续的盈利模式，将是决定它们生死存亡的关键。 穿越AI周期 要穿越这一周期，也许要回到一个起点：模型不是全部。 真正的产品，不在于参数有多强，而在于能否解决一个具体问题。高考志愿填报、医疗问诊、办公自动化等场景中，都已经出现高频、刚需的AI能力嵌入。用户并不在意底层模型有多少层Attention结构，而是关心能否节省时间、降低成本、减少错误。在这个逻辑下，AI产品的核心将从模型通用性走向任务完成力，从泛智能向垂直刚需收敛。 与此同时，生态协同正在成为关键变量。一个模型即便能力强大，若无法接入业务流程，依然无法落地。百度的“文心+千帆”、腾讯的“混元+微信”、字节的“火山引擎+API”策略，实质上都是在构建“平台-模型-产品”的联动闭环，提升模型在不同层级中的适配能力。初创公司若不能进入这种生态协作体系，势必面临更高的客户教育成本与转化门槛。 在全球视角下，中国AI公司也在探索开源与出海的组合路径。DeepSeek、月之暗面等公司在GitHub的开源项目持续积累开发者口碑，而MiniMax、智谱等也在新加坡、中东等市场布局多语种版本与本地化部署。 技术竞速阶段已经过去，如今的大模型行业不是谁的参数最多，也不是谁的演示最惊艳，而是谁最能将模型能力嵌入到真实业务中，形成可持续的现金流，熬过资本降温后的淘汰期。 最终留下的玩家，不一定是最先锋的探索者，而是那个最早找到客户、最早形成收入、最能调整方向并活下来的团队。这场赛跑的终点，不属于浪漫主义者，而属于在冷静中构建价值闭环的现实主义者。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 16612,
      "title": "行业大模型完成关键一跃,商业落地迎来新春天",
      "time": "2024-05-30T00:00:00+00:00",
      "content": "AI通用大模型如火如荼，开源模型生态和算法优化领域相继取得重大突破，带动各大产业走上“AI+”进化之路。 然而，繁荣表象之下，通用大模型发展仍面临政策、技术、商业化多重挑战。特别是AI+落地最后一公里（落地应用），考验着市场的韧性，驱动着品牌探索、创新与突破。有压力就有会动力，有困局就会有突破，于是AI头腰部品牌领路，各行业知名企业与创业公司跟随，AI行业大模型迅速火热起来，并将迎来新一轮的密集爆发，持续推进大模型应用落地的垂直化、企业化。 来自“不可能三角”的行业困扰 基于参数规模大、泛化能力强、支持多模态等特点，通用大模型在多行业展现出蓬勃活力，为企业提供广泛知识基础以及优秀交互体验。只是，规模定律驱动通用大模型性能提升的同时，也产生了“不可能三角”问题：专业性、泛化性和经济性三方面很难兼得。尽管通用大模型在泛化能力和涌现能力上表现出色，或许能在100个场景解决70%的问题，但是却未必能100%满足企业对某个场景的需求。 《大模型落地路线图研究报告（2024年）》也对通用大模型工程实践复杂、技术选型困难、能力评估不全面等问题进行了阐述。几处要点尤为值得关注，比如，专业背景差异导致沟通鸿沟，通用大模型数据积累不足，在强专业性产业难以提供高价值服务。结构复杂，计算量大，响应时间延迟无法满足实时性应用场景需求。输入模型数据不准确，导致输出结果不可靠，也会影响到决策。 基于上述问题，《研究报告》也给出了解决方案，即遵循“需求拉动、问题驱动、创新推动、技术带动”四大原则，扎根基础设施、数据资源、算法模型、应用服务、安全可信等市场需求，着力优化大模型提示工程与引导，充分融入领域知识与实践经验。而从品牌方角度来看，提升大模型对任务需求理解能力以及场景适应力，以达到大模型与特定领域“天生适配”的目标，则成为加速商业落地，攻克技术力与服务力“最后一公里”难题的核心点。 期间，科大讯飞、标普智元、百川智能、百度智能云作为中国AI大模型四大新锐品牌，以不同技术路线、资源禀赋和商业模式，演绎破局之道，为全行业发展带来启迪。 “技术适配+场景重构”的落地新范式 以优秀的通用大模型为基础，通过提示工程、检索增强生成、精调、继续预训练/后训练等方式生成可满足企业实际需求的行业大模型版本（或具备行业大模型功能），目前已成为加速大模型高效落地的主流选项。只是，这一过程却并不简单，并直接考验着AI品牌多维度综合实力。期间，AI品牌需打造涵盖诊断、建设、应用与评估的有效闭环，需集合大模型训练推理平台、高质量数据集、算法模型资产、应用服务平台、风险控制体系等一揽子配套设备，方能从真正意义上革新大模型运用范式。 科大讯飞、标普智元、百川智能、百度智能云四大新锐AI品牌也均是在完善技术与服务架构的基础上，集合优势点，走出了独特的技术升级与市场拓展路径。其中，科大讯飞依托星火认知大模型3.0架构，实现了语音大模型一体化训练、多方言识别高准确率、实时语音转写等特色技术突破，在教育以及医疗场景实现深度运用。百川智能采用\"基础模型+行业套件\"，将行业知识注入架构，利用动态参数激活技术，打造企业级微调工具链，在政务、制造业、金融科技领域建立深度竞争优势。百度智能云基于文心大模型，实现了文本、图像、语音、视频等多模态数据处理，并围绕金融、医疗、法律等行业进行模型垂直优化，后续还将在算力自主与商业模式上进一步深挖与拓展。 至于标普智元，该品牌具备自主研发大模型的能力，并依托BPai 大模型管理平台、智能体开发底座、知识库管理平台，在保持模型基础能力通用性的同时，持续强化对特定行业知识与业务场景的精准适配，形成了一整套可复用、可迭代的模型训练方法与应用流程，为金融、保险、环保、政务、制造等多领域大中型企业铺就“AI+”的向上路径。 除了多模型管理平台、多模态知识库管理平台、智能体开发管理平台所提供的快速部署与迭代更新、优秀智能问答、智能体全生命周期管理等服务外，标普智元通用智能体还以强大多场景刚需覆盖能力著称：超级办公助手可让客户自然语言描述需求，即可精准获取指定字段内容，精准切入财务、法务、人事等业务场景；超级销售助手支持多渠道接入、全天候服务、客户画像分析，具备真人陪伴式体验，有效提升客户转化率与满意度；超级知识专家则有着企业内部“百事通”的名号，专注解答考勤、报销、审批等规章制度、流程相关问题，提升企业管理效率。 可以看出标普智元属于典型的六边形战士，有着成熟的一站式产品矩阵、完善的模型工具以及齐全的配套服务，具备着门槛低、效率高、适合落地等特点。市场数据不会说谎，在沙利文《2024年中国 AI Agent年度榜单》中，标普智元荣获「最实用 Agent TOP10 」称号。在中国信通院铸基计划《高质量数字化转型产品及服务全景图（2024全年度）》中，标普智元入选“AI 大模型”领域的重点产品及服务提供商。 熔炉与新生中的AI产业新蓝图！ 从政策支持，到品牌创新，从众多大中小微企业积极参与数据更迭，到各应用场景的具象化，在一系列的横纵向产业联动中，中国AI大模型已稳步朝着聚焦高覆盖、强深耕、厚细作的全域智能化体系推进。再加上技术普惠化带动AI大模型规模化应用，AI大模型商业化路径以及规模效应快速凸显。 而对于标普智元这样的AI大模型/企业经营智能体的引领者，其在深度赋能金融、保险、环保、政务、制造等各行业企业的同时，一系列优秀落地成果也为行业大模型训练以及优化提供更多参考，并逐步形成可复制、可推广的经验模式。 例如，在金融领域，标普智元金融（财富管理）大模型基于金融知识库、智能识别、智能录入等方案，可即时响应客户在线咨询以及协助客户智能开户，同时也能为高净值客户实时提供投资建议、产品推荐、产品匹配等个性化优质服务。 又如保险领域，标普智元保险大模型对比传统手工处理，人员使用降低90%、险单处理效率提升10%（7*24小时，每个Agent每天处理上千张）的同时，具备AI防欺诈、AI制定赔付方案等功能，助理保险行业降本增效、增收提智。 再比如环保行业，标普智元打造了“DeepSeek一体机，助力电厂智慧升级”经典案例，帮助电厂实现发酵均匀度提高30%、主蒸汽稳定性提高20%、发电效率稳定性30%、冷却水循环效率提高12%、排放达标率提升至99.5%的预期目标。 林林总总，AI大模型从改变企业内部工作方式出发，驱动企业与产品变革，让产品研发、客户服务、财务管理、营销策划等各个端口秒变性价王者，激发产业新格局。如今，大模型已经成为越来越多企业迈向智能时代，探索企业发展天花板的新标配。 而在这场正在发生的“让企业智力资源更聚焦于认知升级”的商业浪潮中，一副大模型改变中国的宏伟蓝图已浮出水面，包括科大讯飞、标普智元、百川智能、百度智能云在内的大模型品牌也将继续助力企业，助力中国经济开创下一个黄金30年！ （图片由深圳标普智元科技有限公司提供） 来源：中国日报网 举报/反馈"
    },
    {
      "doc_id": 16614,
      "title": "「产业互联网周报」阿里通义千问与DeepSeek开源两款新模型;谷歌...",
      "time": "2024-03-31T00:00:00+00:00",
      "content": "【产业互联网周报是由钛媒体TMTpost发布的特色产品，将整合本周最重要的企业级服务、云计算、大数据领域的前沿趋势、重磅政策及行研报告。】 国内资讯 宝马官宣与阿里达成AI合作 宝马集团宣布与阿里巴巴集团在中国达成AI领域战略合作，双方在AI大语言模型和智能语音交互等前沿领域开展联合研发，提供最贴近中国用户需求的前瞻性解决方案。阿里通义大模型将应用于中国市场的宝马新世代系列车型。 腾讯混元T1正式版上线元宝 腾讯混元宣布，深度思考模型“混元T1”正式版携手DeepSeek V3最新版已上线元宝。 浙江省政府与阿里巴巴集团蚂蚁集团签署战略合作协议 浙江省政府与阿里巴巴集团、蚂蚁集团签署战略合作协议。省长刘捷分别与阿里巴巴集团董事会主席蔡崇信、蚂蚁集团董事长井贤栋见证签约。根据协议，省政府与阿里巴巴集团、蚂蚁集团将紧紧围绕“以高质量发展为首要任务、以缩小‘三大差距’为主攻方向、以改革创新为根本动力、以满足人民美好生活需要为根本目的”，进一步整合资源、紧密协同，推动平台经济健康发展，在人工智能等领域展开合作，更好服务中国式现代化省域实践，共同推动国家重大战略落地实施。 华弘数科发布新款全液冷智算一体机 3月27日，华弘数科发布AI新物种：全液冷智算一体机。据了解，此次发布的新品为承影系列，定位为千亿级模型微调训练与高密度计算平台，主要应用场景为深度学习与人工智能、医疗与生物信息科研、图形渲染与虚拟现实、具身机器人智造等。支持高达96核处理器，8根DDR5 ECC内存插槽，支持2TB内存；GPU方面，支持7张GPU计算卡（液冷散热），显存可达560G。该一体机采用整机CNC精雕一体成型制造工艺辅以纳米级抛光技术，呈现全镜面视觉美学，自研全液冷散热技术，在压缩体积的同时，提升散热效率并降低运行噪音。 快手：AI大模型预计可把客户短视频营销素材制作成本降低60—70% 在快手2024年第四季度及全年业绩电话会上，快手科技创始人兼首席执行官程一笑称，2024年第四季度，快手平台上的AIGC营销素材和虚拟数字人直播解决方案的日均消耗超过3000万元。程一笑表示，根据快手内部测算，AI大模型预计可以把客户的短视频营销素材制作成本降低60—70%甚至更高。目前快手正致力于逐步把磁力引擎全面升级下一代的AI智能商业引擎。 快手程一笑：可灵AI已与小米、亚马逊云科技等数千家企业合作 在快手2024Q4及全年业绩电话会上，快手科技创始人兼首席执行官程一笑透露，自商业化以来截至2025年2月底，可灵AI的累计营业收入超1亿元。除了C端用户订阅，可灵AI也面向B端商家提供API接入等服务。目前，可灵AI已与包括小米、亚马逊云科技、Freepik、蓝色光标等在内的数千家国内外企业客户建立了合作关系。 中欧国际工商学院正将人工智能模块融入课程体系 中欧国际工商学院近日举办以“‘AI+商业’进化论”为主题的行业峰会，并发布人工智能与商业创新白皮书。中欧国际工商学院院长、管理学教授汪泓指出，“技术突破正加速教育体系、科研范式及产业生态的深度变革。人工智能已成为国家战略性新兴产业的核心引擎。针对AI技术对高等教育的冲击，中欧正将人工智能模块深度融入课程体系，打造‘商业智慧+AI技术’的复合培养模式。交叉学科与AI融合已成趋势，当企业家同时掌握专业知识和AI技术时，商科教育需要重新定义人才培养标准。” 中国电信：今年算力资本开支初步计划同比增长22%，将根据需求灵活调整不设限 通过中国电信2024年度业绩说明会获悉，公司2025年计划资本开支836亿元，预计同比下滑10.6%。其中，产业数字化方面占比预计提升至38%，算力方面资本开支预计同比增长22%。公司董事长兼首席执行官柯瑞文表示，“算力方面，我们初步安排是百分之二十几的增长，但不设限。将根据客户需求、市场发展的一些情况灵活调用（投资额）。” 中国电信：2024年面向AI适度超前布局云网基础设施，智能算力资源达35EFLOPS 中国电信发布2024年度业绩，面向AI适度超前布局云网基础设施。建成京津冀、长三角两个全液冷万卡池，在粤苏浙蒙贵等地区部署千卡池，智能算力资源达到35EFLOPS。推动数据中心全面向AIDC升级，依托重点区域大型园区、省市机房和边缘局站，满足训练和推理、中心和边缘、云侧和端侧等各类智算部署需求。建设高通量、低时延的智算互联网，规模部署G.654E新型光纤，建设400Gbps全光传输网络，八大枢纽间平均时延下降7%，新型城域网覆盖超200个边缘算力池，实现毫秒级入算。千兆光网10G PON端口达929万个，城镇住宅覆盖率超95%，试点部署50G PON网络。 微软-张江人工智能与物联网实验室或已关闭 位于上海张江的，号称微软全球最大的人工智能和物联网实验室据传已经关闭。多位接近微软的业内人表示，该实验室最初由张江和微软共同出资建立，不久前合同临近到期时，微软方面表示不愿再投入资金，直至近期，有传言称双方合作已经终止，该实验室已经关闭。 中信集团在港成立人工智能科技创新中心、人工智能数智创新联合实验室 3月27日，中信集团在港揭牌成立中信香港人工智能科技创新中心，并与香港理工大学签署框架协议，宣布共同成立人工智能数智创新联合实验室。此外，中信银行、中信重工、中信泰富特钢、中信国际电讯分别与香港理工大学签署了意向合作协议，明确了实验室成立后双方在工业智能、具身智能、金融科技等领域的首批联合攻关课题。 豆包测试新版深度思考功能，支持边想边搜 AI助手豆包近日测试新版“深度思考”功能。该功能将推理过程的思维链与搜索深度结合，支持“边想边搜”。用户下载最新版豆包App，开启深度思考模式后，豆包在思考过程中可以基于推理多次调用工具、搜索信息，提供更全面，更丰富、准确性更高的结果。 蚂蚁集团战略调整：减持传统投资，加码AI布局 蚂蚁集团近期减持奥比中光和永安行，累计获得超7.75亿元投资回报，引发市场关注。此次减持是基于战略方向的调整，蚂蚁将资金转向人工智能等前沿科技领域，支持新一代科技创新。蚂蚁的投资策略仍以公司战略为导向，重点关注AI大模型、AI算力、具身智能等方向，已投资多家相关企业。蚂蚁强调，持有期较长，注重生态协同，通过投资推动技术创新，为社会创造更多价值。 启明创投邝子平：中国人工智能投资远未过热 在3月23日至24日中国发展高层论坛2025年年会上，与会代表围绕人工智能发展与安全、全球共享共治等话题展开深入探讨。邝子平提出，人工智能将为人类带来巨大福祉，成为未来10年最重要的投资机会之一。他强调了以下四个观点：一是人工智能的国际化，强调人工智能解决的问题具有普遍性，其带来的好处应由全人类共享；二是中国人工智能市场潜力巨大，虽然中国人工智能投资规模远小于美国，但中国市场前景广阔，投资并未过热；三是人工智能投资的国际化，中国应吸引全球资金投资于人工智能领域，投资市场的变化将促使全球投资人越来越关注中国市场；四是人工智能国际治理，人工智能的国际治理前提是国际化，包括人员、技术、投资和产品服务的交流。 阿里通义千问与DeepSeek开源两款新模型 阿里通义千问与DeepSeek均于昨日低调开源了两款新模型。阿里发布了更适合本地部署的高性能“多模态模型”Qwen2.5-VL-32B，DeepSeek则将此前热门的“基座模型”V3更新到0324版本，并官宣在魔搭社区上架开源。截至目前，魔搭社区模型总数已超4万个，已成为中国最大的AI开源社区。 阿里开源首个全模态大模型Qwen2.5-Omni，7B尺寸远超Gemini-1.5-Pro等同类模型 3月27日凌晨，阿里巴巴发布并开源首个端到端全模态大模型通义千问Qwen2.5-Omni-7B，可同时处理文本、图像、音频和视频等多种输入，并实时生成文本与自然语音合成输出。在权威的多模态融合任务OmniBench等测评中，Qwen2.5-Omni刷新业界纪录，全维度远超Google的Gemini-1.5-Pro等同类模型。Qwen2.5-Omni以接近人类的多感官方式立体认知世界并与之实时交互，还能通过音视频识别情绪，在复杂任务中进行更智能、更自然的反馈与决策。现在，开发者和企业可免费下载商用Qwen2.5-Omni，手机等终端智能硬件也可轻松部署运行。 百度网盘和文库联合推出首个一站式视频AI笔记 华为近日举行的新品发布会上，余承东现场介绍鸿蒙版百度网盘及其推出的视频AI笔记。据悉，该功能由百度网盘和文库联合推出，是业内首个一站式视频AI笔记，打通学习资料从存储、总结、创作、编辑到消费的闭环。用户在百度网盘PC端、网页端、APP端观看学习视频时，点击“笔记”侧边栏即可体验。 海外消息 安卓停止开源？谷歌：简化开发不是闭源，将继续发布源代码 据安卓领域专家Mishaal Rahman在垂类网站Android Authority发布的文章，谷歌证实，下周起谷歌将开始完全在内部分支机构闭门开发安卓操作系统，此举是为了简化安卓操作系统的开发。但谷歌也明确强调，安卓不会成为闭源系统。该公司将继续发布新安卓版本的源代码，并对外开放。 (澎湃新闻) 新加坡GTS与马来西亚电信运营商CelcomDigi签订3年独家合同 总部位于新加坡的电信企业集团Globe Teleservices Pte. Ltd. （GTS）宣布，已获得一份为期3年的独家合同，为马来西亚最大的移动网络运营商CelcomDigi部署其先进的A2P短信防火墙解决方案。 OpenAI：对话补全API遭遇高错误率，正努力实施缓解措施 OpenAI发布事故报告称，确认用户在使用对话补全（Chat Completions）API时遭遇高错误率，目前正在努力实施缓解措施。此外，Sora图像生成问题已解决，目前正在进行监控。 DigiCore房地产信托入股日本一数据中心 DigiCore房地产信托宣布，收购日本大阪第二座永久产权、已完全建成并投入运营的数据中心20%股权。这一资产从三菱商事手中收购，交易价格为130亿日元。 谷歌发布旗舰推理模型，单次可处理百万token 美国时间周二，谷歌发布Gemini 2.5系列人工智能推理模型。该系列模型在回答问题前会“思考”片刻。作为这一系列模型的首发产品，Gemini 2.5 Pro Experimental已经率先亮相。这款多模态推理人工智能模型被谷歌称为“目前最智能的模型”，支持高达100万token的超大上下文窗口，单次可以处理约75万英文单词，远超《指环王》三部曲的总字数。谷歌透露，未来Gemini 2.5 Pro将支持200万token的双倍输入长度。这一模型将于周二登陆谷歌开发者平台Google AI Studio，同时向每月支付20美元订阅“Gemini Advanced”的用户开放。谷歌表示，未来所有新推出的人工智能模型都将集成推理能力。 高通向全球监管机构发起对Arm的反垄断行动 据媒体报道，高通(QCOM.O)对Arm(ARM.O)发起了一场全球反垄断行动，这两家长期合作的伙伴正在计算机半导体市场争夺优势。据知情人士透露，在非公开会议和提交给三大洲监管机构的机密文件中，高通称其最大供应商Arm存在反竞争行为。知情人士表示，高通向欧盟委员会、美国联邦贸易委员会和韩国公平贸易委员会提出的申诉称，在运营开放网络20多年后，Arm限制了对其技术的获取，损害了竞争。高通认为，Arm通过开放授权模式，让人们对其技术产生了严重依赖，同时也促成了蓬勃发展的芯片产业。高通正向全球竞争监管机构反映，Arm目前正在限制准入，以推动自身的芯片制造业务并提高利润，从而威胁到这一充满活力的市场。 特朗普政府将多家中国科技公司列入“实体清单” 美国商务部工业与安全局美国当地时间周二在联邦公报上刊发两份文件，将50余个中国科技企业和机构纳入所谓的“实体清单”，预期将于3月28日生效。在其中的一份文件中，美国商务部将一系列与中国AI大模型开发、服务器以及超级计算机产业相关的12家公司列入“实体清单”，包括北京智源人工智能研究院、宁畅信息产业、中科可控旗下的服务器品牌Suma，以及浪潮信息在中国内地以及港台地区的多家子公司。在另一份文件中，还有42家中国公司，19家巴基斯坦公司，以及伊朗、南非、阿联酋的多家公司被纳入“实体清单”。其中美国商务部以“支持中国量子技术发展”为借口，对赛澔仪器、安徽科华贸易、重庆西南集成电路设计有限责任公司等一系列公司展开无理制裁。另外还有数十家中国公司，被美方以“涉军”为由，列入出口关注清单。 OpenAI推出GPT-4o图像生成功能 OpenAI宣布推出4o图像生成功能，“将迄今最先进的图像生成器集成至GPT-4o”。即日起，所有Plus、Pro、Team及免费用户将陆续在ChatGPT和Sora中体验该功能，企业版与教育版即将接入，Sora平台同步启用。开发者即将通过API调用GPT-4o图像生成功能，接口权限将于未来数周内开放。据介绍，GPT-4o图像生成功能可精准文本渲染、严格遵循指令提示、深度调用4o知识库及对话上下文——包括对上传图像进行二次创作或将其转化为视觉灵感。 消息称苹果正在订购英伟达GB300 NVL72系统，订单价值约10亿美元 Loop Capital分析师Ananda Baruah在当地时间周一的一份报告中表示，苹果正在订购英伟达GB300 NVL72系统，订单价值约10亿美元，这相当于大约250台服务器，每台售价370万至400万美元。“苹果正式加入AI大型服务器集群竞赛”，公司正在与戴尔和超微计算机合作开发大型服务器集群，以支持生成式人工智能应用。 美国科技企业高管和外国领导人据悉敦促特朗普重新考虑AI芯片限制 媒体报道称，美国科技企业高管和外国领导人敦促特朗普重新考虑对AI芯片的限制。据悉，英伟达和甲骨文正在推动全面废除AI扩散规则，阿联酋、以色列、印度是要求放宽规则的国家之一。公司需在5月15日前遵守全球AI限制。 OpenAI智能体支持MCP，已开源 3月27日凌晨2点，OpenAI对AgentSDK进行了重大更新支持MCP服务，可以统一接口标准解锁无限工具。现在Agent可以快速集成网络搜索、专业分析、本地查询、网络追踪等各式各样的工具，这对于开发超复杂自动化智能体来说帮助巨大。例如，在开发一个需要同时进行文件处理、数据查询和网络信息收集的智能体时，开发者可以通过MCP服务器分别集成文件系统工具、数据库查询工具和网络爬虫工具，更高效地完成复杂任务。 融资并购 超融合数据库企业「九有数据库」完成A轮融资 专注于高性能、多模态国产超融合数据库产品和解决方案研发的创企「九有数据库」宣布完成A轮融资，由深圳天使母基金和龙华资本的共同子基金深圳市大米成长天使投资合伙企业（大米创投）领投。此轮融资将用于进一步加大技术研发投入，拓展市场版图。 具身智能初创公司它石智航完成1.2亿美元天使轮融资，蓝驰创投、启明创投领投 具身智能初创公司它石智航（TARS）宣布完成天使轮1.2亿美元融资。本轮融资由蓝驰创投、启明创投共同领投，线性资本、恒旭资本、洪泰基金、联想创投、襄禾资本、高瓴创投跟投。它石智航创下中国具身智能行业天使轮最大融资额纪录。本轮融资将主要用于公司的产品和技术研发、模型训练、场景拓展等方向。 具身智能公司“原力灵机”完成2亿元天使轮融资 原力灵机（重庆）智能科技有限公司近日完成2亿元天使轮融资，投资人包含君联资本、九坤创投、启明创投。原力灵机研发团队兼具顶尖学术背景以及超过10年的AI原生产品落地经验，是行业内为数不多的兼具大模型技术与机器人场景的具身智能公司。据透露，原力灵机核心创始团队源于旷视科技，成员包括范浩强、周而进和汪天才。值得关注的是，原力灵机团队在端到端具身算法方面进展迅速，旷视在物流机器人行业又有多年的积淀与场景优势，相信原力灵机会快速推进具身智能技术在实际工业环境中的应用和落地。 苏州吴中机器人产业投资合伙企业成立，出资额10亿元 天眼查App显示，苏州吴中机器人产业投资合伙企业（有限合伙）近日成立，执行事务合伙人为苏州市吴中金控股权投资管理有限公司，出资额10亿人民币，经营范围为股权投资、创业投资、以自有资金从事投资活动。合伙人信息显示，该企业由苏州太湖科技发展投资有限公司、苏州吴中国太发展有限公司、苏州吴中经开产业基金有限公司、江苏吴中高新创业投资有限公司等共同出资。 OpenAI接近敲定由软银牵头的400亿美元融资 据知情人士透露，OpenAI即将完成由软银集团领投的400亿美元融资，包括Magnetar Capital、Coatue Management、Founders Fund和Altimeter Capital Management在内的投资者正在参与谈判。这笔交易将使该公司估值达到3000亿美元。据多位知情人士透露，总部位于伊利诺伊州埃文斯顿的对冲基金Magnetar Capital可能会贡献高达10亿美元的资金。 英伟达计划收购阿里云前副总裁贾扬清的创企Lepton AI 据报道，英伟达计划以数亿美元收购阿里云前副总裁贾扬清的创企Lepton AI。Lepton成立于2023年，是被称为“Caffe之父”的AI领域大牛贾扬清在离开阿里之后创办的，其主要业务是出租英伟达GPU服务器，开发软件帮助创企在云中构建和管理自己的应用。该公司于2023年5月完成了1100万美元（折合人民币约7900万元）天使轮融资。据猜测，英伟达收购Lepton意在进军云和企业软件市场，与AWS和谷歌等主要云服务商竞争。 政策&趋势 工信部：1-2月 中国电信业务收入累计完成2950亿元 工信部公布2025年前2个月通信业经济运行情况。前2个月，电信业务收入保持正增长，5G、千兆光网等网络建设和应用不断推进，连接用户规模稳步扩大，移动互联网接入流量较快增长。前2个月，电信业务收入累计完成2950亿元，同比增长0.9%。按照上年不变价计算的电信业务总量同比增长7.6%。截至2月末，三家基础电信企业的固定互联网宽带接入用户总数达6.75亿户，比上年末净增493.6万户。 湖北省发布科技型企业知识价值信用贷款政策 湖北省科技型企业知识价值信用贷款政策发布会昨日在武汉举行，会上发布《湖北省科技型企业知识价值信用贷款实施办法（试行）》。《办法》针对科技型企业轻资产债权融资难题，充分开发知识价值的信用空间，围绕企业科技创新要素生成知识价值评价模型，对全省28.5万家科技型企业进行评价，评价结果按5个等次推送各银行机构，银行机构运用评价结果相应为科技型企业提供“全线上、纯信用、优利率”、期限不超过3年、单笔金额不超过1000万元的授信支持。在健全风险分担机制，运用财政资金设立风险补偿资金池的同时，建立以合理不良贷款率为触发条件的熔断机制，解决银行机构后顾之忧。 国资委：持续壮大发展人工智能的长期资本、战略资本、耐心资本 在国务院国资委召开的中央企业“人工智能+”媒体通气会上，国务院国资委规划发展局相关负责人表示，将积极引导中央企业加大资金投入，坚持产投结合、以投促产，持续壮大发展人工智能的长期资本、战略资本、耐心资本，优化人才引育，建立更加符合行业特点规律的人才评价体系，发挥需求规模大、产业配套全、应用场景多的优势，聚焦关键领域，加快掌握“根技术”，积极参与开放生态建设，推动产生更多“从0到1”的原始创新，深化与各方协同合作，为加快推动中国人工智能产业高质量发展作出更大贡献。 国资委：中央企业人工智能产业发展将进一步提速加力 在国务院国资委召开的中央企业“人工智能+”媒体通气会上，国务院国资委规划发展局相关负责人表示，目前，中央企业人工智能产业发展将进一步提速加力。该负责人表示，国务院国资委持续深化中央企业AI+专项行动，指导央企紧盯发展态势、服务国家战略，全力当好国家智算基础设施的重要供给者、人工智能赋能千行百业的重要破题者、产业体系化布局的重要组织者，着力提升中央企业在人工智能领域全方位的能力，在应用、算力、数据、模型等人工智能产业重点领域取得积极成效。 李开复称DeepSeek将中美AI差距缩小至3个月 据新加坡《联合早报》网站3月25日报道，中国初创企业零一万物首席执行官李开复说，在人工智能（AI）发展方面，中国已将与美国在某些领域的差距缩小至仅3个月，因为中国初创企业深度求索（DeepSeek）等公司已经研究出如何更有效地使用芯片和应用算法。 谷歌高管：量子计算离实际应用可能剩五年 谷歌量子AI硬件部门负责人Julian Kelly日前表示，量子计算机可能能够实现前所未有的技术突破，包括进行尖端物理学的研究，并生成新型数据。他表示：“我们认为大约五年后，量子计算机会迎来一次真正的突破，能够解决只有量子计算机才能解决的实际问题。” 三大运营商AI投资提速且设立特别预算或不设上限 中国移动、中国电信和中国联通已披露2024年业绩，均计划大手笔分红回报股东。三大运营商的资本开支计划合计达2898亿元，尽管总体投资规模有所下调，但算力、AI成为运营商适当超前布局发力的重点，甚至还设立了特别预算或者“不设上限”。中国移动计划2025年投1512亿元，聚焦5G和智算基础设施，预计智算规模达34EFLOPS。中国联通和中国电信也分别调整投资，提升AI和算力的投资比例。AI应用成为三大运营商的共同关注点，中国移动推出多款AI产品并布局云智算，中国联通和中国电信则加速智算服务和AI终端产品的发展，以推动业务转型升级。 机构：中国大陆云基础设施服务支出将在2025年增长15% Canalys的最新数据显示，2024年第四季度，中国大陆的云基础设施服务支出达到111亿美元，同比增长14%。2024年全年，云服务总支出从2023年的353亿美元增长至400亿美元，年增幅为13%。AI模型的快速应用超出预期，带动了对云服务需求的显著增长。得益于其卓越的性能和成本效益，DeepSeek在全球市场迅速崛起，进一步激发了中国大陆企业客户加快AI应用探索和部署的热情。Canalys预测，2025年中国大陆云基础设施服务市场的增长将进一步加快，预计增速将达15%。 重庆：加快研发智能车载操作系统，强化车路云网图协同等智能驾驶技术攻关 《重庆市人工智能赋能制造业高质量发展行动方案（2025—2027年）（征求意见稿）》公开征求意见。其中提到，组织实施人工智能“模动山城”计划，加快研发迭代垂直行业大模型，做精细分场景专用模型，鼓励基于DeepSeek等前沿开源模型开展蒸馏、量化，发展轻量、高效、易部署的中小型模型。鼓励企业开展智能体（Agent）研发，推进产品与服务标准化、模块化发展；加快研发具有自主知识产权的智能车载操作系统、工控操作系统等智能操作系统；依托国家智能网联汽车“车路云一体化”应用试点城市建设，强化车路云网图协同、多传感器融合感知、高动态智能执行等智能驾驶技术攻关。持续研发具身智能多模态“大脑”和运动控制“小脑”，推动机器人双臂协同、手眼协同、脑身协同、力控制技术等关键技术攻关。 今年以来中国已新增智慧医疗相关企业超过3万余家 天眼查专业版数据显示，截至目前中国现存在业、存续状态的智慧医疗相关企业超76.4万家。其中，2025年截至目前新增注册相关企业约3万余家，从企业注册数量趋势来看，近五年间，智慧医疗相关企业的注册数量呈现出逐年增长的态势，并在2024年达到顶峰，为15万余家。从区域分布来看，广东省、上海省、江苏省智慧医疗相关企业数量位居前列，三个省市数量总和超过25.5万余家，占企业总数的33.4%。排在其后的是山东省和北京市。此外，通过天眼查天眼风险和深度风险来看，涉及司法案件的智慧医疗相关企业约占总数的2.7%。 AI驱动卖方研究转型，私域数字资产价值凸显 人工智能（AI）助推投研提效，驱动转型的不只是券商分析师，也包括研究所本身。在这场效率革命中，从人力、组织、科技投入等各方面，券商研究所都需要在变化中寻求未来的方向。近日，有大型券商研究所从业人士表示，“AI平权加速推动卖方研究转向深度”，也有人士直言，“卖方研究行业可能会迎来大浪淘沙的洗牌”。还有人提出，“私域数字资产会是研究所未来差异化服务的基石”。总体而言，在公募佣金新规的大背景下，AI为券商研究所带来了更多构建差异化发展路径的可能性，同时也驱动券商研究所更加重视具有价值的研究工作。 福建发布全国首个公共数据运营服务定价收费标准 据福建省发展和改革委员会官网27日消息，近日，福建省公共数据资源开发服务平台发布了《福建省公共数据运营服务收费标准（试行）》，弥补了全国公共数据运营服务定价收费的空白，在全国率先建立公共数据授权运营价格形成机制，破局打通公共数据资源市场化配置利用最后一公里。下一步，福建省将重点推动公共数据应用赋能，充分发挥公共数据资源在推动产业升级、优化公共服务、提升治理能力等方面的重要作用,加快公共数据应用场景建设，推动公共数据赋能产业发展示范场景培育，形成一批经济社会效益突出、产业带动效应强的应用,充分释放公共数据资源价值。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 16620,
      "title": "宣布了!免费",
      "time": "2024-02-25T00:00:00+00:00",
      "content": "这两天，国内外多家大模型厂商纷纷宣布免费开放其大模型服务，这一举措引发了行业的广泛关注。 百度2月13日发布消息，文心一言将于4月1日0时起全面免费，所有PC端和App端用户均可体验其最新模型，包括超长文档处理、专业检索增强、高级AI绘画、多语种对话等功能。 同日，OpenAI也宣布免费版ChatGPT将在标准智能设置下无限制使用GPT-5进行对话。 此外，谷歌最新人工智能模型套件也于近期宣布正式向所有用户开放使用。 中国信息通信研究院技术与标准研究所工程师 龚正：像DeepSeek等开源模型的崛起，其灵活、低门槛的特性正在重构行业生态，迫使头部玩家必须打破封闭生态。当开源模型能实现商用模型80%甚至90%的功能，而成本仅为10%时，闭源系统的护城河自然瓦解，免费开放成为巩固用户黏性的战略选择。 在过去的几年中，人工智能大模型的商业运营模式主要围绕付费使用展开。随着大模型训练技术越来越成熟，硬件效率的提升，让模型训练和推理的成本大幅降低。 免费背后 人工智能大模型的商业逻辑 人工智能大模型免费，听起来像是“赔本赚吆喝”，免费背后隐藏着怎样的商业逻辑？ 中国信息通信研究院技术与标准研究所工程师 龚正：头部厂商的技术优势为免费铺平了道路。无论是DeepSeek、百度、阿里还是OpenAI，当技术领先者能够以更低成本提供更高性能的服务时，“免费”反而成为巩固市场地位的利器。 免费潮将加剧行业洗牌。中小厂商若无法承担长期免费所需的技术迭代成本，可能被迫退出市场，而头部企业则通过用户数据积累反哺模型优化，形成“技术升级-用户增长-成本下降”的循环。这种模式下，资源会进一步向具有算力、数据和资金优势的企业集中。 中国信息通信研究院技术与标准研究所工程师 龚正：免费的基础服务将成为流量入口，通过技术输出、企业级解决方案等增值服务实现商业闭环。这场竞争的本质，是争夺下一代人机交互标准的制定权。 大模型免费后 人工智能商业模式如何演变 免费模式的推出，让人工智能行业进入了一个新的发展阶段。随着技术的不断进步和成本的降低，未来人工智能大模型的商业运营模式如何演变？ 赛迪顾问人工智能与大数据研究中心分析师 白润轩：基础功能免费是大势所趋，但对于企业级需求，还是会按需收费。 专家告诉记者，免费会吸引更多用户和开发者，推动AI技术的普及和应用。另一方面，这也会引发新的竞争格局，促使其他企业跟进或探索新的商业模式。 赛迪顾问人工智能与大数据研究中心分析师 白润轩：随着各国对AI监管的加强，比如欧盟的AI法案、数据溯源、安全审核这些要求会让厂商面临更高的隐性成本。这也可能导致一些新的收费模式出现，比如“合规增值服务”。 转自/广西女性 原标题：《宣布了！免费》 阅读原文"
    },
    {
      "doc_id": 16625,
      "title": "大模型之家2025年6月热力榜:多款重磅模型开源,赋能AI应用繁荣",
      "time": "2024-07-04T00:00:00+00:00",
      "content": "2025年6月，人工智能行业迎来应用落地的爆发式增长，标志着AI从技术验证阶段全面进入规模化商用周期。与此同时，开源生态呈现爆发式增长：华为首次开源盘古大模型体系，涵盖70亿参数稠密模型与720亿参数MoE混合专家模型，配套昇腾推理技术体系；百度则推出文心大模型4.5系列10款开源模型，实现预训练权重与推理代码全量开放，共同推动大模型技术向产业纵深演进。 大模型的发展也为行业迎来了全新的范式。6月29日，在2025年“速途AI引力场”沙龙上，大模型之家主编乔志斌以《AI带给我们的变与不变》为题结合产业实践与数据洞察提出了三大核心观点： 其一，企业家更关注AI的实际价值转化认为AI能否提升产业效率、带来直接商业回报是核心命题，并以“预制菜”比喻AI创作强调标准化生产与差异化价值的分野； 其二，AI创业生态呈现显著分层基础技术层（如算力平台、底层大模型）因具备规模化变现能力成为盈利主力。而自动驾驶、行业大模型研发等下游领域仍处于长周期投入阶段需通过技术迭代与场景深耕突破瓶颈； 其三，成功的AI创业范式需聚焦真实痛点以“小团队+强模型”实现高效产品开发。例如MIT团队创立的Cursor公司凭借明确标准、扩展性技术和快速迭代能力以40人团队完成9亿元C轮融资验证了新范式的可行性。他强调，在技术浪潮中企业需锚定产业价值平衡标准化效率与差异化创新方能在AI赋能中把握机遇。 在《2025年6月大模型热力榜》中，共收录了302个大模型及其所属企业。在其中，百度、腾讯、华为等头部科技企业在这一月纷纷重磅开源了自家的核心模型系列，引发行业的广泛关注。这些头部企业的模型产品开源，不仅会推动基础模型整体能力的新一轮迭代，同时为行业带来了更加普惠且性能更为强大的模型能力，而随开源而扩充的开发者生态，也将反哺基础模型的发展进程，推动新一轮的模型技术腾飞。 2025年6月，百度在AI领域多项突破标志着其技术生态与产业应用的全面升级。6月30日，百度正式开源文心大模型4.5系列，涵盖10款模型（包括47B激活参数的混合专家模型和0.3B参数的稠密模型），实现框架（飞桨3.0）与模型的“双层开源”，并在多模态能力上超越部分国际模型，例如文心4.5-VL-28B-A3B在视觉常识推理中优于OpenAI-o1。此次开源不仅开放预训练权重和推理代码，还通过百度智能云千帆平台提供API服务，推动国产大模型生态建设。 在技术应用层面，百度智能云于6月6日宣布与65%的央企达成深度合作，推出覆盖金融、能源、交通等领域的行业场景智能体家族。针对中小企业，6月17日成都站百度城市大会推出伴飞商业系统，借助文心大模型优化营销获客，使线索成本降低32%，夜间流量利用率提升150%。 2025年6月，腾讯持续推动技术开源与产业落地。6月27日，腾讯开源首款混合推理MoE模型Hunyuan-A13B，总参数80B但激活参数仅13B，支持单张中低端GPU运行，数学推理能力显著提升，并发布ArtifactsBench和C3-Bench两个新数据集填补行业评估空白。同日，混元大模型标准版上线，全面提升数学、科学、长文理解和Agent能力。6月14日，腾讯在CVPR2025上开源工业级3D生成大模型混元3D 2.1，优化几何生成质量并开放PBR材质生成，实现全链路开源且适配消费级显卡，推动3D资产生成进入超高清时代。 同时，腾讯混元T1深度思考模型正式版上线，其复杂任务处理能力获企业客户认可，已全量接入腾讯元宝等C端产品，用户反馈问答质量显著提升；而面向通用场景的混元Turbo S模型则实现“秒级响应”，首字时延降低近半，优化了用户体验。 在产业落地层面，腾讯CSIG坚持“大模型+知识库”技术路径，通过腾讯云TI平台提供覆盖数据标注、模型训练、精调部署的全链路工具，支持混元、DeepSeek、Llama等主流模型的一键调用。此外，腾讯元宝、微信搜一搜等亿级用户产品已接入“混元+DeepSeek”双引擎，结合腾讯云智算集群的算力支撑，实现深度推理与流畅交互的平衡。 战略层面，腾讯集团高级执行副总裁汤道生提出“大模型是智能时代的操作系统”，并强调腾讯将聚焦“离产业最近的AI”，通过智能体开发平台、知识引擎等工具降低企业应用门槛。目前，腾讯大模型已落地零售、医疗、教育等20余个行业，助力比亚迪等超30万家企业构建专属AI中台。同时，腾讯云宣布加码AI基础设施建设，在大湾区布局的智算中心算力规模持续提升，为产业升级提供底层支持。这一系列动作表明，腾讯CSIG正以技术开放与场景深耕为核心，加速AI技术从实验室走向产业一线。 6月，阿里巴巴在AI与大模型领域持续深化技术布局与产业融合，通义大模型系列实现多维突破。技术开源层面，通义团队开源全新千问3量化模型，完成对苹果MLX框架的深度适配，进一步拓展跨平台生态。 产业落地方面，阿里云与美图达成战略合作，以2.5亿美元可转债投资加速“AI电商”布局，美图承诺三年内采购5.6亿元阿里云服务，双方聚焦“底层大模型+应用层开发”协同，推动AI工具在B端市场的商业化突破。同时，阿里云AI产品收入连续七个季度三位数增长，服务63%中国A股上市公司，Qwen3大模型发布后登顶全球权威评测榜单，支撑淘宝、1688、钉钉等核心业务加速智能化转型。 6月11日，火山引擎原动力大会发布豆包1.6及视频生成模型Seedance 1.0 pro，技术层面，豆包1.6采用23B激活参数的稀疏MoE架构，支持256K长文本推理，并通过动态思考能力平衡性能与效率。据悉，豆包大模型日均tokens调用量突破16.4万亿，较去年增长137倍，据IDC报告，其在中国公有云市场占有率达46.4%同时，火山引擎升级AI云原生工具链，发布MCP服务、PromptPilot等12款产品，助力企业构建智能体。目前，豆包大模型已渗透汽车、金融、教育等场景，覆盖4亿终端设备及八成主流车企。 6月20日，华为开发者大会上，盘古大模型5.5全面升级自然语言处理、计算机视觉、多模态、预测及科学计算五大基础模型，其中718B参数的Ultra MoE架构在知识推理、工具调用等领域跻身业界第一梯队，并创新采用自适应快慢思考融合技术，实现简单问题敏捷回复、复杂问题深度思考，推理效率提升8倍。此次升级还推出盘古世界模型，为智能驾驶、具身智能构建数字训练空间，已助力车企实现端到端模型“两天一迭代”。 技术开源层面，华为首次开源盘古Pro MoE 72B大模型，包含权重、推理代码及昇腾优化技术，推动国产AI算力生态建设。行业落地方面，盘古大模型已渗透30余个行业、500个场景。此外，华为云发布CloudMatrix 384超节点昇腾AI云服务，将384颗NPU与192颗CPU全互联，支撑复杂场景并行推理，单卡吞吐量达2300 Tokens/s，标志着华为以“技术+生态”双轮驱动，加速AI与产业深度融合。 6月，商汤日日新SenseNova融合模态大模型率先通过中国信通院可信AI多模态大模型最高4+级认证，成为国内首个获此认证的多模态大模型，其在多模态融合、跨模态感知等核心能力上表现突出，并已在教育、金融等领域落地应用。技术层面，商汤大装置总算力达 23,000 Petaflops。 在医疗领域，商汤科技联合上海新华医院推出\"AI儿童全科医生\"系统，与罗氏诊断发布IVD场景AI方案。开发者生态方面，商汤开源低代码框架LazyLLM，支持10行代码构建多Agent应用，推出万象平台实现可视化开发，服务超30家企业。 360于6月11日发布国内首个“超级搜索智能体”——纳米AI超级搜索智能体，该产品可自动规划任务、调用工具并交付结果，例如一键生成宣传片脚本或产业分析报告，效率较传统模式提升数倍，标志着搜索引擎进入3.0时代。开发者赋能方面，360推出超级企业智能体构建运营平台（SEABOT），帮助企业快速部署智能体应用，推动“数字员工”与人类协作的新范式。 360集团创始人周鸿祎在夏季达沃斯论坛等场合多次强调，AI发展已进入下半场，智能体成为核心，需通过“大模型+智能体”组合实现复杂任务的全流程执行。 为此，360深度参与行业标准制定，联合信通院等20余家单位发布《大模型应用交付供应商总体能力要求》，推动大模型落地规范化。周鸿祎特别强调AI安全风险，指出智能体与大模型结合后可能引发的业务中断等问题，呼吁企业建立安全防护体系。同时，360依托“智盾”等产品构建大模型安全护栏，相关方案入选工信部未来产业创新案例，成为行业标杆。 2025年6月，智谱发布AutoGLM智能体系列，其中沉思智能体支持50步长复杂任务、联网搜索及多工具调用，以免费策略降低企业应用门槛，被称“全球首款通用AI智能体”。教育领域，智谱联合深圳福田区教育局推出“i福娃”教育智能门户，整合50余种教育智能体，覆盖教学、心理辅导等场景，推动K12教育数字化转型。 开发者生态方面，智谱开启“开源年”，开源GLM-4-32B模型支持本地部署，同时提供AutoGLM桌面客户端与浏览器插件，降低技术接入门槛。政企合作上，智谱中标杭州城投集团产业大模型项目，布局智慧交通、能源等领域；与澜舟科技深化金融合作，推出智能知识库等方案服务头部机构；免费工具清影2.0支持文本/图生4K视频，拓展广告影视场景。 6月，DeepSeek在AI领域面临多重挑战与突破：国际方面，德国数据保护部门以“数据违规”为由要求苹果、谷歌下架其应用，此前美国已通过技术封锁、芯片禁令等手段打压，但DeepSeek凭借技术优势仍获汇丰、沙特阿美等机构采用；技术层面，其升级版DeepSeek-R1模型推理能力显著提升，医疗大模型以70B参数实现3300 token/s处理速度，创下千万级智慧医疗项目纪录，同时教育领域与学而思、有道等合作推出AI原生硬件。 6月24日，科大讯飞在香港成立国际公司，发布基于星火大模型的医疗、教育、会议等多领域产品，如星火医疗大模型国际版、晓医APP香港版及准确率96.2%的讯飞听见SaaS系统，并与香港大学合作研发教育AI技术。同日，讯飞AI学习机完成暑期升级，新增AI1对1问诊规划等功能，覆盖全学段，自研新课标体系课同步上线。26日，语音合成技术实现“一句话声音复刻”，相似度接近真人，应用于车企座舱及医疗导诊场景。"
    },
    {
      "doc_id": 16626,
      "title": "腾讯、阿里重磅!大模型竞赛持续演绎,加速AI应用繁荣!信创ETF基金...",
      "time": "2024-07-01T00:00:00+00:00",
      "content": "今日（7月1日）重仓软件开发行业的信创ETF基金（562030）随市盘整，场内价格现跌1．53%，成份股方面，AI应用概念股福昕软件涨近2%，成都华微、远光软件涨逾1%；国产EDA概念股概伦电子、华大九天逆市飘红。 消息面上，6月27日，腾讯混元发布首个开源的混合推理MoE模型Hunyuan-A13B，总参数80B，激活参数仅13B，效果比肩同等架构领先开源模型，但是推理速度更快，性价比更高。 同日，阿里推出多模态统一理解与生成模型Qwen VLo，在原始多模态理解与生成能力上进行了全面升级，显著增强了对图像内容的理解深度，并在此基础上实现了更加准确和一致的生成效果。 开源证券指出，马斯克官宣将于7月4日后发布Grok4。中美巨头大模型军备竞赛加速，有望促进AI应用繁荣。 平安证券认为，对于AI应用层，应重点关注AI垂直类应用与端侧智能两类细分方向，其中垂直类应用关注AI应用普及较快的互联网、金融、运营商以及有望加速普及的医疗、服务、教育、政府等领域；端侧落地方面，高阶智驾技术有望加速渗透，此外人形机器人作为AI、高端制造、新材料等先进技术的重要载体，有望迎来量产。 展望后市，华安证券认为，包括AI在内的泛科技板块下半年仍有望出现类似催化事件，如DeepSeek和OpenAI新版大模型的发布、英伟达推出新型计算平台、苹果秋季发布会等，届时板块有望启动新一轮上涨行情，下半年板块整体或呈现出“先抑后扬”走势。 业内人士认为，政策托底+AI赋能+国产替代刚需，共同构建信创产业的“黄金三角”。AI商业化不仅为信创提供应用场景和市场空间，更通过技术平权降低生态门槛，加速国产化从党政军向全行业渗透。当前，金融、政务领域的信创订单已进入爆发期，叠加AI推理算力国产化机遇，建议重点关注核心硬件（服务器/芯片）和场景化软件企业。 扎根自主可控，护航国家安全 重仓软件开发行业的信创ETF基金（562030）及其联接基金（A类：024050；C类：024051）被动跟踪的中证信创指数，覆盖基础硬件、基础软件、应用软件、信息安全、外部设备等信创产业链核心环节，指数具备高成长、高弹性特征，当前形势下，重点关注信创产业的四重投资逻辑： 1、国际形势：地缘政治扰动，逆全球化趋势加剧，自主可控需求迫切，从国家安全、信息安全、产业安全的角度来讲，信创领域，均有国家大力扶持和企业加速发展的必要性； 2、宏观层面：地方化债力度加码，政府信创采购有望回暖； 3、技术层面：以华为为代表的国产厂商实现新技术突破，看好国产软硬件市场份额攀升； 4、把握节奏：信创推进到达关键时间节点，采购标准进一步细化。 数据安全为王，科技自立自强 信创含量近70%的大数据产业ETF（516700）被动跟踪中证大数据产业指数，重仓数据中心、云计算、大数据处理等细分领域，权重股汇聚中科曙光、科大讯飞、紫光股份、浪潮信息、中国长城、中国软件等龙头股，看好科技自主可控方向的投资者，或可重点关注这三方面的催化： 1、高层号召“科技打头阵”，新质生产力方向有望突围； 2、数字中国顶层设计，激活数字生产力，国产替代进程加快； 3、乘风信创热潮，信创2.0有望加速，科技自主可控前景广阔。 本文图片、数据来源于沪深交易所。 风险提示：信创ETF基金被动跟踪中证信创指数，该指数基日为2017.12.29，发布于2012.12.21；大数据产业ETF被动跟踪中证大数据产业指数，该指数基日为2012.12.31，发布于2016.10.18，指数成份股构成根据该指数编制规则适时调整，其回测历史业绩不预示指数未来表现。本文中提及的指数成份股仅作展示，个股描述不作为任何形式的投资建议，也不代表管理人旗下任何基金的持仓信息和交易动向。基金管理人评估的该基金风险等级为R3-中风险，适宜平衡型（C3）及以上的投资者，适当性匹配意见请以销售机构为准。任何在本文出现的信息（包括但不限于个股、评论、预测、图表、指标、理论、任何形式的表述等）均只作为参考，投资人须对任何自主决定的投资行为负责。另，本文中的任何观点、分析及预测不构成对阅读者任何形式的投资建议，亦不对因使用本文内容所引发的直接或间接损失负任何责任。基金投资有风险，基金的过往业绩并不代表其未来表现，基金管理人管理的其他基金的业绩并不构成基金业绩表现的保证，基金投资须谨慎。 转自：市场资讯 举报/反馈"
    },
    {
      "doc_id": 16628,
      "title": "腾讯 AI「登陆战」",
      "time": "2024-05-27T00:00:00+00:00",
      "content": "作者｜连冉 编辑｜郑玄 在过去一年 AI 产业的剧烈演进中，「大模型」几乎成为所有讨论的核心。从参数规模、推理速度到多模态能力，技术指标不断刷新。但回归冷静的视角，大模型的真正竞争早已超越了「谁的模型更大更强」。站在 2025 年的时间节点上，决定胜负的关键在于：是否能够持续构建有价值的模型能力，是否真正理解复杂的用户场景，并最终将这些能力转化为「好用」的产品。 在互联网行业说到「做产品」，很多人首先会想到腾讯。但在这一波 AI 大模型浪潮下，腾讯很长一段时间都表现得极为「低调」。甚至很多人是通过谷歌 I/O 开发者大会，才发现腾讯混元已经站到了全球模型第一梯队。在 5 月份的这次大会上，谷歌 CEO 桑达尔·皮查伊（Sundar Pichai）引用 Chatbot Arena 榜单，顺带手曝光了腾讯的混元大模型：全球第七，中国第二，仅次于 DeepSeek。 腾讯 AI 的惊艳时刻是今年年初。DeepSeek 火爆出圈之后，腾讯一反常态，第一个高调快速接入；旗下的 AI 原生应用「元宝」，更是以「日更」的速度高频迭代，日活在短短两三个月，快速攀升到国内 TOP 水平，这和此前「不紧不慢」状态判若两人。腾讯 AI「一快一慢」之间，究竟在下一盘怎样的棋？ 5 月 21 日，腾讯云 AI 产业应用峰会上，腾讯集团高级执行副总裁、云与智慧产业事业群 CEO 汤道生，用一句话概括了腾讯发展 AI 的方向：「让 AI 人人可用，让价值触手可及。」这句话背后，是腾讯在 AI 领域的一种整体心态：不执着于「谁率先提出 AGI」，不追求「制造热词和新概念」，而是致力于打造一个结构完整、持续演进、体验扎实的 AI 能力体系。 这套体系的核心，不在某一项指标上的「单打」，而在于「模型与产品的协同演进」。腾讯并不回避模型的重要性，反而始终强调模型是整个 AI 能力的根基。就在今年 4 月，腾讯正式组建「大语言模型部」和「多模态模型部」，进一步系统性地强化自研模型能力。这也体现出，腾讯在基础技术层面，依然秉持着「小步快跑、快速迭代」的长期主义逻辑。 腾讯的优势，也不仅止于模型本身，而在于如何将技术能力长期沉淀，最终落地为真正能够被用户使用、并持续创造价值的工具。这背后体现的是一种技术层面的耐心，也是一种产品视角下的现实主义。 01 腾讯 AI 打法的核心：不追「最大」，而做「好用」 在 DeepSeek R1 横空出世之前，国内大厂在大模型布局上的主流思路是构建大模型、大参数，以及「AI 闭环」——从模型、工具到应用场景实现全链条的自给自足。 相比之下，腾讯的策略显得更加务实：不是一味地追求参数规模的竞赛，而是将重心放在，如何将大模型能力真正转化为可触达、可服务、可持续的产品形态。从年初腾讯元宝的狂飙逆袭，到最近又喊出「腾讯各项业务全面拥抱 AI」，都能够看出腾讯死磕产品的决心。而如今，做「好用」的 AI 产品，也开始成为整个行业的共识。 在汤道生看来，这种转变来自 DeepSeek 给行业带来的「里程碑式」的改变，一种从「量」到「质」的变化——「用户在实际使用过程中，切实感受到了 AI 的『可用性』在进一步提升，AI 正在跨过产业化落地的门槛，站在普及应用的全新节点上。」 在最近的腾讯云 AI 产业应用峰会上，他又进一步指出，生成式 AI 接下来要从「可用」到「好用」。而这种「跃迁」，还需要在大模型、智能体、知识库与基础设施四个层面，完成新一轮的「加速」。 腾讯集团高级执行副总裁、云与智慧产业事业群 CEO 汤道生丨来自：腾讯云 具体来看，模型能力的持续优化，可以带来更强的性能、更好的交互体验；智能体能够基于模型，自主思考、决策和执行任务；知识库系统则有助于减少幻觉、增强上下文理解，使模型「更懂企业、更懂用户」；而底层基础设施的持续迭代，则显著降低了训练和推理成本，提升了系统响应速度。腾讯的这套结构，背后是其在产品化和服务化过程中对「可用性」理解的持续积累。 这种「以用促建」的思路，在腾讯自研大模型「混元」家族的演进中，也体现得尤为清晰。自 2023 年首次发布以来，混元不断迭代，技术能力不断提升：今年以来相继推出快思考模型 Turbo S 和深度思考模型 T1，均在公开基准测试中达到业界领先水平。 除语言模型外，腾讯也持续加码对多模态能力的投入，推进涵盖图像、视频和 3D 生成，以及图像理解、端到端语音模型等多类模型的研发，目的是为更广泛的商业场景，提供全面的 AI 支撑。这种能力体系的不断扩展，丰富了模型支持的交互方式，也帮助应用显著降低了用户的使用门槛。 除了自研体系的持续深化，腾讯也坚持以「好用」为目标，积极吸纳外部优质模型能力，以实现更优组合。这一策略最早可以在「腾讯元宝」这款通用 AI 助手中窥见端倪。元宝采用混元与 DeepSeek 的双引擎架构，是国内最早接入 DeepSeek 模型的大厂产品之一。这一架构是腾讯在性能对比、场景匹配和用户需求之间，所做出的策略性融合选择。 自上线以来，腾讯元宝保持高频迭代，陆续集成了微信文件、公众号内容、语音输入、文档处理等功能，并支持联网搜索、图像理解等能力。表面看是细节的打磨，实则构成了产品体验稳定性与可持续性的基础支点。腾讯在财报中披露，自 2 月 13 日以来，元宝的 DAU 在一个月内增长超过 20 倍。 这不是某个模型参数上的胜利，而是一种「以交付为目标」的系统能力体现。 腾讯也持续在多个自有场景中验证这一体系的有效性：腾讯会议的 AI 助手可基于实时与历史内容生成会议摘要和建议；腾讯云代码助手 CodeBuddy 已覆盖公司超过 85% 的开发员工，显著提升开发效率，整体编码时间缩短逾 40%；腾讯健康推出的 AI 健康助手，则能自动解读体检报告，生成个性化的复诊建议。 可以说，腾讯的 AI 战略从来不只是打造一个「最聪明的大脑」，而是始终致力于构建一个「真正能派上用场的助手」。 02 从「能用」到「好用」：打造一整套可交付的 AI 体系 实现从「能用」到「好用」，靠的不是某个环节的爆发，而是一整套技术栈背后的能力积累。 腾讯并没有试图用参数量来定义 AI 能力的边界，而是从底层架构到最终体验，系统性地搭建了一条「可交付」的路径。这背后，是一整套高度协同的技术能力体系：涵盖多模态交互、推理优化、知识增强（RAG）、多源数据支撑、高并发处理、云安全机制、敏捷开发方法、用户洞察机制，以及面向合作伙伴的开放生态。 高质量的内容和数据，是大模型可用的核心要素。在大模型能力趋同的状况下，也将是未来 AI 产品力竞争的核心领域，这也恰恰是腾讯最能发挥独特优势的地方。 腾讯有丰富的内容资源，例如图文方面的公众号、腾讯新闻、微信读书；视频领域的视频号和腾讯视频；还有专业领域的腾讯医典这样的权威医学科普。这些内容数据，可以作为模型调取的优质信源，帮助生成高质量的回答。腾讯元宝正是凭借微信公众号的内容源，加上强大的「联网搜索」能力，确保了检索和生成结果的质量和时效性。根据 SuperCLUE 报告测评，在 10 家接入 DeepSeek-R1 的平台中，元宝的联网搜索能力最强，在总分、基础检索能力和分析推理能力三项核心指标上，均排名第一。 优质内容生态，也对国内很多的模型厂商、内容和硬件厂商构成了巨大的吸引。比如 OPPO 手机、小米智能音响等，这些产品的音乐问答模块中，都在尝试接入结合了 QQ 音乐等资源的模型能力，满足用户的音乐需求。 多模态能力一度被视为通向 AGI 的必由之路，如今已成为产品化竞争的重要分水岭。也是腾讯厚积薄发，势必要拿下的关键战场。 腾讯从早年的优图、天籁实验室开始，就在图像、音视频等领域，积累了丰富的专利技术，今天大家用到的腾讯会议，就是腾讯多媒体技术的集大成者。AI 时代，腾讯则持续增强多模态能力优势。5 月 21 日，腾讯宣布了一系列的多模态模型上新，混元 Image 2.0，率先实现了商用级实时生图；视觉深度推理模型 T1-Vision，支持多图输入，具备原生长思维链，轻松实现「边看图边思考」；混元 3D 凭借业界首创的稀疏 3D 原生架构，实现了可控性与超高清生成能力的代际飞跃；端到端语音通话模型混元 Voice，实现低延迟语音通话，拟人性和情绪应用能力也有明显提升。 汤道生曾多次表达过对多模态的重视。他认为，现实世界是一个由多维信息构成的复杂系统。「未来，AI 要像人一样具备视觉和听觉，才能立体且完善地理解世界；在文字之外，还应该通过语气、动作，完整而真实地传递信息。」 从这个角度看，发展多模态模型不只是技术拓展，更是体验的重构。通过将图像、语音、视频、文本等形态的内容输入和输出纳入统一模型能力，用户可以用更简单的方式与 AI 交互，并得到更丰富的结果，从而显著降低使用门槛。这种交互方式使 AI 不再只是「极客的玩具」，而是真正向更广泛用户普及。 模型除了要低门槛、强交互，落地更重要的是要准确和靠谱。汤道生之前也说，「企业所需要的是，在实际场景中真正解决了某个问题，而不是在 100 个场景中，每个都只做到了 80%。」 在「让 AI 更靠谱」这一层面，RAG（检索增强生成）技术，被广泛认为是短期内提升模型准确性和上下文理解力的有效路径。而腾讯也是最早提出并拥抱「大模型+RAG」的云厂商之一。腾讯依托其文档解析、向量化等方面的长期积累，构建出一套结构化的知识增强能力，能够将企业的私有知识库与通用模型无缝融合，有效降低幻觉率，提高业务理解深度。这也为企业客户构建定制化 AI 助手提供了底层保障。 腾讯的这套 RAG 能力，同样源自过去多年的技术累积和海量应用实践。早在 2019 年，腾讯就将向量数据的检索处理能力，用在了腾讯视频、QQ 浏览器、QQ 音乐等 40 多个内部业务场景，每天处理超过 1600 亿次请求。在向量检索的帮助下，QQ 浏览器的检索成本降低了 37.9%，QQ 音乐人均听歌时长、腾讯视频有效曝光人均时长，都有了明显的提升。 为了支撑流畅的「前台体验」，背后的基础设施能力是决定规模化落地的隐性门槛。比如 AI 模型的训练与推理，对算力资源调度、数据流通效率与系统响应能力，提出了极高要求，腾讯通过构建包括腾讯云 TI 平台、高性能 HCC 集群、GooseFS 高速存储、星脉网络等在内的软硬一体化基础设施，大幅提升了训练效率与推理性能，显著降低响应延迟与成本。 而 AI 系统一旦进入真实业务场景，数据隐私、权限管控、可追溯性等问题将成为客户最关心的底层风险。腾讯也借助其服务亿级用户所积累的系统调度与安全能力，构建起涵盖身份认证、数据隔离、权限分级、加密传输等模块的完整安全体系。相比一些只专注算法性能的新兴玩家，这种「老业务带来的系统经验」成为腾讯 AI 能够深入复杂行业场景的底层壁垒。 所以说，腾讯 AI 能力体系的核心逻辑，并不只是追求模型本身的「最强」，更要让模型真正「能被交付」。从能用的技术能力，到可用的系统能力，再到好用的产品体验，推动前沿 AI 能力向普适工具转化。这也是为什么，当 DeepSeek 出现时，腾讯能成为第一批完成集成、快速上线、稳定运营的大型公司之一——不是因为它跑得最快，而是因为它一直在为「跑得更久」而准备。 03 从自用到共建：腾讯云如何推动 AI 在 B 端落地 腾讯在 AI 领域的打法，并不是「闭门造车」，而是始终坚持在自有场景中沉淀能力，在实际验证中拓展市场。真正支撑其走进 ToB 市场的关键，不是单点模型能力的突破，而是一整套「可交付」的体系构建：不仅能把 AI「做出来」，更能把 AI「做成服务」，并稳定、便捷地交付给客户。 这次腾讯云的 AI 应用峰会上，新升级的智能体开发平台，以及知识库产品，受到企业和开发者的关注。这些工具的出现，极大地降低了 AI 部署的门槛，提升了应用的覆盖面。 在全行业都很关注 AI 智能体的当下，腾讯云新升级的「智能体开发平台」，给企业提供了多种构建智能体的模式和配套工具，首次实现了零代码支持多 Agent 的转交协同方式，大幅降低了智能体搭建的门槛。同时，平台还构建了完备的 Agent 工具体系，支持 MCP 协议、兼容 OpenAI Agents SDK 的关键定义，帮助 Agent 更好地调用工具、拓展服务。 企业知识库的搭建，也是企业落地 AI 的「刚需」配置。腾讯乐享企业 AI 知识库，能够打破部门与层级壁垒，对知识的有效性、更新时间、权限进行管控，同时支持多人协作、知识共创，不仅加速了企业内部知识的流动，也让 AI 能够更好地管理和应用企业知识，生产出更高质量的内容。 除此之外，模型应用的普及，对算力的需求也从训练转向推理。规模化推理的成本优化，成为云厂商的核心竞争力。腾讯云也通过 IaaS 层与工具层协同优化，提升了模型在推理场景下的响应速度、延时和性价比。 汤道生在最近的演讲中，专门提到了他们帮助荣耀手机高效部署 DeepSeek 的成功用例。荣耀手机希望接入 DeepSeek-R1 服务，但随着手机里的 AI 功能越来越多，大模型调用频繁、并发量很高，模型回复的高延迟，会严重影响用户体验。腾讯云基于自身的加速能力，帮助荣耀部署了 DeepSeek-R1 满血版服务，使得模型推理吞吐最高提效 54%，大幅提升推理速度，也让模型运行更快更稳，系统调度更顺畅。 腾讯的 ToB 能力并不止于基础设施支撑，更体现在其对行业与场景的深度理解。 以汽车行业为例，一汽丰田在客服系统中引入腾讯云智能体开发平台，着手系统性解决传统智能客服「答不准、答不全、答不快」的行业共性难题。在此前，企业在部署大模型时常面临专属知识调取难、生成内容宽泛等技术瓶颈，导致 AI 难以真正落地。腾讯云以自研的大模型为基础，结合 RAG、自研长文本 Embedding 能力和 OCR、多模态等组件，帮助一汽丰田结合自身专属客服知识，构建起涵盖官网、App、小程序、公众号等全渠道的一体化智能客服体系。 一汽丰田智能在线客服机器人对话丨来自：腾讯云 今年 1 月该系统上线后，智能客服独立解决率从原本的 37% 提升至 84%，月均自动解答用户问题超过 1.7 万次，有效缓解人工客服压力，提升客户满意度。更重要的是，一汽丰田还借助腾讯云工具，从历史客服问答中提炼结构化知识，扩充企业专业知识库，为客服系统长期稳定运营打下基础。 作为一家年销量近百万、服务触点遍布全国的汽车企业，一汽丰田的这次升级不仅是一项技术改造，更标志着「AI 从实验走向生产」。它用切实可感的结果，验证了腾讯云 AI 的「可交付能力」——从模型融合、系统接入到知识调度与体验闭环，每一步都可衡量、可部署、可迭代，真正实现了技术价值与业务价值的统一。 这背后反映出的，不是 AI 在某个行业的「试验性应用」，而是腾讯正在通过工具平台化、知识结构化、交互自然化的路径，把 AI 真正转化为一种「可交付、可演进、可协同」的新型生产力。 在 AI 产业逐步迈入「实用期」的节点上，一些曾靠「技术光环」出圈的玩家开始进入冷却期，而像腾讯这样在能力沉淀与系统服务上长期积累的公司，正在逐步显现出结构性优势。 腾讯能够迅速接住 DeepSeek 的机会，并稳定推动 ToB 市场边界扩展，靠的并不是某种模型红利或偶然策略，而是对「如何把模型用好、用稳、用出价值」的体系性理解。 它的打法，不依赖某一项「核心算法」，也不靠一句「战略口号」站位。支撑腾讯 AI 走到今天的，是对用户需求的持续理解、对系统能力的长期打磨，以及对场景落地逻辑的敬畏。 这，或许就是腾讯在 AI 时代真正构筑起的长期护城河。 *头图来源：视觉中国 本文为极客公园原创文章，转载请联系极客君微信 geekparkGO 举报/反馈"
    },
    {
      "doc_id": 16636,
      "title": "腾讯给AI下了一剂猛药",
      "time": "2024-05-12T00:00:00+00:00",
      "content": "海内外大厂大模型研发正在进入新升级周期，为了加速补齐技术短板，腾讯混元近日进行了大幅架构调整，重构研发体系。但面对海内外对手的凌厉攻势，手握大把国民级应用的腾讯，还需要找到更好的攻防节奏。 01、混元重构研发体系 4月下旬，在腾讯技术工程事业群（TEG）内，混元大模型将进行大幅架构调整的传闻开始在团队中流传。 4月29日，靴子落地。腾讯宣布混元新成立了大语言模型部和多模态模型部；同时将大数据、机器学习平台部、AI Lab、安全平台部、信息安全部等几个部门，重组为数据平台部、机器学习平台部两个部门，构建技术底座，为混元大模型训练提供算力与数据支撑——新成立的多个部门负责人均向混元大模型负责人、腾讯公司副总裁蒋杰汇报。 腾讯内部人士向《财经天下》透露，此前混元团队是以虚拟组织的形式，横跨在TEG的大数据、机器学习平台部、AI Lab等多个部门中。“数据学习和AI Lab还曾为争夺混元主导权进行过‘赛马’，各个条线建设了一些独立的‘小模型’，造成了较大比例的资源浪费。” 而此次腾讯调整混元模型团队，重心放在了研发体系的重构。这也意味着腾讯的AI战略将从业务驱动转向技术驱动，对于AI底座的研究将被强化。 腾讯内部人士对《财经天下》透露，近期混元也吸纳了AI行业内的技术带头人物。 “混元大模型缺少一些像阿里、百度、字节那样的有声望的基础技术‘大拿’。混元好几个条线的业务负责人是工作了十几年的‘老腾讯’，更擅长做具体业务。负责人中做技术算法优化的比较多，但他们更擅长的是搜索和广告算法优化。” 混元加速调整也源于，近期海内外科技大厂纷纷进入新一轮大模型重大升级周期。DeepSeek-R2被曝有可能在5月上线，更带给了各家强烈的紧迫感。 4月17日，字节发布了最新推理模型Seed-Thinking-v1.5。4月25日，百度发布了文心大模型4.5 Turbo与文心大模型X1 Turbo。4月29日，阿里一口气更新了包括2个混合专家（MoE）模型和6个稠密（Dense）模型在内的Qwen3系列模型。 不约而同地，几家大模型都将性能标准向DeepSeek-R1看齐，同时主打推理成本大幅下降。 而腾讯的上一次模型重要更新还停留在3月21日。当天，腾讯推出了强推理模型“混元T1”正式版，其更多沿用的是腾讯的“快思考”模型混元Turbo S架构。 相比于竞争对手在大模型、应用赛道上的“万箭齐发”，混元的实力显得身位尴尬。在微信对话框进行AI搜索时，腾讯也还在提供DeepSeek-R1和混元T1两种选择。这都倒逼混元需要加速补齐短板，拿出更强技术底座、更优体验的模型产品。 02、微信元宝，撬动增量 近日，除了聚焦混元的技术研发，腾讯对于元宝的布局速度也在明显加快。4月16日，腾讯在微信中上线了AI助手“元宝”，用户可以添加元宝为好友，在微信聊天界面与其互动。 与元宝App相似，微信元宝同样搭载了混元和DeepSeek双模引擎。但在元宝App上，用户可以预先选好模型、设定深度思考、联网搜索等功能。而微信元宝均默认使用“快速思考”，在多轮对话中，需要用户在卡片页面中手动选择“深度思考”重新生成回复。 受限于微信聊天界面，微信元宝也将功能做了取舍。《财经天下》使用后发现，与App端元宝相比，微信元宝与用户的交互更像一个“聊天机器人”，轻量化的回复可直接呈现；遇到复杂问题时，微信元宝会在“卡片”中生成更详细的内容，并在卡片左下方提供“去App继续提问”。 如果用户转发公众号文章或第三方链接给微信元宝，元宝也会给出分析、总结，并支持识图功能。 或是为了让微信元宝更像“好友”，腾讯为其设计了更为拟人的语言风格和界面。它在回复时，不会像元宝App生成“流式输出”，而是会在对话框上方显示“对方正在输入”，并发一句“我想一想”。 业内人士分析，将元宝做成“微信好友”的形式，意在通过高频入口来吃掉增量市场，而非与豆包、Kimi等竞争存量市场。“类似拼多多在微信生态里，先吃掉四、五线的增量市场，然后再反攻五环内；企业微信拿到微信互通入口，实现逆风翻盘。” 不过，目前微信元宝的体验还有不少不尽人意的地方。例如，微信元宝没有新建对话的功能，用户持续提问时，常会忘记上下文的情况。有用户吐槽，“想让它记住的记不住，不想让它记住的记住了”。 《财经天下》也发现，向其提出“称呼我为xx”的指令后，在多轮对话中元宝仍会偶尔忘记这个前提。 而元宝App端在默认开启深度思考后，当用户为其设定不同身份并提问不同问题时，在其推理思考的过程中，会将前后文联系起来，思考几个问题之间有无联系。 不过，腾讯也为微信元宝保留了改进空间，在元宝回复的卡片页面下方，设置了“倾听与共进”，给用户提供了对微信元宝提建议的渠道。 03、还需找到攻防节奏 从3月到4月，腾讯在AI应用领域的布局已经显著加快。腾讯旗下的QQ浏览器、QQ音乐、ima（腾讯智能工作台）、腾讯文档、腾讯地图等均先后接入DeepSeek和混元大模型。 近日腾讯又在微信中增大元宝社交互动，在TEG成立多模态新部门，也让外界猜测，腾讯希望在AI Agent、AI应用等方向取得更多斩获。 虽然微信元宝目前尚不支持一些场景化的快捷操作，诸如AI编程、数据分析解读、图像生成、自定义智能体等功能；相对更容易实现的一键管理群聊、制定好友发信息、公众号内容整合等功能也还未出现。但从年初腾讯为元宝加大投入并植入微信，便有分析称，“微信+元宝”或将是整合AI Agent、落地AI助手的最好场景。 晚点报道称，在2024年第四季度之前，腾讯都在等待大模型技术发展的一个拐点。马化腾对内说的是，“要清醒地认识到实际情况，不要过高估计自己的能力”。 而比起大模型底座研发，腾讯更想抓住的正是AI应用的机会。 随着DeepSeek-R1横空出世，为大厂重开一局，腾讯AI也进入了重投入期。 3月19日，腾讯发布新一季财报。2024年，腾讯在AI战略推动下，全年资本开支达到767亿元，同比增长 221%，创下历史新高。财报电话会上，腾讯总裁刘炽平表示：“我们计划在2025年进一步加大资本支出，预计资本支出将占收入的十几个百分点。” 对于AI Agent，刘炽平表示：腾讯计划利用高质量的模型构建独立的AI Agent，并借助其在浏览器、元宝等软件平台上的庞大用户基础来推动这些Agent的发展。同时，腾讯也将在微信和QQ等核心应用中融入AI Agent，以进一步提升用户体验。 而对于用户来说，没有什么场景比微信内的活动更加多样化和高频。未来腾讯若基于模型连接，将小程序、视频号等功能运用大模型能力整合，微信势必将成为AI Agent发展的最理想平台。 不过，由于混元的技术能力限制，目前微信元宝与用户显然还停留于浅层互动，元宝App也仍未摆脱留存的魔咒。近日，随着腾讯对元宝大举投流、高举高打的节奏减缓，截至5月7日，《财经天下》发现元宝App在“iOS免费App下载” 中的排名已下降到第29名。 而在B端市场，竞争对手正在利用技术红利期频频拿下大笔订单。有媒体报道称，近期大量政企应用已接入DeepSeek，阿里则凭通义千问拿到了不少国有金融机构智能风控项目。与之相比，腾讯的AI解决方案还更多停留于游戏和泛娱乐领域。 在海内外大模型发布节奏越来越密集，竞争日益激烈的背景下，腾讯需要一场更为坚决的技术攻坚，让自身产品与大模型更紧密地结合起来，抓住制定行业规则的窗口期。 （作者 | 林小葵，编辑 | 李不清，图片来源 | 视觉中国，本内容来自财经天下WEEKLY）"
    },
    {
      "doc_id": 16650,
      "title": "大模型之家2025年3月热力榜:BAT齐发力,DeepSeek迎来挑战者",
      "time": "2024-04-02T00:00:00+00:00",
      "content": "随着DeepSeek-R1推理模型在年初掀起的技术风暴持续发酵，整个AI产业正经历着以“推理能力革新”和“规模化落地”为核心的深度变革。作为首个完整展示思维链推理过程的国产大模型，其在2月创下的“7天用户破亿”纪录仍令人记忆犹新。而进入3月，行业竞争格局迎来新变量——百度、阿里、腾讯等互联网巨头加速释放技术储备，DeepSeek自身也推出了新一代V3模型，共同勾勒出大模型赛道的全新图景。 在《2025年2月大模型热力榜》中，共收录了234家大型模型及其所属企业。其中，BAT三家巨头搞个猛进，全面挑战深度求索的DeepSeek行业地位，百度推出了文心大模型4.5和X1两款全新大模型，阿里则凭借QwQ-32B强大的推理能力与轻量化部署方式提供了新的思路，此外腾讯旗下推理模型混元T1的上线，让推理模型的赛道更加热闹。同时，360、智谱、商汤科技等企业则在垂直领域构筑技术壁垒，正形成“多元竞争、生态协同” 的行业格局。 2025年3月，百度在人工智能领域动作频频，展现出技术实力与战略转型的决心。16日，百度正式发布文心大模型4.5及X1，并宣布用户可通过官网免费使用，不仅兑现了此前“4月1日免费”的承诺，还提前了时间表，同时文心4.5与X1两款大模型也全面应用到旗下产品之中，标志着百度从“技术领先”向“生态主导”的战略转型，试图通过技术、价格和生态的三重布局，应对国产大模型DeepSeek的崛起以及国际巨头OpenAI的免费策略，重新夺回AI竞赛的主动权。 阿里巴巴则在月初正式宣布全面“AI化”，CEO吴泳铭要求所有业务部门以AI促进增长。18日，阿里开源推理模型QwQ-32B，该模型以320亿参数规模在LiveBench测评中跻身全球前五，推理成本仅为同类模型的1/5，支持消费级显卡本地部署，显著降低了企业应用门槛。20日，阿里启动“T项目”，研发下一代AI引擎，聚焦多模态未知领域技术突破，持续深化其在AI技术前沿的布局。 腾讯则更为注重生态布局的双重优势。8日，腾讯混元开源图生视频模型，推动多模态生成技术向影视、广告等领域渗透，加速产业应用落地。12日，腾讯混元团队发布全球首个Transformer-Mamba混合模型Hunyuan-TurboS，21日，腾讯发布推理模型T1，首次进入全球Top15榜单，支持复杂逻辑推理和低代码开发，进一步丰富了其AI模型矩阵，正式加入到推理模型的“混战”之中。 面对BAT巨头们用全新模型带来的挑战，24日，DeepSeek发布混合专家（MoE）语言模型DeepSeek-V3-0324，引发了行业的高度关注，该模型总参数6710亿，每次激活370亿参数，显著提升了推理性能，同时增强了前端Web开发能力，优化了中文写作和搜索能力，适合中长篇写作和报告分析。 除了基础模型能力的快速迭代，智能体也正在成为行业的新风潮。 3月31日，智谱在2025中关村论坛上发布最新智能体产品“AutoGLM沉思”，该智能体集深度研究和操作执行于一体，能像人类一样打开并浏览网页，完成从数据检索、分析到生成报告的任务，推动AI智能体进入“边想边干”阶段。这款智能体的能力实现依托于智能体的“大脑”——沉思模型，即通过强化学习，让模型学会自我批评、反思，甚至沉思，并通过更长的深度思考时间换取更优的效果。此外，智谱还与金融、教育、医疗、政务等领域的合作伙伴共同推进Agentic LLM的落地应用，并计划搭建AgenticLLM平台，助力生态合作伙伴构建行业、地域与场景深度融合的智能体应用。同时，智谱在本月也获得了资本市场的积极响应，先后宣布获得杭州、珠海、成都等三地国资的战略投资，融资金额达18亿元。 3月26日，商汤发布财报，生成式AI收入突破24亿元，同比增长103.1%，成为集团最大业务。商汤坚持“AI基础设施（大装置）-大模型（日日新）-应用”三位一体战略，持续投入建设并自持全国首个5A级智算中心上海临港AIDC，算力总规模提升至23,000PFlops，同比增长92%。商汤表示将计划开发面向未来的AI助手智能体创新应用，加速多模态大模型在机器人、智能眼镜、智能座舱等智能硬件的应用布局，开放测试以来已接入超过70家企业，展现出全面的业务布局和增长潜力。 火山引擎在3月通过开源合作、战略签约、降价让利及人事调整等多维度布局，持续强化其在AI领域的竞争力。具体来看，3月，火山引擎宣布将大模型应用开源，并正式上线“大模型应用实验室”平台，推动AI生态共建，并同期宣布对Doubao1.5系列和DeepSeek系列部分模型的批量推理价格调整为原价的50%，降低企业AI应用门槛，进一步拓展市场份额。然而，在人事层面，3月12日，火山引擎AI解决方案负责人骆怡航离职，加入生数科技出任CEO，引发行业关注。 3月13日，360智慧商业在厦门举办2025全国合作伙伴战略启动会，提出“打响AI卫国战争”的战略蓝图。会上，360集团副总裁、商业化总裁黄剑表示，将以纳米AI搜索、360AI办公两大战略级产品为核心，加速AI与商业场景的深度融合，与代理商合作伙伴携手锻造“超强组织力”，共筑PC营销新生态。 3月20日，百川智能与北京儿童医院、小儿方健康共同发布全球首个儿科大模型——“福棠·百川”儿科大模型。该模型不仅覆盖了儿童常见病与疑难病症的立体化知识体系，具备强大的儿科临床推理能力，还首创了儿科“循证模式”，能像专业儿科医生一样整合最佳医学证据，为患儿制定科学、个性化的诊疗方案，将覆盖北京市海淀区、经济技术开发区社区医院以及河北省150余家县级医院，提升儿科医疗服务水平。 3月26日，昆仑万维正式发布Mureka O1与Mureka V6两款AI音乐模型。其中，Mureka O1被定位为全球首款音乐推理大模型，首次引入MusiCoT（Music Chain-of-Thought）技术，使AI具备自我优化能力，能推理旋律、编曲和歌词，提高音乐创作质量。此外，其“歌曲参考”与“音色克隆”功能支持个性化音乐风格定制。测试结果显示，Mureka O1在旋律结构、混音质量及人声质感方面均超越Suno V4。此次发布不仅推动AI音乐从辅助创作向智能创作演进，也为个性化音乐生成开辟新路径。"
    },
    {
      "doc_id": 16652,
      "title": "腾讯元宝弯道超车,AI 大模型打进“熟人局”",
      "time": "2024-03-27T00:00:00+00:00",
      "content": "“之前都没听说过元宝，身边用豆包的朋友比较多，怎么突然下载量冲到第一了，有点奇怪。”一位AI产品使用者感到些许疑惑。 感到突然的不只是普通用户。 3月3日晚间，腾讯旗下AI助手“腾讯元宝”（以下简称为“元宝”）在中国区苹果应用商店免费App下载排行榜上的排名超过深度求索（DeepSeek），升至第一，字节跳动旗下的豆包位居第四。 数据仍在飞涨。3月19日，腾讯集团总裁刘炽平在2024年年报电话会上表示，元宝2月至3月日活激增超20倍。 事实上，从2月中旬开始，元宝的步伐明显开始加快。从朋友圈广告，到各大APP首页推荐，元宝产品的快速迭代升级以及密集的推广投放让其迅速破圈。 图 / 元宝界面 过去一年间，豆包与Kimi（月之暗面旗下）作为最受市场关注的大模型产品，通过大规模市场投放迅速占领用户心智，同期元宝则处于相对沉寂的蛰伏期。 如今大模型市场的情势已经大变。 春节期间，DeepSeek横空出世，其MoE架构不仅凭借低算力高性能的特点改写了AI算力成本的底层叙事逻辑，更是推动了中国大模型开源生态建设。 就连此前对模型开源持保守态度的百度CEO李彦宏也表示：“优秀的模型开源，能够极大地促进应用。”而将AI产品接入DeepSeek，又是一波“泼天的流量”。 以接入DeepSeek为契机，元宝开始发起进攻。 月之暗面Kimi创始人杨植麟曾表示，AI时代的获客和移动互联网时代没有本质区别。这也是大厂们争相砸钱试图获得更高印象分的根本原因——在AI大模型市场格局以及商业化路径明朗化之前，抓住那波用户才是最重要的。 但在流量之外，产品体验、底层技术的迭代，也构成了大模型产品的重要部分。一个反例是，Kimi曾在去年因投流成本高登上热搜，然而从数据上看，其日活仍落在同样不差钱的元宝之后。 不过几个月时间，AI圈的创业明星变为DeepSeek创始人梁文锋，月之暗面的杨植麟似乎逐渐走出聚光灯下。 “推理大模型”“杀手级应用”......AI圈几乎是一日一世界。腾讯在打磨元宝和投流上同时发力，字节埋头自研推理模型，大厂跑步进场，创业公司疯狂迭代，大模型行业又要变天了。 1 元宝“后来居上” 相比其他大厂和创业公司，此前的腾讯在大模型研发及产品推广方面略显低调。 2023年9月，腾讯推出自研大模型混元，此后又上线多个应用产品，基于混元大模型的AI助手应用元宝直到2024年5月才正式上线，支持AI搜索、AI阅读、AI写作、AI画图等功能。 图 / 元宝界面 Quest Mobile数据显示，今年1月，元宝的月活跃用户数为275.16万人。在产品不断吸引用户、功能不断迭代的背后，离不开产品研发团队日夜兼程的付出。 「界面新闻·创业最前线」在某PAAS服务商小型分享会上，听到一位来自阿里方面的技术人员透露，为追赶研发进度，从春节期间DeepSeek出圈后至今，其团队成员下班时间基本在凌晨2点左右，而另一位来自腾讯方面的技术人员则表示，加班基本至凌晨12点。 “肝”，似乎已经成为AI圈当下的常态。 此前，元宝App是由腾讯TEG（技术工程事业群）团队主导研发，今年1月进行了组织调整，元宝产品团队整体调至CSIG（云与智慧产业事业群）部门。 更多的变化发生在今年2月。 2月13日，元宝宣布接入DeepSeek-R1满血版，成为支持混元和DeepSeek双模型的AI应用。打开元宝，用户可以自主选择Hunyuan和DeepSeek两种模型，还可以支持联网搜索，打通公众号信源。 图 / 元宝界面 产品迭代仍在加速。从2月13日起，元宝在35天内实现了30次更新，基本是三天迭代一个版本。 2月17日，腾讯自研的“混元T1”大模型完成全量上线；2月18日，腾讯内部紧急协调，让尚未被微信搜索灰度到AI功能的用户能通过元宝体验DeepSeek-R1。 3月1号，元宝上线了快思考模型混元Turbo S，今后用户在元宝内选择“Hunyuan”模型、关闭深度思考，即可体验混元Turbo S，相比Deepseek R1等深度思考模型，混元Turbo S能够实现“秒回”，吐字速度提升一倍，首字时延降低44%。 据3月26日最新消息，元宝再次完成重磅更新：接入DeepSeek V3-0324最新版——这距离该模型发布开源仅1天。 除了底层技术的持续迭代，元宝也在不断通过用户反馈来完善产品细节。例如元宝最开始只上线了网页版，但春节后捕捉到用户在工作场景下对电脑的需求，2月28号就上线了电脑版。 此外，在和元宝助手进行对话时，内容可以生成链接，还能“接着聊”，有效解决了大模型记忆时间短、容易出现幻觉的问题。 投流也在同步进行。 据DataEye数据，元宝在2月18日至23日期间的投放素材量环比增长345.1%，达到5.5万组，单日投放素材量超过豆包和Kimi。据AppGrowing数据，截至2月27日，腾讯元宝在27天里投放共花了2.81亿元。 2月22日，元宝终于超越豆包，升至苹果应用商店大陆地区免费榜第二名。3月3日，元宝在苹果应用商店的下载量甚至超过DeepSeek，荣登榜首。 “从小红书到知乎、微博，我已经在好多个APP上看到过元宝的广告了。”一位互联网用户表示。 图 / 腾讯元宝的朋友圈广告 接入DeepSeek后，即便是针对同一问题，基于独有的公众号信源和联网功能，元宝能有效放大腾讯生态的价值（包括微信在内），打破信息孤岛；另一方面，采用Hunyuan和DeepSeek双模型，既蹭上了爆红明星产品的流量，也给自家大模型产品打了一波大大的广告。 除了腾讯元宝、微信之外，腾讯文档、企业微信、腾讯地图、QQ音乐、QQ浏览器等腾讯系App，也纷纷接入了DeepSeek。 而在两个月前（2025年1月），豆包的数据还是一骑绝尘，月活高达7861万，在国内AI类应用中位列第一，仅次于ChatGPT。 基于腾讯生态，元宝似乎有底气谋定而后动。而在确立目标之后的迅速迭代升级，以及T1模型上线，则是想在其他大厂推理大模型上市前抢一波大的。 2 大厂投流“勒紧裤腰带” 在元宝横空出世前的2024年，豆包和Kimi是最热衷投广告的AI大模型产品。 图 / 豆包界面 Kimi最开始出圈的优势就是长文本处理能力，能够有效应用在垂直领域如法律、学术领域，积累了第一批种子用户。 2024年，杨植麟曾这样评价AGI的商业逻辑：“从C端的角度来说，推理成本可能会显著低于获客成本，所以从商业本质上来讲，可能不会跟之前的各种商业模式有非常本质的区别。” 在他看来，即便是AGI时代，前期也依然需要烧钱来获客、实现商业化，其成本甚至要高过研发本身的成本。 创始人基于对移动互联网投流策略的延续，Kimi在这方面也显得十分阔绰，至少在2024年是这样。 AppGrowning平台数据显示，从2024年3月开始，Kimi几乎每个月的广告投放都达上千万元；10月，Kimi的广告投放金额达到2.2亿元。彼时，Kimi还曾因“20天烧钱1个亿”登上热搜。 据不完全统计，在2024年的前三个季度，Kimi智能助手全网广告投放金额就达到了1.5亿元、豆包投放金额则为2亿元。 DeepSeek的出现改变了这一切。 当其他大厂争先恐后接入DeepSeek，且不同部门因不能首发接入DeepSeek而懊恼时，字节显得十分冷静——相比全家桶式对接，字节旗下仅有飞书、火山引擎等应用接入了DeepSeek。 DeepSeek呈现出的深度思考第一次被大多数普通人了解，但这在字节看来并非新鲜事。字节CEO梁汝波甚至坦言公司在AI技术上有所滞后：“DeepSeek-R1的长链思考模式并非业界首创，2024年9月OpenAI发布相关模型后，字节就意识到了技术变化，但‘没有觉得要马上复现出来’。” 浙商证券报告显示，字节在2024年AI领域的投入达800亿元，接近百度、阿里、腾讯三家总和（约1000亿元）。而尽快推出自研推理大模型，是字节的下一个目标。 相比大厂追赶DeepSeek的底气，现实对于创业者可就没那么友好了。 过去一年，Kimi虽然深谙移动互联网时代的获客之道，但其费尽心力月活仍远不及豆包，增速更是不如DeepSeek，后者正是增速最快的AI应用。 图 / Kimi界面 而DeepSeek的优质体验让“自来水”数据飞涨，更是让这家明星企业的操作略显尴尬。 外界不乏对Kimi投流策略过于激进的声音。2月中旬，DeepSeek爆火后，月之暗面内部复盘认为要坚持基础模型SOTA（State-of-the-art，当前最佳），接下来可能会重新训练基础模型。 同时，有消息称月之暗面近期决定大幅收缩产品投放预算，包括暂停多个安卓渠道的投放，以及第三方广告平台的合作。 豆包回归常态化投放，而Kimi则直接从撒钱投流的牌桌上离开，转向基础模型的研发和迭代。 从去年至今，大厂和创业公司都由大手大脚变得更加谨慎，一个重要原因是，大规模投流的转化率似乎并不太高。 QuestMobile数据显示，截至2024年9月，豆包APP的活跃用户3日留存率为39.1%，高于文小言（31.2%）和Kimi（32.2%）的留存率。 “大模型产品差异化较小，很多AI都是火过一阵就忘了，而且目前这种对话体的形式C端互动频率并不高，留存率有限，所以投流、成为用户脑子里第一个跳出来的AI产品，也是无奈的选择。”一位AI行业观察人士表示。 市面上的AI产品留存率并不算高，而DeepSeek的出现，不仅降低了算力成本，更是单纯凭借产品能打，让底层技术能力成为比肩流量营销的存在。 国内大模型产品大多仍以技术研发为导向，因此前期用户的订阅费用是较为重要的收入来源。但很快，大厂们开始向C端免费开放产品，将收费矛头对准企业端。 以豆包为例，其产品一直针对普通用户免费，这也为其迅速占据C端市场打下基础。 TO C业务免费可以积累更多数据和用户反馈，从而更好地给B端商家做产品定制和适配，提高B端服务能力。而抢B端客户的难度比普通用户更高。 现阶段，对B端企业来说，底层技术能力是基础，但价格仍然是杀手锏。 2月26日，DeepSeek API开放平台宣布错峰优惠活动，每日00:30-08:30为错峰时段，DeepSeek-V3降至原价的50%，DeepSeek-R1低至25%。 图 / Kimi界面 降价背后是技术优化和规模效应的展现，而中国大模型价格战正酣。 去年，字节、腾讯、百度、阿里等大厂就纷纷降价，其中通义千问在2024年12月31日进行了第三轮大模型降价，通义千问视觉理解模型全线降价超80%，最低0.0015元/千tokens，按最新价格算，1块钱可以最多处理大约600张720P图片，或1700张480P图片。 当市面上存在的大模型产品体验趋向同质化时，降本增效、以质美价廉的产品揽客也成为了玩家们优先级最高的任务之一。 3 淘汰赛开始了？ Open AI曾提出AGI发展的五级标准：聊天机器人、推理者、智能主体、创新者和组织者。 而要从拥有最基本的对话能力到能够执行复杂任务，几乎所有的大模型产品都是从早期的语言、视觉、声音等各个模态独立发展走到如今的多模态融合阶段。 比如GPT-4V可以理解输入的文字与图像，Sora可以根据输入的文字、图像与视频生成视频。大模型通过学习处理文字、图像、音视频信息，方能实现和真实世界的交互，并做出反应及预测。 DeepSeek的出现，不仅印证了低成本、高性能大模型训练方式的可行性，从数据表现来看，这也是国内用户首次大规模接触“深度思考”功能，其推理能力以及回答质量均大幅提升。 DeepSeek选择开源也掀起了国内大模型开闭源之争的高潮。 据业内人士透露，大模型开源意味着核心代码公开，其技术路径可以被快速复制，选择闭源的厂商大多是出于技术壁垒和数据安全的考虑，例如OpenAI早期未开源GPT-3。 但如今在DeepSeek的带动下，大厂们也不愿放弃开源这一超级流量入口，并在寻找技术封闭之外业务及生态共赢的可能性。 目前，阶跃星辰、腾讯、360均在自家AI大模型产品中加上了DeepSeek R1深度思考+联网搜索选项。 而百度在3月16日发布了文心大模型4.5和文心大模型X1，目前已在文心一言官网上线，免费向用户开放。 文心4.5是百度首个原生多模态大模型，其多模态理解、文本和逻辑推理能力显著提升；X1则为深度思考模型，在性能上对标DeepSeek-R1。 此外，百度宣布文心大模型4.5系列将于2025年6月底全面开源。截至目前，百度、阿里、腾讯的大部分模型都已经开源或宣布开源。 图 / 摄图网，基于VRF协议 而字节在面对DeepSeek时可以算是另外一股“清流”，小范围的接入不过是试水。据字母榜报道，字节自研的推理大模型预计将在3月底推出。此外，据界面新闻报道，豆包正在小范围测试深度思考模型，但接入的不是DeepSeek。 作为一家专注自研的大厂，字节的大模型团队近期也处在深度调整及磨合过程中。 据公开信息，原谷歌DeepMind副总裁吴永辉加入字节，担任大模型团队Seed基础研究负责人，主要负责AI基础研究探索工作；朱文佳主要负责模型应用相关的工作，两个人都在Seed部门，都向字节CEO梁汝波汇报。 一边是大厂加速追赶，另一边创业公司们也在积极寻找自己的护城河。 目前，已有六家大模型创业公司成为独角兽——零一万物、百川智能、阶跃星辰、智谱华章、月之暗面、MiniMax，业内人称“大模型六小龙”。 阶跃星辰、MiniMax均接入DeepSeek模型；百川智能继续加注AI医疗赛道；零一万物开始探索商用场景大模型能力的产业化落地；月之暗面、智谱AI则继续发力大模型与Agent智能体应用。 在不少业内人士看来，未来六小龙中能活下来的不过一两家。随着大厂利用资本和人才优势逐渐打破“创新者的窘境”，技术迭代已非一款大模型产品能否走红的唯一决定性因素，C端用户的产品体验、价格设置，针对B端企业的融合服务能力等，共同组成了更加智能、更受欢迎的AI产品。 这也意味着，大模型的淘汰赛开始了。 *注：文中题图来自摄图网，基于VRF协议。 举报/反馈"
    },
    {
      "doc_id": 16655,
      "title": "腾讯混元T1正式版震撼发布,AI领域再掀狂澜!",
      "time": "2024-03-22T00:00:00+00:00",
      "content": "3月21日深夜，腾讯再次在AI领域投下了一枚“重磅炸弹”。继2月底推出新一代快思考模型混元Turbo S后，腾讯宣布推出自研深度思考模型混元T1正式版，并同步在腾讯云官网上线。这一消息迅速引起了业界的广泛关注和热议，腾讯在AI领域的持续发力和快速迭代，再次彰显了其作为互联网巨头的强大实力和前瞻眼光。 腾讯混元T1正式版如期发布，性能业界领先 腾讯混元T1正式版的发布，可以说是“如期而至”。此前，在混元Turbo S正式发布时，腾讯就曾透露，正式版的腾讯混元T1模型API也将很快上线，对外提供接入服务。如今，这一承诺终于得以实现。 据知情人士介绍，腾讯混元T1正式版以混元Turbo S为基座打造，其亮点在于是一个能够秒回、吐字快、擅长超长文处理的强推理模型，性能保持业界领先。这一模型沿用了混元Turbo S的创新架构，采用Hybrid-Mamba-Transformer融合模式，这是工业界首次将混合Mamba架构无损应用于超大型推理模型。这一架构显著降低了训练和推理成本，让混元T1实现首字秒出，吐字速度达到最快80 tokens/s。 在超长文本推理领域，混元T1也展现出独特优势。它能够有效解决长文推理中常见的上下文丢失和长距离信息依赖问题，同时混合Mamba架构针对长序列处理进行了专项优化，提升了解码速度。通过大规模强化学习，并结合数学、逻辑推理、科学和代码等理科难题的专项优化，混元T1正式版的推理能力得到了进一步提升。与此前已上线腾讯元宝的混元T1-preview模型相比，综合效果明显提升。 腾讯方面提供的数据显示，在体现推理模型基础能力的常见Benchmark上，以及在中英文知识及竞赛级数学、逻辑推理的公开基准测试中，混元T1的成绩都达到了业界领先推理模型的水平。此外，T1还在多项对齐任务、指令跟随任务和工具利用任务中展现出了非常强的适应性。 目前，混元T1已在腾讯云官网上线，定价方面，输入价格为每百万tokens 1元，输出价格为每百万tokens 4元。这一价格策略无疑将吸引更多开发者和企业用户尝试和使用混元T1，进一步推动其在AI领域的广泛应用。 腾讯混元大模型持续快速迭代，AI成为最大驱动力 今年以来，腾讯混元大模型持续快速迭代，AI似乎已成为腾讯内部最大的驱动力。腾讯相继推出了深度思考模型T1 Preview和快思考模型Turbo S，并已广泛应用于腾讯元宝、ima、腾讯文档、微信读书、搜狗输入法、QQ浏览器等多款内部产品。这一举措不仅提升了腾讯产品的智能化水平，也为用户带来了更加便捷、高效的使用体验。 同时，腾讯混元积极拥抱开源，其开源模型全面覆盖文本、图像、视频和3D生成等多个模态。这一战略选择的背后，一方面基于腾讯长期以来坚持技术普惠的理念，希望将AI技术的成果惠及更多开发者和用户；另一方面也得益于腾讯在用户与产业多端的场景与生态优势，为AI技术的落地提供了广阔空间。 在日前公布的2024年财报中，腾讯年研发投入707亿元创下纪录。其中，AI技术对微信新芽业务的提振效应尤为显著，推动了腾讯营销服务板块的快速增长。2024年第四季度，腾讯在AI领域的资本开支超390亿元，并宣布2025年将持续加码，AI战略已进入重投入期。 腾讯董事会主席兼首席执行官马化腾表示：“受益于AI赋能的广告平台升级、视频号用户参与度提升以及长青游戏的增长，我们2024年第4季取得双位数的收入增长，并持续提升运营效率。数月前，我们重组了AI团队以聚焦于快速的产品创新及深度的模型研发，增加了AI相关的资本开支，并加大了我们对原生AI产品的研发和营销力度。” 巨头竞逐AI，我国AIGC应用或已进入加速期 随着2025年我国进入科技突破大年，各大互联网巨头纷纷加大在AI领域的投入和布局。近期，字节跳动豆包大模型团队官宣开源一项针对MoE（混合专家模型）架构的关键优化技术，可将大模型训练效率提升1.7倍，成本节省40%。这一技术的推出，无疑将进一步提升字节跳动在AI领域的竞争力。 阿里巴巴也不甘示弱，近日宣布推出AI旗舰应用——新夸克，将“深度思考”能力融入AI搜索。据介绍，用户在“AI超级框”中输入指令后，夸克智能中枢可以自动识别意图，规划梳理后调动各种不同模型和智能体（Agent）模块，帮助用户完成任务。这一创新应用无疑将为用户带来更加智能、便捷的搜索体验。 百度方面也是动作频频，日前连发两款免费新模型——文心大模型4.5和文心大模型X1。据百度相关负责人介绍，文心大模型4.5在多模态理解能力方面显著提升；而文心大模型X1则为深度思考模型，在性能上对标DeepSeek-R1，具备“长思维链”，擅长中文知识问答、文学创作、逻辑推理等，而且大幅降低推理成本。 值得关注的是，国产大模型开源步伐也在持续加速。阿里巴巴在基础模型和原生应用方面持续发力，近期相继发布了多款性能领先的开源模型。百度方面则表示，将在6月30日正式将文心大模型开源，并在今年下半年发布文心大模型5.0。 业内分析认为，在技术创新与商业应用的双轮驱动下，AI有望在互联网等数字原生领域率先形成规模化落地。随着AI在各行业深入渗透，有望诞生更多AI创新模式与高质量产品，进一步推动人工智能产业链向更加现实、业绩可落地的方向发展。 华富人工智能ETF基金经理郜哲表示：“结合腾讯财报和近期互联网巨头竞逐AI的情况来看，我国AIGC应用或已进入加速期。随着AI在各行业广泛应用和深入渗透，我们有理由相信，未来将有更多AI创新模式与高质量产品涌现出来，为人工智能产业链的发展注入新的活力。” 本文源自：金融界 作者：青枫 举报/反馈"
    },
    {
      "doc_id": 16656,
      "title": "中国企业开源浪潮重塑全球AI版图",
      "time": "2025-07-23T00:00:00+00:00",
      "content": "参考消息网7月21日报道 据香港《南华早报》网站7月19日报道，2024年7月9日或许会被称为中国人工智能（AI）界的“羞辱日”。从当天起，美国初创企业、全球人工智能模型开发领军企业开放人工智能研究中心(OpenAI)禁止中国开发者使用其模型。 与之形成鲜明对比的是，大部分国家的开发者均可正常访问，这无声地传达了该公司的立场：其宝贵的模型必须提防中国使用。 如今风向已变。2024年12月，深度求索推出面向所有人免费的DeepSeek-V3大语言模型；2025年1月，深度求索又发布推理模型DeepSeek-R1，能力媲美OpenAI的o1模型。中国企业掀起的这场开源浪潮，已在硅谷和华尔街掀起冲击波。 这一趋势不仅在中国催生了一波人工智能应用大爆发，也重塑了全球人工智能版图，并赢得世界各地开发者的拥护。中国开源模型为美国科技巨头所力推的封闭系统，提供了切实可行的替代方案。 报道称，开源人工智能模型的源代码和模型权重对所有人公开，可自由使用、修改和分发，倡导一种协作式开发模式。 以往，类似Linux的开源计算机操作系统未能取代微软Windows等专有系统，但分析师指出，这一次，中国免费开放的人工智能模型正对美国同类产品构成重大挑战。 英伟达公司创始人兼首席执行官黄仁勋称赞中国在开源人工智能方面的成就，表示将继续深化与中国企业的合作。 黄仁勋说中国公司开发的大语言模型是“世界级”的，对全球人工智能进步至关重要。 这几天在北京举行的中国国际供应链促进博览会上，他表示，中国的开源人工智能发展已成为“全球进步的催化剂”，让每个国家和行业都有机会加入人工智能变革。 报道称，与中国企业快速推出开源模型形成鲜明对比的是，OpenAI创始人兼首席执行官萨姆·奥尔特曼近日宣布，原定数日内发布的开源大模型将推迟上线，理由是出于安全考量，还需进一步测试。 科技行业投资人凯文·徐(音)指出，对深度求索等中国初创公司而言，采用开源策略是追赶的有效手段，因为这让它们能够借力更广泛的开发者社区。 自2022年底OpenAI推出聊天生成预训练转换器(ChatGPT)以来，中国开源人工智能开发者的模型开发取得显著进展。凯文·徐说：“现在大多数中国开源人工智能模型已处于或接近前沿水平……最新一波开放权重模型的发布，显示出中国在开源采用与贡献上的日益成熟。” 报道称，中国模型的先进能力已获得用户广泛认可。 截至7月中旬，深度求索在全球人工智能模型市场平台“开放路由器”上的份额达到24%，成为第二大受欢迎的模型开发商，仅次于占据37%份额的谷歌。 与此同时，世界最大开源人工智能社区抱抱脸公司网站的数据显示，阿里巴巴的千问模型家族已成为全球最大的开源人工智能生态系统，衍生模型数量超过10万个，超越元宇宙平台公司的模型社区。 中国科学院下属的多模态人工智能系统全国重点实验室研究员郑晓龙指出，中国庞大的开源生态系统应用场景遍及智能制造、数字政务等各个领域。 郑晓龙认为，技术演进与产业需求汇聚，在中国形成了独特的发展模式——应用需求驱动创新，开源生态又反哺产业成长。 他表示，中国的开源发展体现了“技术平权”的趋势，正在挑战闭源模型的地位。（编译/郭骏） 【责任编辑:郭晓婷】 部级领导干部历史文化讲座20周年纪念版 定位就是聊个天 金融市场技术分析 疗愈的饮食与断食 写作教练在你家 注音详解古文观止"
    },
    {
      "doc_id": 16657,
      "title": "大厂入局“围猎”AI Agent,谁能先闯出路?",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "2025年被创业公司密集占据的热门Agent（智能体）赛道，终于等来头部大厂下场“收割”。 北京时间7月18日，OpenAI发布ChatGPT Agent产品。功能上，ChatGPT Agent融合了此前OpenAI发布的Operator远程可视化浏览器环境执行任务能力、DeepResearch的多步研究与整合高质量信息能力，以及ChatGPT的对话能力；人员配置上，据OpenAI官方披露，为了开发ChatGPT Agent，Operator与Deep Research团队已合并为一个20到35人组成的统一团队。 另在近日，亚马逊云科技在纽约AWS峰会上发布Bedrock AgentCore服务，提供了一组核心组件，帮助企业构建、部署和管理AI Agent。今年3月，亚马逊AGI实验室开发的Nova Act已能自主操作网页浏览器完成购物、填表等复杂任务。 而在太平洋彼岸，中国一级市场正被金沙江创投主管合伙人朱啸虎的言论搅动。他认为大模型会“吃”掉90%的Agent，并将当前AI智能体创业者比作互联网早期的个人站长——充满草根精神却面临残酷淘汰。两相对比，Agent终于在多方鼓吹“2025元年”的热潮中，跨入大厂“收割”、创业公司焦虑的节点。 平台化竞争开启 整个Agent行业已有Manus、Lovart、Flowith、Genspark等明星产品，ChatGPT Agent发布后也面临同质化、速度慢、技术缺乏代际差等质疑。但从官方演示来看，ChatGPT Agent的核心优势在于OpenAI直接搭建专用模型，与OpenAI o3同系列，采用端到端训练方法，系为Agent任务开发的统一模型，而非其他Agent产品调用外部厂商产品建立的多模型工程化组合。 另从定价来看，此次OpenAI虽未再次实行降价策略，但创业公司也未占据明显价格优势。其中可调用ChatGPT Agent功能的GPT Plus套餐每月20美元，Manus基础计划每月19美元。 AIGCLINK发起人、行行AI合伙人占冰强对第一财经表示，通用类Agent领域竞争已经进入成熟期，大厂开始下场，包括OpenAI、字节跳动Coze空间等，这是一条属于大厂的赛道，而垂类行业的Agent如果具备一定交付能力，创业公司在其中仍有机会。 更值得注意的一点在于，OpenAI或将开辟一条新的营收路径——与最终交易绑定，但该模式此次暂未正式对外披露。有消息称，OpenAI计划开发电子商务功能，测试ChatGPT内部集成结账系统，并通过ChatGPT完成在线产品销售进行分成。过去的Agent类产品可以帮助用户搜索、对比、筛选，甚至包括支付下单，但并未在该流程内进行收费举动。OpenAI此次虽未披露新营收方式，但山姆·奥尔特曼此前在接受采访时称：“我们不会为了改变推荐排名而收费，但用户若通过Deep Research发现了某款商品并进行购买，我们会抽取约2%的费用。” OpenAI从底层模型优势切入，亚马逊则直接提供技术与资金支持，所发布的Amazon Bedrock AgentCore为客户提供从部署到运行的全套能力。此外，亚马逊云科技宣布向其生成式AI技术创新中心追加1亿美元投资，并与Meta达成合作，支持初创企业利用Llama模型开发AI应用。 不论是OpenAI从流量入口添加交易收佣丰富生态，还是亚马逊从底层能力提供全栈支持，Agent领域的竞争越来越平台化。正如朱啸虎三日前在社交平台所言：AI Agent领域创业者可以借鉴互联网早期的个人站长模式，从个人站长逐渐成长为具有影响力的互联网公司。他分享的代表性案例包括网易、腾讯等，均从“工具”或“入口”切入，解决用户最基础或最迫切需求，形成用户黏性，再发展壮大。 从早期迈入分化路口 虽然成长路径可参考，但目前多元的Agent产品生态尚未有哪一款产品，能够在用户群中构建起牢固的黏性壁垒。Demo（演示版）产品引发一波讨论与测试后，一旦开启收费，用户流失严重，形成热闹Agent浪潮下的伪需求陷阱。也因此，朱啸虎认为，如果产品不具备用户黏性，未来大模型能够“吃”掉90%的Agent产品。 这并非夸大其词，此前Gartner预测，到2027年底，40%的代理型人工智能 （Agentic AI ）项目将被取消，原因在于成本高昂、商业价值有限及风险控制不足。当下大多数项目都处于早期试点或概念验证阶段，许多组织低估了扩展Agentic AI系统的复杂性。 Gartner高级总监兼分析师阿努什里·维尔马（Anushree Verma）表示，部分Agent项目“受炒作驱动，且常常被误用”，“这可能会让组织忽视大规模部署AI Agent的真正成本和复杂性，导致项目无法推进到生产阶段”。 另外，Gartner认为，当下“智能体包装（Agent Washing）”现象兴起，即供应商将机器人流程自动化（RPA）工具、聊天机器人和AI助手等技术重新包装成Agent产品，但名不副实。在Gartner的调研数据中，仅有19%的受访者表示所在公司已在Agentic AI方面进行了大量投资，42%的受访者称投资较为保守，超过30%的受访者持有不确定或持“观望”态度。核心原因仍类似于AI1.0时代的问题——数据格式不兼容、系统接口老旧、权限申请流程漫长、内外部系统不匹配等。 头部厂商下场虽然带来更明确的方向，但也带领行业加速迈入关键性十字路口。专用模型的迭代将较多模型拼凑的“工程化组合”更具优势，成为技术门槛的核心；平台化能力会倒逼中小创业者向垂直场景深耕，复制早期互联网时代“工具-入口-生态”的成长逻辑；商业化层面，单纯依赖工具收费的路径将面临营收压力。预计未来三至五年，Agent行业将正式从“概念炒作”迈入“实用主义”。 (本文来自第一财经) 举报/反馈"
    },
    {
      "doc_id": 16666,
      "title": "AIO或将爆发?AI的尽头也是广告,大模型或秒变AI带货助理",
      "time": "2024-04-29T00:00:00+00:00",
      "content": "最终，AI大模型没能逃脱植入广告的命运。 据英国《金融时报》报道，多家广告集团和技术初创公司正在开发新工具，帮助品牌在AI大模型的回复中植入广告，并透露Profound和Brandtech的工具可以监控品牌被AI提及的频率，通过向聊天机器人提供文本提示内容的方法，分析AI生成内容的情感导向。 广告一直是搜索引擎公司营收的主要来源，以行业巨头谷歌为例，刚披露的财报数据显示，2025年第一季度营收为902.3亿美元，其中搜索业务营收为507.02亿美元，占比超过一半，广告业务总营收则达到了惊人的668.85亿美元。 一个规模庞大市场摆在面前，相关企业考虑在AI大模型的回复中加入广告也是顺水推舟。继SEO/SEM（搜索引擎优化/营销）、ASO（应用市场优化）后，市面上也将兴起类似AIO（AI优化）等营销产业。 广告投放，从搜索引擎扩散到AI大模型 搜索引擎竞价排名众所周知，无论是国内头部厂商，还是谷歌这种海外巨头，都无法免俗。对于搜索引擎公司而言，竞价排名是最简单有效的赚钱方案，而对于投放广告的企业而言，则可以提高曝光率和产品销量。 最关键的是，与开屏广告、App植入广告不同，搜索引擎竞价排名只有在检测到关键字时才会推送，针对有需求的用户，而且无需下载特定App，具有成本低、易传播、易维护的优势，得到了企业的高度重视。 然而AI大模型的广泛应用，已经对传统搜索模式造成了冲击。企业需要增加新的广告投放渠道，以便于提高品牌和旗下产品的曝光度，逐渐崛起的AI领域无疑是这些企业最好的方向。 （图源：豆包截图） Profound联合创始人James Cadwallader表示，AI广告植入的到来，就像CD到流媒体的转变。的确，搜索引擎广告植入主要是在用户搜索某些物品时，将产品链接或网站网址摆在前列，能够提高点击率，却无法让用户直观了解到他们的优势和特点。 AI大模型则不同，不但会推荐具体的产品和网址，还会对其进行总结，方便用户快速、直观地查看该产品是否符合自己的需求和预期。在小雷的实际体验中，如果问两款产品哪个更好，AI大模型有时还会列出表格，以便于用户进行对比，体验比搜索引擎更胜一筹，只是硬件配置常有错漏。一些多模态大模型，除了文字总结外，也会给出产品图片，贴心程度远高于搜索引擎。 （图源：豆包截图） 在AI大模型的回复中植入广告，或将对企业提高曝光度、增加产品销量起到重要效果。尤其是在AI冲击到搜索引擎的情况下，企业更需要AI作为新的广告投放窗口。对于AI企业而言，也应当考虑在AI大模型中植入广告，包括但不限于AI应用生成的内容。 国内AI大模型众多，文心一言、豆包、通义千问、混元、Kimi、DeepSeek等均有大量用户群体，在文心一言免费向用户提供服务后，这几款大模型已经没有一家收费了。 营收模式方面，国内AI大模型普遍面向B端，比如与软硬件厂商合作，定制相应的大模型，并发力垂直领域，寻求在金融、医疗等方面取得突破。其次则是利用AIGC帮助企业提高工作效率，以百度为例，基于文心一言大模型，百度通过AIGC实现了从营销方案、图片、文字生成，到智能体、直播、转化增强等经营方式，再到精准投放一条龙服务。 （图源：百度截图） AI大模型行业仍在发展期，企业正在全力建设数据中心，提高算力规模，用于大模型的训练和推理任务，这些布局投入甚巨，现有的营收模式不足以抹平亏损。尽管互联网巨头们财力雄厚，也需要尽快提升AI业务的盈利能力，而广告植入，或许是他们扭亏为盈的最好方案。 互联网的尽头是广告，AI呢？ 「互联网的尽头是广告和放贷」这句话一度在网上十分流行，的确，搜索引擎、App、网站的广告植入无孔不入，各类贷款App的广告更是不断骚扰着我们。小雷并非要为互联网企业开脱，只是任何企业都不可能「用爱发电」，哪怕现阶段国内AI企业还不敢在AI大模型的回复中植入广告，但在小雷看来广告的加入几乎已成必然。 至于AI企业会以何种形式在AI回复中加入广告，则值得我们深度探究。从Profound和Brandtech开发的工具中可以看出，他们正在通过定向提示词，检索AI大模型生成内容的偏好。 当我们向AI大模型提问即时性问题，AI大模型会通过在线搜索功能查询大量互联网内容，并抓取内容进行分析和总结，进而生成回复，以提高准确性。Profound和Brandtech针对AI大模型抓取内容的偏好，在网上发布大量图文内容，提高自家产品被抓取的可能性，从而对AI大模型生成的内容造成影响。 这点其实不难做到，例如此前AWE 2025大会召开时，雷科技报道团产出了大量报道，因而向DeepSeek提问AWE报道最强的媒体，DeepSeek给出的回答中雷科技位列第一。只要文章数量足够多，自然会被AI注意到。 （图源：DeepSeek截图） 不过对于AI企业而言，这种行为却似乎有点不够意思，AI大模型企业拿不到利益。察觉到利益受损的AI企业，可能会限制AI大模型输出某些品牌的内容。投放广告的企业与AI企业合作，联合为AI大模型植入广告，类似当前搜索引擎竞价排名的形式，可能会是双方最终的合作模式。 该模式下，AI企业可以提高广告投放企业相关内容在AI大模型回复中的优先级，并依靠大语言模型的总结能力和投放企业的准确数据，对产品优势和特点进行归纳整理，帮助其提高获客效率。AI企业则有望通过广告业务快速增加营收，让AI业务不再是赔本的生意。 行业的起落兴衰，总是伴随着企业的崛起与衰败，仅在互联网行业，曾经盛极一时的天涯社区、聚美优品、人人网等，如今都已少被提及。在AI大模型的回复中加入广告，或许会导致AI大模型被用户唾骂，但生存才是这些AI企业的第一要务。 今天AI企业未必没有在AI大模型的回复中加入广告，只是行业竞争激烈，文心一言都选择了以免费吸引用户的方案，这种大环境下没有企业敢于顶着网友们的骂声为产品加入广告。或许在行业更加成熟，且有一家企业起到带头作用，率先加入广告后，其他企业才会跟进。 AI大模型会被广告塞满吗？ 为了生存在AI回复中植入广告无可厚非，甚至已经习惯了广告的小雷，也不是不能接受。但与许多反对的网友相同，小雷担心的是植入广告后的AI，生成的内容还值得信任吗？ 若是广告在AI回复中渗透率太高，用户可能会无法得知产品的真实情况，以至于AI大模型在日常使用中的可信度大打折扣，沦为纯粹的AIGC工具。相较于这种情况，小雷更愿意接受类似App的广告植入模式，在各类信息中插入广告的链接，哪怕误触后会跳转到广告网页，也比AIGC生成的内容不可信要强。 （图源：豆包生成） 在小雷看来，这种情况出现的可能性较低，准确性是AI大模型的立身之本，减少AI幻觉是所有AI大模型开发机构都在做的事。况且如果AI大模型的问题回答准确性不高，用户还不如用搜索引擎查询答案，大不了多花点时间在茫茫多的网址中寻找有用信息。 除了内容准确性问题，网友担心的另一件事则是破窗效应。一旦开始有企业在AI回复中加入广告后，其他企业可能会更加肆无忌惮地在各个地方加入广告，例如弹窗广告、横幅广告等，大幅降低用户的体验。 AI企业在AI大模型的回复中植入广告，小雷可以理解，但小雷不希望看到AI大模型未来充满广告，影响到用户的正常使用。互联网的尽头可以有广告，但绝不能只有广告。 AI大模型把握好广告与容质量之间的平衡性，要比搜索引擎竞价排名困难许多，对于任何AI企业都不容易，但在众多企业的竞争下，小雷相信最终会有AI企业能够完美平衡体验、内容质量、广告收入，并取得用户的认可。 举报/反馈"
    },
    {
      "doc_id": 16667,
      "title": "大模型“上新潮”持续释放人工智能潜力",
      "time": "2024-04-18T00:00:00+00:00",
      "content": "从效率工具到生产力重塑 大模型“上新潮”持续释放人工智能潜力 随着人工智能（AI）市场持续蓬勃发展，作为人工智能领域炙手可热的技术方向，多模态大模型正迎来“上新潮”——企业纷纷以多模态融合、推理效率提升以及成本优化为突破口，加速人工智能技术的商业化落地。 “通过多模态长思维链训练、全局记忆、强化学习的技术突破，形成领先的多模态推理能力，并突破成本边界。”在商汤科技日前举行的2025技术交流日活动上，商汤科技董事长兼首席执行官徐立在介绍公司推出全新升级的“日日新V6”大模型体系时表示，该大模型体系将跨越多模态边界，释放推理与智能的无限可能。 此外，在近日举行的“2025快手磁力大会”上，快手也明确表示，在人工智能生成内容（AIGC）的内容生产方面，基于多模态大模型，快手的AIGC内容生成能力飞速提升。而在稍早前，智元机器人于3月初发布通用具身基座大模型GO-1，该大模型借助人类和多种机器人数据，让机器人获得了革命性的学习能力，可泛化应用到各类环境和物品中，快速适应新任务、学习新技能。同时，还支持部署到不同的机器人本体，高效完成落地，并在实际的使用中持续快速进化。 纵观近期业内的一系列动作，不仅反映出人工智能领域的技术跃迁，更是行业竞赛加速的缩影。专家认为，当前，行业竞争焦点已从参数规模转向应用效能，大模型的价值也正从实验室的各类技术指标向能否最终转化为实际生产力转变。与此同时，多家上市公司也在积极探索将多模态大模型引入到日常工作中。 ● 本报记者 乔翔 大模型频“上新” “多模态正在成为大模型行业发展的重要趋势。”商汤科技联合创始人、大装置事业群总裁杨帆在接受中国证券报记者采访时表示，2025年，行业头部企业愈发强调多模态能力，这是一个自然的市场趋势。因为人工智能最终会走向线下，走向物理现实。在这一过程中，多模态的处理和思考能力就成为一种必然的趋势性需求。 在商汤科技日前举办的2025技术交流日活动上，公司推出全新升级的“日日新V6”大模型。其模型能力显著提升，在长思维链、推理、数理、全局记忆方面具备优势，做到高效能与低成本兼具。 值得一提的是，凭借全局记忆能力，“日日新V6”大模型打破了传统模型仅支持短视频的限制，可支持10分钟级视频全帧率解析。此外，“日日新V6”大模型还可以对视频的精彩内容进行智能剪辑输出，帮助用户保留珍贵瞬间。 徐立告诉记者，全局记忆使得交互更加自然，例如能处理更长的视频段，并且能对视频有整体的理解和深度推理，从而实现更好的交互。 不仅是商汤科技，3月10日，智元机器人发布首个通用具身基座大模型——智元启元大模型（GO-1），其主要是基于2024年底智元机器人推出的AgiBot World数据集。该数据集是包含超过100万条轨迹、涵盖217个任务、涉及五大类场景的大规模高质量真机数据集。 为了有效利用高质量的AgiBot World数据集以及互联网大规模异构视频数据，增强策略的泛化能力，智元机器人提出了Vision-Language-Latent-Action（ViLLA）这一创新性架构。 “该架构由VLM（多模态大模型）+MoE（混合专家）组成，其中VLM借助海量互联网图文数据获得通用场景感知和语言理解能力，MoE中的Latent Planner（隐式规划器）借助大量跨本体和人类操作视频数据获得通用的动作理解能力，且MoE中的Action Expert（动作专家）借助百万真机数据获得精细的动作执行能力。”智元机器人表示，三者环环相扣，实现了利用人类视频学习，完成小样本快速泛化，降低了具身智能门槛。此外，作为通用机器人策略模型，其能够在不同机器人形态之间迁移，快速适配到不同本体，群体升智。目前，已成功部署到智元多款机器人本体，将具身智能推上了一个新台阶。 据智元机器人介绍，通过ViLLA创新性架构，公司在五种不同复杂度任务上测试GO-1大模型的表现显示，其平均成功率提高了32%。其中，倒水、清理桌面和补充饮料任务表现尤为突出。 值得一提的是，在智元机器人4月初公开发布的一则招聘公告中，关键岗位就包括多模态大模型算法研究员/工程师。据公司透露，今年1月，智元机器人已累计量产下线1000台通用具身机器人。 应用价值日益显现 头豹研究院研报显示，2023年中国多模态大模型市场规模达到90.9亿元，预计到2028年将增长至662.3亿元，年复合增长率达48.76%。该研报认为，这一快速增长主要归因于技术创新的持续驱动，以及行业需求的强劲推动。此外，随着多模态大模型在图文生成、跨模态检索和视频内容分析等领域的技术突破，其在各领域的应用价值日益显现。 “过往人工智能应用有非常多的宏大场景构想，但真实环境存在的复杂问题更考验大模型对于混合图文的理解推理能力。”在徐立看来，AI之道，在于百姓之日用。每天的高频日常使用才能从真正意义上辅助人工智能通用模型的大规模发展。 “在日常生产生活高频出现的需求场景中，以保险理赔为例，传统方案通常高度依赖事先设定的规则，根据规则定向去找文档里面的关键信息，比如总金额、治疗开药日期等。”徐立表示，如今通过多模态数据的深度整合与强推理能力，能够更全面地捕捉全部文档的全量信息，判断商业医疗保险理赔材料是否符合理赔要求，并以开放式的方式进行推理，检查诸如是否存在乱开药、乱检查、材料缺失或者材料对不上等问题。 徐立表示，现实生活中小额理赔的材料审核往往需要3至7天的时间，而交给人工智能，从测试情况看，平均时间可大幅缩减至1分钟。 除此之外，徐立还介绍了例如在线上购物比价、商铺运营、剪辑视频、题目讲解与分析等多个日常高频场景中使用大模型进行效率提升的案例，进一步传递出大模型在日常生活中的实用性。 徐立认为，当人工智能聚集了人类现有的大量平均水平的知识后，能够通过触类旁通的能力，形成一种对于开放性问题的确定性应对能力，进一步完成从模型到客户使用的“最后一公里”。 “我们是从视觉智能开始起步的，当时我们的很多场景设置都非常宏大，包括城市管理、智能工业、电网、物业、运营等，其中一个比较重要的原因是当时的模型只能针对单一任务提供闭环价值，通用性不够强。”徐立表示，在如今的通用人工智能时代，那些“看不见摸不着”的技术能够真正走进“寻常百姓家”，并且能够在多个日常细分场景中带来价值闭环。 上市公司深度布局 业界普遍认为，大模型的核心竞争力已从单一模态处理逐步转向跨模态融合与深度推理，并在此过程中使得大模型的价值不再仅是单点工具，而是有望进一步重塑系统性生产力。在此趋势下，不少上市公司通过自研、合作等方式加速布局多模态大模型，并在垂直领域持续深度优化。 企业安全隐患排查，往往需要工作人员“一天三班倒”持续现场巡检。面对繁杂的排查工作，如何帮助工作人员减负增效？对此，海康威视正探索基于海康观澜大模型技术体系，将多模态大模型能力应用到安全生产管理领域。 “将多模态大模型引入到日常安全生产管理工作中，对现场可能存在的隐患问题进行智能识别和快速判断，结合安全生产知识库，给出详细的排查依据和整改措施，不仅可以让现场排查工作效率得到提升，还可以通过远程巡查快速发现问题。”海康威视表示。 据海康威视介绍，依托企业安全生产管理平台，结合多模态大模型，可有效实现远程隐患智查。例如针对生产区、储罐区、仓库区的跑冒滴漏、油封破损、表计破损、外观裂纹、螺栓脱落等隐患，安全员可以将日常点巡检规范导入系统，并筛选匹配对应的视频点位，配置完成后一键启动排查，自动生成隐患分析报告。 海康威视表示，海康观澜大模型加持安全生产，助力企业构建更坚实的安全防线。未来将深入更多业务领域，探索新的应用场景，助力形成更准确、更高效的管理模式。 “公司在电力巡检领域所应用的产品包括轮式机器人、四足机器人以及无人机等。”泽宇智能日前在互动平台上透露，公司已于上月完成了“基于多模态融合的智能巡检模型算法”的评审。目前，公司正在积极参与轮式机器人的集中检测工作。 汉仪股份此前在接受机构调研时表示，公司长期布局人工智能应用技术，一直通过自研、投资并购等方式，持续扩大研发团队尤其是AI技术团队，加大资源投入进行AI技术的应用研究，尤其是多模态大模型的应用研究，探索各种大模型在文字、图像、视频等设计领域的应用创新落地。 据介绍，针对服饰类电商客户，汉仪股份研发的AI模特商拍和商品图合成技术，替代了传统拍摄方式，为品牌营销图智能换脸、智能合成商品背景图等功能，降低了客户商品拍摄与处理成本，提升了商品上架速度和展示效果；针对视频电商客户，其研发的AI视频剪辑解决方案，替代传统人力剪辑方式，可大大降低剪辑处理的成本，提升营销内容生产和投放效率。 “结合文本、图像和视频的多模态内容生成技术，公司布局开展了营销海报生成、虚拟换装、图生视频、视频混剪等方面的产品规划和研发工作。”汉仪股份表示，上述应用已在公司“kreatr”工具平台上线，并已和外部企业展开商业合作。 更多资讯或合作欢迎关注中国经济网官方微信（名称：中国经济网，id：ourcecn） 来源：中国证券报 更多内容或合作欢迎关注中国经济网官方微信（id：ourcecn） 举报/反馈"
    },
    {
      "doc_id": 16674,
      "title": "腾讯给AI下了一剂猛药",
      "time": "2024-05-11T00:00:00+00:00",
      "content": "海内外大厂大模型研发正在进入新升级周期，为了加速补齐技术短板，腾讯混元近日进行了大幅架构调整，重构研发体系。但面对海内外对手的凌厉攻势，手握大把国民级应用的腾讯，还需要找到更好的攻防节奏。 01、混元重构研发体系 4月下旬，在腾讯技术工程事业群（TEG）内，混元大模型将进行大幅架构调整的传闻开始在团队中流传。 4月29日，靴子落地。腾讯宣布混元新成立了大语言模型部和多模态模型部；同时将大数据、机器学习平台部、AI Lab、安全平台部、信息安全部等几个部门，重组为数据平台部、机器学习平台部两个部门，构建技术底座，为混元大模型训练提供算力与数据支撑——新成立的多个部门负责人均向混元大模型负责人、腾讯公司副总裁蒋杰汇报。 腾讯内部人士向《财经天下》透露，此前混元团队是以虚拟组织的形式，横跨在TEG的大数据、机器学习平台部、AI Lab等多个部门中。“数据学习和AI Lab还曾为争夺混元主导权进行过‘赛马’，各个条线建设了一些独立的‘小模型’，造成了较大比例的资源浪费。” 而此次腾讯调整混元模型团队，重心放在了研发体系的重构。这也意味着腾讯的AI战略将从业务驱动转向技术驱动，对于AI底座的研究将被强化。 腾讯内部人士对《财经天下》透露，近期混元也吸纳了AI行业内的技术带头人物。 “混元大模型缺少一些像阿里、百度、字节那样的有声望的基础技术‘大拿’。混元好几个条线的业务负责人是工作了十几年的‘老腾讯’，更擅长做具体业务。负责人中做技术算法优化的比较多，但他们更擅长的是搜索和广告算法优化。” 混元加速调整也源于，近期海内外科技大厂纷纷进入新一轮大模型重大升级周期。DeepSeek-R2被曝有可能在5月上线，更带给了各家强烈的紧迫感。 4月17日，字节发布了最新推理模型Seed-Thinking-v1.5。4月25日，百度发布了文心大模型4.5 Turbo与文心大模型X1 Turbo。4月29日，阿里一口气更新了包括2个混合专家（MoE）模型和6个稠密（Dense）模型在内的Qwen3系列模型。 不约而同地，几家大模型都将性能标准向DeepSeek-R1看齐，同时主打推理成本大幅下降。 而腾讯的上一次模型重要更新还停留在3月21日。当天，腾讯推出了强推理模型“混元T1”正式版，其更多沿用的是腾讯的“快思考”模型混元Turbo S架构。 相比于竞争对手在大模型、应用赛道上的“万箭齐发”，混元的实力显得身位尴尬。在微信对话框进行AI搜索时，腾讯也还在提供DeepSeek-R1和混元T1两种选择。这都倒逼混元需要加速补齐短板，拿出更强技术底座、更优体验的模型产品。 02、微信元宝，撬动增量 近日，除了聚焦混元的技术研发，腾讯对于元宝的布局速度也在明显加快。4月16日，腾讯在微信中上线了AI助手“元宝”，用户可以添加元宝为好友，在微信聊天界面与其互动。 与元宝App相似，微信元宝同样搭载了混元和DeepSeek双模引擎。但在元宝App上，用户可以预先选好模型、设定深度思考、联网搜索等功能。而微信元宝均默认使用“快速思考”，在多轮对话中，需要用户在卡片页面中手动选择“深度思考”重新生成回复。 受限于微信聊天界面，微信元宝也将功能做了取舍。《财经天下》使用后发现，与App端元宝相比，微信元宝与用户的交互更像一个“聊天机器人”，轻量化的回复可直接呈现；遇到复杂问题时，微信元宝会在“卡片”中生成更详细的内容，并在卡片左下方提供“去App继续提问”。 如果用户转发公众号文章或第三方链接给微信元宝，元宝也会给出分析、总结，并支持识图功能。 或是为了让微信元宝更像“好友”，腾讯为其设计了更为拟人的语言风格和界面。它在回复时，不会像元宝App生成“流式输出”，而是会在对话框上方显示“对方正在输入”，并发一句“我想一想”。 业内人士分析，将元宝做成“微信好友”的形式，意在通过高频入口来吃掉增量市场，而非与豆包、Kimi等竞争存量市场。“类似拼多多在微信生态里，先吃掉四、五线的增量市场，然后再反攻五环内；企业微信拿到微信互通入口，实现逆风翻盘。” 不过，目前微信元宝的体验还有不少不尽人意的地方。例如，微信元宝没有新建对话的功能，用户持续提问时，常会忘记上下文的情况。有用户吐槽，“想让它记住的记不住，不想让它记住的记住了”。 《财经天下》也发现，向其提出“称呼我为xx”的指令后，在多轮对话中元宝仍会偶尔忘记这个前提。 而元宝App端在默认开启深度思考后，当用户为其设定不同身份并提问不同问题时，在其推理思考的过程中，会将前后文联系起来，思考几个问题之间有无联系。 不过，腾讯也为微信元宝保留了改进空间，在元宝回复的卡片页面下方，设置了“倾听与共进”，给用户提供了对微信元宝提建议的渠道。 03、还需找到攻防节奏 从3月到4月，腾讯在AI应用领域的布局已经显著加快。腾讯旗下的QQ浏览器、QQ音乐、ima（腾讯智能工作台）、腾讯文档、腾讯地图等均先后接入DeepSeek和混元大模型。 近日腾讯又在微信中增大元宝社交互动，在TEG成立多模态新部门，也让外界猜测，腾讯希望在AI Agent、AI应用等方向取得更多斩获。 虽然微信元宝目前尚不支持一些场景化的快捷操作，诸如AI编程、数据分析解读、图像生成、自定义智能体等功能；相对更容易实现的一键管理群聊、制定好友发信息、公众号内容整合等功能也还未出现。但从年初腾讯为元宝加大投入并植入微信，便有分析称，“微信+元宝”或将是整合AI Agent、落地AI助手的最好场景。 晚点报道称，在2024年第四季度之前，腾讯都在等待大模型技术发展的一个拐点。马化腾对内说的是，“要清醒地认识到实际情况，不要过高估计自己的能力”。 而比起大模型底座研发，腾讯更想抓住的正是AI应用的机会。 随着DeepSeek-R1横空出世，为大厂重开一局，腾讯AI也进入了重投入期。 3月19日，腾讯发布新一季财报。2024年，腾讯在AI战略推动下，全年资本开支达到767亿元，同比增长 221%，创下历史新高。财报电话会上，腾讯总裁刘炽平表示：“我们计划在2025年进一步加大资本支出，预计资本支出将占收入的十几个百分点。” 对于AI Agent，刘炽平表示：腾讯计划利用高质量的模型构建独立的AI Agent，并借助其在浏览器、元宝等软件平台上的庞大用户基础来推动这些Agent的发展。同时，腾讯也将在微信和QQ等核心应用中融入AI Agent，以进一步提升用户体验。 而对于用户来说，没有什么场景比微信内的活动更加多样化和高频。未来腾讯若基于模型连接，将小程序、视频号等功能运用大模型能力整合，微信势必将成为AI Agent发展的最理想平台。 不过，由于混元的技术能力限制，目前微信元宝与用户显然还停留于浅层互动，元宝App也仍未摆脱留存的魔咒。近日，随着腾讯对元宝大举投流、高举高打的节奏减缓，截至5月7日，《财经天下》发现元宝App在“iOS免费App下载” 中的排名已下降到第29名。 而在B端市场，竞争对手正在利用技术红利期频频拿下大笔订单。有媒体报道称，近期大量政企应用已接入DeepSeek，阿里则凭通义千问拿到了不少国有金融机构智能风控项目。与之相比，腾讯的AI解决方案还更多停留于游戏和泛娱乐领域。 在海内外大模型发布节奏越来越密集，竞争日益激烈的背景下，腾讯需要一场更为坚决的技术攻坚，让自身产品与大模型更紧密地结合起来，抓住制定行业规则的窗口期。 （作者 | 林小葵，编辑 | 李不清，图片来源 | 视觉中国，本内容来自财经天下WEEKLY） 举报/反馈"
    },
    {
      "doc_id": 16675,
      "title": "一天之内,阿里、腾讯大动作!",
      "time": "2024-04-30T00:00:00+00:00",
      "content": "4月29日凌晨，阿里巴巴开源新一代通义千问模型Qwen3（简称千问3），参数量仅为DeepSeek-R1的1/3，成本大幅下降，性能全面超越R1、OpenAI-o1等全球顶尖模型，登顶全球最强开源模型。 千问3是国内首个“混合推理模型”，“快思考”与“慢思考”集成进同一个模型，对简单需求可低算力“秒回”答案，对复杂问题可多步骤“深度思考”，大大节省算力消耗。 千问3采用混合专家（MoE）架构，总参数量235B，激活仅需22B。千问3预训练数据量达36T ，并在后训练阶段多轮强化学习，将非思考模式无缝整合到思考模型中。千问3在推理、指令遵循、工具调用、多语言能力等方面均大幅增强，即创下所有国产模型及全球开源模型的性能新高：在奥数水平的AIME25测评中，千问3斩获81.5分，刷新开源纪录；在考察代码能力的LiveCodeBench评测中，千问3突破70分大关，表现甚至超过Grok3；在评估模型人类偏好对齐的ArenaHard测评中，千问3以95.6分超越OpenAI-o1及DeepSeek-R1。 性能大幅提升的同时，千问3的部署成本还大幅下降，仅需4张H20即可部署千问3满血版，显存占用仅为性能相近模型的三分之一。 值得一提的是，记者获悉，就在同一天，腾讯对其混元大模型研发体系进行了全面重构，围绕算力、算法和数据三大核心板块，刷新团队部署，加码研发投入。 调整后，腾讯成立两个新的部门：大语言模型部和多模态模型部，分别负责探索大语言模型和多模态大模型的前沿技术，持续迭代基础模型，提升模型能力。 同时，进一步加强大模型数据能力和平台底座建设，其中数据平台部专注大模型数据全流程管理与建设，机器学习平台部则聚焦机器学习与大数据融合平台建设，为AI模型训练推理、大数据业务提供全面高效的PaaS平台底座，共同支撑腾讯混元大模型技术研发。 腾讯相关人士表示，这意味着腾讯在快速调整组织架构以应对日新月异的大模型行业发展，这次调整有利于整合资源，优化研发流程，进一步提升腾讯在AI领域的长期技术作战能力。 混元是腾讯自研的通用大模型，支持文本、图像、视频和3D等多种模态内容的理解与生成。今年以来，混元大模型技术迭代速度显著加快，相继推出快思考模型Turbo S和深度思考模型T1，均在公开基准测试中达到业界领先水平，在视频生成和3D生成领域也推出多个新版本模型。混元3D生成、视频生成、DiT文生图及千亿参数MoE语言模型等模型均已对外开源，GitHub总Star数超过2.9万。 近期，国产大模型发展按下提速键,生成式人工智能正带来产业变革。据央视网报道，目前，我国已形成覆盖基础层、框架层、模型层、应用层的完整人工智能产业体系。最新数据显示，截至2025年4月9日，我国人工智能专利申请量达1576379件，占全球申请量的38.58%，位居全球首位。目前，我国已累计培育400余家人工智能领域国家级专精特新“小巨人”企业，占据全球1/10的人工智能产业规模。 来源：每日经济新闻 责编：左宗鑫 编辑：马锶宇（实习生） 举报/反馈"
    },
    {
      "doc_id": 16679,
      "title": "腾讯再“出牌”!比DeepSeek-R1便宜3/4的深度思考大模型",
      "time": "2024-03-22T00:00:00+00:00",
      "content": "在此前35天“更新”30次后，3月21日深夜，腾讯混元大模型团队正式推出了自研深度思考模型混元T1正式版。相比以往，这次深夜“上新”也是腾讯摒弃了传统及主流的纯Transformer架构，首次将混合Mamba架构无损应用于超大型推理模型。 深夜“上架”能秒回更便宜 值得关注的是，作为腾讯自研的强推理模型，T1吐字速度达到60~80token/s，在实际生成效果表现中远快于DeepSeek-R1。 目前，用户在使用DeepSeek-R1等推理模型时，由于模型需要进行深度思考，并在提供回答前列出详细的思维链，虽然能够体现较高的智能化水平，但存在响应速度慢、不够高效的短板。 混元T1正式版则吐字快、能秒回，还擅长超长文处理。在体现推理模型基础能力的常见基准测试上，如大语言模型评估增强数据集MMLU-PRO中，混元T1取得87.2分，超越了DeepSeek-R1，仅次于o1。 同在3月21日深夜，混元T1已在腾讯云官网上线。价格方面，输入价格为1元/每百万tokens，输出价格为4元/每百万tokens，输出价格为DeepSeek标准时段的1/4，与DeepSeek优惠时段一致。 年研发投707亿元全速推AI 腾讯发布的最新财报显示，2024年第四季度，腾讯资本开支同比增长386%至365.8亿元，2024年全年资本开支达到767.6亿元，同比增长221%，创历史新高，占总营收的11.6%。研发投入方面，2024年全年的AI研发投入达到706.9亿元，2018年至今累计投入3403亿元。 腾讯董事会主席兼首席执行官马化腾在业绩会上表示，在过去一两个月里，AI得到了很大发展，尤其是在DeepSeek横空出世后，腾讯在云业务、“元宝”（AI应用）上都积极拥抱DeepSeek。 马化腾在业绩会上还表示：“数月前，我们重组了AI团队以聚焦于快速的产品创新及深度的模型研发，增加了AI相关的资本开支，并加大了我们对原生AI产品的研发和营销力度。我们相信这些增加的投资，会通过提升广告业务的效率及游戏的生命周期而带来持续的回报，并随着个人AI应用的加速普及和更多企业采用我们的AI服务，创造更长远的价值。” 腾讯元宝的日活跃用户数在2月至3月增长超20倍。自2月来，腾讯元宝接入DeepSeek满血版和全新混元模型，双核驱动元宝高速进化、日更级迭代，35天版本更新30次； 除此以外，目前腾讯已有元宝、微信、腾讯文档、QQ浏览器、QQ音乐、微信读书等数十款产品及业务接入DeepSeek。 腾讯大模型业务动作频频 从2月13日至3月19日，腾讯元宝35天版本更新共30次，关键更新包括： 2月13日，接入DeepSeek-R1满血版； 2月17日，上线推理模型混元T1； 2月17日，支持读微信文件； 2月18日，紧急支持微信搜索； 2月21日，支持混元和DeepSeek理解图片； 2月23日，支持语音输入； 2月25日，支持一键将对话导出为长图； 2月28日，正式上线电脑版； 3月1日，混元Turbo S灰度上线元宝； 3月4日，支持检索历史对话； 3月6日，支持折起/展开思考过程； 3月7日，支持通过对话链接“接着聊”； 3月8日，朗读支持续播、倍速与暂停； 3月12日，电脑版支持大字体、拖拽上传； 3月12日，支持停止生成回答，可重新编辑再提问； 3月13日，支持上传和导出腾讯文档； 3月17日，支持深色模式； 3月18日，电脑版上线截图提问等多项功能。 文｜记者 王丹阳 图｜腾讯混元 举报/反馈"
    },
    {
      "doc_id": 16685,
      "title": "腾讯要为AI砸千亿重金",
      "time": "2024-03-20T00:00:00+00:00",
      "content": "原创 全天候科技 全天候科技 争夺AI时代霸主。 作者 | 黄昱 周智宇 编辑 | 张晓玲 大模型应用的热潮中，腾讯等来了在AI时代再创巅峰的机遇期。 基于腾讯过去一个多月在AI应用战场推行的“闪电战”，资本市场期待，腾讯能对外宣告全面拥抱AI时代的决心，而最新的财报发布无疑是一个重要的观察窗口。 3月19日，腾讯发布2024年第四季度及全年业绩报告显示，由于AI战略进入重投期，其去年全年资本开支突破767亿元，同比增长221%，创历史新高，占全年6603亿元收入的约12%。 当日腾讯的业绩发布电话会上，AI战略毫无疑问成为了焦点。 腾讯总裁刘炽平透露，腾讯去年四季度资本支出增加的非常显著，因为腾讯在这一季度购买了更多GPU以满足推理需求。“我们计划在2025年进一步增加资本支出，并预计资本支出将占收入的低两位数百分比。” 也就是说，腾讯今年的资本支出很有可能达到千亿级别。 对于腾讯而言，发力AI不仅能助力其抢夺下一个超级流量入口，还能成为腾讯业务发展的倍增器。按照高盛的说法是，中国人工智能产业“AI基建看阿里，AI应用看腾讯”，但显然这两大中国互联网巨头现在已然释放出都想要的气势。 然而，要想在这场全球AI军备赛中拔得头筹，“钞能力”很重要。经过前两年“降本增效、收敛聚焦”的变革，腾讯去年业绩也已经实现了筑底反弹，总收入第四季度营收恢复两位数增长，这是腾讯大力投入AI的底气。 站在AI应用爆发以及中国资产被重估的关键节点，拥有庞大用户基础和丰富AI应用场景的腾讯，有望在加深传统业务护城河的同时，抓紧AI带来的新机遇，带领市值重回7万亿甚至更高点。 1 重塑AI战略 从去年的谨慎推行，到如今的全军出击，腾讯正在重塑AI战略。 腾讯董事会主席兼首席执行官马化腾表示：“数月前，我们重组了AI团队以聚焦于快速的产品创新及深度的模型研发、增加了AI相关的资本开支、并加大了我们对原生AI产品的研发和营销力度。” 腾讯相信这些加大的投资，会通过提升广告业务的效率及游戏的生命周期而带来持续的回报，并随着其个人AI应用的加速普及和更多企业采用腾讯的AI服务，创造更长远的价值。 财报发布的同一日，在2025腾讯全球数字生态大会上海峰会上，腾讯系统阐释了AI战略思考。 据悉，腾讯将以“坚定投入自研模型+开放拥抱先进开源模型”的多模型策略，在基础能力层、模型层、应用层全面布局，为用户提供丰富的AI 应用产品，助力产业创新增长。 这就意味着，在积极接入DeepSeek大模型的同时，腾讯将继续加大自研大模型技术的研发投入。 腾讯自研的混元大模型在行业中率先采用MoE架构，旗舰模型参数规模达万亿级，目前已在腾讯接入超过700个产品和业务场景。 接入DeepSeek大模型，在一定程度上也在倒逼混元大模型更快升级。近期，擅长复杂任务和深度推理的腾讯混元自研推理模型Thinker（T1）已经在腾讯元宝上线，此外腾讯还发布了主打更快任务处理能力的新一代快思考模型混元Turbo S，上线并开源“图生视频模型”、“3D生成模型”等多款模型。 此外，为进一步提升组织协同效率，腾讯已将腾讯元宝、QQ浏览器、搜狗输入法、ima等更多AI产品和应用调整到CSIG (云与智慧产业事业群)。 这一举措，无疑可以让元宝等AI产品矩阵更专注于商业化，而负责腾讯混元大模型开发任务的TEG（技术工程事业群）聚焦提升模型性能。 腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生表示，随着Deepseek的开源与深度思考的突破，AI大模型正跨过产业化落地的门槛，站上普及应用的全新节点。行业由之前的模型训练主导，发展到今天更多是应用与Agent驱动。 2 转守为攻 在ChatGPT掀起的这一波AI浪潮中，腾讯过去两年尽力投入但没有扭转局势的产品出现。DeepSeek在今年春节爆火后，AI应用来到破局的关键节点，同时DeepSeek带来的AI模型平权，直接洗牌了整个AI行业，让AIGC产品的竞争似乎都回到了同一起跑线。 腾讯敏锐捕捉到这一点，一改常态，在AI战略上开始主动转守为攻。 腾讯在2月全面启动“闪电战”计划，成为了大厂中最积极拥抱DeepSeek的一家，不仅旗下多个产品中接入DeepSeek模型，更成为首个在主力C端产品中引入DeepSeek的头部厂商。 截至目前，微信、元宝、QQ浏览器、QQ音乐、ima（腾讯智能工作台）、腾讯文档、腾讯地图等产品都悉数已接入DeepSeek，并同步支持自研混元大模型。 在这场AI应用的开年战役中，腾讯有两个备受行业瞩目的战术，一个是微信搜索接入DeepSeek大模型；另一个则是，集中资源加码元宝，据腾讯披露35天更新了30个版本，力度可见一斑。 DeepSeek-R1模型发布并开源近两个月来，众多互联网产品纷纷接入，其本质都是想通过借助这一能力受到认可的模型来抢夺市场份额。但这些产品的接入，都比不上微信，这样一个拥有超13亿月活的超级流量池接入受人瞩目。 2月15日，华尔街见闻从腾讯方面确认，微信搜一搜正式灰度测试接入DeepSeek-R1。而用户对DeepSeek模型的使用热情远远超出微信团队的预期，调用量产生了巨大的算力消耗。 因无法短期内满足所有用户使用AI搜索的需求，三日后，微信只能选择将泼天流量让给“兄弟APP”元宝，尚未被灰度到AI搜索的用户，点击微信对话框顶部的搜索栏，进入微信搜索，将有机会在页面中看到“下载元宝（体验DeepSeek-R1）”。 作为腾讯生态的核心入口，微信流量分配策略一贯谨慎，更多聚焦于自身功能优化，而非主动为其它应用导流。此次通过微信搜索入口分流下载元宝的动作，体现出腾讯在AI战略上的重大转向，既标志着元宝将更主动地引流，也有腾讯对C端AI场景的野心。 3 元宝先锋 腾讯选择“混元+DeepSeek”双引擎的策略已浮出水面，而在其打造的一众AI产品矩阵中，元宝已然站到了腾讯AI战略的核心位置，是腾讯抢夺下一代超级流量入口的先锋。 腾讯希望元宝能成为每个人口袋里的“全能AI助手” ，同时，从AI搜索的能力上来看，元宝也像一个连接器，链接了腾讯内部所有的生态，包括微信公众号、企业微信等。 转变去年低调的作风，一方面挑灯夜战迭代元宝，同时密集投流助攻。在接入DeepSeek后，很快，元宝的广告几乎刷遍了腾讯系App在内的所有平台， 同时B站、知乎、小红书等外部渠道也成为其重要阵地。 据DataEye数据，从2月18日开始，腾讯元宝投放量激增，由此前日素材量2000组左右攀升至月底超过1.7万组，从在豆包、Kimi三家中垫底的位置冲到头部，相反的是, Kimi投放力度大幅下滑，从此前的日素材投放量2万组左右到接近停滞。 不难看出，元宝希望借助DeepSeek的热度打一场闪击战，除了大量的广告投入外，同时通过自身产品功能的快速迭代来抢占市场，包括上线深度思考模型“混元T1”、 上线快思考大模型混元Turbo S、上线电脑版，以及支持上传、导出腾讯文档等。 在这样一番操作下，3月3日，腾讯元宝APP在中国区苹果应用商店免费App下载排行榜上，超越DeepSeek跃升至第一，而豆包位居第四，要知道在2月13日，元宝在这一榜单上的位置还在100名之外。 不过，值得一提的是，下载量仅能反映短期推广效果，而留存率、用户活跃数则能直接体现产品的长期价值和用户认可度。 刘炽平透露，从2月到3月，元宝的日活跃用户 （DAU ）增长了20倍，成为了中国 DAU 排名第三的 AI 原生移动应用。 据Xsignal，从2月17日一直到2月末，元宝DAU（日跃活用户数）呈直线攀升的态势，2月17日当天，元宝DAU大概百万级别，与豆包相差近2000万；等到了25日，元宝DAU已经破1000万。 不过，DeepSeek R1发布的一个月内，DeepSeek 的DAU最高已破亿，且日均稳定在8000万上下。如果未来腾讯元宝成想做成AI超级应用第一，相比豆包，DeepSeek将是更强劲的对手。 刘炽平指出，作为启动，腾讯确实给元宝有很大的投流，在这个过程中也在密切关注留存率的问题，现阶段留存率还是相当不错的。 “所以我们（投流）还在继续，但未来肯定不是纯粹靠投流来获得用户，未来会在元宝中加入很多各种各样的功能，让它变成一个更智能的AI助手，并且让元宝和我们现有的产品进行有机联动。” 4 重估未来 腾讯过去在AI上的投资已然在财报上有所体现。 腾讯董事会主席兼首席执行官马化腾表示，“受益于AI赋能的广告平台升级、视频号用户参与度提升以及长青游戏的增长，我们2024年第四季取得双位数的收入增长，并持续提升运营效率。” DeepSeek虽然爆火，但和微信、抖音、微博等动辄数亿的国民级应用相比，还远称不上是超级应用，而如今腾讯有望凭借其庞大用户基础和丰富的场景优势，迅速实现价值变现，而这也是如今资本市场对腾讯最大的期待之一。 资本支出是最能彰显腾讯投入AI决心的指标，也是投资者如今关注的焦点。腾讯此番释放出进一步提升资本支出的决定，无疑将有助于提升市场信心。 作为对比，前不久，阿里巴巴宣布，未来三年，将投入超过3800亿元用于建设云和AI硬件基础设施，总额超过过去十年总和。 腾讯今年冲千亿级别的预算，在投入力度上似乎也并不会比阿里弱。 就具体资本支出的方向，刘炽平透露，在研发方面，将继续投资自研模型，并加速各个业务集团的 AI 应用开发。同时，腾讯还将在市场营销方面进行投资，以提高用户对新AI产品，比如说元宝的认知和采用率。 “我们相信这一些投资将带来良好的经济回报，但是我们也有能力和意愿继续为股东提供资本回报。并计划在2025年回购至少800亿港元的股票。” 在真金白银的支持下，从B端到C端，腾讯AI应用的版图正在全面打开，AI战略将有望成为其第二增长曲线。 不过，有投资者指出，AI技术能为腾讯现有产品带来智能化提升，尤其是微信生态的商业化潜力巨大，但能否通过AI实现新的增长，关键在于技术突破和市场应用。 在这场全球AI军备赛中，腾讯自身优势明显。 华安证券分析师指出，对于腾讯来说，自身旗下产品与DeepSeek的深度结合，体现了腾讯“内生外化”的技术整合能力，通过将AI能力渗透到社交、内容、金融等核心场景，腾讯正在打造一个用户需求及时响应、数据价值闭环流转的智能服务网络。 “当技术红利通过微信、QQ、腾讯云等超级入口实现指数级释放时，其产生的网络效应可能形成其他企业难以复制的“数据-场景-技术”飞轮。”华安证券分析师如是认为。 高盛则认为，受惠于小商店电子商务基础设施、小程序生态系统和微信支付功能，腾讯是AI应用的主要受益者。 华创证券指出，看好2025年腾讯自上而下推动AI改造产品，带来的用户体验革新，并打开增量商业化空间，带动估值提升，给予腾讯2025年544-604.45港元的目标价。 年初以来，港股科技股表现亮眼，其中，腾讯股价持续攀升，突破500港元大关，年初至今涨幅超过29%。截至3月19日收盘，腾讯股价约为540港元/股，总市值约为4.96万亿港元。 在移动互联网时代，腾讯是绝对的赢家，凭借着社交和游戏这两大护城河业务，牢牢坐着中国“科技股之王”的位置，在2021年初，其股价一度超700港元/股，市值超过7万亿港元。 如今AI时代呼啸而来，腾讯能否抓住移动互联网时代带来的流量根基，抢占下一代超级流量入口，将成为其能否在市值上重回巅峰的关键。 *本文为全天候科技原创作品，未经授权不得转载，如需转载，请在后台回复“转载”二字，获取转载格式要求。"
    },
    {
      "doc_id": 16687,
      "title": "...推出目前最昂贵的人工智能模型;马化腾:和梁文锋有交流,目前 AI...",
      "time": "2024-03-20T00:00:00+00:00",
      "content": "马化腾：和梁文锋有交流，目前 AI 生态还在早期 3 月 19 日，在腾讯年报沟通会中，腾讯 CEO 马化腾表示，AI 的智能化程度相比往年有大幅度提升，对于腾讯来说经过慎重思考，云业务和元宝都拥抱了 DeepSeek。未来应用大发展的机会已经到来，各家都在采用 AI 落地，也看到 AI Agent（智能体）的发展，背后有很多 AI 相关工具的想象空间。 目前 AI 生态还在早期，各行各业都会受益于 AI 普及，相信每个行业都会拥抱这个机会。「我们业界和梁文锋都有交流，很敬佩市场上出现独立、开源的产品，我们非常尊重。」 同时，马化腾也透露，腾讯在数月前重组了 AI 团队以聚焦于快速的产品创新及深度的模型研发、增加了 AI 相关的资本开支、并加大了对原生 AI 产品的研发和营销力度。（来源：电商派） Meta Llama 模型下载量突破十亿，增长速度惊人 3 月 19 日，Meta 公司首席执行官马克·扎克伯格在 Threads 平台上宣布，Meta 的「开放」人工智能模型家族 Llama 的下载量已达到 10 亿次，相较于 2024 年 12 月初的 6.5 亿次下载量，在短短约三个月内增长了约 53%。 Llama 模型是 Meta 旗下人工智能助手 Meta AI 的核心技术支撑，广泛应用于 Meta 旗下的多个平台，包括 Facebook、Instagram 和 WhatsApp 等。作为 Meta 多年来致力于构建广泛人工智能产品生态系统的关键组成部分，Llama 模型及其相关微调和定制化工具均以专有许可的形式免费提供给开发者和企业使用。 自 2023 年推出以来，Llama 取得了广泛的成功。目前，包括 Spotify、AT&T 和 DoorDash 在内的多家知名企业已在生产环境中使用 Llama 模型。（来源：IT之家） OpenAI 推出 o1-pro，目前最昂贵的人工智能模型 3 月 20 日，OpenAI 近日在其开发者 API 中推出了更强大的推理人工智能模型——o1-pro。据 OpenAI 称，o1-pro 相比之前的 o1 模型，使用了更多的计算资源，以提供「持续更好的响应」。 目前，该模型仅向特定开发者开放，特别是那些在 OpenAI API 服务上消费至少 5 美元的用户。然而，o1-pro 的定价相当高昂：对输入模型的每百万词元（约 75 万字）收取 150 美元，对模型生成的每百万词元收取 600 美元。这相当于 OpenAI 的 GPT-4.5 价格的两倍，普通 o1 价格的 10 倍。 OpenAI 认为，o1-pro 性能的提升将说服开发者支付这笔不菲的费用。然而，早期用户发现，该模型在处理数独谜题时表现吃力，并在简单的视错觉笑话上出现错误。此外，OpenAI 去年年底进行的某些内部基准测试显示，o1-pro 在编码和数学问题上的表现仅略高于标准版 o1，但在回答这些问题时确实更加可靠。（来源：cnBeta） 腾讯：2024 年净利润 1940.7 亿元，比上年增长 68% 3 月 19 日，腾讯控股发布 2024 年 Q4 及全年财报显示，2024 年全年，腾讯实现营收 6602.6 亿元，同比增长 8%；净利润 1940.7 亿元，比上年增长 68%，研发投入创下历史新高，达到 707 亿元。 微信及 WeChat 合并月活跃账户数增至 13.85 亿，同比增长 3%；QQ 的智能终端月活跃账户数 5.24 亿，同比下降 5%。（来源：界面新闻） 软银宣布 65 亿美元全现金收购美国芯片设计公司 Ampere 以加速 AI 创新 3 月 20 日，软银集团宣布与美国芯片设计公司 Ampere 达成协议，软银集团将通过子公司以 65 亿美元（约合 469.97 亿元人民币）全现金方式收购 Ampere 的全部股权。 根据协议条款，Ampere 将作为软银集团的全资子公司运营并保留其名称。作为交易的一部分，Ampere 的主要投资者——凯雷集团和甲骨文公司将出售其在 Ampere 的各自股份。 软银集团董事长兼 CEO 孙正义表示：「AI 未来需要突破性的算力。Ampere 在半导体和高性能计算方面的专业知识将有助于加速这一愿景，并深化我们对美国 AI 创新的承诺。」 公开资料显示，Ampere 成立于 2018 年，是一家专注于为数据中心设备制造处理器的芯片设计公司，其技术基于 Arm 的技术架构。（来源：IT之家） GTC 演讲并未带动股价，英伟达估值触及 29 个月低点 3 月 19 日，在加州圣何塞举行的 GTC 人工智能大会上，英伟达一系列发布未能提振公司股价，该股在当日交易中下跌超过 3%。自 2025 年 1 月 10 日 DeepSeek 发布以来，英伟达市值已减少 4200 亿美元。 数据显示，自 2024 年 12 月 31 日以来，英伟达股价年内下跌了 14.04%，英伟达的市盈率为 40.66 倍，为自 2021 年 10 月 20 日以来的最低水平，即 29 个月以来的最低点。（来源：新浪科技） 百度回应「开盒」事件：信息并非来自百度，对侵犯用户隐私行为零容忍 3 月 19 日，针对「谢广军女儿开盒」事件，百度在官方公众号发布声明表示，事件相关信息并非来源于百度，任何职级员工及高管均无权限触碰用户数据。 声明中强调，百度坚决谴责窃取和公开他人隐私的网络暴力行为，对任何侵犯用户隐私的行为零容忍。 声明里，百度表示内部实施了数据的匿名化、假名化处理；数据存储和管理实行严格隔离和权限分离，任何职级的员工及高管均无权限触碰用户数据。百度安全部门反复调取了相关日志，并查验当事人权限。结果表明，开盒信息并非源自百度。 其次，经过调查，开盒信息来自海外的社工库——一个通过非法手段收集个人隐私信息的数据库。相关调查过程已取证，并得到公证机关公证。（来源：新浪科技） 哪吒汽车：近期网传「哪吒汽车解散研发团队」等系不实传闻 3 月 19 日，哪吒汽车 发布声明称，近期网络传闻「哪吒汽车解散研发团队」等信息，系不实传闻。公司目前正通过组织与流程优化，推动进一步降本增效。对传播不实信息、损害企业声誉的行为，公司保留法律追责的权利。（来源：界面新闻） 宇树 G1 人形机器人全球首次完成侧空翻动作 3 月 19 日，宇树科技官博更新视频，标题为「Unitree G1 全球首次完成侧空翻的人形机器人」。 宇树科技表示，一周年前宇树 H1（1.8 米）实现全球首次电驱人形机器人原地空翻（2024 年 3 月），这次挑战更高难度原地侧空翻。 视频中，宇树 G1 机器人在完成侧空翻动作后保持平衡。宇树科技还称，此程序开发和拍摄期间，G1 无任何故障损坏。（来源：IT之家） 理想 L 系列 / MEGA 智驾焕新版申报：换装小体积激光雷达，5 月上市 3 月 19 日，理想汽车旗下的 L 系列车型及理想 MEGA 智驾焕新版已现身工信部变更扩展目录，其中搭载 AD Pro 智驾系统的车型将新增激光雷达，其主动安全能力将与 AD Max 看齐。 新车全面采用体积更小的全新激光雷达方案，搭载 AD Max 智驾系统的车型将会从英伟达双 Orin-X 芯片升级至单 Thor-U 芯片。官方表示，单 Thor-U 芯片与双 Orin-X 芯片的 AD Max 系统均能提供高级辅助驾驶和全场景 NOA 功能，并且支持运行端到端 + VLM 大模型以及今年后续推出的 VLA 大模型。 此外，理想 L6、L7、L8、L9 搭载 AD Pro 智驾系统的车型将从地平线 J5 芯片升级到 J6M 芯片，并增加激光雷达，在主动安全能力上看齐 AD Max。J5 与 J6M 的 AD Pro 智驾系统均提供高级辅助驾驶和高速 NOA 功能，并可通过 OTA 持续升级。 在动力总成（增程器、电机、电池）以及造型设计方面，理想 L 系列及理想 MEGA 智驾焕新版与现款车型保持一致。值得一提的是，理想 L9 智驾焕新版选装绿色车漆时将同步提供金色饰条和全新配色轮辋。（来源：IT之家） 腾讯混元全新推理模型 T1 官宣：3 月 21 日发布 3 月 19 日，腾讯混元通过官方公众号宣布，全新的推理模型 T1 将于本周五（北京时间 3 月 21 日 23 时）正式发布。 与此同时，腾讯宣布，混元大模型首次登上 Chatbot Arena 榜单，跻身全球 Top 15。用户在该平台上以匿名方式与多个模型互动，投票决定何种模型更佳，从而根据分数生成排行榜。这种测评也被看成是大模型直接 PK 的竞技场，简单直接。 去年 9 月 5 日，腾讯发布了新一代大模型混元 Turbo，采用 MoE 架构，比上一代产品推理效率提升 100%，推理成本降低 50%。（来源：IT之家） Stability AI 发布新模型 Stable Virtual Camera，2D 照片轻松转 3D 视频 3 月 19 日，Stability AI 推出了其最新的人工智能模型——Stable Virtual Camera，该模型能够将 2D 图像转换为「沉浸式」视频，并呈出逼真的深度和视角。 Stable Virtual Camera 可以从一张或多张图像（最多可处理 32 张）中生成场景的「新视角」，用户还可以指定相机角度。该模型可以生成沿着「动态」相机路径或预设路径移动的视频，包括「螺旋」、「缩放」、「移动」和「平移」等多种效果。 目前版本的 Stable Virtual Camera 为研究预览版，可以生成方形（1:1）、竖屏 (9:16) 和横屏 (16:9) 三种宽高比的视频，最长可达 1000 帧。然而，Stability AI 警告说，该模型在某些情况下可能会产生较低质量的结果，尤其是在处理包含人类、动物或「动态纹理」(如水面) 的图像时。 目前，Stable Virtual Camera 在 Hugging Face 平台上以非商业许可的形式供研究使用，用户可以下载体验。（来源：aibase） 前英特尔 CEO 帕特·基辛格亮相 GTC：称英伟达在 AI 时代很幸运 本周，前英特尔 CEO 帕特·基辛格是英伟达的 GTC 2025 大会的特邀嘉宾，该大会目前正在加利福尼亚州旧金山举行。科技新闻媒体从基辛格在 Acquired 的「GTC 现场」视频播客中亲自露面时的思考中摘录了关键语录。 过去，这位前英特尔负责人认为英伟达能够占据市场领先地位是「极其幸运的」。昨天的小组讨论再次让基辛格重拾了他长期以来的观点：「CPU 是王者，我赞赏黄仁勋的坚韧，他只是说，『不，我不是想打造其中之一；我只是想从图形开始应对工作负载。'你知道，这变成了一个更广泛的视角。然后他在人工智能方面很幸运，有一次我和他辩论时，他说：『不，我在人工智能工作负载方面很幸运，因为它需要那种类型的架构。』这就是应用程序开发的中心所在。」（来源：cnBeta） 举报/反馈"
    },
    {
      "doc_id": 16694,
      "title": "AI战场,腾讯向左,阿里向右",
      "time": "2024-05-23T00:00:00+00:00",
      "content": "文 | 硅基研究室，作者 | kiki 作为中国两家公开表示「追求AGI」的科技大厂，腾讯和阿里成为了「互联网大厂派」中对AI投入最激进的两个典型案例。 这几天，腾讯前脚在北京开了今年的AI产业应用峰会，把主题定位「全面拥抱AI」，阿里云后脚就开了中企出海大会，继续展露全球化的野心。 特别是自DeepSeek「掀桌」的三个多月里，腾讯和阿里的共同动作体现在三方面： 一是自上而下快速决策承接DeepSeek流量，让这一超级入口「为我所用」； 二是推动整体业务AI化，阿里巴巴董事会主席蔡崇信此前在510阿里日亲友见面会上表示，阿里要把AI融入每一块业务、每一块环节，未来三到五年，所有业务都应以AI为驱动； 三是AI的早期红利也已反应在基本面上。据最新的财报业绩和电话会，AI给两家科技大厂的基本面带来实质性贡献，比如，阿里的电商和云，腾讯的广告和游戏。 但两家科技巨头的AI路线也出现明显的分野。 我们试图以从业务基本盘、应用逻辑和组织人才三个层面，结合腾讯和阿里的最新财报，拆解它们的不同。 1、AI基本盘不同：阿里要入口，腾讯要故事 相比2024年大模型战场上的高调的刷榜评分，2025年，来自DeepSeek的「暴击」，彻底调转了腾讯和阿里的AI布局风向。 一年前，尽管已提出「用户为先，AI驱动」的战略，但市场对阿里的AI布局理解为「微软+OpenAI」，彼时竞技场上最耀眼的还是「大模型六小龙」们，而腾讯在AI上过于谨慎克制的投入难免让人想起库克和他的苹果——有天然的流量入口，但对AI呈现明显的防守态势。 DeepSeek如同一条鲶鱼，彻底搅活了大模型这池春水，也刷新了人们对两家科技大厂的认知。 一方面，腾讯和阿里因此变得更开放，也更激进，两家企业高管均在2025年对外释放极为强烈的AI乐观主义，马化腾甚至在财报电话会上直言：“未来应用大发展的机会已经到来”。 另一方面，开源带来的技术平权，DeepSeek以「低成本、高效率」的新技术范式让下游应用开发变得更具性价比。这之中，阿里Qwen的出圈赚足了开发者的好感，腾讯则在加速已有应用场景和AI原生应用的开发更新速度。 但尽管步调类似，双方的意图则全然不同——阿里要的是AI入口，腾讯要的则是AI故事。 这种差异当然取决于它们的基本盘。 阿里目前电商业务（淘天+阿里国际）依旧贡献了接近六成的收入，淘天更是贡献了阿里的主要利润。 但电商已是存量市场，并不占据主要的用户入口，蔡崇信此前也强调，电商是一个垂类，有更多其他的互联网公司占据了对用户的入口。“阿里能聚焦在AI上的话，能够对整个入口的突破，也许可以把新的入口用AI的方式做出来，让阿里增加更多的用户”。 阿里近期与美图的合作也印证了对「流量的渴求」。阿里以2.5亿美元可转债的形式投资美图，美图则承诺未来三年向阿里采购不低于5.6亿元的云服务。 而另一边以广告和游戏为现金牛业务的腾讯，并不像阿里拥有「云+AI」顺畅的成长性逻辑，因此向AI要增长，显然也是向未来要成长性。 今年的两次财报电话会上，腾讯高管都主动披露了Agent相关进度，马化腾就提到：“每个人都可以做通用的智能体AI，微信有可能形成独特Agent AI生态，与微信生态系统的独特组成部分相连接，包括社交图谱、内容生态系统（如公众号、视频号），以及微信内数百万个小程序。” 当然这些都只是AI长期叙事，阿里能否造出AI时代的新入口，腾讯能否讲出如Agent一样的新故事，这些决定了两家巨头是否能成为一家「AI公司」。 2、做AI应用的方法论不同：阿里「合」，腾讯「分」 腾讯和阿里对AI的大笔投入，对外展现出的长期耐心，似乎让互联网大厂重回曾经的「古典时代」。 一边的马化腾在内部频繁提及「Debug」文化，另一边是频繁现身阿里的马云，有阿里员工甚至调侃：“马云出现越频繁，阿里的日子越好。” 移动互联网时代，一句「技术看百度，产品看腾讯，运营看阿里」曾总结了大厂各自的生态位，但在AI时代，一切都变了。 重新找到新生态位的关键之一，无疑就在AI应用侧。 阿里巴巴集团CEO吴泳铭对AI领域的两个最新研判也都关于「应用」，他提到，一是在大中型企业，AI应用开始从内部系统向用户侧场景渗透；二是积极使用AI产品的客户，从大中型企业延展到大量中小企业。 「吴妈」的话翻译过来，就是BC两端，软硬两侧，AI的扩散和渗透都在加速。 但具体在AI应用侧，腾讯和阿里是两种截然不同的做应用逻辑。 阿里自上而下，腾讯自下而上；阿里「合」，腾讯「分」。 从去年年底，大厂均开启了新一轮的组织架构调整，一致的共识是从「模应一体」转向将应用与基础模型分离。 去年年底，阿里将通义千问一分为二，模型层留在阿里云，而2C产品则从分到了阿里信息智能事业群。今年开始，腾讯先是将元宝应用团队从腾讯混元所处的TEG（技术工程事业群）产品团队并入到CSIG（云与智慧产业事业群），2月，QQ浏览器、搜狗输入法、ima等更多产品和应用也汇入了CSIG。 模型和应用分开，并不奇怪，本质上是专业化分工的体现。 但阿里在专业分工中呈现出「自上而下」的「合」。 阿里云CTO周靖人在接受晚点采访时提到，尽管分工更清晰，但协作很紧密。虎嗅此前也提到，「吴妈」也会频繁参与到基础模型团队的业务沟通之中，并密切留意模型团队的各种进展，另一年阿里「AI to C」的扛旗者吴嘉也直接向「吴妈」汇报。 从阿里AI原生产品的整合中也能看出，此前通义团队推出的AI原生产品通义听悟迅速被集成进夸克，目前在AI应用侧，阿里有通义APP和夸克两个C端产品，双方间尽管在产品定位上有类似，但在「合」的大思路下，并不排除未来打通和整合的可能。 相比之下，有着充足C端经验的腾讯，其AI产品呈现出「自下而上」的特点，因此AI探索相对独立，但也更佛系。 腾讯的AI原生工具ima就是一个典型案例，ima产品团队提到，团队起初的主要开发者来自QQ浏览器，项目最初启动在去年7月，用不到半年的时间跻身腾讯的明星产品之列。 几天前，腾讯又推动另一个应用入口的AI化——QQ浏览器宣布升级为AI浏览器，参考管理层在财报点会上对Agent的表述，腾讯在应用端的AI创新尝试都还在继续，公司高层也曾表态，针对开发独立的AI工具产品，在资源保障的前提下，将不设算力和人力限制。 3、管理AI的人不同：阿里的「铁三角」，腾讯靠老人坐镇 基本盘的差异，做应用逻辑的分化下，腾讯和阿里在AI战场上的差异化还在于管理AI的人不同。 随着通义大模型和夸克走向台前，阿里的AI军团形成了一个以吴妈为核心，周靖人和吴嘉为左右的「铁三角」，这符合阿里过去「转型先选将」的逻辑。 周靖人目前既是阿里云的CTO，也领导阿里通义实验室全盘，他加入接近10年，曾是阿里算法的头号负责人，2022年他正式成为阿里云CTO，公开报道中周靖人被形容为一个懂研究、能做产品，也能带队伍的全能选手。 吴嘉则是阿里的「校招生」，曾在阿里云做了七年的研发，随后其几乎做遍了阿里的创新业务，在他手中孵化出了阿里的C端产品夸克，他也是阿里内部少数从0到一做出C端产品的「少壮派」，外界认为，他的优势除了懂技术外，还在于能理解年轻用户的想法。 周靖人和吴嘉的共同点也类似，他们都懂技术和产品，也有丰富的一线管理经验，更为重要的是，他们都是「懂云」的人。 另一边的腾讯AI，则由十几年的老腾讯人管理。 CSIG由「腾讯云之父」汤道生领导，今年是这位中国香港人加入腾讯的20年，他曾推动QQ、QQ空间等社交产品的技术架构升级，具备to B和to C双重经验，也亲历了腾讯在社交、to B等领域的战役。 对外，汤道生给媒体留下的印象是温和，甚至不时有些幽默感，对内，他曾多次扮演腾讯业务「拓荒者」的角色，擅长把控方向，做取舍、够开放。 大模型端，腾讯混元团队目前的负责人是腾讯集团副总裁、TEG副总裁蒋杰，他在2012年加入腾讯，此前曾在传统IT行业、阿里巴巴分别工作过五年，加入腾讯后，他主要负责大数据平台和广告平台的技术研发。 今年4月，TEG架构升级，成立大语言模型部、多模态模型部等多个部门，均向蒋杰汇报。 蒋杰公开采访并不多，但从其个人文章来看，他是一个擅长将技术回归到业务终局的管理者。他曾在《大模型时代：广告系统的量变与质变》中谈及大模型对广告行业的改变，提到自己对模型的思考： “模型永远无法端到端解决所有问题，投放广告本身不是目的，广告的目的是最后的销售，作为品牌、代理商，则要从关注广告投放的过程中解放出来，更多来思考如何满足消费者的本质需求......从管理过程到管理终局。” 而在应用侧，随着腾讯将元宝并入CSIG，腾讯会议负责人吴祖榕的标签又多了一个——元宝负责人。 吴祖榕毕业于南京大学，2005年毕业加入腾讯，也是一位20年的老腾讯人，2017年，时任增值产品部助理总经理的吴祖榕轮岗到腾讯多媒体视频实验室，参与了腾讯完整的音视频技术栈研发，也为后续他从0到1孵化腾讯会议这一明星产品做了铺垫。 吴祖榕和吴嘉的经历也十分类似——他们都是大厂自家人，一毕业就经历了大厂的锤炼，都在内部作出过成功的明星产品。 迄今为止，阿里成立26年，腾讯成立27年，它们随着中国互联网的发展，形成了自身独特的管理模式和企业文化，这些基因持续影响它们在AI牌桌上的身位，有优势，也有劣势。 阿里和腾讯也互为一面镜子，马云重提阿里的创业文化，马化腾号召每个腾讯人保持「Debug的精神」，两家企业也仍在持续探索AI的新机会。 参考资料： 1、腾讯文化：“在腾讯我们为什么这么看重Debug？” 2、光子星球：阿里AI，“吴妈”的一场服从性测试 3、晚点：字节阿里腾讯的 AI 人才竞赛：2330个究者背后的共识与分歧 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 16704,
      "title": "AI圈水太深:OpenAI保密、Meta作弊!国产MoE却异军突起",
      "time": "2025-07-17T00:00:00+00:00",
      "content": "新智元报道 编辑：KingHZ 【新智元导读】从GPT-2到Llama 4，大模型这几年到底「胖」了多少？从百亿级密集参数到稀疏MoE架构，从闭源霸权到开源反击，Meta、OpenAI、Mistral、DeepSeek……群雄割据，谁能称王？ 从传统稠密架构到如今流行的稀疏专家模型（MoE），语言大模型发展突飞猛进： 最初参数量只有百亿级别，而现在即便仅激活的参数，也已达数百亿！ 从百亿到万亿，参数膨胀的背后，是AI界对Scaling Law的「信仰」。 自2019年GPT-2发布以来，大语言模型（LLM）在参数规模、训练数据量和模型架构上不断实现飞跃。 大模型到底有多大？从2019年到现在，大模型到底经历了什么样的「体重暴涨」？ Github网友rain-1手动总结了基础模型趋势，「不含任何AI生成成分」。他还表示： 近年来，语言模型波澜壮阔，宏大深远。 所记述的不过是其中一个微小片段，如同管中窥豹，可见一斑。 本文旨在客观呈现大语言模型的规模信息。不涉及泄露信息或坊间传闻，仅聚焦基础模型（即原始文本续写引擎，而非ChatBot）。 AI模型参数量呈指数级增长 大模型来时路之GPT系列 OpenAI走向「CloseAI」 主要分为2大阶段：早期密集模型和中期转型与保密期。 早期密集模型（2019-2020）： GPT-2家族：参数从137M到1.61B，训练数据约10B tokens。 GPT-3（175B）：首个真正意义上的「大模型」。 中期转型与保密期（2022-2023）： GPT-3.5和GPT-4：未公布参数或数据规模，信息高度保密。 具体而言，GPT-2（2019年）参数规模： GPT-2-small：1.37亿参数 GPT-2-medium：3.8亿参数 GPT-2-large：8.12亿参数 GPT-2-xl：16.1亿参数 训练数据基于未公开的WebText数据集，约40GB互联网文本，估计约100亿token。 2020年，OpenAI发布GPT-3，代号davinci/davinci-002，参数规模为1750亿（175.0B）。 链接：https://www.lesswrong.com/posts/3duR8CrvcHywrnhLo/how-does-gpt-3-spend-its-175b-parameters 训练数据约4000亿token，来源包括CommonCrawl、WebText2、Books1、Books2和Wikipedia。 具体数据来源信息，参考下列论文。 论文链接:https://arxiv.org/abs/2005.14165 GPT-3训练耗时数月，动用了数万块A100 GPU的数据中心算力。 2022-2023年，GPT-3.5&GPT-4官方未公开架构细节、训练数据规模等信息。 之后。OpenAI一度成为高度保密的「黑箱」。而开源模型，特别是LLaMA家族「水涨船高」： 从7B到65B，其中65B使用1.4T tokens训练； LLaMA 3.1达到405B参数、3.67T tokens数据，是开源领域的一个转折点。 大模型来时路之Llama系列 Llama初代版本规模7B、13B、33B、65B参数。 训练数据方面，官方确认采用了Books3数据集。65B版本预训练使用了1.4万亿（1.4T）token的数据集。 2024年，Meta开源Llama-3.1 405B，参数规模高达4050亿，采用密集Transformer架构（即推理时所有参数均参与计算）。 训练数据方面，Meta未详细披露数据源，仅模糊表述为「来自多种知识来源的混合数据」，共消耗了约3.67万亿token： 初始预训练：2.87万亿token 长上下文训练：8000亿token 退火训练（Annealing）：4000万token 论文链接：https://arxiv.org/abs/2407.21783 他们还有项关键发现： 实验表明，在核心基准测试中，对小规模高质量代码和数学数据进行退火训练（Annealing），可显著提升预训练模型的表现。 但网友本人对当前流行的「Benchmax退火预训练」趋势表示遗憾—— 它使得基础语言模型逐渐偏离了「初心」——纯粹的文本续写引擎定位。 这种优化本该属于后训练阶段（即让模型扮演「AI聊天助手」角色的过程），但企业显然更看重benchmark分数的短期提升。 2025，Meta推出Llama-4系列，其中2万亿参数巨兽「Behemoth」，或永不面世。 Llama4系列中的旗舰大模型Behemoth，是参数总量达2万亿的稀疏专家模型（MoE），架构为A288B 16E——即具备2880亿激活参数、共计16个专家模块，但尚未公开发布 Llama4的Maverick和Scout模型都是从这款大模型中蒸馏而来。然而，围绕这些轻量版本，却爆发了一场丑闻—— Meta（原facebook）被曝在lmarena基准测试平台上「作弊」： 此举被外界视为学术不端，严重打击了外界对Llama团队的信任。此后，，至今不明这款2T模型是否还有问世的可能。 至于已经发布的Llama4小模型，尽管打着「继承大模型精华」的旗号，但目前普遍评价是：智能水平较低，难堪大用。 大模型荒原时代 曾经，AI界一度陷入「大模型荒原」——其他模型无法与GPT-3匹敌。 大家只能反复微调LLaMA等小模型，试图追赶GPT-3留下的庞大身影。 但这种「用AI训练AI」的做法，也让模型性能陷入恶性循环。 Llama 405B模型的发布堪称转折点。在此之前，Mistral发布了2款混合专家模型： 2023年12月，推出Mixtral 8x7B（混合专家模型）。 2024年4月，升级发布Mixtral-8x22B（总参数量141B，实际激活参数39B的稀疏混合专家模型）。 Mixtral-8x22B尽管不是GPT-3那样的密集模型，但总参数量级已与GPT-3（175B）相当。 混合专家MoE架构的革命性在于，它让普通研究者也能训练和使用超大规模的模型——不再需要动用成千上万张GPU组成的计算集群。 2023末，稀疏MoE架构的兴起：Deepseek V3等接踵而来。 在参数总量远超GPT-3的同时，MoE模型激活参数维持在几十B级别，从而降低推理成本。 这些LLM支持多语言、多模态，并采用更大上下文窗口（32K~256K tokens）。有的新模型还采用「退火」式后训练，提升特定基准测试上的表现。 MoE热潮来袭 群雄并起，谁主沉浮？ 2024年圣诞节次日，DeepSeek发布了震撼之作—— V3 Base。官网如此描述： V3新特性 6710亿MoE参数 370亿激活参数 基于14.8万亿高质量token训练 这不仅实现了模型规模的巨大飞跃，衍生的R1推理模型更让业界惊艳—— R1可能是首个真正达到GPT-4水平，而且可自由下载使用的模型。 稀疏的不是能力，是让计算更精准地对焦。 此次突破掀起了MoE大模型的训练热潮，尤其在中国市场。值得注意的是，这些新模型普遍具备多模态、多语言能力，训练数据维度大幅拓展。 代表性模型巡礼： 1. Databricks DBRX（2024年3月） 架构：1320亿总参/360亿激活/12万亿token训练 创新点：采用16选4的细粒度专家系统（相较Mixtral-8x7B的8选2架构更精细） 2. Minimax-Text-01（2025年1月） 架构：4560亿总参/459亿激活 特色：创新性融合注意力机制与MoE架构 质量控制：采用前代60亿参数MoE模型进行数据标注 3. Dots.llm1（2025年6月） 亮点：128选6超细粒度专家系统+2个常驻专家 成就：不使用合成数据即达到Qwen2.5-72B水平 技术：引入QK-Norm注意力层优化 4. 混元（2025年6月） 突破：20万亿token训练/256K上下文窗口 架构：8专家动态激活+1个常驻共享专家 5. 文心4.5（2025年6月） 规模：4240亿总参/470亿激活 特点：多模态基座模型 训练：基于「数万亿」token（具体数据未披露） 尾声 未来在哪里？ 在很长一段时间内，市面上几乎没有与GPT-3规模相同的LLM可供使用。 由于缺乏可下载的同等级模型，人们很难复现GPT-3的性能。 而且坦率地说，人们当时并没有真正意识到：要想要达到GPT-3的表现，模型的规模必须接近1750亿参数。 当时能拿来用的，最多也只是LLaMA系列中参数不超过700亿的模型，大家也只能靠这些凑合着用。 而目前，网友rain所知的最新、最大的可用稠密基础模型有4050亿参数。在预训练中，它使用了更近时段的数据（包括人们讨论大语言模型、分享模型对话记录的内容），而且模型本身也经过「退火」（annealing）处理。 因此相比以往那些基础模型，它更像已经初步具备助手特性的系统。 最近一批稀疏专家模型（MoE）也有类似的问题，并且这些模型在训练数据中还融入了一些中文文化元素。 要怎么公平地比较稀疏模型（MoE）和致密模型，目前还没有明确标准。 也许大语言模型的一些高级能力，只有在模型足够深、结构足够密集时才会显现出来。而现有的自动评测指标，可能并不能很好地捕捉这些能力。所以现在很多人索性一头扎进了MoE模型的研发中。 一些新模型也在尝试采用新的网络架构（比如RWKV、byte-latent、bitnet）或者使用合成数据生成的新方法。 不过，要打造一个优秀的文本生成引擎，目前还不清楚这些新技术到底有多大帮助。 网友rain说得直接：文本生成引擎才是一切的基础。 没有优秀的文本续写能力，后续的微调、角色扮演都只是空中楼阁。 在「助手化」狂潮之外，也许是时候重新思考—— 我们真的理解基础模型的本质了吗？ 参考资料： https://gist.github.com/rain-1/cf0419958250d15893d8873682492c3e 原标题：《AI圈水太深：OpenAI保密、Meta作弊！国产MoE却异军突起》 阅读原文"
    },
    {
      "doc_id": 16708,
      "title": "价格战没完没了:车企“以价换量”背后的生存逻辑与行业洗牌",
      "time": "2024-04-29T00:00:00+00:00",
      "content": "新能源观（ID：xinnengyuanqianzhan）原创 全文2847字，阅读时间8分钟 价格战真是没完没了了。 就在2025上海车展开幕前一天，特斯拉中国宣布了新的价格策略：焕新Model Y首次推出5年0息，6月30日前，首付7.99万元，月供低至约3060元。要知道，焕新Model Y才交付了两个月，且离它推出3年0息政策不足一个月。 蔚来全新品牌萤火虫从14.88万元的发布价降到了11.98万元，相当于打了八折。这对于一辆精品小车来说，幅度不算小。 图/萤火虫降价至11.98万元 来源/互联网 新能源观截图 比亚迪在打出“全民智驾”、兆瓦闪充技术和王朝网旗下汉L和唐L上市的组合拳后，近日对海洋网、王朝网三款车型推出限时一口价活动。其中，宋PLUS DM-i降1.6万元至11.98万元；海豹06 DM-i降1万元至8.98万元；海豹07 DM-i降1万元至12.98万元。 降价最狠的当属合资品牌。比如原价36.98万元的捷豹XFL现在标价18.98万元；去年在25万元左右的奔驰A级车，如今近乎腰斩；1.5T+9AT动力组合的别克君威，从30万元级的豪华轿车定价跌到了10万元出头。 事实上，“价格战”作为全行业常态，并没有减弱，只不过是被智能驾驶的声浪遮挡了一些而已。在这场“没有赢家只有幸存者”的战争中，2025年一季度机械制造行业平均利润率已跌破5%，倒闭离场的车企和品牌接二连三。 车企在利润与生存之间走钢丝，更深层的产业变革正在发生：技术迭代速度超过企业盈利能力的提升速度，政策补贴退坡倒逼车企提前透支市场潜力，消费者对“降价减配”的质疑声日益高涨。 整个行业激烈厮杀、价值扭曲的背后，究竟隐藏着怎样的生存逻辑，又将如何重塑汽车行业的未来格局？ 1.价格战众生相：从“明刀明枪”到”花式内卷” 2025年春节刚过，汽车市场就已硝烟弥漫，各大车企纷纷加入价格战的行列，竞争态势异常激烈。 特斯拉作为全球电动汽车的领军品牌，率先打响了价格战的第一枪。它推出“8000元保险补贴+5年0息”的组合拳，使得Model 3在中国市场补贴后22.75万元起，比美国市场低近30%，5年0息政策更是让月供低至2460元。 图/特斯拉优惠政策 来源/互联网 新能源观截图 这一举措迅速刺激了销量的增长，但也引发了诸多质疑。上海工厂产能利用率跌至70%，库存周期拉长至28天，销售提成大幅下降，只能依靠走量来冲业绩。 尤其是刚刚上市的新款Model Y，交付1个月后就推出了3年0息的优惠策略，紧接着又是1个月，免息3年变5年，优惠力度加大，试图让更多消费者从观望转向下订。 此外，特斯拉在技术上也面临着来自中国对手的挑战，理想的端到端+VLM智能驾驶技术架构、华为ADS 3.0等已部分超越特斯拉FSD，这都让特斯拉的销量号召力骤减，不得不通过价格来换取发展时间。 图/理想端到端+VLM与华为ADS 3.0架构 来源/互联网 新能源观截图 比亚迪则将花式“价格战”演绎到极致。先是以秦PLUS荣耀版7.98万元的低价强势杀入燃油车市场，喊出“电比油低”的口号；再是将“全民智驾”拉低到10万元级以下的车型；然后又推出“一口价”，促销无智驾的车型。 图/秦PLUS低至7.98万元 来源/互联网 新能源观截图 新势力车企同样不甘示弱。小鹏X9推出“0首付+5年0息”组合拳，综合优惠近7万元；蔚来则是5年免息叠加48张换电券。 图/小鹏优惠价格 来源/互联网 新能源观截图 但新势力车企普遍面临着毛利率低、亏损严重的问题。小鹏2024年净亏损扩大至104亿元，蔚来每卖一辆车亏4万余元。资本市场对它们也不乐观，2025年一季度，蔚来、小鹏股价较峰值下跌超80%。 传统车企也深陷价格战泥潭。广汽丰田锋兰达一口价8.98万元，威兰达直降4.4万元，还推出“三大核心部件终身质保”。 图/广汽丰田优惠价格 来源/互联网 新能源观截图 价格战中，合资品牌市场份额已从2020年的60%跌至2025年的不足30%。大众安徽工厂裁员30%，本田关闭武汉二厂，日产将中国产能削减40%。一位日系车企高管坦言，在电动化上慢了两年，每降价1万元，就有200家经销商退网。 2.价格战背后的“生死逻辑” 在“价格战”中消亡的诸多车企也是直观反映了竞争的残酷。 据不完全统计，近5年，已有超过30家车企倒闭或者退出中国市场，而从2014年开启的新势力造车浪潮，60余家新势力如今也仅剩蔚小理和零跑，淘汰率超过九成。如极越、高合、远航和恒驰汽车等，缺席本次上海车展的哪吒汽车，也是风雨飘摇。 有车企退出，当然就有市场余量释放。当前的头部车企，特斯拉、比亚迪、蔚小理合计占据超70%份额，中小车企生存空间被严重挤压。某二线品牌CEO曾直言，降价不是为了赢，只是不想死得太快。 “马太效应”在市场中愈发明显，赢家通吃，比亚迪单月销量突破40万辆，相当于蔚小理全年销量之和。 但即便强如特斯拉和比亚迪，新款车型上市导致的老款车型库存积压也是不得不面临的难题，降价就是释放库存的最好良药。 比如特斯拉在Model Y的改款车型上市前，就对老款Model Y采取了直降1万元、5年0息和可免费选配星空灰的叠加优惠措施。 图/老款Model Y优惠方案 来源/新能源观拍摄 而曾经说出“比亚迪在10-20万区间的车型上有定价权，但比亚迪不会搞的大家都没活路”的比亚迪总裁王传福，还是将智驾卷到了7万元级的海鸥上，将A+级纯电轿车秦L EV的价格定在了10万元级，甚至还在此后推出了几款爆款车型的一口价，不给友商喘息时间。 图/秦L EV指导价 来源/互联网 新能源观截图 当然，补贴政策退坡也是车企价格战的原因之一。众所周知，2026年新能源购置税将减半征收，车企需要在政策红利消失前抢占市场。某车企高管算了一笔账，一辆20万元的车，2025年能省1.8万元税，明年只能省9000元。 地方政府也在推动降价，比如深圳追加10亿元购车补贴，上海对置换新能源车给予1万元“绿色积分”，成都对建充电桩车企每桩补贴2000元。 乘联会秘书长崔东树警告称，2026年后，车企必须学会在“无补贴时代”生存。 3. 未来趋势：价格战之后，行业向何处去？ 毫无疑问，对于车企来说，价格战是一场“杀敌一千自损八百”的“艰难决定”，而且，价格战对于行业、对于车企自身，甚至对于消费者造成的损害逐日剧增。 在今年3月底举办的中国电动汽车百人会论坛上，国家发改委相关负责人就严肃批评了部分车企一系列不当行径。诸如“不惜牺牲利润抢占市场”，大打“价格战”，甚至在宣传领域毫无底线，“虚假宣传、恶意抹黑竞争对手”，种种乱象层出不穷。 图/发改委批评部分车企 来源/互联网 新能源观截图 所以，价格战之后，卷智能驾驶成了众多车企的突破口。小鹏城市NOA普及至20万元车型，比亚迪“天神之眼”剑指L3，华为ADS 3.0实现“车位到车位”全场景。 某车企高管放话：“2025年，无智驾不卖车！” 然而，消费者对智驾功能的接受程度仍有待提高。调研显示，60%用户认为“现有智驾功能华而不实”。智驾普及面临着技术门槛、成本压力和用户教育等问题。L3级事故责任界定不明，车企不敢全面开放；激光雷达单价仍超5000元，下沉市场用户宁愿要“真皮座椅”；某车主开启自动泊车后误踩油门，索赔20万元维修费。 积极寻求海外市场也是国内车企的突破方向。 比亚迪在国际市场也是动作频频，在瑞士推出三款新能源车型，计划2025年底设立15个销售点；奇瑞与西班牙Ebro合资建厂布局南欧市场，越南工厂预计2026年投产；吉利则计划2030年实现海外销量中50%来自本地生产。 此外，小鹏、理想等新势力加速布局中东和欧洲，其中小鹏对于2025年海外销量目标较为乐观。不仅如此，宁德时代在德国、匈牙利建电池工厂；蔚来投资欧洲能源网络降低补能成本；上汽、奇瑞等通过“整车+零部件”联合出海模式，在俄罗斯/中东建立本土化供应链，等等。 图/小鹏汽车进军波兰市场 来源/互联网 新能源观截图 价格战，或许还将继续。那些真正掌握核心技术、构建生态壁垒、敬畏用户价值的企业，才能在这场淘汰赛中幸存下来，定义汽车行业的下一个十年。而那些靠“PPT造车”“资本催熟”的玩家，终将被市场淘汰，成为行业发展史上的过客。"
    },
    {
      "doc_id": 16709,
      "title": "用“O2O式”创作对抗快餐化阅读 内容社区用算法+人文探索大众阅读...",
      "time": "2025-07-23T00:00:00+00:00",
      "content": "封面新闻记者 欧阳宏宇 知乎2025人文季启动，面向全网发起“城市微观纪实创作计划” “人群交汇处，皆是城市篇章”，7月22日，知乎“街巷备忘录—2025城市微观纪实创作计划”正式启动，这也标志着2025知乎人文季的大幕拉开。本次人文季以“可读的城市”为核心主题，知乎与单向空间携手作为联合发起方，为大众带来一场深度对话。整个人文季囊括文学创作计划、线上圆桌、盐沙龙等活动，作家天下霸唱、饶雪漫、“外卖员诗人”王计兵等多位嘉宾深度参与其中，共同挖掘藏在街巷里的文字力量，让城市的故事被看见与被记住。 点评：城市的魅力不在天际线，而在拐角处陌生人的微笑里。知乎将镜头对准菜市场的烟火、胡同斑驳的砖墙与深夜便利店的人影，一场关于城市灵魂的打捞正在展开。以“可读的城市”为锚点，撬动的不只是文学创作，更是一座对抗数字时代情感速朽的堤坝。由此，这一人文季的深层价值，在于用非虚构写作对抗空间的均质化，用文字为即将消逝的城市记忆建档。将纪实在数字碑林上镌刻城市密码。 阿里通义千问宣布更新旗舰版Qwen3模型 阿里通义千问宣布更新旗舰版Qwen3模型，推出Qwen3-235B-A22B-FP8非思考模式（Non-thinking）的更新版本，命名为Qwen3-235B-A22B-Instruct-2507-FP8。本次更新的Qwen3模型，长文本提升到256K。目前，Qwen3新模型已在魔搭社区和HuggingFace上开源更新。 点评：阿里通义千问Qwen3旗舰模型的此次更新直指行业痛点，尤其是2在56K上下文窗口的突破性扩展，让模型处理超长文档、复杂代码库或多轮深度对话的能力跃上新台阶，直逼全球顶级大模型的长文本处理水平。时下，中国大模型正从参数竞赛转向实用性与场景深度的精耕。技术突破的号角已经吹响，下一步，就看开发者如何创造属于智能时代的全新可能了。 QQ浏览器25高考季数据报告发布，人工智能首次进入热门专业前十 7月22日，QQ浏览器联合腾讯新闻，聚焦AI时代下的志愿新选择，发布《25高考季数据报告》（以下简称“报告”）。报告显示，2025年高考期间，工学专业热度断层领先，人工智能专业首次进入热门专业前十，AI志愿填报高居搜索热度第二，智能择校成时代趋势。 点评：QQ浏览器这份报告揭示的不仅是专业选择的变迁，更是智能时代对人才结构的重塑。从\"热门专业风向标\"到\"智能择校工具普及\"，这场静默变革背后，是青年一代主动拥抱AI浪潮，将个人发展锚定技术前沿；教育体系则借力算法优化决策路径，用智能工具弥合信息鸿沟，共同决定了AI既成为教育选择的工具，又成为教育目标本身。 星巴克中国回应广东部分门店新推“星子自习室” 7月22日，针对广东部分星巴克门店新推“星子自习室”一事，星巴克中国发文回应称，希望门店空间在炎炎夏日给消费者提供一个“自习”的去处；未来在更多门店也准备尝试更多的“兴趣向”空间和活动。 点评：在咖啡馆里铺开书本的年轻人，正在用行动重新定义\"第三空间\"的价值内涵。星巴克的自习室实验则似一面多棱镜，既照见企业社会责任与商业创新的交融，折射城市公共服务缺位的现实，更映出年轻世代对多功能生活场景的渴求。未来商业体的胜负手，或许就藏在能容纳多少种兴趣空间的答案里。 举报/反馈"
    },
    {
      "doc_id": 16715,
      "title": "重拳整治!国家多次要求严厉打击这些“内卷”乱象,一些动作已展开",
      "time": "2024-06-19T00:00:00+00:00",
      "content": "撰文丨余晖 国家层面，正大力促进平台经济健康发展。 6月15日至17日，中共中央政治局委员、国务院副总理张国清在广东调研了“促进平台经济健康发展”工作。 张国清再度对“规则”和“监管”提出了要求： 加快完善平台规则、算法、收费、直播电商等方面法律法规。 健全平台经济常态化监管制度，强化监管执法，严厉打击虚假宣传、劣质低价、刷单抢单等“内卷”乱象，依法查处不合理收费抽佣、不公平分配流量等滥用市场支配地位行为，规范竞争秩序，促进平台经济健康发展。 平台经济是以互联网为平台，提供各类生产生活服务的经济活动总称，是经济发展新动能新形态，是新质生产力的重要代表和载体，在赋能实体经济、做强国内大循环、促进创新发展、就业创业等方面，平台经济都发挥了重要作用。 涉及数千万网络经营主体、众多灵活就业人员、9亿多网络消费者的平台经济，已经成为了一个覆盖面广、包容性强、开放度高的生态系统。 但高速发展的同时，平台经济也存在不少问题。 比如，在平台收费方面，不少平台商户反映，由于名目繁多，计算方法复杂，平台收费不透明，加上平台营销推广费用上涨快等因素，加重了商户的成本负担。 再比如，在直播电商方面，也存在良莠不齐、鱼龙混杂的问题，不少消费者反映，部分主播恶意炒作、搞虚假营销，假冒伪劣产品现象比较突出。 总体来看，我国平台经济监管模式和治理体系，与平台经济自身特征还没有完全匹配。 国家的态度很明确，一手促发展，一手抓监管。而抓监管的最终落脚点，也是为了促进平台经济健康发展。 二十届三中全会提到，促进平台经济创新发展，健全平台经济常态化监管制度；2024年11月，国务院总理李强主持召开国务院常务会议，研究推动平台经济健康发展有关工作，要求“规范市场竞争秩序，健全常态化监管制度”“切实保障消费者和劳动者合法权益”。 近期，张国清至少三度就平台经济健康发展进行了调研。 3月，张国清到有关平台企业调研“促进平台经济健康发展和市场监管”等工作。5月，张国清在上海市调研“促进平台经济健康发展和市场监管”有关工作；6月，张国清在广东调研了“促进平台经济健康发展”等工作。 任何调研的目的，都是为了摸清实际，之后改进工作、解决问题、推广经验。 副总理三次调研，足迹涉及各个类型的平台企业，有外卖送餐、网络零售、直播电商、交通出行，也有互联网货运平台企业。这些平台企业，有的直接面对消费者，也有的面向企业用户。但有一个共同点，就是他们在促进平台经济健康发展方面，发挥着重要作用。 上述几次调研，还有一个共同点——均对规则和监管提出了明确要求。 比如，“加快完善平台规则、算法、收费、直播电商等相关法律法规”“坚决整治低质低价‘内卷式’竞争、不合理设置配送时限、不合理收费抽佣等问题，严厉打击假冒伪劣、虚假宣传、虚构优惠、虚假比价、流量炒作等行为”“对恶意比价、虚假宣传、刷单炒作等违法违规行为及时采取限流、停播、封号、纳入黑名单等措施，重拳整治各种乱象”等。 事实上，一些动作已经展开。 5月25日，市场监管总局发布《网络交易平台收费行为合规指南（征求意见稿）》，主要内容包括明确平台收费要遵循的原则、倡导降低平台内经营者负担、强化平台合规自律、规范平台收费行为、加强监督与实施等。 近日，市场监管总局正式批准组建“全国平台经济治理标准化技术委员会”。 据悉，全国平台经济治理标准化技术委员会将针对目前“内卷式”竞争、直播电商乱象等平台经济治理中的突出问题和关键环节，广泛吸纳平台企业、平台内经营者、平台从业人员、优质商贸企业、政府部门、科研院所、行业组织、消费者等多方参与，加快急需标准研制，以统一标准引导行业自律、支撑行业监管。 欢迎下载“北京青年报”客户端 举报/反馈"
    },
    {
      "doc_id": 16721,
      "title": "已处罚3家大型网站平台!官方发声:进一步强化整治!",
      "time": "2024-05-27T00:00:00+00:00",
      "content": "近日，中央网信办专门印发通知，从阻断“开盒”信息传播、完善预警机制、加大惩治力度、优化保护措施、加强宣传引导等多个维度明确工作要求，督促各地网信部门、各网站平台进一步强化“开盒”问题整治工作。同时，召开专题部署会议，要求微博、腾讯、抖音、快手、百度、小红书、知乎、哔哩哔哩、豆瓣等多家重点网站平台，对照通知抓好各项任务落实，切实履行主体责任，以“零容忍”态度坚决打击“开盒”乱象。 中央网信办有关负责同志表示，“开盒”问题直接关系人民群众切身利益，近段时间以来，网信部门结合职责，深入开展整治工作，全面清理各类涉“开盒”违法违规信息，从严处置传播相关内容的账号和群组，依法按程序处罚3家大型网站平台，组织重点网站平台定期发布治理公告，公布典型案例，并向公安机关通报违法犯罪线索。 中央网信办有关负责同志强调，利用“开盒”等方式非法获取并公开他人个人信息，涉嫌违法犯罪，性质极为恶劣。下一步，中央网信办将继续坚持高强度打击和高力度保护并重，着力做好“开盒”问题整治工作。 一是全力阻断传播渠道。督促网站平台深入清理各类违法发布个人信息，诱导网民跟进泄露隐私，借机进行攻击谩骂、嘲讽贬低的内容，清理教授、买卖或者提供“开盒”方法、教程和服务等信息内容，对于组织煽动“开盒”、提供“开盒”服务等账号、群组，一律予以关闭或者解散。 二是升级完善保护措施。指导网站平台在前期治理网络暴力的基础上，进一步升级完善防护措施，加大“开盒”风险提示力度，设置涉“开盒”举报快速入口，及时核实网民投诉举报，最大限度帮助网民防范和处置“开盒”问题风险。 三是加大打击惩治力度。结合个人信息保护系列专项行动，深入治理违法违规收集使用个人信息等问题，会同有关部门严厉打击泄露、盗取、贩卖个人信息，以及利用个人信息开展违法犯罪活动等行为。此外，也希望广大网民提高防“开盒”意识，强化个人信息保护，自觉抵制相关行为，共同营造清朗有序的网络空间。 何谓“开盒”？ “开盒”是一种新式网络暴力违法犯罪行为。不法分子通过非法手段进行网络搜索、挖掘，搜集个人隐私信息，包括姓名、个人照片、身份证号、家庭住址、手机号码、社交账号等，将这些内容在网络公开发布。 被“开盒”人往往会遭遇网民的侮辱谩骂、造谣诋毁，甚至在现实生活中也会遭到骚扰，如电话、短信等遭陌生人轮番“轰炸”。 来源/中国网信网 监制/韩霁 原标题：《已处罚3家大型网站平台！官方发声：进一步强化整治！》 阅读原文"
    },
    {
      "doc_id": 16748,
      "title": "不靠价格战,豆包大模型靠技术杀出重围",
      "time": "2024-06-12T00:00:00+00:00",
      "content": "6月11日，字节跳动旗下火山引擎举办Force原动力大会，发布豆包大模型1.6、视频生成模型Seedance 1.0 pro等新模型，并升级了Agent开发平台等AI云原生服务。 过去两年多，AI从生成式智能，正加速迈向“能自主执行”的Agent 智能。顺着这一大势，全球研发方向出现明显收敛：视频生成正成为生成式 AI 的新高地，高品质文生视频模型不断涌现；AI 编程被视为生产力“第二曲线”。 字节跳动旗下火山引擎最新发布的系列产品正对准这两条主线：Seedance1.0负责视频生成，可一键产出 1080P 多镜头短片；豆包 1.6及TRAE 则把 AI写代码嵌进工程流程，字节跳动内部已有80%以上工程师使用。火山引擎正在为即将到来的Agentic AI时代打下技术与场景的双重基础。 据火山引擎披露，豆包大模型日均tokens使用量超过16.4万亿，较去年5月首次发布时增长137倍。另据IDC报告，豆包大模型在中国公有云大模型市场份额排名第一，占比达46.4%。高强度的实际使用，反映出模型的成熟稳定和用户的认可，也反哺模型效果持续优化。 字节跳动CEO梁汝波以视频形式致辞表示：“字节跳动致力成为优秀的创新科技公司，会坚定长期投入，追求智能突破，服务产业应用。通过火山引擎，持续把新模型、新技术开放给企业客户。”这一表态阐释了公司从上而下的战略定力，让科技创新创造更长远的价值。 目前，豆包大模型已涵盖多模态、视频、图像、语音、音乐等模型品类，全方位推进智能提升和应用落地。在行业应用上，豆包大模型服务着全球TOP10手机厂商中的9家、8成主流汽车品牌、70%的系统重要性银行及超5成985高校。 火山引擎总裁谭待告诉参会的各媒体们：“我们的营收里，与大模型相关的业务增长最快，毛利也是最好的之一。” 豆包1.6与Seedance：Agent时代的模型底座 作为字节跳动自研的大模型，豆包大模型在短短一年内快速迭代，最新发布的豆包1.6系列已全面迈入全球第一梯队。在复杂推理、数学竞赛、多轮对话、指令遵循等权威评测中，豆包1.6-thinking（深度思考版本）表现跻身全球前列。 据谭待介绍，豆包1.6支持多模态理解和图形界面操作能力，能够理解图像等非文本信息，并模拟人类操作电脑界面完成任务。 例如，在现场演示中，豆包1.6可以自动操作浏览器预订酒店、读取购物小票并整理为Excel表格等，实现从“认知”到“行动”的飞跃。这意味着豆包不仅能对话答疑，还具备了初步的工具使用和执行能力，行动力显著增强为构建自主Agent提供了强大模型支撑。 豆包视频生成模型Seedance 1.0 pro是火山引擎同期发布的另一大亮点。该模型支持文字与图片输入，可生成多镜头无缝切换的1080P高品质视频，画面自然流畅，主体运动稳定。 在国际权威评测榜单Artificial Analysis上，Seedance在文本生成视频和图生成视频两项任务上均排名全球第一，这标志字节跳动在视频生成领域已跻身全球前沿。至此，豆包大模型家族覆盖了通用多模态、视频、图像、语音、音乐等模型品类，全面推进智能能力提升与应用落地。 在AI Agent快速发展的当下，规模化落地面临多重挑战。根据行业观察，企业级Agent的实际应用成本压力尤为突出——单个Agent每日token消耗成本可达20美元，高成本成为企业投入Agent开发和应用的一个阻碍。 值得一提的是，高性价比成为豆包1.6的一大竞争优势。谭待强调，要推动Agent大规模应用，模型每次执行消耗大量Token，使用成本必须降下来。 豆包1.6首创按“输入长度”区间定价，深度思考、多模态能力与基础语言模型统一价格。在企业使用量最大的0-32K输入区间，豆包1.6的输入价格为0.8元/百万tokens、输出8元/百万tokens，综合成本只有豆包1.5深度思考模型或DeepSeek R1的三分之一。Seedance 1.0 pro模型每千 tokens仅0.015元，每生成一条5秒的1080P视频只需3.67元，为行业最低。 谭待表示， 除了整体Tokens规模的迅猛增长，新的应用场景正在不断被解锁。以今年 5 月份火山引擎的 Tokens消耗构成为例，较去年 12 月的数据有明显跃升：深度推理模型的推出，带动了 AI工具的Tokens 消耗在5 个月内增长了 4.4 倍。 其中，AI 搜索的调用量增长了 10 倍，AI 编程的增长幅度也达到 8.4 倍。同时，智能巡检、视频检索等新兴场景也快速突破了日均百亿 Tokens级别的调用量，显示出多模态深度推理在各行各业的加速落地。这意味着在行业里，大模型的应用也在不断深化。 在消费电子行业，企业将大模型应用在语音助手，创作工具，效率提升等诸多场景，全球Top10手机厂商有9家和火山引擎深度合作； 在汽车行业，大模型覆盖了从智能座舱，到智能营销，到自动驾驶标注等全流程场景。在刚过去的上海车展，豆包大模型是被最多提及的名词，助力八成主流汽车AI升级； 在金融行业，火山引擎为客户提供智能展业、投顾、投研等大模型应用方案，已服务华泰证券、国信证券等数十家券商和基金公司，招商银行、浦发、民生等70%的系统重要性银行； 在教育行业，火山引擎面向教学服务、科研辅助、师生服务和管理辅助等场景，提供大模型解决方案，已与北京大学、浙江大学、南开大学等超五成985高校达成合作，持续推动高等教育智能化转型。 高性价比背后的成本逻辑：技术成熟胜于价格战 当火山引擎把豆包1.6的价格大幅下调时，业界一度猜测这是否预示着一场云服务商之间的价格战。毕竟，在云计算乃至AI服务领域，行业龙头通过降价抢占市场的案例并不鲜见。去年豆包 1.0 发布时，把价格下调了99%，引发了广泛的讨论。 实际上，去年以来技术、软件和硬件都在持续进步，此次火山引擎的价格下调更像是凭借技术进步实现成本优化的自然结果，而竞争的手段。Agent复杂度更高，深度思考和多模态能力是必需，但这意味着更高的推理成本。为此，火山引擎在模型和商业模式上做了三点优化： 首先，豆包大模型1.6降价建立在统一定价的新模式之上。以往，大模型的高级功能（如长上下文、深度思考、多模态）往往按功能分级定价，企业使用成本居高不下。 火山引擎创新性地取消了这些“附加费”，直接做统一定价，免去区别带来的复杂和成本负担。也就是说，客户不再为高阶AI能力额外买单，人人都用得起“全功能版”的大模型服务。 这种策略背后是一系列技术攻关：通过模型架构改进和推理优化，字节跳动团队成功将模型推理所需的算力代价降低到可接受范围，使其能以标准配置开放。当技术瓶颈被突破，服务成本下降，价格下调就水到渠成。 其次，豆包模型降价得以实施还有赖于规模效应摊薄成本。前文提及，豆包模型日调用量已逾16万亿Token，在金融、汽车、互联网等各行业大规模实战。海量的使用为模型迭代提供了宝贵经验，也让字节跳动能够优化算力部署和调度，实现单次调用的边际成本递减。 谭待也指出，每个Agent任务耗费的Token非常可观，只有成本降下来，Agent应用才能铺开。显然，字节跳动选择在豆包1.6阶段推出区间定价模式，正是因为模型和基础设施已经达到足够成熟的经济规模，降低价格不仅不会亏损，反而能激发更大量的使用，从而形成良性循环。 反观传统的“价格战”，往往是以亏损换市场份额，不具备可持续性。而火山引擎此举是在确保自身技术和运营足以支撑低价高质服务的前提下进行的。豆包1.6发布会上宣布降价，伴随的是模型性能的大幅提升以及产品形态的丰富完善（如多模态、Agent支持等）。 这传递出一个清晰信号：高性价比是技术成熟度的体现，而非简单的价格竞争手段。对于企业客户而言，这样的降价是健康的、可持续的，因为他们享受到的是更高效且更实惠的AI能力；对于行业而言，这有助于加速AI的普及和落地，而不会因为低价而牺牲服务质量或压垮供应商。 豆包模型落地案例：联想、飞书、瑞幸、百胜中国、顺丰的实践 大模型只有与行业场景深度结合，才能真正释放价值。字节跳动旗下火山引擎，已在企业办公、零售消费、餐饮、终端设备等多个领域积累了标杆案例，展现了模型能力的产业落地与跨行业渗透力。 联想集团执行副总裁兼中国区总裁刘军表示：“这是联想与火山引擎发挥各自领域技术优势的一次全新尝试，对混合式AI安全架构的搭建具有里程碑意义。我们希望与火山引擎继续深入合作，将安全方案拓展到更多AI终端、AI 基础设施和AI解决方案与服务，为中国消费者和中国企业打造安全可信的AI新未来，助力中国AI产业在全球实现弯道超车。” 在办公领域，飞书率先上新知识问答功能，受到了众多企业的欢迎。知识问答基于豆包大模型构建，融合外部与企业专属知识，并严格遵循知识权限，精准回答业务问题。目前，飞书知识问答已在安克创新、地平线等企业落地。 在零售消费场景中，瑞幸咖啡携手火山引擎推出AI智能点单助手“Lucky”。用户只需动动嘴，比如说出“老样子，再来一单”，AI智能体就会基于用户历史订单精准推荐并快速下单。AI点单在高峰期也能保障流畅体验，离不开豆包大模型准确的意图识别与语义理解能力，以及火山引擎的算力支持和性能优化。瑞幸计划继续升级这一智能体，探索更多AI服务可能，成为新消费领域“科技赋能”的样板。 在物流领域，顺丰基于豆包大模型和HiAgent智能体开发平台，能够帮助业务同学将通用知识和顺丰的专业知识进行融合，并通过零代码、低代码的方式打造每个人专属的AI办公助理。 在餐饮行业方面，百胜中国（肯德基、必胜客母公司）携手火山引擎，打造了专有云平台“百胜云”。借助火山引擎的弹性容器云，百胜中国在业务高低峰灵活调度IT资源，实现降本增效。更重要的是，百胜将豆包大模型引入智能客服、员工培训等场景：AI客服可自动回应顾客咨询，AI培训助手能基于专属知识库回答员工问题，显著提升服务效率，降低人力成本。 在智能终端领域，联想集团与火山引擎深度合作，将豆包大模型集成到AI桌面助手“如意”中，实现从简单系统工具到智能对话助手的飞跃。升级后的如意，具备AI搜索、AI写作、AI聊天三大功能：既可个性化搜索和智能问答，也能快速生成营销文案、专业报告，极大提升创作和交互体验。 这些多维度的合作案例充分展现了火山引擎豆包大模型的产业落地力：从知识工作场景的智能化，消费者服务的个性化，到行业后台的运营升级以及智能终端的体验革新，AI不再是概念，而是推动产业高效转型的关键引擎。 字节跳动通过火山引擎，正在用大模型和AI云服务打破传统边界，让AI真正服务产业创新、助力企业实现更具竞争力的智能化升级。 字节跳动全力投入科技创新 在此次豆包大模型发布中，火山引擎总裁谭待和字节跳动技术副总裁洪定坤发表了演讲，展现出对技术长期演进的理性判断与愿景。 谭待提出，AI时代技术范式与底层架构都在重塑，企业需要拥抱Agent智能体的全新形态：“PC时代的主体是Web，移动时代是App，AI时代则是Agent。”这意味着火山引擎未来将围绕Agent形态，持续演进豆包模型和AI云原生平台，支持企业将智能体融入日常业务流程，实现规模化应用。 洪定坤则更专注于开发者视角，认为大模型有潜力成为软件生产的调度核心，帮助企业调用不同Agent和工具，重塑开发模式，大幅降低门槛，提升效率。他透露，豆包1.6在编程能力上有显著进步，已接入AI编程助手TRAE进行内侧，并将很快对外开放，意味着AI写代码等能力将加速普惠到更广泛的开发群体。 无论是梁汝波倡导的长期投入，还是谭待、洪定坤的技术解读，都指向字节跳动正在努力成为更优秀的创新科技公司。 行业人士分析，唯有掌握大模型等关键技术，持续投入并服务产业，字节才能在AI时代延续增长动能。 市场反馈也初步印证了这一战略的可行性：豆包模型推出一年，迅速占据中国公有云大模型近半市场份额；在飞书、瑞幸、百胜中国、联想等企业场景中，已经见证了大模型与企业智能化的深度融合。 火山引擎的实践还表明，字节跳动的AI布局不仅仅是商业化，更是一种与全社会共享技术红利的尝试。 在技术层面，豆包大模型以高性能、低成本、强适配和安全可信为基础，满足了各行业对AI的多样化、个性化需求；在理念层面，管理层坚持以技术创新降低成本、强调安全合规，展现出兼顾商业成功与社会责任的平衡取向。 可以说，字节跳动进入AI产业化赛道，并非偶然，而是长期在算法、数据、算力领域积累的自然延伸。或许在不久的将来，在Agentic AI加速到来的未来几年，火山引擎将成为字节跳动连接产业的关键纽带，一个又一个行业智能化升级的故事会在其平台上演。 届时，当人们提起字节跳动，也许不再仅仅想到抖音的流量奇迹，而会更多谈论起这家公司的技术创新、生态构建和产业贡献。 在全球范围内，Agentic AI 已被视为智能化浪潮的下一个“拐点”，也是产业数字化转型的新引擎。 随着字节跳动等企业不断夯实大模型基础设施、提升多模态理解与工具调用的深度，AI 智能体正在从实验室走向企业前台，成为可落地的生产力工具。对产业而言，这意味着生产力工具不再只是“人手延伸”，而将成为企业智能化的核心驱动器； 对字节跳动而言，这是一条更宽阔、也更具想象力的增长曲线。未来，Agentic AI 的真正价值将不仅体现在效率提升，更在于深度改造企业流程和重塑行业格局——这场变革的脚步，已经悄然开始。 周悦/文 举报/反馈"
    },
    {
      "doc_id": 16750,
      "title": "豆包1.6登顶全球第一梯队,火山引擎如何用“成本革命”点燃企业AI...",
      "time": "2024-06-12T00:00:00+00:00",
      "content": "【亿邦原创】“真正的技术竞争力，是让客户用更低成本触摸未来。”在6月11日火山引擎Force原动力大会现场，字节跳动CEO梁汝波通过现场视频形式，为火山引擎的AI战略写下注脚。 面对AI大模型带来的技术变革，这家以“技术战争密”为生命线的科技公司，正通过火山引擎向全球企业递出通往智能时代的船票。 当日，火山引擎发布豆包大模型1.6、视频生成模型Seedance 1.0 pro等新模型，并升级了Agent开发平台等AI云原生服务。 01 全场景模型矩阵重构生产力边界 “豆包大模型已跻身全球第一梯队，但我们的目标是让AI成为产业变革的调度者。”火山引擎总裁谭待在演讲中展示的成绩单印证着梁汝波的“野心”——豆包1.6模型在复杂推理、数学运算等核心指标上突破全球天花板，更关键的是，其多模态能力正从“感知”迈向“行动”。 亿邦动力在现场看到，在演示视频中，豆包1.6自主操作浏览器完成酒店预订、将购物小票转化为Excel表格，展现出Agent（智能体）的雏形——这标志着AI从工具进化为能自主规划的执行者。 事实上，技术突破的触角已延伸至产业深处，Seedance 1.0 pro视频生成模型以1080P画质、多镜头无缝切换技术登顶国际评测榜，正在重塑电商展示、影视制作等场景；语音大模型实现方言演绎与播客级对话，让智能交互更具温度。 数据显示，豆包日均tokens使用量已达16.4万亿，服务着全球90%头部手机厂商、80%主流车企及70%系统重要性银行，印证着“技术必须经市场检验”的承诺。 02 用“技术红利”点燃规模化应用引擎 “AI的马拉松刚跑完前500米，要让更多企业穿上跑鞋。”谭待现场揭晓的定价策略引发行业震动——豆包1.6首创按输入长度区间定价，0-32K输入区间价格低至0.8元/百万tokens，综合成本仅为前代模型的三分之一；Seedance 1.0 pro生成5秒高清视频仅需3.67元，创下行业新低。 实际上，这种“技术普惠”逻辑背后，是火山引擎对AI开发范式的重构——通过MCP服务、PromptPilot工具链、AI知识管理系统等全栈升级，企业开发Agent的成本门槛被压缩80%。 在字节跳动内部，这种技术红利已转化为生产力革命；AI编程助手TRAE月活突破百万，80%工程师借助豆包1.6提升研发效率。 “当模型能力成为新时代的APP，我们的使命是让每个企业都能低门槛构建自己的Agent生态。”字节跳动技术副总裁洪定坤透露，火山引擎正与吉利汽车等企业共建工业仿真平台，AI调度者的身影开始出现在研发、营销、服务等全价值链环节。 从实验室到生产线，从参数竞赛到场景深耕，火山引擎用五年时间验证了梁汝波的信念：“被市场信任的科技，才是真正改变世界的力量。” 当AI大模型进入万企竞发的新赛道，这场关于技术普惠与商业创新的双向奔赴，或许比模型参数本身更值得期待。 亿邦持续追踪报道该情报，如想了解更多与本文相关信息，请扫码关注作者微信。 举报/反馈"
    },
    {
      "doc_id": 16759,
      "title": "李开复:中美大模型竞争关键在于开源与闭源之争",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "来源：格隆汇APP 近日，2025格隆汇·中期策略峰会在深圳南山香格里拉酒店举行。 零一万物CEO、创新工场董事长李开复博士带来了《生成式AI：从ChatBot到Agent 的跃进与机会》的主题演讲。 李开复在演讲中指出，未来5到10年最重要的技术领域就是生成式AI驱动的AI 2.0，如不能及时接纳AI未来会被淘汰。 相比于PC时代、移动互联网时代，AI 2.0时代全球GDP会迎来更大幅度的增长。 中美之争不是OpenAI和DeepSeek谁强，而是开源与闭源之争。 英伟达依然是一个比较稳妥的投资标的，但需寻找合适的买入时机。美国科技巨头股票“七选一”，可能会选择微软。 01 预训练Scaling Law失效 推理Scaling Law成为模型智能增长新范式 生成式AI驱动的AI 2.0是有史以来最伟大的技术革命和平台革命，未来5到10年，AI 2.0将快速走出实验室，赋能千行百业，创造巨大的经济价值。 过去两年大模型赛道的一个重要趋势是，大模型的智能在以每年30个点的速度快速提升，同时，AI的推理成本也在以每年降低10倍的速度快速下降，应用层发展的成本担忧也在逐步解决。这些重要的变化为AI-First应用的爆发，穿透千行百业奠定了坚实的基础。 现阶段，预训练的Scaling Law基本已经结束了。其中一个原因在于，超大规模的GPU集群越来越不好管理。举例来说，从一张GPU到10张GPU，可能会得到9.5倍算力提升；但是从1万张GPU到10万张GPU，算力可能只有2倍的提升。另一个原因则是可用于模型训练的数据也存在瓶颈，缺乏高质量数据，GPU烧起来也是事倍功半的结果。 新的机会在推理阶段的Scaling Law。在推理阶段Scaling Law的加持下，大模型的智力不但没有停止成长，而且还会成长得更快。 DeepSeek令人佩服的其中一点就在于，它破解并开源了慢思考推理模型，并且得到了媲美顶级闭源模型的优秀性能。 02 中国在开源模型路径上开始赶超美国 李开复在策略会中指出，美国的前沿技术研究是领先中国的，但是中国吸收消化技术快速迭代的能力很强，中国工程能力也处于世界第一梯队，更可贵的是，中国的创业者很有拼劲，目前看，世界大模型竞赛中只有中美两国，没有第三方。 美国还有一个新的优势，就是无论是企业（2B）还是消费者（2C），其付费能力都很强，这个中国还赶不上。 然而，中国也有新的优势，就是开源。 中美之间的竞争关键并不是OpenAI与DeepSeek孰强孰弱，也不是Deepseek追不追得上OpenAI，而是开源与闭源的路线之争。 中国两大模型都选择了开源路线，而美国最好的模型仍在闭源。如果按照这种趋势，美国可能会输。 开源是中国团队做出的正确决定。阿里巴巴Qwen和DeepSeek的顶级开源模型让中国优秀大模型能进一步普惠全球，未来一定会在全球大模型创新生态中带来巨大的红利。 03 英伟达仍是一个比较稳妥的投资标的 关于投资标的，李开复表示依然看好英伟达。 无论是模型预训练领域、无人驾驶等等，这些领域都离不开英伟达的芯片和技术支持，所以英伟达的价值还是很大的。 未来一段时间，英伟达股价也许不会涨几十倍，但仍有上升空间，是一个比较稳妥的投资。 但是，英伟达在未来可能会面临各种利好和利空因素，例如，最新芯片是否能进入中国市场的潜在风险等，这可能会对公司的股价产生相当大的影响。投资者要综合考虑，理性投资。 在美国七巨头中，李开复坦言自己更看好微软。 因为微软敢于大胆投资和创新，有发展前景，同时对商业模式有着深刻的理解，能够清楚地认识到如何实现盈利，这种兼具多种优势的公司很少。微软对于大模型的盈利模式就有着清晰的认知。 但是微软的体量很大，未来实现几十或上百倍的增长可能性较低。尽管如此，如果美国七巨头里面只选一家投资，李开复可能会选择微软。 举报/反馈"
    },
    {
      "doc_id": 16762,
      "title": "顶级模型性能差距正在缩小中美模型质量差距降至0.3%",
      "time": "2024-04-10T00:00:00+00:00",
      "content": "本报讯 近日，Nature杂志发文称，斯坦福大学以人为本人工智能研究所发布的《2025年人工智能指数报告》显示，人工智能领域的竞争日益激烈：中国高性能AI模型的数量和质量不断提升，对美国的领先地位构成威胁，顶级模型之间的性能差距正在缩小。美国此前在模型质量方面的领先优势已经消失。中国是人工智能出版物和专利产出最多的国家，如今其开发的模型在性能上已经与美国不相上下。2023年，在大规模多任务语言理解测试（MMLU）中，中国领先的模型落后美国顶级模型近20个百分点。然而，到2024年底，与美国的差距缩小到了0.3个百分点。 （达涌）"
    },
    {
      "doc_id": 16765,
      "title": "图数室丨DeepSeek让中美AI差距缩小了吗?",
      "time": "2024-02-08T00:00:00+00:00",
      "content": "来源：图数室 2025年春节期间，国产AI大模型DeepSeek以“低成本+开源”模式掀起全球性科技浪潮，不仅以日活用户突破2000万、登顶全球140国应用商店榜首的成绩刷新行业纪录，更在技术路径、资本市场和社会应用层面引发多重震荡。 DeepSeek的技术成果被认为是中国AI行业的一次重大突破，标志着中国在全球AI领域从“跟随者”向“创新者”的转变。DeepSeek到底有多强？高薪招兵买马的背后，人工智能专业还是香饽饽吗？ 当地时间2025年1月27日，美国股市开盘后出现大幅下跌，其中科技板块受到的冲击尤为严重。美国芯片巨头英伟达(NVIDIA)股价历史性暴跌，一度下跌近17%。英伟达市值一日内蒸发近6000亿美元，创下美股单日市值损失的历史纪录。 市场分析指出，这一现象的核心原因是来自中国的人工智能初创公司DeepSeek的最新技术突破，其发展势头对美国科技行业的传统优势地位构成了挑战。 DeepSeek对股市的“冲击波”延续至春节后A股市场。在蛇年首个交易日，DeepSeek概念股表现异常抢眼，多支相关股票强势上涨，成为春节之后的首个亮点。 根据腾讯自选股数据显示，截至收盘，飞利信、拓尔思、每日互动、竞业达等多支股票纷纷涨停，市场资金对这些股票的追捧热情高涨。此外，其他与人工智能、大数据、云计算等相关的概念股也表现活跃，市场情绪明显升温。 这股“来自东方的神秘力量”，正在打破美对AI话语权垄断，搅动着科技圈。 根据移动应用分析机构Sensor Tower的研究，自1月28日以来，DeepSeek在谷歌母公司Alphabet的Android Play Store美国区的下载量一直位居榜首。数据显示，这款应用在短短18天内的下载量达到了1600万次，几乎是OpenAI的ChatGPT首次发布时900万次下载量的两倍。 狂飙之下的DeepSeek，也引发了多国对数据安全和技术风险的担忧。多个国家陆续发出“禁令”，禁止/屏蔽DeepSeek。 1月20日，DeepSeek正式发布了开源强推理模型DeepSeek-R1，该模型在性能上对标OpenAI-o1正式版，在成本上却有显著优势。 DeepSeek官方文章显示，DeepSeek-R1在AIME2024（美国数学邀请赛）上以79.8%的成绩，高于OpenAI-o1-1217的79.2%。 在MATH-500（不同难度的竞赛数学问题的基准）上，它获得了97.3%的惊人成绩，表现与OpenAI-o1-1217相当，并明显优于其他模型。 在编码相关的任务中，DeepSeek-R1在代码竞赛任务中表现出专家水平，在Codeforces（在线编程竞赛平台）上获得了2029 Elo评级，在竞赛中表现优于96.3%的人类参与者。 对于工程相关的任务，DeepSeek-R1的表现略优于OpenAI-o1-1217。 最新面世的DeepSeek-R1，API服务定价为每百万输入tokens 1元（缓存命中）/4元（缓存未命中），每百万输出tokens 16元，输出API价格仅仅只有OpenAI o1的3%。 这意味着DeepSeek-R1在成本上更具优势，对于开发者来说，使用DeepSeek-R1的成本会更低。 这不是DeepSeek第一次举起“价格屠刀”。 在去年5月，DeepSeek已经带着开源第二代MoE大模型DeepSeek-V2，顶着“价格屠夫”、“AI界拼多多”的称号一炮而红——性能比肩GPT-4，但定价上每百万token输入0.14美元（约合人民币1元）、输出0.28美元（32K上下文，约合人民币2元），仅是GPT-4的近百分之一的水平。 DeepSeek是怎么做到的？在大模型 API 的使用场景中，用户的输入有相当比例是重复的。基于此，DeepSeek 启用上下文硬盘缓存技术，把预计未来会重复使用的内容，缓存在分布式的硬盘阵列中。如果输入存在重复，则重复的部分只需要从缓存读取，无需计算。该技术不仅降低服务的延迟，还大幅削减最终的使用成本。 专业人士表示，大模型定价的持续走低有望带来更快的商业化落地，进而会衍生出更多的微调及推理等需求，将逐步盘活国内AI应用及国产算力发展。 从国内整体大环境来看，2024年，国内大模型能力进步显著，研发能力不断增强。多家AI模型也凭借有限资源在竞争中占据了一席之地。 不仅仅是DeepSeek一家，比如，李开复的初创公司零一万物成立八个月就成为独角兽公司，2024年创造近1400万美元收入，其模型训练成本仅为300万美元，远低于GPT-4的8000万到1亿美元。阿里巴巴的千问也大幅降低了大型语言模型的成本。 中国AI研发能力已居世界前列，国内外大模型能力差距被不断缩小，迎来竞争新格局。 DeepSeek爆火，相关岗位工资也成为热议的话题。在招聘网站上，DeepSeek放出了多个职位，涵盖客户端研发工程师、深度学习研发工程师、全栈开发工程师等不同职位，薪资水平大多在30-60k·14薪，岗位要求为本科。 人工智能工程师的薪资高不是个例。《中国企业招聘薪酬报告》发布的2024年第三季度企业招聘薪酬榜单显示，人工智能工程师位于榜首，平均月薪为 21930 元。相关岗位，比如芯片工程师、软件研发、通信及硬件研发等也位居高位。 AI行业对深度研究和创新能力有着迫切需求，人工智能相关岗位，学历越高招聘薪资就越高。 据一份基于6000万份招聘数据的研究报告，2023-2024年上半年，要求博士学历的人工智能相关岗位，给出的平均年薪高达34.6万元；硕士的平均年薪为25.4万元，相差9.2万元；再到本科、学历不限，平均年薪都会低一个数量级。 欲赚高薪，先承其重，薪资越高，责任越大。高学历的岗位，通常意味着，要成为前沿技术突破的带头人，或是在实际产品研发中的领头羊。 相对来说，高学历需求的岗位也是凤毛麟角。招聘博士的人工智能岗位只占0.94%，硕士占8.16%，本科和学历不限则占到90.9%，成为就业市场的主力。 由于人工智能专业设置时间较短，人才培养尚未形成较大规模，目前人工智能相关岗位主要依靠计算机、电子信息类传统专业支撑。 数据显示，人工智能工程技术人员本科毕业生中计算机专业背景的占比达41.1%，电子信息专业背景占比为12.1%，自动化类占比8.8%。 近年来，人工智能技术越来越广泛而深入地融入千行百业，我国人工智能人才供需比例失衡的现象还在逐渐扩大。 数据显示，截至2024年12月，我国生成式人工智能产品的用户规模达2.49亿人，占整体人口的17.7%。随着人工智能产业的快速发展，人力资源和社会保障部发布了19个新职业，其中包括生成式人工智能系统应用员。行业报告预测，到2030年，中国AI人才缺口将达到400万。 DeepSeek的崛起，是一场全球AI话语权的转移，也为全球市场多元化提供了新发展，更为大众提供了新机遇。 举报/反馈"
    },
    {
      "doc_id": 16768,
      "title": "大模型“独角兽”亟须差异化应对价格冲击",
      "time": "2024-01-24T00:00:00+00:00",
      "content": "图为位于上海徐汇滨江的全国首个大模型创新生态社区“模速空间”。 资料图片 岁末年初，国内外主流大模型的再次降价让行业开始反思，无限追逐更大算力集群、更多数据量是否是大模型优化的唯一道路。业界认为，在与互联网大厂价格比拼中不具备优势的创业公司，迫切需要找到一条差异化道路。 效率成为行业关键词 日前，杭州深度求索人工智能基础技术研究有限公司（DeepSeek）推出的新一代大模型DeepSeek-V3，因其训练成本之低引发行业热议。从其正式发布的技术报告来看，包括预训练、上下文长度外推和后训练在内，DeepSeek-V3完整训练只需2.788M H800 GPU小时。假设H800 GPU的租金为每GPU小时2美元，其总训练成本仅为557万美元。不过，Deepseek也透露，上述成本不包括与架构、算法或数据相关的先前研究以及精简实验的成本。 美国人工智能公司Anthropic的CEO达里奥·阿莫迪曾透露，GPT-4o这样的模型训练成本约为1亿美元，这意味着DeepSeek的成本只有GPT-4o的1/20。 训练成本降低的同时，DeepSeek-V3却保持了高性能。根据其公告，DeepSeek-V3多项评测成绩均表现优秀，性能与世界顶尖的闭源模型GPT-4o以及Claude-3.5-Sonnet不分伯仲。 为什么DeepSeek-V3能够实现低成本、高性能？“包括模型架构、基础设施优化、数据优化在内，DeepSeek-V3从端到端都进行了工程优化，叠加后呈现出很好的效果。”Gartner研究总监闫斌介绍说，大模型进入公众视野时间尚短，只有两年多时间。期间，行业模型训练相对粗放，通过尽量多收集数据，建设更大的数据中心，以获得更好的训练结果，行业也用“Scaling Law”总结这一过程。 “DeepSeek-V3证明，通过更好的工程化能力，我们可以通过相对较少的算力资源、较小的模型，也可以达到不错的训练效果。”闫斌认为，“目前行业在数据和算法方面仍有优化空间，低成本的训练和高效推理应用或将是下一阶段大模型发展的方向之一。” 值得关注的是，伯克利大学NovaSky团队也刚刚发布了Sky-T1-32B-Preview开源模型，在常见的推理和编码基准测试中，与OpenAI的o1-preview“平分秋色”。据称，其训练成本不到450美元，展示了以经济高效的方式复制高水平推理能力的可能性。 NovaSky团队能够以如此低成本进行模型训练，其关键之处包括使用了数据筛选机制，如通过QwQ-32B-Preview生成初始数据，通过GPT-4o-mini重写数据格式等。此外，NovaSky团队选择了Qwen2.5-32B-Instruct作为基础模型进行训练。行业人士评价称，“这个项目证明，高水平AI研发不需要天价预算。” 瑞银证券中国软件分析师张维璇说：“效率是2025年大模型行业的关键词之一。除了少数公司有能力、有愿景用万卡，乃至十万卡继续追求顶级大模型，大多数公司未来要降本增效。事实上，优化注意力机制、采用MOE架构、降低模型激活的参数量等，都已经是很主流的降本方式。我们相信这会带来AI门槛的降低，以及技术的普及化，不仅体现在应用侧，还有研发侧。” 大模型创业公司将直面降价冲击 伴随着训练成本的降低，DeepSeek-V3的API价格目前为每百万输入tokens 0.5元（缓存命中）/2元（缓存未命中），每百万输出tokens 8元。同时，DeepSeek提供了45天优惠价格体验期，在2025年2月8日之前，所有用户使用DeepSeek-V3 API的价格分别下降了80%（输入命中）、50%（输入未命中）、75%（输出）。 事实上，2024年上半年中国大模型价格竞争的发起者正是DeepSeek。2024年5月，DeepSeek率先宣布降价，其发布的第二代MoE大模型DeepSeek-V2定为0.001元/千tokens的输入价格与0.002元/千tokens的输出价格。随后，智谱AI、火山引擎、阿里云、百度、科大讯飞、腾讯云等国内主要大模型厂商迅速跟进。 可以看到，2024年年底，除了DeepSeek-V3新版本的推出以及API价格调整，国内大模型其他厂商也在降价。2024年12月31日，阿里云宣布2024年度第三轮大模型降价，通义千问视觉理解模型全线降价超80%，其中，Qwen-VL-Plus直降81%；更高性能的Qwen-VL-Max降幅高达85%。此前，在12月18日举办的火山引擎Force大会上，字节推出的豆包视觉理解模型也宣布进行降价。 “大模型的不断降价，无疑有利于吸引更多企业使用新的技术，为大模型创业公司提供了更大的市场。同时，这也对大模型创业公司构成了挑战。‘独角兽’仅仅做到提升大模型能力还不够，还要不断优化算法，快速降低模型的推理成本。只有真正做到为用户提供更有性价比的大模型服务，才能赢得市场份额。”MiniMax副总裁刘华说。 经过一年多来的行业竞争，中国人工智能大模型的行业格局不断清晰，主要玩家从“百模大战”时代不断收敛。MiniMax与智谱AI、百川智能、月之暗面、阶跃星辰、零一万物6家行业“独角兽”企业估值均超10亿美元，被行业称为国内“大模型六小虎”；再加上关注度较高的幻方和面壁智能，以及互联网大厂中的字节、阿里、百度和腾讯，行业主要玩家缩减到十来家。 API接口调用付费是大模型企业B端重要商业化实现路径之一。不过，ToB业务中，由于互联网大厂可以将AI功能绑定算力和云服务业务，二者叠加商业推广效率更高。因此，在“价格战”中，大厂因为业务复合、资金雄厚，也更有优势。面对价格竞争，创业公司只能化压力为动力，从加快迭代模型、不断优化算法中寻找解法。 “如果要拼低价和资源，创业公司肯定不如大厂。下一步，大模型创业公司可以聚焦在提供个性化服务，比如提供情感类大模型的API接口。”行业人士对记者表示。 “独角兽”还需差异化发展 无疑，大模型训练成本、推理成本的下降，将进一步加快行业场景应用落地。事实上，寻找更合适的大规模落地场景、更好的商业闭环模式，已经成为大模型企业下一阶段发展的当务之急。 在接受采访时，多位行业人士提到，上述“大模型六小虎”开始出现分化，已有独角兽企业出现“掉队”势头，“这也说明，大模型行业发展遇到了瓶颈。” “从全球来看，大模型企业都面临一定的融资压力。大模型出现之初，大家对它的预期很高，后面又经历了预期的回调。与此同步，行业融资热度稍降。当然这也符合一项新技术的发展曲线。单纯通过讲故事已经很难找到投资人。”闫斌表示。 从B端应用来看，Gartner的一份最新调研结果显示，截至2024年6月，只有8%的中国企业将生成式人工智能部署在生产环境中。对此，闫斌解释称，目前大模型在中国企业生产场景中小规模落地已出现，但大规模企业落地仍然较为少见。“如果把最终落地应用比作一场考试，那么大模型能力、数据、工程化、产品设计将是几门关键课程。根据我们观察，国内很多大模型能力已经不错，目前落地短板更聚焦在其他几个方面。” 再来看C端的落地情况。根据AI产品榜数据，目前用户量排名靠前的应用分别为抖音的豆包、MiniMax的Talkie AI、月之暗面的Kimi智能助手、百度的文小言，全球2024年12月的月活分别为7117万、2977万、1669万、1347万，在全球主要C端产品榜单中，分别位列第2位、第4位、第15位、第20位。 与创业“独角兽”相比，“大厂”在C端应用推广上，展示出了流量和资本方面的巨大优势。字节2024年5月才推出AI对话助手“豆包”，凭借投流买量后来居上，成为过去半年增长最快的移动应用。“一些创业公司此前通过投流买量的方式迅速扩大了用户量。但随着‘大厂’下场，这种做法就显得不那么划算了。”有行业人士对记者表示。 “目前国内大模型企业的C端产品存在‘同质化’的问题，很多企业都推出了AI对话助手类产品，功能大同小异。但是，大模型技术在不断迭代。各家企业需要基于大模型能力的提升趋势，去探索新的AI产品形态，去满足客户尚未被满足的需要。尤其是创业公司，更是要把资源聚焦于技术和产品的创新，而不是通过投流买量进入变成‘红海’的赛道。”刘华说。（记者 杜康 朱程） 【责任编辑:冉晓宁】 部级领导干部历史文化讲座20周年纪念版 定位就是聊个天 金融市场技术分析 疗愈的饮食与断食 写作教练在你家 注音详解古文观止"
    },
    {
      "doc_id": 16772,
      "title": "大模型价格战,打到了负毛利",
      "time": "2024-09-23T00:00:00+00:00",
      "content": "来源：《财经》杂志 国产大模型淘汰赛在加速。这轮淘汰赛会持续一两年，只有少数真正具备实力的基础模型企业能继续活下去 文 | 《财经》特约撰稿人 吴俊宇 编辑 | 谢丽容 中国市场的大模型价格战已经打了近半年。这轮价格战已经打到了负毛利，而且暂时没有停止迹象。头部云厂商仍在酝酿新一轮降价。这轮降价会在今年9月下旬落地。 今年5月，中国云厂商开始大模型推理算力价格战。字节跳动旗下云服务火山引擎、阿里云、百度智能云、腾讯云先后把大模型推理算力价格下降了90%以上。 使用大模型要输入提示语言，经过推理得到内容输出。这个过程会调用API（应用程序编程接口，就像水电开关），按消耗Token（Token是大模型的文本单位，一个Token可以是单词、标点、数字、符号等）数量付费。这就像为水电按使用量缴费。 降价后，推理算力消耗量确在快速增长。今年8月，百度二季度财报电话会披露，百度文心大模型5月API日均调用次数是2亿，8月增长到了到6亿次；5月日均Token消耗量是2500亿，8月增长到了1万亿。字节跳动今年8月宣布，截至7月字节跳动豆包大模型日均Token用量超过5000亿。相比5月，平均每家企业日均Token使用量增长了22倍。 Token价格下降了90%以上。这在短期内会降低云厂商的推理收入。但云厂商期望通过这种方式降低企业客户试错门槛，形成10倍以上的指数级算力消耗，最终获得长期收入增长。 国内大模型市场的推理算力价格战持续半年，目前有三个基本事实： 其一，推理算力价格战，已经打到了负毛利。近期，包括阿里云、百度智能云在内的多位云厂商负责人向我们透露，今年5月以前，国内大模型推理算力毛利率高于60%，和国际同行基本一致。今年5月各大厂接连降价后，推理算力毛利率跌至负数。 其二，国内模型和OpenAI的同规格模型相比，价格普遍只有其20%-50%。国内大模型毛利率远低于OpenAI。国际市场调研机构FutureSearch今年8月的研究报告称，OpenAI旗下GPT-4系列旗舰模型毛利率约为75%，GPT-4o系列主力模型毛利率约为55%。OpenAI综合毛利率至少超过40%。 其三，模型能力不足是价格战的重要成因。一位云厂商大模型业务核心负责人认为，目前国内的旗舰模型能力普遍和OpenAI的GPT-4系列旗舰模型存在差距，所以要通过降价鼓励客户试错。随着模型价格持续下降，价格已不再是企业客户最关注的因素。模型的能力、效果，才是企业客户最关心的。 不得不打的价格战 我们查阅了阿里云、火山引擎、百度智能云、腾讯云以及OpenAI官网公布的大模型推理价格。国内模型和OpenAI的同规格模型相比，价格普遍只有20%-50%。 以阿里的通义千问-Max、百度的ERNIE-4.0-8K、腾讯的hunyuan-pro三款旗舰模型为例，三者每百万Tokens的输出价格分别是120元、120元、100元。它们对标的OpenAI旗舰模型GPT-4-turbo每百万Tokens输出价格是210元（OpenAI官网标价是30美元，此处已按美元和人民币汇率1：7换算）。这三款国产大模型的价格仅为GPT-4-turbo的50%左右。 以阿里的Qwen-Long、百度的ERNIE-Speed-Pro-128K、腾讯的hunyuan-embedding三款入门模型为例，三者每百万Tokens的输出价格分别是2元、0.8元、5元。OpenAI的廉价模型OpenAI gpt-4o-mini百万Tokens输出价格是4.2元（OpenAI官网标价是0.6美元，此处已按美元和人民币汇率1：7换算）。阿里和百度的入门模型仅为OpenAI入门模型价格的48%和19%。 大模型价格战已经打到了负毛利，但这并未止住各个云厂商继续降价的步伐。 我们得到的消息是，阿里云等头部云厂商仍在酝酿新一轮降价。这轮降价会在今年9月下旬落地。高性能的旗舰模型是这轮降价重点。 上述云厂商大模型业务核心负责人认为，廉价小尺寸模型目前降价空间不大，上轮降价已降到了企业客户的“心理底线”。下一步的关注重点是，各家旗舰模型是否会继续降价。旗舰模型也会进一步细分，分化出能解决大部分问题的高性价比版本，以及解决超难问题的高质量、高价格版本。 大模型推理算力到了负毛利，为何还要持续降价？ 大型云厂看长期市场大势——云计算的算力结构正在剧变。抢占更多推理算力，就是抢占更多增量市场。国际市场调研机构IDC预测，2022年-2027年中国通用算力年复合增速16.6%，智能算力年复合增速33.9%。2022年-2027年，智能算力内部，推理算力占比将上升到72.6%，训练算力占比会下滑到27.4%。 云厂商愿意为了预期中的长期增长放弃短期收入。在短期内，推理算力能带来的收入并不多。一位中国云厂商技术人士解释，2024年各家模型调用收入不会超过10亿元，这在每年数百亿营收的大盘中规模有限。云厂商愿意在未来1年-2年接受短期收入损失和业务亏损。大家赌的是，未来1年-2年大模型调用次数至少有10倍以上的指数级增长。最终，长期收入增长能弥补短期收入损失。 他进一步解释，这个过程中，算力成本会随着客户需求增长逐渐摊薄。大模型业务最终仍有机会实现正向利润。即使赌局不成立，也会有一批模型厂商死于价格战，活下去的厂商会收拾残局。 不同云厂商面对价格战，也有不同的竞争考量——火山引擎、阿里云、百度智能云都在参与一场必须要打的价格战。 火山引擎目前在中国公共云市场份额未进入前五，但2023年火山引擎营收增速超过150%。大模型是它在云市场弯道追赶的重要机会。火山引擎总裁谭待今年5月向我们提到，今年3月他在硅谷发现，美国AI应用创业呈现了2012年-2014年中国移动互联网初期的趋势。“AI应用创业小团队，很快取得营收和融资。中国市场未来可能会呈现这种趋势。但前提是，推理价格要降低，试错门槛要降低。” 阿里云在中国公共云市场位居第一。面对对手降价，阿里云必须跟进。阿里云公共云事业部总经理刘伟光今年6月曾向我们分析，阿里云内部经历了多轮推演和测算，发现两个矛盾点： 一是，降价后存量收入会下降，增量收入会增长。理想情况是，增量收入能覆盖存量收入。 二是，如果同行降价更激进，要如何应对。最终结论是，现在的规模比利润更重要。阿里云要用大模型提高全行业的云计算渗透率。 百度智能云把AI作为核心战略。一位百度大模型技术负责人今年7月对我们直言，大模型是必打之仗，价格战咬牙也得打。这一战略取得了实际成效。百度智能云2024年二季度的营收增速已回升至14%，是近两年的最高点。百度管理层在2024年二季度财报电话会中披露，百度智能云的大模型收入占比已从2023年四季度的4.8%提升到了2024年二季度的9%。 一位中国头部科技企业的AI战略规划人士分析，火山引擎背靠字节跳动，母公司的广告业务可以输血。火山引擎在云市场份额未进前五，希望通过价格战抢占更多市场份额。阿里云主要来自公共云四大件（计算、存储、网络、数据库），低价模型会促进客户业务数据消耗，进而带动上述基础云产品的销售。大模型是百度的核心战略，百度在国内最早布局大模型业务，当其他对手决定价格战时，百度必须跟进。 价格不是决定因素 大模型推理价格战负毛利的另一面是，低价并不是企业客户是否使用大模型的主要因素。 前述云厂商大模型业务核心负责人认为，云厂商不能指望靠长期烧钱亏损推动大模型产业落地。低性能、低价格的模型意义不大。模型能力不足，才是负毛利价格战的重要原因。随着国内模型调用价格大幅下降，价格不再是企业客户最关注的因素。模型的能力、效果，才是企业客户最关心的。 一位保险公司的IT负责人对此认同。他直言，目前金融保险行业IT支出在公司营收中的占比约为3%-5%，刨除80%的硬件IT支出，真正用于数字化转型的IT支出只有20%。使用大模型这种新技术必须算清投入产出比。除了显性的模型成本，还要考虑隐性成本——大模型要与现有IT系统兼容，为大模型准备业务数据需要进行数据治理，还要招聘一批懂AI的产品经理。他最关注的是，模型能力和实际效果。 斯坦福大学基础模型研究中心（CRFM）长期进行全球大模型测试排名。截至9月17日的大规模多任务语言理解 （MMLU）测试排名显示，排名前十的模型厂商包括AI创业公司Anthropic（亚马逊投资）旗下的Claude 3.5系列、Meta旗下的Llama3.1系列、OpenAI（微软投资）旗下的GPT-4系列、谷歌旗下的Gemini 1.5系列。中国大模型目前仅有阿里旗下的通义千问2 Instruct （72B）进入了前十。 多位中国云厂商大模型技术人士对《财经》表达了同一个观点：大模型市场，低性能、低价格的策略不可持续。理想情况是，依靠高性能和合理的价格建立健康持久的商业闭环。 比较有参考价值的标杆是OpenAI。截至今年9月，OpenAI拥有10亿月活跃用户、1100万付费用户（其中包括1000万付费个人订阅用户和100万企业订阅用户）。今年5月，OpenAI管理层宣布，公司年化收入（年化收入为当月收入×12，订阅制软件公司每月会收到用户订阅续费，有稳定的收入预期，因此常采用年化收入口径）达到了34亿美元（按美元和人民币汇率1：7换算，约合241亿元）。 国际市场调研机构FutureSearch最新研究报告根据OpenAI公布的年化收入、付费用户结构测算了这家公司的收入结构——1000万个人订阅用户带来了19亿美元收入，占比56%；100万企业订阅用户带来了7.1亿美元收入，占比21%；API调用带来了5.1亿美元收入，占比15%。 即使经过多轮降价之后，OpenAI依旧能保持相对健康的毛利率。今年4月，OpenAI的旗舰模型GPT-4-turbo输出价格降低了67%。今年8月，OpenAI的主力模型GPT-4o输出价格降低了30%。FutureSearch今年8月发布的研究报告称，OpenAI旗下GPT-4系列旗舰模型毛利率约为75%，GPT-4o系列主力模型毛利率约为55%。OpenAI综合毛利率至少在40%以上。 OpenAI的成长环境得天独厚。它既拥有充足的算力供应，又有庞大的To C（面向消费者客户）用户，还身处全球最大的To B（面向企业客户）软件市场。 OpenAI过去两年的成功经验是，靠大算力“暴力出奇迹”。中国企业缺少OpenAI这样的算力条件和融资环境。算力是中国模型厂商的关键短板。 一位中国云厂商的模型技术人士解释，过去一年多，中国云厂商为英伟达的AI芯片付出了1.5倍以上的采购成本，这使得模型算力成本居高不下。这会影响大模型的性能上限，也阻碍大模型的产业落地。一位服务器经销商介绍，2023年中国市场搭载英伟达H100/H800系列AI芯片的八卡服务器一度超过300万元/台，是英伟达官方定价的1.5倍以上。 中国企业在算力资源受限、算力成本高昂的情况下，如何找到适合自己的发展路径？这需要精打细算、量体裁衣。 过去两年，大模型的发展遵循着Scaling Law（OpenAI在2020年提出的定律，直译为“缩放定律”）——模型性能主要与计算量、模型参数量和训练数据量三者大小相关。 上述云厂商大模型业务核心负责人提到，核心原则是在Scaling Law的约束下提升数据质量、数量，适当降低模型参数，还可以采用MoE（Mixture of Experts，一种模型设计策略，通过混合多个专业模型，获得更好性能）架构提升模型性能、降低推理成本。落地到具体的业务策略，有两种方案。 其一，通过增加数据质量/数量、优化算法和架构的方式提升模型性能、降低模型尺寸。这可以有效减少算力消耗，还能提升主要应用效果，适应主流市场需求。 其二，采取更精准、细分的模型产品策略。不指望靠少数几款模型解决所有问题，而是让不同模型解决不同问题。比如，让性价比模型切经济市场，让高质量模型切高端市场。 OpenAI今年三款模型GPT-4、GPT-4Turbo、GPT-4o就是沿着这种思路发展演进的。GPT-4o的模型参数比GPT-4更小，但可以精准解决大部分日常问题。GPT-4 Turbo被用于解决更多困难的问题。OpenAI最新的o1-preview性能最强，它经过了强化学习，甚至不再是单一模型，会在输出回答前会反复思考，以此增强模型能力。这三款模型百万Tokens的输出价格分别是，70元、210元、420元（OpenAI官网标价为10美元、30美元、60美元，此处已按美元和人民币汇率1：7换算）。 淘汰赛加速 负毛利的价格战，正在加速大模型市场的淘汰赛。多位行业人士对《财经》表达了同一个观点，这轮淘汰赛会持续一两年，只有3家-5家基础模型企业能继续活下去。 中国信息化百人会执委、阿里云智能科技研究中心主任安筱鹏今年7月曾对《财经》表示，大模型需要持续投资，要有万卡甚至十万卡的能力，还需要商业回报。很多企业不具备这样的能力。未来中国市场只会有三五家基础模型厂商。 发展大模型需要采购芯片和服务器，租赁土地建设数据中心。这部分投入每年甚至高达百亿元。这些成本会体现在科技公司的资本支出中。微软2024财年四季度财报电话会披露，当月190亿美元资本支出几乎全部用于算力投入。近一年（2023年三季度-2024年二季度），阿里、腾讯、百度的资本支出分别高达232亿元、231亿元、113亿元，分别增长了77.1%、154.1%、46.9%，均是算力投资带动的结果。 除了百亿元级别的持续算力投入，大模型推理业务每年还要十亿元级别的补贴。一位中国云厂商高管分析，大模型调用负毛利意味着，短期内调用次数越多，亏损就越大。按照目前的推理算力用量，几家参与价格战的头部云厂商2024年要为大模型推理算力消耗补贴超过十亿元。 阿里云、火山引擎、百度智能云、腾讯云可以靠集团输血大模型打价格战，但大模型创业公司很难坚持下去。上述中国头部科技企业的AI战略规划人士认为，这轮价格战中，阿里云、火山引擎的血最厚。阿里能靠云盈利，火山引擎有字节跳动的广告业务输血。打价格战，百度不如阿里、字节跳动。但百度的文心大模型技术强，会有一批愿意为技术付费的客户。这对百度扛住价格战有帮助。 大模型创业公司，短期内要靠大厂和融资才能存活。一位大模型创业公司技术人士今年9月对《财经》表示，智谱AI、百川智能、月之暗面、零一万物和Minimax，国内大模型“五小虎”全部都是阿里投资的。其中一种投资方式是，投资额以算力形式支付，被投企业使用阿里云的算力。“五小虎”能否持续生存，一定程度上取决于阿里是否要继续投入。 上述头部云厂商技术人士和上述大模型创业公司技术人士同时认为，中国市场的大模型创业公司未来两年会面临考验，它们在基础模型市场很难突围，未来可能有三条出路——要么选择成为政企项目模型开发公司，要么转向To B的垂直行业模型，要么转向To C的应用市场。事实上，市场分化已经开始了。智谱AI正在大量中标政企项目，月之暗面则只专注于To C市场。 举报/反馈"
    },
    {
      "doc_id": 16777,
      "title": "行业大模型回归价值本质 绿色低碳领域构建落地新范式",
      "time": "2024-06-04T00:00:00+00:00",
      "content": "当大模型的技术神话遭遇产业现实的拷问，可再生能源双碳领域正成为检验AI价值的终极试验场。这里没有互联网行业的数据红利，没有金融业的资本护城河，有的只是严苛的度电成本约束、复杂的能量转换规律和瞬息万变的政策环境。在这个技术与产业规律激烈碰撞的战场，大模型正在经历从参数竞赛到价值创造的关键蜕变。 商业化困局：大模型落地的重重障碍 当前，人工智能领域正在经历一场深刻的价值重构。根据麦肯锡最新研究报告显示，全球AI投资持续增长，但能实现规模化商业落地的大模型项目不足四分之一。这一数据揭示了一个根本性问题，我们是否过度沉迷于技术突破的表象，而忽视了价值创造的本质？ 在算力层面，大模型发展正面临可持续发展的严峻考验。训练一个千亿参数模型的碳排放量相当于300辆汽车行驶一年的排放总和，这种环境代价正在引发业界反思。更为关键的是，资源消耗与实际产出严重不成正比。斯坦福AI指数报告指出，过去三年大模型参数规模增长了100倍，但在具体业务场景中的准确率提升不足30%。 技术适配性的困境同样值得深思。在金融风控领域，毫秒级的响应延迟要求让大多数通用模型难以胜任；在医疗诊断场景，专业知识的深度整合成为关键瓶颈。这些现实挑战正在推动行业从“大而全”向“专而精”转变。某头部金融机构的实践表明，经过领域优化的专用模型不仅将推理速度提升了5倍，更将业务转化率提高了40%。 转型背后的哲学意义在于，技术发展必须回归价值理性。德国哲学家哈贝马斯关于“工具理性”与“沟通理性”的论述在此极具启示性，当大模型研发陷入参数竞赛的怪圈时，实际上是一种工具理性的过度膨胀。而要突破这一困境，就需要建立技术与业务之间的“沟通理性”，让技术创新真正服务于实际需求。 市场正在用脚投票。越来越多企业开始采用“价值优先”的AI战略，注重可衡量的业务产出而非技术噱头。某制造业龙头通过部署专用模型，不仅将设备故障预测准确率提升至95%，更实现了3000万元的年度成本节约。这些成功案例揭示了一个朴素但深刻的道理，技术的价值不在于其复杂性，而在于其解决问题的有效性。 面向未来，大模型发展需要建立新的范式，从追求技术先进性转向注重商业可行性，从关注评估指标转向聚焦业务价值指标。这一转型不仅关乎个别企业的成败，更决定着整个人工智能产业的可持续发展方向，当前的大模型困境或许正是行业走向成熟的必经之路，行业需求正在不断重塑产业未来的发展方向。 双碳赛道：一场技术与现实的深度博弈 在全球碳中和目标的推动下，可再生能源领域正在成为检验大模型商业价值的“终极试验场”。这个看似前景广阔的赛道，实则上演着一场残酷的技术生存实验。 在这个试验场上，数据碎片化是首个严峻挑战。根据国际可再生能源署（IRENA）报告显示，全球光伏电站平均每天产生超过2TB的监测数据，但这些数据分散在SCADA系统、气象站、设备传感器等数十个异构系统中。这种数据生态呈现出典型的“蜂窝状”特征，每个数据单元都相对独立，却又存在潜在关联。更棘手的是，不同厂商的设备采用各自的数据标准，使得原始数据就像一座座信息孤岛。英国剑桥大学能源数据研究中心的最新研究表明，当前可再生能源领域的数据利用率不足15%，大量有价值的信息被埋没在数据碎片中。 政策环境的动态性构成了第二重障碍。中国光伏行业协会2024年政策白皮书指出，仅2023年各省市就出台了47项与可再生能源相关的新规或修订案。这种政策“流动性”对需要稳定训练环境的大模型提出了严峻挑战。以碳排放权交易为例，各试点市场的配额分配方法、核查标准都存在显著差异，这使得模型必须保持持续的在线学习能力，否则很快就会知识过时。 工程实践的复杂性则是第三个关键瓶颈。实验室里的模型表现与现场应用效果往往存在巨大落差。世界银行《可再生能源数字化转型报告》（2024）披露，在实验室准确率达到95%的预测性维护模型，在实际电站环境中平均性能下降20-30个百分点。这种差距源于多种因素：设备老化带来的数据漂移、极端天气导致的异常工况、以及现场运维人员与AI系统的配合问题等。正如古希腊哲学家赫拉克利特所言“人不能两次踏入同一条河流”，可再生能源场景的动态性决定了没有放之四海皆准的静态模型。 这三个相互交织的困境构成了一道严密的过滤网，将那些仅靠炫技的方案拒之门外。真正能在这场生存实验中存活下来的，是那些深刻把握行业本质规律的技术解决方案。这类方案通常具备三个特征：首先，采用“分散学习+知识网络”相结合的技术架构，既能整合碎片化数据，又能保持各数据源的独立性；其次，建立政策变化的动态响应机制，通过持续学习保持模型的时效性；最后，设计足够的工程冗余度，确保在复杂现场条件下的稳定表现。 当前，这场生存实验已经进入关键阶段。那些能够突破三重障碍的技术方案，不仅将赢得商业成功，更将为整个大模型产业指明发展方向。我们欣喜地看到，技术与现实的博弈正在经历深刻的认知升级，从孤立的技术研发转向融合的业务创新，从单一模型优化转向系统解决方案构建。在这个过程中，像标普智元这样的实践者正在为行业探索出一条切实可行的落地路径，他们的经验或许能够为大模型产业突破商业化困境提供重要启示。 技术破局：标普智元的创新实践 在人工智能与产业深度融合的今天，行业大模型正成为推动传统领域数字化转型的关键力量，而标普智元构建的可再生能源双碳大模型无疑展现了一条极具价值的突破路径。 标普智元的可再生能源双碳大模型的核心竞争力首先体现在其深度专业知识融合能力上。与通用大模型不同，该模型通过知识蒸馏技术，将风电、光伏、水电等清洁能源领域的技术原理、设备参数、运维规范等专业知识转化为模型可理解的结构化表示，构建了完整的可再生能源行业知识。 更为关键的是其独特的动态政策理解机制，在双碳目标下各国能源政策频繁调整的背景下，模型内置的政策语义解析引擎能够自动抓取、解析最新政策文件，实现法规变化的实时响应。这种设计理念使得技术发展与政策环境保持同步，据国际能源署数据显示，该机制将企业政策理解时间从传统人工处理的2-3周缩短至实时响应，大幅提升了合规效率。 深入技术实现层面，标普智元大模型展现了一系列原创性突破。最引人注目的是其创新的混合稀疏化训练策略，通过动态调整注意力头的重要性，在实现高达60%参数稀疏化的同时，仍保持了98%以上的原始模型精度。这种高效能计算方案配合分层知识蒸馏技术，使得模型能效比达到同类产品的1.8倍，推理延迟降低40%，为边缘计算部署创造了条件。同时，其多模态融合架构采用统一的编码器-解码器框架，通过跨模态注意力机制实现了文本、数值数据和图像信息的互补处理，这种设计特别适合处理可再生能源领域常见的复合型数据场景。 在实际应用维度，标普智元系统通过语音指令、图纸解析和数据可视化等多样化交互方式，显著提升了用户体验。其端到端语音理解技术即使在嘈杂工业环境中也能保持90%以上的专业术语识别准确率；图纸解析功能可以自动解读电气原理图等专业图纸，在某风电项目中成功识别出叶片设计隐患，避免了约1200万元的经济损失；而自适应数据可视化系统则能根据用户角色智能调整展示维度，配合AR辅助功能实现设备状态的叠加显示，极大提升了现场工作效率。这些创新应用不仅改变了传统的人机交互方式，更重塑了行业工作流程。 实践效果验证了这套系统的实际价值。在某大型光伏电站的应用中，系统实现了设备异常提前72小时预警，准确率达到92%，帮助电站将计划外停机时间减少58%，年发电量增加约7.2%。另一个典型案例是省级电网的可再生能源消纳优化，模型通过多时间尺度发电预测，将光伏发电的日前预测准确率提升至94.3%，帮助电网提高了12%的清洁能源消纳比例。从经济效益看，采用该解决方案的企业通常在12-18个月内即可收回投资成本，而系统带来的综合效益可使项目全生命周期收益率提高15-25%。 站在更广阔的视角，这些创新实践为行业大模型的未来发展提供了重要启示。随着量子计算等新技术的成熟，行业大模型将在实时性、能效比方面实现更大突破，而模型的可解释性、安全性和伦理合规性也将成为关键发展方向。技术哲学家唐·伊德曾指出：“技术不是简单的工具，而是我们与世界互动的新方式。”标普智元的行业大模型正是这种新型互动的生动体现，在能源转型的关键时刻，这种拓展正展现出前所未有的现实意义——当专业智能与可持续发展目标深度耦合，技术终将成为文明进步的协同者，而非旁观者。 商业启示：从技术到价值的闭环 在人工智能技术从实验室走向产业落地的进程中，我们正面临着一个关键转折点：技术突破的狂欢之后，如何实现可持续的商业价值创造？这一命题在垂直行业大模型的应用中显得尤为突出。标普智元在可再生能源领域的实践，为我们提供了一个极具启发性的观察样本，其成功不仅源于技术创新，更在于构建了一个完整的价值实现体系，这或许揭示了行业大模型商业化落地的本质规律。 深入分析标普智元的商业化路径，我们可以发现三个相互关联的价值创造维度，它们共同构成了垂直领域大模型落地的“黄金三角”。 首先是技术产品化能力。标普智元创新性地设计了“三维立体”的交付体系，这种设计体现了对能源行业数字化转型现状的深刻洞察。在能源行业这个特殊场景中，数字化基础参差不齐、数据治理水平差异显著，这就要求解决方案必须具备极强的适应性。其BPai一体机的设计理念尤其值得关注，这不是简单的硬件集成，而是将复杂的AI能力封装为工业级产品，实现了从“项目交付”到“产品交付”的范式转变。这种转变大幅降低了AI技术的使用门槛，使得即便是数字化基础薄弱的中小能源企业也能快速获益。 其次是价值量化机制。标普智元“按效果付费”模式的创新性不仅体现在收费方式上，更深层的意义在于重构了技术服务商与客户的价值关系。这种模式将技术服务从成本中心转变为利润中心，使AI技术真正成为客户业务增长的助推器。在实践层面，这种模式倒逼技术供应商必须深入理解客户业务，确保解决方案能够产生可量化的价值。这种压力传导机制，恰恰是确保技术不偏离业务需求的关键保障。 最后是生态协同网络。标普智元以上下游产业协同为核心，打造融合“产学研用”的开放式创新生态，展现了对产业链协同与技术演进规律的深刻理解。在技术快速迭代的今天，单点突破已经难以持续，必须构建开放协同的创新网络。这一生态网络不仅链接了企业、高校、研究机构与应用场景，更实现了知识共享、价值共创与资源高效流动，形成了可持续、可进化的良性循环，具备深远的战略意义。 这三个维度的有机结合，形成了一套完整的价值实现机制。这种机制的核心在于，将技术创新与商业价值创造紧密耦合，使技术进步能够持续转化为客户价值和企业收益。这种耦合不是简单的线性关系，而是形成了相互促进的正向循环，技术创新带来商业价值，商业回报反哺技术迭代，技术升级又创造更大价值。 这一模式让我们意识到，AI产业正在经历关键转折，从关注技术指标转向重视商业价值，从追求模型规模转向强调投资回报。从更宏观的视角来看，这种商业化范式的意义可能超越单个企业的成功。当AI解决方案能够系统性地证明其商业价值，当技术创新能够与产业发展形成良性互动，整个社会的数字化转型进程将获得新的动力。在能源转型这个关乎人类可持续发展的重大议题上，这种技术与商业的深度融合，正在开启一个全新的发展阶段，在这个阶段，技术创新不再是孤立的实验室突破，终将成为推动产业变革的系统性力量。 举报/反馈"
    },
    {
      "doc_id": 16784,
      "title": "大模型2025三大争议:技术、价格、AGI",
      "time": "2024-01-24T00:00:00+00:00",
      "content": "想站稳脚跟，不能走捷径。 在大模型“撞墙论”不绝于耳的当下，行业比任何时候都更为迫切地渴求探索、渴求创新。 步入2025年这短短一个月之内，全球大模型玩家仿佛集体“冲业绩”，OpenAI、谷歌、DeepSeek等玩家密集发布了一系列新品。 而纵观整个大模型行业，几乎是有史以来的第一次，大模型行业内部出现了大规模分歧与非共识： 1.应用 vs技术——基础模型的更新是否已经基本停滞？行业创新的重点转移到应用？ 2.价格战 vs价值战——“价格战”打不打？怎么打？创业公司打得过吗？ 3.单模态 vs多模态——对于AGI来说，多模态究竟有多重要？ 在这十字路口前，每家大模型企业，都自愿或是被迫地，选择了自己的站位。 例如，OpenAI的GPT-o1试图用强化学习为Scaling Law“续命”，谷歌Titans开始探索全新的模型记忆力架构；但同时也有更多玩家开始将注意力转至应用优化、功能更新、用户留存上。 作为国内“大模型六小龙”之一，MiniMax此前一直以产品力强而闻名业内，在这个时间点也通过开源和一系列更新表达了自己的态度。 2025年1月以来，MiniMax在十天内连发四个AI模型，包括基础语言大模型MiniMax-Text-01和视觉多模态大模型MiniMax-VL-01，以及视频模型S2V-01、语音模型T2A-01。而两个MiniMax-01系列模型，更是公司有史以来首度开源。 创始人在近期的媒体访谈中也直接表示，“如果重新选，第一天就应该开源”。一家商业公司从开源走向闭源是常见的，从大家调侃“OpenAI变CloseAI”可见一斑，但从闭源走向开源却不多。 从MiniMax这一系列更新可以看出来，这家公司正试图通过开源、创新、技术驱动的路径，扭转市场对其的“只有产品强”的印象。创始人表示，“技术品牌之所以重要，本质也是因为这个行业最大的驱动力是技术进化”。 同时，面对当前大模型行业的三大“非共识”，MiniMax也试图通过这一系列模型更新，给出自己的答案。 卷应用vs 卷技术 行业再次来到“Transformer时刻” 从去年以来，大模型行业内部一个显著的趋势是——底层技术突破开始变慢。 OpenAI的GPT-5屡屡跳票，时至今日仍不见踪影。AI三大要素算力、算法、数据均出现了不同程度的发展停滞，2024年的模型能力似乎停止增长。 与之相对应的，是大模型应用“投流大战”的爆发。 根据AppGrowing数据，自从月之暗面（Kimi）打响国内大模型“投流大战”以来，国内前十款大模型产品合计投放广告超过625万条，按市场价折算，金额达到了15亿元人民币。 以至于坊间戏称：“大模型行业里唯一赚到钱的是B站、抖音、小红书”；“共享单车补贴战好歹普惠用户，现在赚钱的只有广告平台。” 落到应用层面，不少企业选择了专攻APP产品、定制合作项目、为政企定制小模型等方案；而在模型技术层面，无论是国内还是海外，其大部分都统一选择了较为安全的“对标GPT”方案，在技术路径上全面跟随OpenAI——而当OpenAI疑似“撞墙”后，整个行业看上去都放慢了脚步。 1月15日，MiniMax发布并开源了最新一代MiniMax-01系列模型，包含基础语言大模型MiniMax-Text-01和视觉多模态大模型MiniMax-VL-01。 与之同步公开的一份68页技术论文《MiniMax-01:Scaling Foundation Models with Lightning Attention》，更是几乎在整个AI技术圈都引起讨论。 硅谷科技媒体VentureBeat及AI科技学者、投资人与创作者评价MiniMax-01系列模型的架构创新及长文本能力 从参数上来看，MiniMax-01总参数规模达到4560亿，其综合性能在多个主流评测集上与GPT-4o、Claude-3.5-Sonnet等SOTA（State-of-the-Art，业内顶尖）模型持平，支持400万token的输入，可输入长度是GPT-4o的32倍、Claude-3.5-Sonnet的20倍。 在测评集LongBench V2的最新结果中，MiniMax-Text-01综合评分仅次于OpenAI的o1-preview和人类，位列第三。 Long Bench V2排行榜，LongBench V2是面向现实情景进行长上下文多任务深入理解和推理的测试集 如果只是模型性能很强，MiniMax-01并不会在AI研究人员中引发如此广泛的关注。 引人注目的点在于，MiniMax第一次在一个4560亿参数的超大规模商用模型上，引入了有别于传统Transformer架构的线性注意力（Linear Attention）机制，以极低的算力成本，试图为困扰着整个大模型行业的难题提供一个新的解题思路。 MiniMax-01针对大模型最底层、最核心的Transformer架构进行了重构，在传统方案（下图上半部分）的基础上，引入了Linear Attention线性注意力，相当于从“分子”层面对物质进行改变。 这也是为什么，这次MiniMax-01的开源会在AI研究圈引起如此大的关注。 MiniM ax-01核心 架构示意图 线性注意力技术并不是MiniMax第一个提出的，正如大语言模型技术并不是OpenAI第一个提出的，但它们却是第一个大胆、坚定地对其进行大规模应用，并围绕其进行了从算法到框架的全面创新，最终取得颠覆式成功的玩家。 正是这种针对最底层技术的创新，使得MiniMax-01能够以GPT-4o十分之一的算力成本，达到比肩业内SOTA的性能，以及国际第一的400万token超长上下文。 在技术论文的最后，MiniMax的研究人员表示，MiniMax-01仍有八分之一的部分沿用了传统Transformer技术思路。当前，他们正在研究一套更高效的全新架构，最终完全去掉传统方案，从而实现无限制上下文窗口。 这也就意味着，如果MiniMax成功了，大模型将从此不再受限于输入长度，人类离AGI（通用人工智能）前进了一大步。 正如当年BERT横空出世，大模型产业迎来“Transformer时刻”一样；从某种程度上来说，我们也许正在见证“第二个Transformer时刻”。 价格战vs 价值战 算力成本居高不下，“人人都在为英伟达打工” 如果要回顾2024年大模型行业发展，有一个关键词绝对不容错过——“价格战”。 这一领域的战场主要集中在B端，更精确来说，是为to B用户提供大模型API服务并按量计价的大模型供应商们。 2024年5月初，国内初创企业DeepSeek（深度求索）在发布最新模型DeepSeek-V2的同时，突然大幅调低了API价格，其每百万token输入价格低至1元，接近于当时GPT-4 Turbo价格的百分之一。此后，字节跳动、百度、阿里、腾讯、智谱AI、科大讯飞等行业玩家全面跟进，一场轰轰烈烈的大模型价格战就此打响。 与之相对应的，却是居高不下的算力价格。 自ChatGPT于2022年底火爆以来，本已接近供不应求的英伟达GPU芯片，在全球AI大模型爆火的背景下，价格也进一步飙升，带动着英伟达公司市值一路突破3万亿美元，超越苹果，成为仅次于微软的全球第二大市值企业。 GPU不仅价格高昂，并且有价无市，2023年甚至出现过海外AI初创企业用英伟达GPU抵押融资23亿美元的新闻。由于算力昂贵而稀缺，即便在科技巨头内部，也有不少部门为集团GPU算力分配争得头破血流——不少大模型从业人员戏称“人人都在为英伟达打工”。 一边是高昂的算力成本，另一边却是惨烈的价格大战，夹在其中的大模型厂商两相为难。 不过并非没有解法。 答案似乎有些老生常谈——技术带来的问题，终究还是要回到技术找解法。 以DeepSeek为例：与MiniMax类似，DeepSeek也是坚定不移的“卷技术”派。2024年，在对技术不断优化后，其推出的V3模型参数量达到了671B，训练成本仅为557.6万美元，对比之下，2020年的GPT-3训练成本已经接近1200万美元，GPT-4的训练成本更是超过1亿美元。 事实上，模型训练成本的降低不仅与模型算法有关，它涵盖了算力和应用的中间层的多个步骤，涉及算法、架构、硬件、软件、工具链的优化与调度，一般称为AI Infra（AI基础设施）。在算力成本居高不下的背景下，AI Infra的首要目标是优化算力资源，在保证性能的同时尽可能降低模型部署成本。 而MiniMax-01所引入的Linear Attention技术，本质上是通过算法降低矩阵输入复杂度，从而降低算力成本。与此同时，MiniMax还引入了数据打包（Data-packing）、线性注意力序列并行性（LASP+）、多级填充（Multi-level Padding）等一系列技术，从数据、算法、到GPU通信间进行了全面优化，使得其在英伟达H20 GPU上机器浮点利用率（MFU）高达75%，极大降低了模型的训练与推理成本，其输入价格仅为1元/百万token，是GPT-4o的十分之一。 在被媒体问到“MiniMax过去一年比较满意的技术成果是什么？”时，MiniMax创始人的回答是：AI Infra与算力优化，以及多模态。 单模态vs 多模态：我们离AGI还有多远？ 多模态可能是业内分歧最小，但竞争最为激烈的领域。 模态（Modal）是计算机用语，可以理解为计算机和人之间的感知交流模式的分类——如文字、图像、声音、视频等。 目前除了极少数坚持单模态的玩家外，市场上的大部分AI企业都会瞄准多模态赛道，最基础的是文字、图像两个赛道，涉猎更多的则会涵盖音频、视频、3D建模等等。 以语音为例，1月20日，MiniMax发布T2A-01系列语音大模型，支持17种语言，目前已经上线其海螺语音产品，面向所有用户开放。 合成效果可以看看下面的示意视频。 01:19 从视频的16秒开始，在不看画面的情况下，你大概也能准确判断出说话者的性别、年龄与情绪：白发苍苍的老人、坚毅认真的女性、愤怒的青少年、稚嫩天真的孩童，语音语调里有着各自的悲伤、兴奋、喜悦、抑扬顿挫。 文本转语音其实是个老技术了，此前的发声效果一直很生硬，无法像人类一样控制语调的情绪起伏、抑扬顿挫。谷歌翻译还曾因为发音太过机械，一度成了互联网热梗。 MiniMax这次上线的语音大模型基本已经到了商用水准，AI有声书、广播剧、动画、视频配音这些场景目前看来都能够覆盖。 而比语音大模型更受关注的，则要数视频大模型。 2024年2月，Sora横空出世，带动全球AI视频大模型开始“狂飙”。不过，在此期间行业其他玩家的视频生成大模型不断涌现，Sora在发布后却始终处于“期货”状态，直到12月才正式推出。 目前AI视频大模型领域有两大主流技术路径：文生视频、图生视频。 二者各有优劣，文生视频（Text-to-Video）主流采用Diffusion技术，拥有极好的“发散思维”能力，用户可以通过文本描述生成任何想象中的视频内容；但另一方面模型训练和推理的计算复杂度高，而且视频主体稳定性极差——尤其是人物的面部。 图生视频（Image-to-Video）与其相反，模型将根据用户输入的图片生成视频内容，一个典型的应用场景就是“让老照片动起来”，其相比文生视频主体稳定性更好，计算资源需求更低，但视频自由度严重受限。 不过，MiniMax在1月10日发布的最新视频模型S2V-01却打破了两者间的壁垒，其自研基于单张图片的主体参考功能，用户在上传一张图片创建参考角色后，模型会将图片中的主体视觉信息抽取出来，再根据用户的文本Prompt进行视频生成，在保证视频主体稳定的同时，将创意表达得更灵活。 00:05 以上为海螺AI用户创作案例。提示词：一名男性警官打开车门，从警车里出来。镜头跟随这名男子，保持近景，聚焦于男子的面部。这名男子穿着警服。男子的表情从平静变为有攻击性。城市被夜晚的场景包围，周围有几辆警灯闪烁的警车。 00:06 以上为海螺AI用户创作案例。提示词：末日废土的九龙城寨，一个退伍老兵，牵着一条狗，警惕性的在街边移动着，躲避天空中不时飞过的巡逻无人机，不远处还传来类螳螂的机器人（隐约看见）在街边与反抗军对峙的开枪声。 尤其如下图所示，是在用人物特写图像生成视频时，S2V-01能够保证极高程度的人物五官、面部细节稳定、自然。 尤为值得一提的是，下图人物的眉心、脸颊、唇角各有一颗痣，海螺AI所生成的视频不仅能够清晰还原参考图中痣的细节，还能在不同镜头中保持其位置的一致性——在目前所有AI视频生成大模型中，这可能是第一个能做到的。 海外平台上，创作者们对S2V-01表现出极高热情 值得关注的是，MiniMax-S2V-01模型对于视觉和文字信息的处理方式，非常接近人类。 事实上，多任务、多语境、多模态是AI界“冠上明珠”——通用人工智能（AGI）——的几大主要研究方向。 在AI界的目标中，AGI是一种极其复杂、灵活的人工智能，不仅能完成图像分类或跨语种文本翻译等任务，还能模拟人类分析、策划、创造等一切认知能力。 不过，多模态并非是当前唯一的技术路径，也有技术流派将语言大模型认定为AGI的通路。不过就目前而言，在行业尚未达成明确AGI共识的当下，Agent（智能体）是个目标更明确的关键节点。 随着大模型底层技术的发展，各行各业对Agent能力要求也在不断提高，任务变得越来越复杂、数据量越来越庞大，相应而言，大模型本身不仅需要更长的上下文处理能力，同时也需要越来越“像人”，不断提升其对图像、视频、声音等多模态信息的处理能力。 2025年，可能是AI Agent爆发的一年。 结语 截止至2024年12月，根据AI产品榜数据，MiniMax旗下的AI内容社区Talkie以2977万的月活跃用户数，成为全球第一大AI内容社区——这是中国AI厂商第一次在海外超过同类应用，登顶全球第一。 按理来说，作为这场比赛中的赢家，MiniMax应该比任何人都要拥护“卷应用”。 但很有意思的是，MiniMax创始人在最近接受媒体采访时，却抛出了“中国人工智能产业过去一两年走入了巨大的误区：认为用户越多，模型能力提升越快。这也导致企业为了有更多用户，就花大量的钱来买流量”的观点，引发了业内激烈讨论。 坦白说，他可能是对的。 一直以来，MiniMax都是大模型行业里一个非常独特的存在。 一个事实是，全球许多大模型公司基本都在2022年底ChatGPT火了之后才成立，但MiniMax则早在2021年底就成立了。这也导致当年ChatGPT突然爆火之后，所有人都懵了，回过头来四处打听这个MiniMax到底是何方神圣。 在技术路径上，MiniMax也始终有些“特立独行”。 2023年，彼时国内市场还是Dense（稠密）模型的天下，MiniMax却将80%以上的算力和资源全部投入MoE（混合专家）模型的开发中，于2024年初推出了国内第一个MoE大模型。 事后，MiniMax曾经透露，当时公司没有准备任何MoE以外的备选计划。 一年后来看，MiniMax赌对了。如今，MoE路径已经成为各家共识，尤其在模型规模、计算规模越来越大的当下，混合专家技术已成为模型大规模部署必不可少的核心技术。 在行业普遍选择跟随GPT-o1路径的当下，MiniMax却大胆地瞄准了困扰全行业的“Transformer撞墙”问题，通过底层架构的创新，用有限的算力成本达到真正可以比肩国际领军模型的效果。 用户从来都是用脚投票的。 无论是文本、图像、语音还是视频，每当模型能力、处理速度有重大提升时，这一提升都会真切地反映在产品与用户体验中。MiniMax曾经透露，每当模型能力变强后，产品内用户的留存表现和使用深度都有着显著提升。 从创业第一天起，MiniMax就是一个集合了大量“非共识”的存在，它在业务选择、技术路线、AGI实现路径上都有着独立而清晰的判断，不焦虑，也不跟风，敢于在非共识路上突破上限、做难而正确的事。 当前的大模型产业，已经进入了比赛的下半场，所有“低处的果子”都已被摘光，仅靠跟风与模仿，几乎毫无胜算。 靠技术创新打开的市场，终究还是要靠技术创新站稳脚跟。 举报/反馈"
    },
    {
      "doc_id": 16787,
      "title": "中国大模型“狂飙”又一年:“大浪淘沙”后“由有到专”",
      "time": "2024-12-27T00:00:00+00:00",
      "content": "图虫创意/供图 翟超/制图 证券时报记者 周春媚 最近，随着OpenAI长达12天的“马拉松式”新品发布会告一段落，这家全球瞩目的大模型明星独角兽企图霸占全球科技媒体的头条，但除了Sora等个别关注度高的新品外，实际并未掀起太大的涟漪。与两年前发布堪称AI领域“原子弹”的ChatGPT-3.5相比，大模型过去一年的“进化”恰如这场漫长的发布会，小步快跑、持续迭代，却难以再现令人眼前一亮的巨大飞跃。 将目光收回国内，中国大模型在经历去年白热化的“百模大战”后，今年又迎来了“大浪淘沙”，竞争格局趋于稳定，呈现互联网大厂与初创公司“共舞”的局面。随着大模型技术演进曲线趋于平缓，怎样落地成为被摆在台面、亟待解决的问题，不同行业玩家开始调整各自的业务重点与前进方向，这或将在2025年迎来更为激烈的“生死战”。 技术演进曲线走向平缓 行业竞争格局走向收敛 “OpenAI年末的线上发布会，从侧面说明了基础模型的能力可能已到达了一个临界点，技术进步的曲线已从陡峭走向平缓。”一名人工智能行业资深从业人士在接受证券时报记者采访时表示。 在大模型领域，Scaling Law（规模定律）被普遍推崇。所谓Scaling Law，指的是随着参数规模、训练数据集及计算资源越多，大模型的性能将越好。然而，业内开始形成的一个共识是，大模型规模已到达一定程度，加上高质量训练数据逐渐枯竭，大模型能力的进化速度与去年相比有所放缓，能力并没有十分明显的提升。 不过，虽然指数级的能力增长未在今年复现，但国产大模型在技术层面始终在进步。对国内大模型行业来说，技术迭代速度放缓是件好事，领跑的人速度变慢，追赶者就获得了更多的时间窗口。今年6月，在全球权威测评中，阿里通义千问Qwen2-72B超越美国最强开源模型Llama3-70B，问鼎全球性能最强的开源模型；12月，字节跳动火山引擎对豆包大模型家族进行全面升级，其中通用模型Pro已全面对齐OpenAI最新的GPT-4o模型。 “经过两年的发展，中国大模型在技术上取得了长足的进步。各大厂商和研究机构纷纷推出新一代大模型，不仅在参数规模上有所提升，更在算法优化、性能提升等方面取得了显著成果。”北京社科院研究员王鹏向证券时报记者表示。 在2023年初野蛮生长期的“百模大战”之后，行业在2024年经历了一场大浪淘沙，行业竞争格局从分散走向“收敛”。咨询机构弗若斯特沙利文指出，中国目前在通用基础大模型领域的竞争者已缩减至20余家，主要由互联网企业、云计算巨头及人工智能创业公司主导。 一方面，中国大模型创业公司在2024年形成了相对稳定的“六小虎”格局，智谱AI、月之暗面、MiniMax、百川智能、零一万物和阶跃星辰在投资机构一轮又一轮的资金加持下，迅速成长为AI独角兽。其中，智谱AI、月之暗面、百川智能均已跻身估值“200亿俱乐部”，这一速度是上个时代“AI四小龙”们所望尘莫及的，显示了大模型时代技术演进与融资历程的加快。 另一方面，中国的传统互联网巨头们也在表演“大象起舞”。百度是最早布局大模型的大厂，今年11月举行的百度世界2024大会上，百度首席技术官王海峰透露大模型产品文心一言的用户规模已达到4.3亿。动作稍慢的腾讯和字节跳动今年也在全力加大对大模型的投入，腾讯在今年5月推出了基于混元大模型的AI助手APP腾讯元宝，字节跳动也凭借着流量投放的优势让旗下的AI大模型应用“豆包”活跃用户数在短时间超越一众竞争对手。 “这反映了当前中国大模型市场的多元化和竞争性。”针对传统巨头与初创公司“共舞”的现象，王鹏向记者表示，创业公司的优势则在于创新能力强、反应速度快、市场敏感度高等，能够更快地捕捉市场机会和技术趋势，推出更具创新性和差异化的产品和服务。而互联网大厂资金雄厚、技术积累丰富、用户基础广泛，同时还能够通过自身的生态系统和资源整合能力，为大模型的发展提供更加广阔的空间和机会。“二者各有优劣，谁能脱颖而出还需要看各自的技术实力、市场策略和执行能力。”王鹏说。 产业链上下游处境分化 模型厂商发展路径分野 据咨询机构赛智时代研究报告，大模型产业链主要包括上游基础层、中游模型层和下游应用层。其中，基础层主要包括算力和数据，模型层主要包括通用大模型和行业大模型，应用层主要包括生活消费应用、产业经济应用和公共服务应用等。 值得注意的是，2024年，一级市场的大模型产品也频频引爆二级市场，相继诞生了Kimi概念股、智谱AI概念股和豆包概念股，开了A股市场以创业公司设立概念板块的先河。“这反映了市场对于人工智能长期发展潜力的认可以及对未来盈利模式的乐观预期。”天使投资人、资深人工智能专家郭涛在接受证券时报记者采访时表示。在这些概念板块中，不仅包括为产品提供算力支持及数据服务的厂商，也包括在主要产品中接入该大模型以实现产品升级的各行业公司。 与全球芯片巨头英伟达在AI大模型的风口下营收与股价齐飞一样，随着国产大模型的加快发展，各大厂商在AI算力扩展、AI芯片采购以及数据中心升级领域的资本开支持续增加，产业链上游尤其是算力基础设施率先受益。Wind数据显示，年初以来，算力概念指数累计涨幅达47.66%，服务器概念指数累计涨幅达84.03%。“资本市场的表现往往基于对公司基本面和行业趋势的综合判断。”郭涛认为，相关概念板块的优异表现，表明投资者普遍认为随着大模型技术的不断进步和应用场景的丰富，对高性能计算能力和专业基础设施的需求将持续增长，从而带动相关产业链上下游企业的业绩增长。 与产业链上下游相比，处于中游的模型厂商却普遍面临盈利困境。一方面，从云服务商手中购买算力开支巨大；另一方面，产品商业化目前仍处于探索阶段，远未能形成稳定和足够覆盖成本的收入。同时，以字节火山引擎、阿里云、百度云为代表的云厂商在2024年掀起了大模型价格战，降价幅度普遍达到90%以上，有的甚至直接免费。云厂商的目的是通过降价，以大模型来获取云客户，但价格战让一些资金实力本就不足的厂商“雪上加霜”。 在激烈的市场竞争中，尤其是在互联网大厂直接下场“搏斗”的2024年，AI大模型创业公司告别同质化竞争，发展路径开始分野。例如，很早就开始探索商业化的智谱AI主要发力B端市场，而主打大模型应用的月之暗面则以C端市场见长，MiniMax发力多模态与海外市场，百川智能目前的精力主要聚焦在医疗模型和产品领域。 政策密集催化前景可期 行业从淘汰赛走向生死战 今年3月，开展“人工智能+”行动首次被写入2024年《政府工作报告》，人工智能被赋予了实现技术变革、推动产业深度转型升级的重要意义，也成为当前加快培育新质生产力的重要抓手。 今年以来，各地人工智能产业相关政策密集出台。例如12月18日，深圳印发《深圳市打造人工智能先锋城市的若干措施》，其中提出每年发放最高5亿元“训力券”、5000万元“语料券”、1亿元“模型券”等真金白银的措施，以超常规力度促进人工智能产业的快速发展。除此以外，北京、上海、成都等城市也不断加大产业支持力度，彼此间你追我赶。 “大模型厂商的角逐，已经不仅仅是投资机构之间的竞争，而是已经上升到各个城市产业布局、发展规划的层面。”一名资深的创投行业从业者向证券时报记者表示，投资人在与一些一线城市政府官员交流时，往往惊诧于他们对行业的了解之多、认识之深，而且全国多地都已设立人工智能产业投资基金，AI独角兽背后往往也站着国资背景的股东。 “当前，人工智能政策环境趋于友好，政府加大支持力度，促进了产学研用协同创新，为大模型的发展提供了良好的生态土壤。”郭涛表示，政策的持续催化，为AI大模型的发展前景增添了较强的确定性。展望2025年，相关领域的投入依然有望持续增加，带动国产大模型在技术创新上的继续深化和应用场景的进一步拓展。 如果说2023年的“百模大战”是“从无到有”，那么2024年国产大模型所经历的“大浪淘沙”则是“由有到专”，而进入2025年，行业或将从“淘汰赛”进入到更激烈与残酷的“生死战”。中国科学院院士、清华大学计算机系教授张钹曾公开表示，即使大模型落地之后，也只有少数企业能活下来，因为暂时还没有那么大的市场，而且中国在AI投入的资本并没有那么大，还极度分散。“必须集中资源，因为我们的资源本来就少。”张钹说。 虽然人工智能代表着未来已经成为行业共识，但是谁能够引领这个未来却依旧悬而未决。以大模型“六小虎”为例，虽然它们取得了亮眼的成绩，但同时也面临着巨额资金的持续投入、技术商业化落地等挑战。同时，在经历了2024年火箭般的融资速度后，它们的估值已经达到了较高的水平，明年的融资可能会面临一定的调整压力。“一方面，高估值可能导致部分投资者持谨慎态度；另一方面，创业公司需证明其商业模式的可持续性和盈利能力以吸引后续投资。预计下一阶段融资将更加注重公司的核心竞争力和市场表现，而非单纯依赖概念炒作。”郭涛表示。 举报/反馈"
    },
    {
      "doc_id": 16788,
      "title": "从算法到艺术:大模型如何重塑广告业?",
      "time": "2024-12-09T00:00:00+00:00",
      "content": "大模型对广告行业的影响，似乎被低估了。 它的价值并不仅限营销素材的AI生成，更大的影响或许在于，大模型算法正在重塑广告技术，提升广告主投流的准确性，合适的、更“懂”自己、能打动你的广告将越来越常见。 广告与大模型的“机缘” 大约三年前，2021年11月2日的下午，钛媒体独家约见了腾讯TEG（腾讯技术工程事业群）数据平台部的总经理蒋杰。沟通的主题是关于腾讯广告产品、技术层面的战略经营思路，其中包括腾讯广告下一代广告系统的建设以及该系统对“大模型”的运用。在当时大模型概念还未爆发的情况下，蒋杰在谈话中透露，腾讯广告具备了训练大模型的条件，模型量级从百亿维升至千亿维。 由于个中缘由，访谈内容在之后并未公开发布。直到两年后的2023年9月7日，在深圳举行的腾讯全球数字生态大会上，腾讯混元大模型正式发布，蒋杰以混元大模型负责人的身份详解了模型参数、规模以及在腾讯内部业务上的运用情况，并表示“腾讯将全面拥抱大模型”。此后，钛媒体App也从腾讯内部人士处证实，彼时蒋杰所提到的“腾讯广告的下一代广告系统”为腾讯混元大模型打下了不小的基础。 到现在，大模型在腾讯广告场景上的应用依然是腾讯混元产业落地不可或缺的版图。2024年7月蒋杰发表署名文章《大模型时代：广告系统的量变与质变》，他这样描述那段经历： 从2021年开始的“下一代广告系统”项目（广告系统2.0）就是按照这个思路（Scaling Law）去做的：用更大的模型、更多的数据、更强的算力来去做广告效果的预估(CTR, CVR等)。以及，生成式AI出来之后我首先做的就是把腾讯的算力集中起来；通过搭建基础设施（机器学习平台）来让各团队可以集中、高效地使用这些算力。于是，在这之上才有了“腾讯混元”模型，现在也是我在负责。 广告技术的迭代，在这里成就了如今风头无两的大模型。而反过来，外界对于大模型在广告行业的价值，似乎被低估了。 但这并不妨碍广告平台对它的押注。 在大洋彼岸，一家来自美国名叫Liftoff的效果营销和广告变现平台在经过一段时间的测试之后，也于近日推出了新一代机器学习引擎Cortex 。据Liftoff 营收平台副总裁Casie Jordan介绍，Cortex 基于神经网络驱动，大幅提升了计算能力与模式识别能力，数据处理能力是逻辑回归模型的 10 倍以上，未来还将扩展到 100 倍的数据量。更深入的技术细节，Liftoff没有披露太多，但其中值得一提的是，Cortex 新引擎在运行过程中，其模型刷新速度提速6倍，并始终基于最新数据进行更新。 Liftoff客户Bigo Live的使用效果反馈显示，在深入分析 Bigo Live 的现有受众，并对互动广告和静态广告进行测试后，Bigo Live运用Liftoff的UGC广告：CPI降低20%，IPM提升12%。 更大数据、更大计算 在蒋杰看来，结合大模型的新一代广告系统，是真正能够“看懂”广告素材的。“我们之前的广告系统它根本不懂。广告系统3.0的核心，就是想办法让广告系统‘多懂一些’。只有广告系统真的‘认识了’、‘懂得了’商品、广告素材和用户，才能做到提升投放确定性，减少投放‘玄学’。”蒋杰表示。 上一代的广告系统因为“不懂”，让广告优化师做了很多“堆基建”的无用功。比如各家优化师都在大量新建广告素材，基本操作就是对素材做一丁点微调再来“赌一次”，这实际上就是在钻“大模型不理解广告，不理解商品”的空子。 但是在能“看懂”广告素材之后，广告系统能够将同类商品、同类素材实现“归堆”，基于归堆后的更大数据量，模型预测也将更加精准。 但现阶段，大模型对广告系统的接入更多在于“看懂”，看懂之后基于更大数据、更大计算的“暴力美学”则由机器学习完成，机器学习将结合平台数据训练出垂直自有小模型而非通用大模型，以此指导后续的链路。 Casie Jordan表示，独立第三方广告系统对数据的收集和利用将帮助广告系统从激烈的竞争中脱颖而出。Casie Jordan透露，Liftoff 的Vungle SDK 已经连接超过 90% 全球应用程序，这个庞大的 SDK 覆盖范围为机器学习提供支持。具体而言，通过基于直接集成或从第三方MMP归因平台获取的第一手归因数据来进行训练，Cortex机器学习系统能够深入了解客户的目标受众，并识别其观看或消费行为的模式；而通过使用来自 Liftoff Creative Studio 的测试数据训练 Cortex 模型，Cortex更容易洞察出哪些内容类型和广告格式更能吸引高意向用户，从而将合适的广告展示给合适的用户，提供个性化的广告体验。同时，通过将第一手数据与来自 Vungle SDK 和 Liftoff 游戏分析平台 GameRefinery 的独家数据结合，竞价和定价的精准度又得以进一步提高。 由此也进一步说明高质量数据对于新一代广告系统的重要性，而新的技术让这些广告系统能够更“懂你”。 不久前，AppsFlyer 正式发布第 17 版《广告平台综合表现报告》，报告显示，在IOS SSOT 全品类指数中，Liftoff在所有广告平台中排名第6。 除了腾讯广告和Liftoff，Meta 在推出通用大模型LLaMA的同时，也在尝试将新一代AI引入广告系统。Meta 在2023年发布的一篇博客中指出，“如果AI能够准确预测和理解任何给定的内容，那么人们有朝一日可以选择让任何图像或视频可供购物。人们将更容易找到他们想要的东西，卖家也可以让他们的产品更容易被发现。” Meta 当前已经建立了一个为购物而设计的通用计算机视觉系统GrokNet，即一个一体化的模型（all-in-one model ）它可以识别数十亿张照片中的细粒度产品属性——包括时尚、汽车和家居装饰等不同类别。而该系统结合AI大模型对文本的理解能力，卖家发布图片时，AI 购物系统会帮助识别未标记的商品并根据其产品目录推荐标签。未来Meta想要实现的场景是，“教会这些人工智能系统了解一个人的品味和风格，以及这个人搜索产品时重要的背景。在实现这一目标的过程中，我们需要取得更多突破。我们需要继续改进内容理解，并构建能够推理、在商品之间建立联系并学习个性化购物偏好的系统。” 不得不说，大模型技术的引入正在深刻重塑广告行业。从优化广告系统平台、帮助广告主降本增效、到广告创意生成，其影响力无处不在。正如蒋杰所说，新一代广告平台的核心转变在于能够“理解”广告素材与用户行为，从而提供高度个性化的推荐，显著提升用户体验。通过大规模数据分析，广告平台能够更精准地洞察用户需求，制定有效的营销策略，实现更高的转化率。 不过，尽管通用大模型在语义理解、复杂任务处理方面表现出色，但目前出于用户隐私、数据安全等原因，通用大语言模型还无法对广告系统核心数据处理产生影响，这方面企业自有的垂直小模型就表现出巨大潜力，并且在更广泛的数据收集、和更大量的数据处理方面展现出的独特性已然成为像Liftoff 这类第三方广告平台的护城河。 未来，随着人工智能特别是大模型技术的持续进步，广告行业将迎来更多令人振奋的变化。智能高效的广告系统将助力企业以更低的成本获得更高的回报，而消费者也将享受到更加个性化且不打扰的良好体验。对于提升用户体验及推动商业增长而言，这一转变具有极其重要的意义。（本文首发于钛媒体APP，作者 | 秦聪慧） 举报/反馈"
    },
    {
      "doc_id": 16794,
      "title": "“基模五强”崛起:谁将主导中国大模型终极之战?|甲子光年",
      "time": "2024-05-13T00:00:00+00:00",
      "content": "原创 小喇叭 甲子光年 解密“基模五强”的制胜密码。 作者｜小喇叭 编辑｜栗子 2025年的中国大模型市场，正经历一场静默却深刻的洗牌。 曾在2023-2024年疯狂融资、高调亮相的“六小虎”们有些逐渐淡出主流视野，而以字节跳动、阿里巴巴、阶跃星辰、智谱AI和DeepSeek为代表的“基模五强”则强势崛起，成为国产基础大模型领域的核心力量。 这场变局的背后，是资本、技术、人才和战略的多重博弈。 接下来，大模型能力的重要性将愈发凸显。追求智能的上限，仍然是当下大模型领域最重要的事情。大模型的应用，绕不过基础模型的能力边界。只有不断突破基础模型的天花板，大模型应用才有可能呈现百花齐放的局面。 1.国产大模型公司正加速洗牌 大模型的故事开始于2022年底，OpenAI发布的ChatGPT以颠覆性效果引爆全球 AI行业。 此后，中国市场迅速反应。2023-2024年，国内大模型市场迎来爆发式增长，政策、资本、企业三股力量共振，触发了一场持续一年的“百模大战”。 首先是政策定调。中国政府将大模型列为战略性新兴产业，多地出台专项扶持政策（如上海“人工智能算力券”、北京“智源计划”），鼓励企业布局通用大模型。 在政策指引下，各类大模型如雨后春笋般涌现，既有互联网巨头布局，也有创业公司纷纷入局，资本也大量涌入大模型赛道，迅速催熟了全国大模型市场。到2024年，国内公开披露的大模型项目达数百个，覆盖语言、视觉、代码等领域。 可以说，整个2023年，几乎都在白热化的“百模大战”中度过。最终，这场混战以“6+2”的市场格局暂告一段落。“6”为月之暗面、阶跃星辰、智谱、MiniMax、零一万物与百川智能，业内也称为“大模型六小虎”；“2”即两家规模稍小但各具特色的公司：深度求索（DeepSeek）与面壁智能。 然而，在这一阶段，由于行业尚在早期，入局的企业几乎都在摸着石头过河，很多企业都在拼参数、拼算力，试图复刻OpenAI的暴力美学路线，一味追求模型规模和性能指标，反而没有考虑到实际的国情和商业环境需要；更有部分初创公司缺乏技术积累，依赖短期融资和概念炒作，商业化路径模糊。 到了2024年，市场格局开始发生重大变化。随着2024年全球AI融资环境收紧，中美融资总额同比缩水超60%，中国大模型市场也开始“去泡沫化”。 具体表现来看，融资重心逐渐向技术和商业化路径更成熟的头部企业倾斜。例如，阶跃星辰在2024年底完成数亿美元B轮融资；智谱AI则在2025年先后完成多笔融资，并开启IPO进程。 事实上，2024年底，“六小虎\"中的部分公司已经开始调整战略方向。据市场消息显示，其中两家已经放弃大模型预训练。2025年初，随着DeepSeek的异军突起，对“六小虎”的生态位置形成挤压，行业加速进入“洗牌时刻”。 2025年，“百模大战”落幕已成为共识，市场格局收敛为“基模五强”（字节、阿里、阶跃星辰、智谱 AI、DeepSeek）为主的新秩序。 巧合的是，美国市场也呈现出OpenAI、Google、Anthropic、X.ai 和 Meta“五强争霸”的格局。某种程度上，这也是技术逐渐深入市场的过程中，市场格局从粗放到收敛的必然经过。 2.“新基模五强”，各有不同 不同于“六小虎”时期的无知者无畏，“新基模五强”格局下，每位玩家都走出了鲜明的差异化路径。依次来看： 字节跳动的 AI 战略不疾不徐，兼具“航母级资源”和“创业级敏捷”。 而字节之所以能走得这么稳，一个关键原因便是，公司将 AI 做成了“一把手”工程。张一鸣直接担任起AI战略的核心推动者，不仅从战略层面统筹全局，还深度参与技术路线与产品落地方向。 通过资源整合、技术攻坚和生态闭环，字节试图从流量驱动转向AI驱动。而其成败关键在于，能否在基础模型、视频生成等领域实现技术突破，同时构建可持续的商业化模式与生态壁垒。 为此，字节也有着充分的人才和资金储备。团队整合了光年之外（LingYuan）、零一万物（01.AI）等外部顶尖 AI 团队，并吸纳吴永辉、黄文灏等技术大牛，形成兼具学术背景与工程落地能力的 AI 团队；资金储备更不用说，支撑其在AI领域的长期投入。同时，抖音、今日头条等平台还可为模型提供海量数据和应用场景。 阿里是全球最早大规模开源大模型的科技巨头之一，以开源为杠杆，撬动开发者生态与行业应用，同时通过全栈技术布局（从算力到模型到应用）构建护城河。 阿里通义系列模型（如Qwen、万相）覆盖文本、视觉、语音等多模态领域，参数规模从0.5B到110B全尺寸覆盖，满足不同场景需求。其开源模型下载量已超9000万次，开发者生态规模仅次于Hugging Face，形成“开源获客-商业版变现”的闭环。 而这些成绩则是得益于阿里云的全栈布局。阿里云未来三年将计划投入超3800亿元建设AI基础设施，包括自研AI芯片（含光系列）、液冷数据中心和高速网络；通过专有云+公共云组合，满足企业敏感数据本地化与弹性算力需求。 与此同时，阿里的通义系列模型也正在深入阿里的整个业务生态。例如，淘宝通过通义千问优化推荐系统，提升用户粘性；通义灵码辅助医生生成诊断报告，提升效率；夸克还推出AI作业助手，解析学生问题并提供解题思路，覆盖K12教育场景。 阶跃星辰则是最低调却也最务实的大模型创业公司，多模态是其显著标签。 目前，阶跃星辰已发布22款自研基座模型，其中16款为多模态模型（占比 70%），覆盖文本、图像、视频、语音、音乐、推理等全模态，多次拿下国内外权威榜单第一，被业界称为“多模态卷王”。 创始人、CEO姜大昕认为，多模态是实现AGI的必经之路。人类智能的多元性（语言、视觉、运动等）需通过多模态融合才能复现，而当前多模态模型仍处于“前 Transformer”阶段，需探索可扩展的多模态理解生成一体化架构。据悉，阶跃也正在此领域加速探索。 因性能行业领先，阶跃的多模态模型已取得广泛落地应用，成为多个爆款AI应用技术底座。公开信息显示，2024年下半年阶跃星辰多模态API的调用量增长了超45倍。 目前，阶跃星辰正将多模态能力嵌入智能终端（手机、汽车、机器人），打造“用户感知的延伸”，并与Oppo、吉利、智元机器人等头部厂商展开深度合作。 智谱AI是首个启动IPO的大模型创业公司。其之所以能成为“清华系”学院派大模型企业中规模最大的一家，很大一部分原因在于，智谱最大程度释放了“清华大学”背后所蕴含的学术、社会以及商业生态价值。 智谱AI脱胎于清华大学计算机系知识工程实验室（KEG），拥有27年AI技术积累。其自研的GLM（通用语言模型）系列通过多阶段增强预训练方法，在中文问答、代码生成等领域表现卓越。 目前，智谱构建了基座模型（GLM）、推理模型（GLM-Z1-32B）、多模态模型（清影文生视频）及智能体（AutoGLM）的全栈产品体系，满足不同场景需求。 此外，智谱将2025年视为开源年，开源旗下多款模型，通过开源社区积累技术反馈，可进一步优化模型性能。 商业方面，智谱则专注2G/2B业务，智谱在B端覆盖金融、医疗、政务等20余个行业，2024年中标32个政府及企业项目（金额1.29亿元）。 DeepSeek的崛起则打破了国产大模型的“常规路线”。 在LMSYS Org榜单中，DeepSeek其模型在数学、代码生成等任务中排名第一。其惊艳的性能表现来自于底层的工程创新。 DeepSeek通过降秩KV矩阵（MLA）减少显存消耗，结合混合专家（MOE）架构动态激活部分专家模型，显著降低计算量（参数数量减少约60%）。同时，DeepSeek放弃传统SFT微调，转向基于GROP算法的强化学习（RL），通过“模糊思考+精确证明”的训练机制，缩小非正式与正式数学推理之间的差距。 更重要的是，DeepSeek凭一己之力，通过开源打破大厂技术垄断，推动全球开发者协作（如与法国AI峰会、国际科研机构的合作），形成以中国为核心的全球AI生态。 通过工程创新，DeepSeek-R1训练成本仅为行业头部模型的1/10，API定价低至 OpenAI的1/30（输入1元/百万token，输出 16元/百万token），将AI服务从“奢侈品”变为“日用品”。 3.“基模五强”诞生背后， 资金、人才与技术缺一不可 虽然如今的“基模五强”各成一派，但他们能在“百模大战”中走到下一阶段，并逐渐形成差异化路线，找到商业闭环方向的深层原因，实则有一定共通性。 训练大模型是典型的“重资产”模式，确保资金来源是入局的基础。 字节跳动和阿里巴巴依托自身大厂优势，明确基础大模型建设战略，得以长期投入。 智谱和阶跃星辰分别背靠北京、上海，国家队实力自不用说。 DeepSeek则依靠自有量化基金平台资本投入，通过开源策略、技术工程优化（如模型压缩、分布式训练）降低边际成本。 而有了资金保障，大模型竞争本质是人才战争。 “基模五强”每家公司均围绕自身技术定位构建差异化团队，字节与阿里侧重全栈生态，阶跃星辰与智谱AI依托多模态与学术创新，DeepSeek则专注数理能力与成本优化。具体来看： 字节的AI团队以张一鸣为核心，吴永辉担任AI基础研究负责人，朱文佳担任AI业务负责人。整个团队以“技术+商业”复合型团队为核心，通过开放创新文化和“Top Seed”博士计划强化人才梯队。 团队注重多模态技术（视觉、语音）与商业场景的快速落地，通过Seed与Flow双轨并行的架构（基础研究与应用开发分离）提升效率，并依托全球AI实验室（北京、上海、新加坡等）构建技术壁垒。 阿里大模型研发一号位是阿里云CTO和通义实验室负责人周靖人。整个团队以“全栈技术矩阵+资源整合”为核心，通过“达摩院（前沿研究）+阿里云（工程落地）+行业应用（电商、政务、物流等）”形成闭环。团队具备连续创业基因与国际化视野，通过“饱和式投入”布局AI基础设施（如通义千问系列），并依托淘天、钉钉、夸克等业务实现技术商业化。 阶跃星辰核心团队，由获得2025 IEEE follow的创始人姜大昕、首席科学家ResNet作者张祥雨以及系统负责人朱亦博等大牛组成。通过顶尖科学家的加入，强化视觉、语音等前沿的模型能力研究，以多模态技术驱动为核心，覆盖手机、汽车、机器人等终端场景，实现技术与数据飞轮和B2C商业化方向。 智谱AI则依托清华大学知识工程实验室（KEG）的学术背景，通过“学术+产业”结合模式构建技术壁垒，核心成员在知识图谱、自然语言处理等领域具有深厚积累。 DeepSeek则汇聚了一群“技术奇兵”，以数理推理与工程优化为核心，团队年轻化且本土化，成员多来自清华、北大等高校。 有了资金和人才的充分储备后，能否孕育出差异化的技术创新能力，是决定企业能否在市场站稳脚跟的关键。 目前，基模五强的技术路线可分为两类： 字节、阿里、阶跃星辰、智谱AI可归为“全才型”，技术矩阵全面覆盖，通过生态协同和行业渗透构建长期壁垒。 这条路线的玩家未来可能通过全栈技术覆盖线上和线下的广泛场景（如类移动互联网的超级应用、AI+硬件等），优先抢占AGI（通用人工智能）入口的主导权。 DeepSeek则更像“专才型”，聚焦语言模型与数理推理，通过开源普惠和极致工程优化，抢占高精度场景的“技术护城河”。在数理推理、代码生成等高精度领域形成差异化竞争力，真正成为垂直场景的“基础设施”。 无论哪种路线，都在共同推动大模型行业从“工具化”向真正的“智能化”演进。 4.下一阶段的决胜点：突破智能的上限 尽管“基模五强”在战略定位、技术路线和商业化路径上呈现出鲜明的差异化特征，但它们的共同目标始终指向一个核心命题——突破大模型的“智能上限”。 无论是字节跳动的全栈布局、阿里的开源闭环、阶跃星辰的多模态探索，还是DeepSeek的极致工程优化，本质上都在为大模型的“天花板”寻找新的突破点。 当然，他们也面临着不小的挑战。从大环境来看，中美技术脱钩加剧的背景下，美国对华AI芯片出口限制可能影响国产大模型的算力供给。 具体到商业模式方面，如何在To B、To C场景中实现规模化盈利，仍是核心命题。而随着AI应用范围越来越广泛，以及人类对智能上限的探索越来越机制，AI的可控性与安全性问题将越发不容忽视。 可以预见，以“基模五强”为代表的头部玩家将在未来3-5年继续主导中国大模型产业的发展，而这场AGI竞赛的真正赢家，或将是那些能突破“智能上限”、实现AGI 愿景的企业。 END. 原标题：《“基模五强”崛起：谁将主导中国大模型终极之战？｜甲子光年》 阅读原文"
    },
    {
      "doc_id": 16795,
      "title": "争算力,争数据,争用户!零一万物、月之暗面再掀国产大模型资本战...",
      "time": "2024-08-07T00:00:00+00:00",
      "content": "国产大模型新一轮融资潮正在袭来。 8月7日，有媒体报道，李开复创办的AI大模型独角兽公司零一万物已经完成新一轮融资，金额达数亿美元。知情人士表示，此轮融资参与方包括某国际战投、东南亚财团等多家机构。对此，有接近公司的知情人士向《每日经济新闻》记者表示，该融资消息属实。而零一万物对该融资消息未予回应。 值得一提的是，这也是零一万物今年内的第二轮融资。去年11月，零一万物曾获得阿里云投资，该轮融资后，零一万物估值已超10亿美元，跻身独角兽行列。 这两年来，中国的大模型赛道也迎来了资本狂欢，创业者云集，资本密集涌入，有不少公司一夜之间成长为独角兽，市场热情高涨。今年上半年，大模型融资相比去年的疯狂已显得冷静，但是依然暗流涌动。 就在8月6日，有市场消息称，国内大模型独角兽月之暗面完成了超3亿美元的最新一轮融资，其最新估值达到33亿美元，领跑“AI新六小龙”，。 《每日经济新闻》记者根据IT桔子和公开资料梳理，今年以来全球AIGC领域已有107起融资事件，其中，国内大模型公司融资金额在亿元级别的有20起。“新AI六小龙”（零一万物、MimiMax、百川智能、智谱AI、阶跃星辰、月之暗面）中有五家公司今年已获得亿元级融资，另外一家也传出正在融资的消息。 知名经济学者、工信部信息通信经济专家委员会委员盘和林向记者表示，相比于去年的融资潮，今年大模型投资人主要关注应用端落地，比如月之暗面是因为Kimi的用户增长，而百川智能则是因为其在工业等垂直领域的应用落地。由于AI大模型最终要靠应用变现，所以投资人更注重AI大模型企业未来盈利的可能性。 一年两轮融资，零一万物要借国际财团发力海外？ 早在今年5月，零一万物创始人兼CEO李开复就在接受媒体采访时透露称，零一万物将在几周内完成2.5亿美元Pre-A轮融资的第二部分融资，并将在年底前开始为其A轮融资寻找投资者。如今看来，融资终于尘埃落定。 去年5月，年过60的李开复亲自下场，成为中国大模型赛道最年长的创业者，自此之后，李开复和零一万物一直活跃在大模型赛道中。自去年9月开始，零一万物不断发布新的大模型产品，如今已有面向B端和C端多款产品陆续上线。 在今年5月发布大模型新产品时，李开复曾向《每日经济新闻》记者表示，中国市场还在发酵、成长中，很多大模型公司各自走出不同的路线，充分看到中国公司在一个新的环境里快速野蛮生长的过程。 去年11月，零一万物被传已完成新一轮融资，由阿里云领投。如今时隔8个月再传融资消息，从本轮投资方均为国际资本可以看出，零一万物或许还将继续发力海外市场。 李开复曾公开表示，从大模型服务来看，美国等国际市场有更好的付费意愿和消费习惯。因此，零一万物在进入国内市场之前，已率先在国际市场试水并取得了积极反馈。在今年首次对外透露零一万物的具体经营情况时，李开复也提到，目前，零一万物海外生产力应用总用户接近千万，营收今年预期过亿元人民币。此外，已实践出大模型2C产品初步摆脱烧钱获客（模式），验证了AI-First（AI优先）产品的用户订阅制商业模式。 据《每日经济新闻》记者了解，零一万物今年面向C端市场推出的一站式AI工作平台万知，也是零一万物去年在海外进行了产品试水，探索PMTF（Product Market Technology Fit产品技术市场契合），明确了AI读文档、PPT制作等高价值场景之后，才在国内上线。 今年以来，国内大模型价格战疯狂，李开复也曾向媒体表示，相信大部分大模型创业者不会不理智地“卷价格”，但是如果中国市场未来真的到了只卷价格、“赔光通输也不让你赢”的程度，零一万物就会转向国外市场。 今年全球大模型赛道已融资107起，“新AI六小龙”均获青睐 今年以来，大模型赛道热闹非凡：一方面国内大模型创业公司打响“价格战”；另一方面，OpenAI宣布终止对中国开发者提供API（应用程序接口）服务也引发了国内大模型争相推出“迁移计划”。与此同时，资本也正在向头部企业进一步聚集。 《每日经济新闻》记者根据IT桔子数据和公开信息统计，今年以来全球AIGC领域融资事件107起，融资总额超过千亿元，而在国内大模型创业公司中，融资金额达到亿元级别的事件有20起。 在“新AI六小龙”中，零一万物、百川智能、智谱AI、月之暗面和Minimax五家公司均在今年获得亿元以上融资，另一家阶跃星辰也在今年6月传出正在进行一轮估值20亿美元的新融资。 而从估值来看，国内已有三家大模型创业公司估值水平达到200亿元以上，分别为智谱AI、月之暗面和百川智能。 互联网分析师丁道师向《每日经济新闻》记者表示，200亿元估值并不算高，据他预测，未来国内跟AR（增强现实）、人工智能相关的企业，会出现一大批几百亿美元估值或者市值的企业。 “人工智能足以改变、重塑千行万业，也是这么多年来最伟大的一次革命，它一定会诞生巨大的商业价值和社会价值，也会深刻地改变大家生产、工作、学习和生活。”丁道师表示。 盘和林向记者表示，大模型创业公司其一需要争算力，争数据，这些是AI大模型公司的关键生产要素，是基础。其二是争用户量，百模大战，战况激烈，但同时也意味着同质化较为严重，未来国内AI公司能活下来的只有2~3家，所以争取一个AI大模型行业领域的头部地位，是他们当下的主要目标。 而在今年7月获得天使轮融资的硅基流动创始人袁进辉此前在接受《每日经济新闻》记者采访时也表示，今年，尤其国内的大模型落地可能更多还是体现在to B服务上，对AI Infra（人工智能基础设施）公司来说，更关注怎么更好地满足大模型公司和行业客户的需求，进一步降低大模型应用的门槛和成本。随着大模型推理部署的成本进一步降低，to C应用的尝试也会越来越多，更有机会出现超级应用。 不过针对国内大模型赛道的“大乱斗”，李开复呼吁创业者关注TC-PMF（Technology-Cost Product-Market-Fit，技术成本X产品市场契合度），拒绝过去共享单车式的烧钱打法，让大模型能够用健康良性的ROI（Return On Investment，投资回报）蓄能长跑，奔赴属于中国的AI 2.0变革。 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 16796,
      "title": "豆包大模型1.6降价超六成,国产大模型价格战再起?",
      "time": "2024-06-18T00:00:00+00:00",
      "content": "在近日举办的火山引擎FORCE原动力大会上，字节跳动旗下豆包大模型1.6正式发布。同时，豆包大模型也进一步降低，最低为2.6元/百万tokens，相较于豆包大模型1.5与DeepSeek-R1的7元/百万tokens的价格，下降63%。 据悉，此次豆包1.6通过分桶调度将80%的请求导向0-32K区间，利用短文本处理的高并行性提升效率，从而降低单位成本。 回顾2024年，国产大模型领域已历经过一轮价格战。当时，字节跳动率先宣布豆包通用模型pro-32k版、pro-128k版在企业市场的推理输入价格大幅降低，推动大模型进入“厘时代”。随后，阿里云、百度智能云等纷纷跟进，对旗下大模型产品进行降价或免费策略调整。 从市场份额来看，据IDC报告显示，豆包大模型在中国公有云大模型市场份额排名第一，占比高达46.4%。其在市场中的领先地位，使得此次降价行为可能对行业格局产生较大影响。若其他厂商不跟进降价，豆包或凭借价格优势进一步扩大市场份额；而一旦有厂商选择跟随降价，国产大模型价格战无疑将再度升级。 分析指出，本次豆包降价或再次引发连锁反应，加速行业从“参数竞争”转向“成本+生态”综合竞争。截至目前，其他主流国产大模型厂商尚未针对豆包1.6降价一事发布明确回应。 举报/反馈"
    },
    {
      "doc_id": 16800,
      "title": "国产大模型发展史:大模型竞争进入“后暴力计算时代”",
      "time": "2024-02-24T00:00:00+00:00",
      "content": "原创 慢放 慢放 后浪凶猛进化，前浪披荆斩棘。 作者丨关键帧 编辑丨刘涵 AI竞技场正静静见证着一场深刻的技术权力腾挪。 这场由DeepSeek引发的变革仍未见平息，大模型竞争进入“后暴力计算时代”，效率的重要性跃然纸上，而AI权力也面临重构，OpenAI“一家独大”的局面正不断受到冲击。 后浪凶猛进化，前浪披荆斩棘，“城头变幻大王旗”赢家尚未有定论，如何既通过开源获取生态的加持，又利用闭源实现商业变现，才是决胜的关键。 01 中国AI项目乘政策风“井喷” 国产AI的发展在不声不响间悄然酝酿。2023年被业内人士视为人工智能发展的分水岭。 人工智能科学家李飞飞曾说：“在历史上，2023 年有望因技术的深刻变化和公众觉醒而被人们铭记。” 而在此之前，关于人工智能的技术探索和创新早已不胜枚举。 1956年约翰·麦卡锡在达特茅斯会议上首次提出“人工智能”（Artificial Intelligence）概念,AI作为一门学科正式诞生。 但到了1973年，由于AI研究遭遇瓶颈，对AI的资金投入大幅缩水，发展进入 “寒冬”。 1986年，直到“AI教父”杰弗里·辛顿（Geoffrey Hinton）提出了反向传播（Backpropagation）算法，神经网络的复兴让AI发展再迎曙光，再到2017年Google提出基于自注意力机制（Self-Attention），取代RNN/LSTM，成为后续大语言模型（LLM）的核心架构…… 回望国内的AI发展历程，2023年同样是“国产AI时代开启元年”。 据天眼查，仅2023年上半年与大模型直接相关的融资事件超20起，国内已发布的各类大模型数量超过100个，而到了2024年7月时完成备案并上线的生成式AI大模型数量接近200个。 直到今天，有机会冲进决赛圈的依然只有十几家。咨询机构弗若斯特沙利文指出，我们目前在通用基础大模型领域的竞争者已缩减至20余家，主要由互联网企业、云计算巨头及人工智能创业公司主导。 大家都是这场没有硝烟的“战争”的亲历者，站在2025年的开年回望，或许是经历了2024年 “百模大战”的大浪淘沙，DeepSeek才得以在2025年开年在全球科技行业投掷下“惊雷”，推动国产AI实现了\"关键一跃\"，站稳脚跟。 拥有持续创新能力的企业逐渐占据市场主导，从图文转视频到多语言广告生成，人工智能的应用范围正在迅速拓展。 与此同时，大模型和智能体技术也进入了加速发展阶段。无论是C端的用户体验优化，还是B端的企业解决方案，智能体和大模型正在重新定义技术与社会的连接方式。 决赛圈里目前有三股力量：一是阿里巴巴、字节跳动代表的互联网大厂、云服务商，介入大模型；二是科大讯飞代表的人工智能国家队，以G/B/C联动的方式，既做解决方案又做硬件产品；三是智谱、DeepSeek等AI创业公司，少数还在坚持基础模型创新。 产业链上下游处境分化，模型厂商发展路径分野。即便“AI六小虎”，也面临道路分化。例如，百川智能已转向医疗等行业大模型；零一万物将超级大模型训练交给阿里；月之暗面和MiniMax专注做C端应用和产品。 业内人士普遍认为，与产业链上下游相比，处于中游的模型厂商普遍面临盈利困境。2025年，大模型决赛圈的选手，还能在基础大模型层创新的企业，会进一步减少。 02 从“烧钱信仰”到“效率革命” 如果说“成本、AI Agent、多模态”是当下AI产业的三个关键词，代表着2024年大模型的进化方向，那么它们或许也代表着大模型迈向产业落地的关键节点。 首先，成本无疑是决定企业生死的关键，训练和部署大规模 AI模型对计算资源的庞大需求不容忽视，这也使得企业必须背负高昂的计算成本和运维成本。 DeepSeek-R1也正是抓了企业在效率和成本控制上的痛点，实现了在相对较低的算力投入下，可媲美甚至超越头部模型的性能表现。 传统人工智能发展模式往往依赖于“规模至上”的逻辑，追求超大规模模型和超大规模算力集群。DeepSeek R1的轻量化模型和开源策略，降低了人工智能应用的门槛，促进了中端算力设施和分布式数据中心的普及。 产业链上游的英伟达，因DeepSeek的出现开始面临一定需求结构调整的压力。 ASIC芯片厂商则迎来了新的发展机遇。由于ASIC芯片能够针对特定人工智能应用进行硬件加速，在能效比和成本控制上具有明显优势，更适应分布式算力发展的趋势。 对于算力服务端来说，区域性数据中心凭借低时延和贴近应用场景的优势，开始承接制造业智能质检、金融风控等对延迟敏感的应用需求。 AWS、阿里云等云计算巨头调整部分大型数据中心的建设策略，加大在边缘计算和分布式算力布局方面的投入。 而应用端则将受益于算力成本的下降，驱动人工智能在制造业、金融、医疗等领域的渗透加速。 在代码托管平台GitHub上，已涌现出大量基于DeepSeek模型的集成应用案例（awesome deepseek integration），形成“需求牵引供给”的正向循环，实现“算力+行业”的双向赋能。 人工智能技术将加速渗透到各行各业，成为推动产业升级和经济发展的重要引擎。 但值得关注的是，DeepSeek R1的技术突破，在降低人工智能应用门槛的同时，也可能引发“杰文斯悖论”。 杰文斯悖论由19世纪经济学家 William Stanley Jevons提出，他发现，随着煤炭使用效率的提高，煤炭的消耗总量反而增加。这一悖论揭示了一个深刻的经济规律：效率的提升并不必然导致资源消耗的减少，反而可能因为成本降低和应用范围扩大，刺激需求增长，最终导致资源消耗总量增加。 微软 CEO 萨提亚·纳德拉引用杰文斯悖论来解释DeepSeek R1可能带来的影响，可谓一针见血。 纳德拉认为，更实惠、更易于访问的人工智能技术，将通过更快的普及和更广泛的应用，导致需求的激增。随着人工智能技术的门槛降低，过去由于成本限制而无法应用人工智能的领域，例如中小企业、边缘计算场景等，将涌现出大量新的应用需求，从而导致算力调用密度指数级上升。 新兴应用场景的爆发，也将加速算力需求的裂变。智能驾驶、具身机器人等前沿领域对实时算力的需求极为庞大，远超DeepSeek技术优化的速度。即使单任务效率提升数倍，百万级智能终端的并发需求，仍将形成巨大的算力吞噬黑洞。 03 “开源”与“闭源”的协同 随着开源大模型DeepSeek的“爆火”，“开源”和“免费”等关键词频现。 如果说，在DeepSeek之前，国内大模型企业关于“开源”和“闭源”的路径仍多有分歧，现在“开源”、“开放生态”、扩大朋友圈的呼声似乎成了主流。 在DeepSeek这条鲶鱼的冲击之下，国内大模型企业展示出更“开放”的姿态，希望加快建立自己的开发者生态和应用生态。 而开源模型和闭源模型的关键差异，则可以从基础条件、技术层面和商业化三个维度来观察。 从基础条件看，开源模型以公开数据集、社区贡献数据为数据来源，以分布式的、开发者自有的GPU集群为算力支撑，为开发者、研究者、企业等提供了平等的接入机会，促进了技术的创新和共享。 闭源模型则是由公司或团队开发，以专有数据如用户行为日志、私有数据库、清洗后公开数据为数据来源，用户只能根据公司提供的接口或平台使用这些模型。 从盈利场景看，开源模型本身并不直接带来收益，但它们通常通过附加服务（如云计算、技术支持、培训、定制化开发等）来实现营利。公司可以通过商业化的方式提供增值服务，依托开源模型形成可持续的收入来源。 闭源模型的商业化路径相对直接，企业通过授权许可、订阅服务、平台收费等方式实现营利。闭源模型能为公司带来高利润，因为客户需要为其使用权限和服务支付费用。 开源与闭源并非“水火不融”，未来很可能会形成开源与闭源相互作用的形式，开源加速了AI技术的普及和创新，而闭源则确保技术能够在商业上获得长足发展并维持稳定性。 未来的赢家将是能同时掌握开源和闭源能力的多面手，，既通过开源获取生态势能，也利用闭源实现价值捕获。 正如纳德拉所说，“超大规模AI不会出现赢者通吃的局面，开源模式将制衡闭源。” 尾声 DeepSeek 在当下的AI时代将扮演重要角色，就像 Android 之于移动互联网革命。 重构产业生态，引发链式反应，加速上层应用发展与下层系统统一。这将调动起跨越软硬件和上下游的生态力量，促使各方加大 “模型 - 芯片 - 系统” 协同优化与垂直打通的投入，进一步削弱 CUDA 生态优势，为国产 AI 产业发展创造机遇。 DeepSeek 通过技术创新，在 AI 模型训练过程中实现了对高端进口芯片依赖的降低，这为国内企业展示了一条可行的技术路径，极大地增强了国内企业自主研发算力芯片的信心。 博弈，不仅仅是开源以及闭源的技术选择，更是涉及 AI 发展的话语权、市场主导权以及算力的分配的角逐。而这场AI权利争夺战已然开始。 END 本文为慢放原创 如对内容有异议请联系投诉邮箱： manfang@manfangjun.com 转载、读者群请联系：ShihuanShi 合作、交流请联系：yinghedahan"
    },
    {
      "doc_id": 16803,
      "title": "国产大模型DeepSeek震惊世界:团队没有“海归”,训练成本不到GPT的...",
      "time": "2024-01-27T00:00:00+00:00",
      "content": "蓝鲸新闻1月27日讯（记者 郝妍）国产大模型DeepSeek超越ChatGPT，登顶苹果中国和美国应用商店免费APP下载排行榜，成为了全球科技圈的热议话题。 DeepSeek登顶苹果美国区免费APP下载排行榜 1月27日，苹果App Store中国区免费榜显示，DeepSeek站上首位。同时，DeepSeek在美区苹果App Store免费榜从昨日的第六位飚升至第一位，超越ChatGPT及Meta公司旗下的社交媒体平台Threads，以及Google Gemini、Microsoft Copilot等美国科技公司的生成式AI产品。 DeepSeek爆火后曾出现两次宕机。 1月26日，DeepSeek曾出现短时闪崩现象。对此，DeepSeek回应称，当天下午确实出现了局部服务波动，但问题在数分钟内就得到了解决。此次事件可能是由于新模型发布后，用户访问量激增，服务器一时无法满足大量用户的并发需求。 今日又有消息称DeepSeek服务状态页面显示，DeepSeek网页/API不可用，目前正在调查该问题。 和国内AI公司背靠互联网大厂不同，DeepSeek由量化对冲基金幻方量化运营。2016年，幻方量化推出首个AI模型，第一份由深度学习生成的交易仓位上线执行。到2017年底，几乎所有的量化策略都采用AI模型计算。2023年，幻方量化宣布成立创新性大模型公司DeepSeek。 2024年12月，DeepSeek-V3首个版本上线，并同步开源，训练成本仅为557.6万美元，整个训练只需要280万个GPU小时。 1月20日，DeepSeek又正式开源R1推理模型。1月24日，DeepSeek-R1在Chatbot Arena综合榜单上排名第三，与OpenAI的顶尖推理模型o1并列。 从硅谷到华尔街，DeepSeek掀起涟漪 DeepSeek的影响迅速蔓延至大洋彼岸的硅谷。据澎湃新闻援引Information网站报道，脸书母公司Meta成立了四个专门研究小组来研究量化巨头幻方量化旗下的国产大模型DeepSeek的工作原理，并基于此来改进旗下大模型Llama。 DeepSeek之所以引发科技圈关注最主要的原因在于其以极小的成本训练出能和OpenAI的ChatGPT 一较高下的人工智能大模型。 据每日经济新闻报道，DeepSeek的R1的预训练费用只有557.6万美元，仅是OpenAI GPT-4o模型训练成本的不到十分之一。同时，DeepSeek公布了API的定价，每百万输入tokens 1元（缓存命中）/4元（缓存未命中），每百万输出tokens 16元。这个收费大约是OpenAI o1运行成本的三十分之一。 受此消息影响，华尔街也作出相应反应。 据21世纪经济报道，美股大V“THE SHORT BEAR”在社交媒体上表示，DeepSeek创造了一个AI巨头们的痛苦时刻，而投资者必须对此敲响警钟。 “如果击败OpenAI所需要的金额是5500万美元（包括5000个H800 GPU和500万预训练费用），那么这个行业的商业化会比很多人预想的要快很多。” 1月25日，AMD宣布，已将新的DeepSeek-V3模型集成到Instinct MI300X GPU上，该模型旨在与SGLang一起实现最佳性能。DeepSeek-V3针对Al推理进行了优化。这对于在AI竞赛时代一直颇为风光的英伟达略显尴尬。 据财联社报道，本周一，在亚洲盘交易时段，美国股指期货大跌，而这背后的主要原因，可能就是华尔街人士们担心DeepSeek的AI模型可能会颠覆美国科技界。 与此同时，在日本东京股市，英伟达的主要供应商Advantest Corp.的股价一度暴跌了8.6%。 本土阵容打造国产大模型黑马，实习生日薪最高上千元 1月26日，《黑神话：悟空》制作人冯骥评价DeepSeek：可能是个国运级别的科技成果。 而这一科技成果背后是一个完全本土化的阵容，据大象新闻报道，DeepSeek团队不到 140 人，但 “人才密度” 极高，成员多是来自清华、北大、北航等顶尖高校的应届博士毕业生、在读生以及硕士生。值得一提的是，团队没有“海归”，完全本土人才。 “我们的核心技术岗位主要由今年或过去一两年毕业的人员担任”，DeepSeek创始人梁文峰在2023年接受媒体采访时表示。 此前，DeepSeek开源大模型DeepSeek-V2的关键开发者之一罗福莉就曾被雷军以千万年薪招揽。 DeepSeek爆火后，媒体也发现DeepSeek正在招聘。招聘网站显示，DeepSeek的北京子公司正在招人，现共放出了52个岗位，包括深度学习研究员、核心系统研发工程师以及资深ui设计师等，均为14薪。其中，薪资最高的为核心系统研发工程师（校招），薪资范围为6万元-9万元；除此之外，大部分岗位的起薪在2万元及以上。值得一提的是，该公司正在招聘实习生，AGI大模型实习生的工资为500元/天-1000元/天，数据百晓生实习生为500元/天-510元/天。 从OpenAi横空出世，到DeepSeek以黑马之姿震惊世界，AI时代一日一变，一切皆有可能。 举报/反馈"
    },
    {
      "doc_id": 16810,
      "title": "大模型竞赛转向:决胜关键为何是“后训练”?|甲子光年",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "来源：甲子光年 大模型价值的主战场正在向后训练转移。 作者｜王艺 北京时间7月10日，xAI正式发布Grok 4模型。 这款被马斯克称之为“宇宙最强模型”的大模型由20万块GPU组成的Colossus超级计算机集群训练而成，拥有25.6万tokens的上下文窗口，主打多模态功能，支持更复杂的交互形式，同时具备更快的推理速度和改进的用户界面。同时，Grok 4通过动态MoE+AdaLoRA技术训练而成，模型的显存占用减少70%。 在“人类最后的考试”（Humanity's Last Exam）中，Grok 4拿到了38.6%的准确率，超过了谷歌Gemini 2.5 Pro的21.6%和OpenAI o3的21%。多智能体版本Grok 4 Heavy拿到了44.4%，如果进一步使用工具辅助，则能达到50.7%。 在和OpenAI o3、Gemini 2.5 pro、Claude 4 Opus的各项基准测试中，Grok 4的跑分结果也均居于前列。 图源：X@xAI “Grok 4是在所有学科里都达到研究生水平的，甚至比大多数PhD都强。”在发布会的现场，马斯克说道。 那么，Grok 4是如何实现如此惊人性能的呢？xAI的答案似乎指向了一个愈发关键的领域：后训练（Post-training）。 1.超越预训练：后训练成为价值主战场 经历了2023年的百模大战、2024年的“六小虎”争霸与多模态巨浪，再到2025上半年DeepSeek掀起的推理模型风潮和Manus引爆的智能体（Agent）革命，大模型行业的叙事正在发生深刻转变。当基础模型的性能逼近物理极限，算力成本成为不可承受之重，喧嚣终于褪去。进入2025下半年，行业共识重回理性：AI的价值不仅在于模型本身，更在于其改造产业的深度与广度。 「甲子光年」观察到，随着基础大模型在通用能力上的边际效益逐渐递减、大模型技术红利向产业端渗透，AI的技术范式也开始从原来的注重“预训练”向注重“后训练”转移。后训练（Post-training），正从过去锦上添花的“调优”环节，演变为决定模型最终价值的“主战场”。 那么，后训练具体指的是什么，其对于大模型的价值又体现在何处？ 大模型的训练过程大致可分为两个阶段：预训练和后训练。预训练阶段通常依赖大规模语料库来预测下一个token，后训练阶段则通常包括多轮微调和对齐。后训练机制的目标是通过优化模型行为，实现与人类意图的对齐，包括减少偏见和不准确度。 要让大模型适应特定领域的任务，通常涉及到微调（SFT）等技术。这些技术虽然可以实现针对具体任务的学习，但也存在过拟合的风险，并且还会产生高计算成本。 为了解决这些难题，强化学习（RL）被引入进来，这能让模型使用动态的反馈和优化序列决策来提升适应能力。 此外，包括思维链（CoT）、思维树（ToT）、低秩适应（LoRA）、适配器和检索增强生成（RAG）、测试时扩展（Test-Time-Scaling，TTS）在内的规模扩展技术（scaling）均被应用于模型的后训练阶段，用以提高模型的计算效率和准确性。 因此，如果要让我们对后训练技术的核心价值做一个总结，我们认为它体现在以下三个维度： 知识精炼：修正预训练阶段的知识偏差与事实错误（微调） 能力对齐：使模型输出符合人类价值观和任务需求（强化学习） 推理增强：赋予模型多步推理、逻辑验证等高级认知能力（规模拓展） 后训练方法分类图谱 图源：《A SURVEY ON POST-TRAINING OF LARGE LANGUAGE MODELS》 这些策略加上分布式训练框架，促进了大规模部署，并进一步提高了大模型在不同应用中的可用性。通过这些目标明确的后训练技术，大模型可以更好地与人类意图和道德伦理要求对齐，最终提高其在现实世界中的适用性。 Pokee.ai创始人、Meta应用强化学习部门前负责人朱哲清表示，后训练的本质是在预训练（Pre-training）阶段在自回归模型（Auto-regressive Model）或扩散模型（Diffusion Model）上训练完LLM之后，用强化学习（Reinforcement Learning，RL)的方式去训练模型，让它能够和用户的意图或需求对齐。对齐的必要性在于，如果用户有某种目标需要语言模型来完成，通过后训练可以让模型不只是对用户的需求进行相关性的回复，而是真正完成这个目标。 从某种意义上来说，现在后训练是大模型训练和研究最重要的一环。 而对于追求极致推理能力的新一代模型而言，后训练阶段的算力消耗，已经开始与预训练阶段分庭抗礼，甚至大有超越之势。 以Grok 4为例，Grok 4之所以能有如此强大的推理能力，得益于其在强化学习方面的巨大投入。在其他公司还在用仅10%-20%的算力做强化学习的时候，xAI团队就决定All in RL，在Grok 4的强化学习阶段投入了之前Grok 3十倍的算力。 Grok 4在强化学习阶段投入了Grok 3十倍的算力 图源：Grok 4发布会 Grok 4的成功，可以看作是大模型领域后训练重要性超越预训练的最有力的说明。 2.产业落地之困：通用模型的深度适配难题 后训练不仅是大模型技术发展的必然趋势，更是AI技术和产业数字化落地的必然要求。 当我们将目光从技术本身投向产业应用，会发现，在出行、住房、教育等与我们生活密切相关的领域，训练大模型时，都不约而同地遇到了一些难题： 首先是大模型知识断层的难题。 由于通用大模型是在各个领域的知识基础上训练而成的，不是某一领域的专家，被问及专业领域问题的时候容易产生幻觉。 某汽车门户网站在训练大模型的时候中，就面临着模型“大而全”的挑战。其核心场景是为用户提供精准的车型信息问答和导购。通用大模型虽然知识广博，但在面对“某款车型的具体参配”、“不同车型的优劣对比”等专业问题时，准确率仅有50%，幻觉严重。 某房产类互联网公司同样遇到了此类问题。该公司的核心诉求之一，是打造一个能理解用户模糊需求、并主动挖掘其潜在偏好的“AI经纪人”。其大模型算法总监表示：“我们需要客户说要学区房时，它（AI经纪人）会追问是应试教育还是素质教育；当客户说要素质教育，它需要知道要关注跳舞、钢琴等具体品类。”这种对用户深层意图的精准挖掘，要求模型具备极强的领域知识和对话逻辑。但现在的通用大模型还无法达成。 其次是模型无法在缺乏明确反馈的情况下，学习和对齐用户的隐性偏好。 以招聘行业为例。在采访过程中，很多招聘公司的算法负责人都提到了“人岗匹配”这一核心场景。其复杂性在于，“匹配”本身是一个非常主观的概念。一个岗位，推荐给A候选人可能非常合适，但B候选人可能完全无感。模型即使给出了看似合理的推荐理由（“你有相关经验”），也未必符合候选人的真实偏好。 “我们会发现它匹配或者不匹配都可以给到你，告诉你看上去很有道理的理由，比如可能说虽然专业不符合，但是这个人有这方面的经验，也是可以的。 单纯做SFT没法达到要求，只能让模型对齐我们设置的目标、对齐平台数据。但对于用户的行为和偏好到底是什么样子，模型的反馈比较稀疏。”某招聘公司算法负责人告诉「甲子光年」。 教育行业同样存在这一问题。 「甲子光年」从几位教育行业的大模型负责人口中得知，教育场景的模型需要被严格控制，不能“超纲”；此外，教育模型不仅要知识准确，更要符合教学规范，比如解题步骤、书写格式等，但现在的经过预训练后的通用模型还无法达到这些要求。 “我们的用户对于整个大模型输出的质量要求很高，需要跟K12的大纲和K12的课程标准非常一致，比如乘号不能是星号，比如说1/2，这个分号应该是除号，以及包括通过方程解决和通过算术法去解决，这些都是需要分开的。但是我们发现通用模型并不是非常关心具体解析时候的解法以及是否超纲、书写是否规范，需要我们做精细化的指标去拆解。就有点像普通的985的学生知识储备都足够、能力也够，但是真正去迈向教师岗位需要跟学生讲课的时候，那些规范都需要重新学习。”某教育行业的大模型负责人表示。 该负责人表示，尽管行业内有一些知识图谱供大模型去学习，但是模型经过几层知识图谱的学习后准确率依然很低，目前测完六层之后的准确率只有大概5%，还需要做大规模的适配。“这还只是在语言模型的层面，多模态模型的效果差得更多。 ” 第三是在现在大热的自动驾驶、具身智能等领域，需要更加强大的多模态模型和更加有空间感知能力的“世界模型”来训练汽车和机器人，但现在这类基础模型发展还不是很完善。 某智能驾驶公司大模型负责人告诉「甲子光年」，视觉模型现在的发展水平仍然赶不上语言模型，会有运动模糊等明显的缺陷。“如果是动漫场景，需要一帧一帧画出来，不会有运动模糊这种情况存在；但是视觉模型经过很多真实数据的训练，本身会带这些模糊，我们就需要一些检测模糊的Reward把这些模糊点修掉。还有就是视频2D的模型经常凭空出现或者凭空消失一些物体，这些东西在2D里面不是那么好判断，但是如果换到3D模型就能很好地解决和修复。”该负责人表示。 而在具身智能行业，存在的问题则是通用大模型无法理解机器人的物理本体（如不同关节、传感器）和环境交互的复杂性，因此无法直接作为“机器人大脑”的基座；此外，具身任务需“多目标优化”（如抓取需平衡速度/力度），预训练模型直接后训练反而退化；与此同时，不同机器人本体的需求差异大，单一的规则无法覆盖全部的机器人训练。 “我们自己做具身智能通用模型，会发现有各种各样的局限性，比如说不同机器人的本体对社区来说其实是不一样的，但是语言模型的Base Model完全没法理解，从这个角度来讲，我们才不得不从头开始去训练具身的大模型，再基于自己的模型做后训练。”某具身智能企业大模型负责人表示。 时代呼唤知识储备更强、输出更精准、更能理解用户意图和需求的大模型。 而后训练，是解决上述问题、获得更好大模型的根本途径。 面对挑战，业界也在积极探索解决方案。 比如，为了解决大模型的知识断层问题，上述汽车门户网站和房产类互联网企业都在尝试通过“增量预训练+SFT+知识图谱”的方法训练大模型，让大模型获得更多行业知识；该具身智能公司则选择从头开始做基础模型，同时在预训练阶段去任务、去场景化，之后再做后训练。 而在奖励的构建方面，该汽车门户网站也在用“配置参数必须100%准确”等规则项和“用户点赞/完读率”等模型项构建奖励模型，先用高质量标注数据做Long-CoT，再逐步放开RL训练。某具身智能研究机构则通过训练结果奖励模型、通过机器人的运动轨迹让模型判断是否完成任务。 3.从Grok 4到夸克：顶级玩家的后训练“方法论” 产业的痛点，是技术进化的最佳催化剂。当汽车、房产、教育等行业纷纷暴露出通用模型的“最后一公里”难题时，一个明确的信号已经出现：传统的后训练已经不足以应对未来的挑战。 在后训练的“上半场”，一个经典的“入门级套餐”统治了市场：企业通常会采用一个中等规模的稠密（Dense）模型，通过监督微调（SFT）的方式注入少量业务数据，并使用BF16精度在前几代GPU上进行训练。 这个组合拳帮助许多企业迈出了模型定制化的第一步。 然而，当应用走向深水区，这套“入门装备”的瓶颈也日益凸显。在后训练领域，「甲子光年」发现了一些新趋势。 首先，在训练方法上，不再局限于SFT，而是正在转向SFT+RL或者纯RL的训练范式。 SFT虽然能让模型学会特定领域的知识和对话格式，但它本质上是一种“模仿学习”，模型只是在模仿标注数据的“标准答案”，却很难真正理解人类复杂的、模糊的偏好。例如，当面对一个开放式问题时，什么答案是“更好”的？哪个回答更“有帮助”、“更安全”或“更风趣”的？SFT很难回答这些问题。 为了让模型能与人类的价值观和偏好对齐（Alignment），强化学习（Reinforcement Learning, RL）应运而生，其中最经典的范式便是从人类反馈中强化学习（RLHF）。RLHF通常分为三个步骤： 监督微调（SFT）：首先，和传统方法一样，使用高质量的标注数据对预训练模型进行SFT，让模型初步具备所需的能力。 训练奖励模型（Reward Model, RM）：这是RLHF的核心。针对同一个Prompt，让SFT模型生成多个不同的回答。然后，由人类标注员对这些回答进行排序，告诉模型哪个更好，哪个次之。接下来，用这些“人类偏好”数据来训练一个奖励模型。这个奖励模型的任务就是给任何一个“提示-回答”对打分，分数高低代表了其符合人类偏好的程度。 通过强化学习优化语言模型：最后，将语言模型本身视为一个“智能体（Agent）”，它生成的回答就是“行动”。奖励模型则充当“环境”，不断给语言模型的回答打分。通过像PPO（Proximal Policy Optimization，近端策略优化）这样的强化学习算法，不断优化语言模型的策略，使其生成的回答能在奖励模型那里获得更高的分数。最终目标是让语言模型在不偏离SFT阶段所学知识太多的前提下，其输出能最大程度地获得奖励模型的高分，从而与人类偏好对齐。 然而，传统的RLHF流程复杂、训练不稳定且成本高昂。因此，业界又进一步探索出了强化学习更高效的对齐方法，如直接偏好优化（DPO）。 DPO巧妙地绕过了训练独立奖励模型的步骤，它通过一个简单的分类目标，直接利用人类的偏好数据（比如“回答A比回答B好”）来调整语言模型本身，使其更倾向于生成人类偏好的内容，而抑制不被偏好的内容。这种方法不仅简化了训练流程，降低了计算成本，还在许多任务上取得了与RLHF相当甚至更好的效果。 xAI就采用了RL+DPO相结合的方法做Grok 4的后训练。他们先是在传统RLHF基础上引入了合成辩论对和50亿人类投票数据，通过多轮迭代优化模型输出；接着跳过奖励模型训练步骤，直接利用人类偏好数据微调模型。 而扩展到动态环境，他们则采用了PPO的方法优化策略梯度，让模型在复杂任务中的表现更接近人类专家水平。 其次在模型的选择上，越来越多公司倾向于用MoE模型作为基础模型。 Dense模型在推理时所有参数均参与计算，导致计算量和显存占用随模型规模线性增长。MoE模型具有部分专家激活、专家间可并行、计算过程可共享等特点，可实现推理速度的显著提升。例如，DeepSeek MoE 16b与LLaMA2-7b效果相当，但前者推理速度是后者的2.5倍。 同时，由于每次推理只激活少数几个专家，相比传统的大规模深度神经网络，MoE架构在推理时的延迟和计算成本相对较低，特别适合需要高效推理的场景，如在线推荐系统、语音识别等。 此外，Dense模型固定计算路径缺乏动态调整能力，而MoE模型则可更快进行多任务学习、多模态融合，实现应用场景适配。 同样以Grok 4为例，其架构延续了MoE设计，但进行了重大优化。独立报告推测其总参数达 1.7 万亿，其中活跃参数约480亿。在专业层面，Grok 4的MoE设计采用了动态路由算法，其中路由器使用softmax激活函数选择专家，以最小化负载不均衡损失、优化计算效率。 第三，在数据精度的选择上，相较于BF16/FP16，FP8可以在精度几乎无损的情况下大幅提升训练和推理效率。 FP8使用更少的指数位和尾数位，能提供两倍的计算吞吐量，如在英伟达的H100 GPU上，FP8的TFLOPS是BF16的两倍。此外，相较于BF16，FP8能节省50%-75%的内存占用，还能保持训练和推理阶段模型性能及数据算法的一致性，避免额外的精度矫正。 Grok 4在前向传播的过程中使用FP8类型的数据，在梯度计算过程中则使用了BF16类型的数据，这是一种被称为“混合精度训练”的先进技术，其核心思想是在不牺牲模型收敛稳定性的前提下，最大化训练效率。具体来说，FP8负责加速计算密集但对精度不那么敏感的前向传播和权重梯度计算，而动态范围更广的BF16则用于梯度的累加和权重的更新，有效防止了梯度消失或爆炸的问题，确保了训练的稳定性和最终模型的精度。 作为另一个引领行业趋势的模型，DeepSeek-V3的训练过程也深度整合了FP8技术。通过在兼容的硬件上全面拥抱FP8，DeepSeek能够在控制成本的同时，高效地训练出性能强大的模型。 可以说，Grok 4的成功不仅证明了“后训练”的重要性，其采用的MoE模型、强化学习的训练方式、FP8精度的数据等更是逐渐成为行业内做后训练的共识。 夸克就在这种后训练路径下，用高考大模型交出了一份“最佳实践”的答卷。 夸克高考大模型以通义千问系列的MoE模型为基座，其后训练阶段由增量预训练（CPT）、监督微调（SFT）、可验证奖励的奖励强化学习（RLVR）和人类反馈强化学习（RLHF）构成： 在指令微调阶段，夸克高考志愿大模型将数百名资深高考志愿规划师的沟通、决策过程进行结构化。围绕他们与考生或家长的多轮真实对话，提取出完整分析路径与语言风格。通过将上万条真实专家“推理链”转化为高质量监督数据，夸克高考志愿大模型得以深度学习人类专家的分析过程； 夸克高考志愿大模型还在复杂推理任务中生成了中间可验证结构，显著降低了幻觉率、增强跨模态演绎能力，并实现了分布外泛化鲁棒性，可以解决各种需要专业知识的复杂问题； 最后通过基于人类偏好强化学习（RLHF）精化策略层，夸克高考志愿大模型构建了一个闭环优化机制，将“模拟填报 → 专家反馈 → 策略评分”引入到模型迭代过程中。 夸克高考大模型后训练流程 图源：夸克 经过后训练的模型会基于模拟的考生档案生成志愿填报方案，随后这些方案将被提交给多位高考志愿专家进行评估。 评估标准包括：专业建议是否准确易懂、排序逻辑是否贴合考生特征、是否兼顾分数与兴趣、是否充分提示风险并给出可行应对策略等。通过引入数万条人类志愿专家推理数据进行训练，结合RLHF和RLVR的方式，夸克在后训练阶段构建了一个“专家反馈-策略评分-策略再优化”的完整闭环。 夸克高考志愿报告 图源：夸克 截至7月8日，夸克高考服务了全国考生及家长超4000万人，累计生成了超过1200万份AI志愿报告，为考生和家长提供考生情况分析、填报策略设计、志愿表解读、风险提示等覆盖全面的信息，辅助志愿填报。 夸克算法负责人蒋冠军对「甲子光年」表示，RLVR提供确定性奖励，基于可验证的规则或标准答案给反馈；RLHF则引入人类主观反馈，用于捕捉难以规则化的质量维度。两者互补，既保证事实正确性，又兼顾人类偏好。现在将RLVR与RLHF结合做强化学习已经成为了业界做推理模型的大势所趋，具体怎么混合要根据模型给的结果反推。 蒋冠军还表示，今年大模型领域尤其关注两件事情：一是后训练，二是Agent RL。“关于后训练的发展趋势，一是确定性答案的推理自动化，这需要更加广泛、更加复杂的数据，但是数据来源仍然是个问题；第二是多模态的推理。Agent RL属于刚起步，因为现在大家连Agent能否调用起来的问题都还没解决，RL的工作怎么做更是无从谈起。我认为第二个会比较慢，但第一个大家今年的争夺会非常激烈。”蒋冠军说。 4.后训练的五大关键要素及平台化破局 大型语言模型（LLM）的后训练过程日益关键，它涵盖了从数据处理到评估、奖励机制、扩展技术以及底层基础设施等多个相互关联的要素，共同决定了模型的最终性能和产业落地能力。 后训练有五大关键要素需要重点关注，分别是数据（Data）、评估（Evaluation）、奖励机制（Reward）、可扩展性（Scaling）、基础设施（Infra）。 第一是数据（Data）。数据是后训练的基石，贯穿整个流程的始终。高效地清洗、标注和管理海量的多模态数据，并构建从线上业务到线下训练的“数据飞轮”是企业面临的首要挑战 。例如，具身智能领域的一些数据需要生成或合成，而语言和多模态模型则依赖于用户标注和线上数据的回流补充 。这个过程涉及数据回流、接入、预处理、样本生成和管理等复杂环节，需要多领域技术栈的联合解决方案 。高质量的数据能有效纠正预训练阶段的知识偏差和事实错误，为模型的知识精炼提供基础 。 第二是评估（Evaluation）。 Evaluation是验证后训练效果的关键环节，它需要快速、可靠地衡量模型表现 。自动化评估流程，并根据评估结果调整训练样本和参数，是提升迭代效率的核心。例如，教育行业的模型不仅需要知识准确，还要符合教学规范，如解题步骤和书写格式，这些都需要通过精细化的指标进行评估 。有效的评估机制能够确保模型输出符合人类意图和任务需求，减少幻觉和不准确度 。MoE模型的分布式训练、RL的稳定高效收敛，对训练框架的能力、易用性和效率提出了前所未有的要求。 第三是奖励机制（Reward）。 Reward和Evaluation相关，也是强化学习在后训练中实现模型与人类意图对齐的核心 。从Evaluation转换到模型训练的Reward是提升效果的有效途径，包括其中Reward方法、Reward Model的训练等等。Grok 4的成功便得益于在强化学习方面的巨大投入。夸克高考大模型则结合了可验证奖励强化学习（RLVR）和RLHF，既保证了事实正确性，又兼顾了人类偏好 。 第四是可扩展性（Scaling）。扩展能力是后训练在行业落地的关键挑战之一，作为放大器，需要确保上述数据处理、模型训练、评测反馈的整个流程，都能在万卡级别的大规模集群上稳定、高效地运行。同时，通过分布式训练和模型压缩等技术，可以显著提升模型的扩展性。 第五是基础设施（Infra）。强大的infra是后训练得以顺利进行的基础。这包括根据不同负载（如SFT、RL、推理）弹性提供算力资源，确保最优的算力配比和成本效益 。分布式训练框架，如阿里云的PAI-ChatLearn，为MoE模型和强化学习的稳定高效收敛提供了支持 。它解决了开源框架灵活性过高、缺乏工程优化和稳定性差等痛点，显著提升了训练效率和成功率 。此外，完善的数据底座和部署闭环，如阿里云提供的数据处理方案和分布式推理服务，也确保了模型训练后的高效服务和快速迭代 。云计算平台提供的原生能力，如向量数据库、弹性伸缩和安全防护，正成为AI应用从“可用”走向“可靠”与“好用”的基石。 可以看到，在AI加速重塑千行百业的浪潮中，作为提升模型业务适配力的关键步骤，“后训练”不仅关乎算法层的优化，更依赖底层算力、平台能力与应用层协同，确保全链路的可行性与稳定性。 阿里云智能集团副总裁、大数据AI平台事业部负责人汪军华在采访中说：“RL非常的脆弱，微小的变化就可能会导致模型无法收敛。所以我们技术团队会不停地盯着收敛曲线，随时进行数据和策略的调整。由于RL的策略及超参有很多组合，很多时候算法团队也会无所适从，不知道如何用好强化学习。” 面对这些复杂的系统性工程挑战，企业最需要的是一个稳定、高效、全能的平台，将自己从繁重的底层工程中解放出来，专注于业务创新。而阿里云正通过其全栈AI能力，为企业提供从算力到平台的“后训练”一体化支撑。 在基础设施层，阿里云部署遍布全球的基础设施，可根据SFT、RL、推理等不同负载弹性提供算力资源，确保不同阶段的训练任务都能获得最优的算力配比和成本效益，从而为复杂的后训练、及推理服务流程提供稳定且经济的算力基座。 在模型层，通义千问系列基础模型能力领先，支持多模态、多尺寸、多架构，客户无需预训练即可启动后训练，快速适配业务场景，显著降低开发门槛与周期。 而当客户完成算力和模型选型、进入后训练阶段后，阿里云则通过人工智能平台PAI（Platform of Artificial Intelligence），围绕“数据-训练-推理-AI应用”的全生命周期，为客户提供高效、低成本的端到端后训练、模型服务技术支撑： 阿里云智能集团后训练解决方案架构 图源：阿里云智能集团 首先卓越的模型基座。在人工智能PAI平台上，企业进行后训练无需从零开始。阿里云提供了通义千问（Qwen）系列大模型作为高质量基座，在PAI-Model Gallery中，已集成Qwen、Kimi K2、DeepSeek等300+顶尖模型，可0代码实现微调、部署与评测，覆盖金融、汽车、教育、具身等多行业需求。尤其是Qwen3支持混合推理（快慢思考），用户可以利用Qwen3强大的通用知识和推理能力作为起点，将精力聚焦于业务场景的精调，极大地降低了后训练的门槛和成本。 其次是强大的训练框架。PAI提供了灵活、易用、高效的大规模强化学习训练框架PAI-ChatLearn：ChatLearn原生支持RLHF、DPO、GRPO等多种先进的Alignment训练算法，并能支持300B+300B量级的Policy和Reward模型协同训练和任意模型的后训练任务快速配置，万卡规模MoE架构训练MFU达35%-40%；同时，通过将复杂的RL流程封装为易用的模块，ChatLearn显著降低了RL的落地门槛。其训练性能对比业界SOTA系统，在不同规模的模型上实现了2-3倍的训练加速，极大地提升了迭代效率；此外，结合阿里云底层硬件和通信库的深度优化，ChatLearn解决了开源框架常见的稳定性问题，保障了长周期训练任务的高成功率。 PAI-ChatLearn的技术架构和特点 图源：阿里云智能集团 最后是坚实的数据底座与完善的部署闭环。在数据层面，阿里云提供面向AI场景的多模态数据处理方案，通过MaxCompute MaxFrame+PAI-EAS+Flink等产品实现统一的数据处理体验，整体数据处理效率提升10倍以上，数据处理推理任务优化提速1倍以上，相同资源产能提升1倍； 阿里云智能集团数据预处理算子引擎Data-Juicer 图源：阿里云智能集团 在评测与部署层面，针对MoE等模型的部署难题，人工智能平台PAI提供了分布式推理服务，通过创新的多机Prefill-Decode-EP分离架构，结合LLM智能路由，能够高效分配计算资源，做到首token生成响应时间降低92%，端到端服务吞吐提升5倍+。 Grok 4的成功揭示了后训练的巨大潜力，而其背后复杂的系统工程也为行业敲响了警钟。对于绝大多数企业而言，重复造轮子去解决数据、评估、奖励机制、扩展方法和基础设施的问题，无异于将宝贵的资源投入到一场没有终点的消耗战中。 随着大模型的发展从“规模的军备竞赛”走向“深度适配业务场景的价值创造”， 越来越多企业认识到：唯有“云+AI”的融合，才能从底层资源到应用层全面释放AI的价值。从向量数据库的构建与检索增强，到应对高并发请求的弹性伸缩，再到企业级的安全防护，云平台所提供的这些原生能力，正成为AI应用从“可用”走向“可靠”与“好用”的基石。 因此，真正的分水岭已经出现。阿里云的全栈AI能力正在将后训练从一个复杂的“工程问题”重新定义为一个清晰的“业务问题”。将复杂的工程挑战交还给平台，将宝贵的精力聚焦于核心业务的创新——这不仅是更明智的选择，更是抓住AI时代机遇的关键路径。 举报/反馈"
    },
    {
      "doc_id": 16812,
      "title": "为什么2025成了Agent落地元年?",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "题图｜视觉中国 如果有一个行业，技术演进如风扇叶片转动之迅速；格局变化如走马灯般眼花缭乱，那么非大模型莫属。 回顾2023年，生成式AI的主题词还是“百模大战”，融资、刷榜成为这一时期的主流。 然而，随着基座大模型的门槛不断提升，短短一年时间，玩家格局就迅速收敛，到了2024年，市场已经从百模齐发变为少数玩家的资本与技术持久战； 到了今年，行业关注重点再次从模型性能转向落地价值，如何将大模型的能力转化为业务的生产力，成为新的核心命题。 而Agent就是AWS给出的答案。 借助Agent，千行百业都有了将生意用大模型重做一遍的可能。 但如何低成本、高质量的重新做一遍，如何让Agent加速落地呢？ 昨天凌晨举办的2024 年AWS纽约峰会，给出了答案。 为什么是现在？为什么是Agent？ 事实上，如果关注最近一段时间的大模型发布会，可以发现一个很有趣的现象，无论是国内的Kimi K2，还是海外的Grok 4，亦或是一个月之前的Minimax M2，在各种榜单SOTA（最佳表现）之外，都不约而同的关注一个指标——工具调用能力。甚至，就连OpenAI，也在今天凌晨推出了最新的ChatGPT Agent，主打多工具集成能力。 更直白来说，过去行业关心的是LLM本身，但今年，更加关注借助LLM能实现什么。 AWS峰会同样如此。 不同于过去将最新的模型发布作为重磅亮点，这一次的峰会，Agentic AI 是唯一的关键词。 一方面，它可以让大模型从被动响应提示转变为通过AI Agents主动行动，来代表人类或系统进行推理、规划和完成具体任务。此外，相比传统的workflow（工作流，其响应机制被代码写死），Agents具有迭代思考的能力——可以评估结果、调整方法，并持续朝着既定目标努力，具备更高的能力提升天花板。 比如，去年市场上一度流行一种AI教程，就是用大模型A，生成提示词，大模型B根据提示词配图，然后将所有内容一股脑丢给办公软件，借助办公软件的自动排版功能进行PPT美化。这个过程不仅繁琐，并且十分低效。而通过AI智能助手，则能够打通不同模型以及工具的内部系统、利用语义数据源自动提取上下文信息，直接根据用户指令完成最终的交付结果。 那么为什么是今年？ 这一波Agentic AI 爆火背后，有两大原因： 其一是 CrewAI，LangGraph，LlamaIndex 在内，过去两三年里各种Agent编排框架逐渐成熟，让Agentic AI 构建变得越来越容易。 其二则是标准化协议的出现，例如模型上下文协议（MCP）和 Agent2Agent（A2A）极大简化了模型与工具之间的链接。也是自去年底MCP横空出世起，从manus到genspark，从heygen到lovart，新的明星Agent玩家，如雨后春笋冒出，小团队、强业务创新、高实用性成为这一时期的创业团队主流画像。 他们的出现，进一步带动了Agent在千行百业的落地。LangChain的（田野）调查结果则更为激进，超过一半的公司已经在生产环境中部署Agent，近80%的正在研发Agent。 当然，这中间存在的一个悖论——知道LangChain的企业，大部分都是有Agent使用经验或者意愿的玩家。 相对而言，Gartner的预测更加保守也更具普适性代表，到2028年，33%的企业软件将使用Agentic AI，15%的日常工作决策将由Agent自主完成。 既然Agent未来将无处不在，那么如何快速找到、试用并部署Agent呢？ AWS在其Marketplace市场中目前已经上架了上百种AI Agents & Tools，用户只需用自然语言搜索，就能轻松找到所需要的Agent产品直接用于生产实践。 不过，当前情况来看，Agent的数量还远远不足以满足千行百业的需求，而通用性Agent也并不足以直接解决行业与企业的独特性问题。 在峰会现场，AWS Agentic AI 副总裁 Swami 将这些尚未被解决的困难一共总结为六点： 如何安全地执行并扩展Agent代码，如何让Agent能记住过往的互动与学习，如何让Agent的身份和权限被进一步细化，如何打造更适合复杂工作流的工具体系，如何发现和使用我们需要的工具与资源，如何让Agent的每次交互都变得可被审核可追溯？ 这些问题每一项都事关Agent能否从poc（概念试验）真正走向生产，也关系着Agent落地的体验与安全。 既然当前仍然供需不匹配，那AWS干脆把构建Agent的成本与门槛直接打下来，让更快速、灵活、大规模、更安全地去部署和构建专属Agent成为可能。 Amazon Bedrock AgentCore，如何降低构建Agent的门槛？ Agent很好，但是哪怕只是半年前，构建一个企业级Agent都依然是一个不小的难题。 原因很简单，不是所有公司都有manus与genspark这样的能力，仅仅依靠模型+框架+MCP，就能把一个概念变成生产级Agent。 要知道，传统的Agent开发，除了需要了解Docker、K8s各种云原生生产环境，还需要能够从上下文管理，到角色控制，到内存系统，再到内容生成的可控性与安全合规，每个环节都能做到极致。 而历史经验告诉我们：一个东西再好，如果它的门槛太高，产能始终受限，那就注定成为一个昂贵的玩具，而无法真正撬动一个时代的创新。 因此，对于常规的有定制Agentic AI需求的客户，AWS发布了一套完整的企业级服务解决方案——Amazon Bedrock AgentCore。 借助 Amazon Bedrock AgentCore，开发者能够直接对接Amazon Bedrock 或第三方平台部署的各类 AI 模型，并快速、安全的将 AI Agent从概念加速到生产环节。 为了弥合agent从poc（概念试验）到production（生产环境）之间的沟鸿，AgentCore 有以下七大模块： • AgentCore Runtime（运行时环境）：提供具备会话隔离机制的沙盒化低延迟无服务器环境，支持包括主流开源框架、工具和模型在内的任意Agent架构，并能处理多模态工作负载及长时运行Agent。说白了，借助AgentCore Runtime，开发者无需掌握Docker、K8s，就能直接上手agent部署。 • AgentCore Memory（记忆系统）：可以通过统一管理会话记忆与长期记忆，为模型提供关联上下文，让Agent持续学习用户偏好等信息，变得更加智能与个性化。 • AgentCore Observability（可观测性）：Agent构建难以一次到位已经成为共识，但如何发现问题，调整问题，就需要过程可视化追溯，AgentCore Observability正是为此而生，可支持元数据标记、自定义评分、轨迹检查及故障诊断/调试过滤器。 • AgentCore Identity（身份管理）：支持AI Agents安全访问AWS服务及GitHub、Salesforce、Slack等第三方工具，既可代表用户操作，也可在获得预先授权后自主执行。 • AgentCore Gateway（网关服务）：将现有API和Amazon Lambda函数转化为Agent工具，提供跨协议统一访问能力（含MCP协议），并支持运行时自动发现功能。 • AgentCore Browser（浏览器功能）：这是今年以来Agent创业最火热的方向，AgentCore Browser可以提供托管式浏览器实例，支持自动化网页操作流程扩展，可以用于访问没有程序化API的系统或需要通过Web界面访问的资源。 • AgentCore Code Interpreter（代码解释器）：提供隔离式代码执行环境，保障生成代码的安全运行。 这些服务可以单独使用，也可以协同工作，按需求按用量计费；此外，AgentCore还可以与任何AI代理框架与模型、协议（包括MCP和A2A）配合使用，真正帮助用户实现适合的才是最好的。 此外，这些能力全都基于AWS成熟的安全基础构建，内置身份控制和安全管控，让Agent原生具备企业级安全与可靠性。 企业级Agent还缺什么，应该长什么样子？ 对于常规Agent需求，通过AgentCore中的工具组合，已经可以解决80%以上的问题。但对于部分有着更高需求的企业级用户而言，深度定制化才是大势所趋。 针对这部分用户，AWS推出了两大亮点功能S3 Vectors、基于Amazon Nova模型的定制化功能，以及一个用于企业级AI coding的Agent范例Kiro。 当下，Agent成为大模型落地的主流，而多数Agent的底层，本质是一个由大模型驱动的复杂RAG系统。 所谓RAG，即检索增强生成，增强与生成部分依靠大模型，而检索部分则依靠向量数据库。 因此，活动现场AWS还推出了Amazon S3 Vectors， 一种基于对象存储的向量数据库产品，可以提供亚秒级查询性能，并将上传、存储和查询向量的总成本降低高达90%，以应对AI时代的海量非结构化数据处理需求。 但一个问题是，在此之前AWS已经推出了向量检索产品OpenSearch，为什么还要额外推出Amazon S3 Vectors？ 原因很简单，OpenSearch为代表传统向量数据库，主要将向量加载在内存之中，优势是高效、及时响应；但是内存方案快速响应的B面则是高成本。 向量数据对应的元数据通常是非结构化数据，信息密度较低、体积较大，全部加载在内存成本高昂，而S3这样的对象存储，成本显然更低，也更适合多数向量数据的检索。 技术上，S3 Vectors 引入了向量桶概念，无需配置任何基础设施，即可通过一组专用的 API 来存储、访问和查询向量数据。在这个结构中，每个向量桶都会对应一组向量索引，用于高效的对数据进行索引，每个向量桶最多可以包含10，000 个向量索引，每个向量索引可以包含数千万个向量。 此外，不同于市面上一些开源向量数据库只是单纯向量索引的集合，在S3 Vectors ，还支持将元数据与向量数据作为键值对的形式匹配，进而支持向量+时间，向量+类别，向量+颜色，向量+价格等更高级的过滤检索操作。 随着时间的推移，当用户对向量进行增删改查，S3 Vectors会自动优化对应的索引与数据分布，以实现向量存储的最佳性价比。 而对于一些对高性能、实时响应有更高要求的检索增强生成（RAG）场景，S3 Vectors则可以与亚马逊OpenSearch服务集成，将低频的冷数据存储在S3 Vectors，而将一些更高频的热数据，移动到OpenSearch，从而达成性能与成本的高效平衡。 基于高效的大模型与向量存储系统，Prompt优化和 检索增强生成（RAG）已经可以很好地用于多数Agent的落地，但是仍有一些特殊业务，仍需对模型层面进行微调从而达成目标。 一个常见的场景比如，企业需要基于RAG架构构建一个医学或者法学Agent。但是在将非结构化数据存储到向量数据库之前，还需要经过一个embedding环节，把原始数据转化为计算机可以理解的向量语言。 目前，市面上已经有了很多成熟的embedding模型，但是具体到落地，我们依然要根据业务特性不同，对各种embedding模型进行微调，才能保证农业中的苹果与科技产业的苹果被更好的区分，现实中的水桶与数据库概念中的桶指向不同含义。 基于这一背景，AWS在Amazon SageMaker AI中推出了Amazon Nova定制化的功能，对模型进行包括监督微调（SFT）、直接偏好优化（DPO）、近端策略优化（PPO）、人类反馈强化学习（RLHF）、持续预训练（CPT）、知识蒸馏等在内的操作。 目前，这些技术已经可以作为现成的亚马逊 SageMaker 组成使用，无缝部署到Amazon Bedrock，并支持按需和通过提供吞吐量推断。据AWS官方数据，目前已经有超过10000名客户使用Amazon Nova系列模型带来显著降本增效。 除了向量数据库与模型微调，最近大火的AI coding，AWS也没有落下。 针对市面上常规的IDE产品只关注coding本身，而忽略了coding背后的产品需求、文档、交互的问题，AWS推出了AI IDE产品Kiro，其关键创新有三： • 规范驱动开发（spec-driven development），可以帮助开发者通过自然语言和架构图清晰地表达他们对复杂功能的构建逻辑。 • 智能代理钩子（Intelligent Agent hooks），可以自动处理生成文档、编写测试和优化性能等重要但耗时的任务，在保存文件或提交代码等情况下自动触发。 • 专门设计的界面（purpose-built interface），支持聊天交互开发，也支持规范驱动开发，适合的就是最好的。 而借助Kiro，专业开发者不仅能更高效的产出代码，更能高效的产出高可用，更符合业务需求的代码。 尾声 回顾过去的历史，当下的AI浪潮已经不是人类历史上的第一次。而过去的多次AI泡沫已经明明白白告诉我们，模型要落地才有价值。 这也是这一轮大模型浪潮与过去的最大不同之所在： 一方面模型本身具备极强的通用能力，构建了其落地千行百业的地基； 在此基础上，经过AWS这样的企业助推，框架、数据库、调用接口、开发工具、模型微调工具依次成熟，让Agent加速从概念走向落地，甚至成为每一个行业，每一个企业的专属定制。 而这，也是技术泡沫与技术革命最大的区别之所在。 - end - 想把AI的想象力变成业务的增长力？ 2025亚马逊云科技城市巡演，聚焦最热门的 AI 场景，现场拆解、即时体验，为城市伙伴带来零距离的前沿洞察。七城席位同步开放，搜索“亚马逊云科技”小程序，即刻注册！ 本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系 hezuo@huxiu.com 本文来自虎嗅，原文链接：https://www.huxiu.com/article/4592549.html?f=baijiabaiducom 举报/反馈"
    },
    {
      "doc_id": 16818,
      "title": "模型之外,数据为王:Meta天价收购揭示AI新战场",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "文｜数据猿 “当模型军备竞赛陷入瓶颈，数据成为巨头争夺的下一个高地。 近日，Meta以148亿美元收购AI初创公司Scale AI的49%股份，这一交易将创下私营公司融资交易的历史新纪录。Scale AI是一家快速崛起的数据标注公司，拥有50多万遍布世界各地的员工，从事数据标注工作。这一重磅新闻释放了一个信号：数据在AI竞赛中的战略地位越发凸显——当模型军备竞赛陷入瓶颈，数据成为巨头争夺的下一个高地。 在这场由数据驱动、大模型实现、算力支撑的智能革命里，市场上几乎所有人都在攒模型、买算力，数据逐渐成为了这个“大三角”最薄弱的一环。 AI时代，一道悄然树立的“硅幕” 作家尤瓦尔·赫拉利指出，随着人工智能的快速发展，一道“硅幕”正在落下。这道“硅幕”不仅是企业之间，在企业内部同样显著。 ☆数据割裂与治理缺位：恶性循环的根源 过去十年数字化系统的膨胀埋下隐患：业务、系统、部门间形成数据孤岛。其根源在于支撑工具链的深度割裂——数据采集、存储、处理、分析、建模、应用等环节采用互不联通的不同工具。这种割裂制造了人为“断点”，导致数据流动受阻、价值难以整合：看似各环节工具“完整”，却因无法协同而失效。 工具链的断裂必然引发数据治理缺位。一方面源于战略轻视（在很多企业数据治理被视为“成本部门”的脏活累活）；另一方面受制于能力不足——将散碎数据转化为标准化的“数据资产”面临取数、治数、用数三重挑战。治理“失能”不仅使数据无法支撑动态业务，更会导致治理结果与业务脱节。 企业由此陷入 “高投入、低产出” 困局，加深决策层疑虑，最终形成恶性循环：数据链路断裂->价值损耗->AI决策失效->治理投入削减。打破循环不能仅靠意识觉醒，需要找到病根对症下药。 ☆千头万绪一根针：数用一体是破局关键 数据治理问题根源在于传统的 “建用分离” 模式，致业务与数据系统 “两张皮”，如果不从底层颠覆这个运行模式，数据治理工作将是缘木求鱼。 产业界急需一场深层变革。数睿数据提出的“数用一体化” 方法论，提供了一条崭新路径。其核心理念是打破工具壁垒，将数据采集等全流程置于统一连贯平台，并实现深度工具融合，使得数据从源头可治理、复用，从而支撑高效自动化建模。这一全新模式从根源上突破了业务与数据“两张皮”的困境，将数据价值直接嵌入到业务流程中，穿越“硅幕”，实现从数据支撑应用，应用支撑业务创新的跨越。 “数用一体化”的理念引人注目，但关键在于能否落地。数睿数据近期发布了smardaten2.0平台，致力于将软件工程、数据工程与AI工程化融为一体。smardaten2.0平台的问世，也将“数用一体化”推向了新的高度。我们就以此为出发点，探察“数用一体化”与产业会产生怎样的化学反应。 AI解锁医疗数据的深层价值 自从OpenAI推出GPT-4，整个世界就进入到大模型时刻。大模型的到来深刻改变了数据生态，同时也深度塑造了AI的产业化进程。 在此背景下，数睿数据率先踏入无代码领域的大模型时代。其标志性成果是融入生成式AI能力的smardaten 2.0平台。该平台基于全域实时数据，通过“低代码+AI”驱动技术民主化，实现业务敏捷响应，并在应用生成、意图识别与命令执行、深度知识检索等方面实现能力跃升。 1.数据治理智能化：从“人工追数”到“AI主动管数” smardaten 2.0依托 “专家知识库+AI双引擎”，推动数据治理从低效人工模式转向智能化，加速数据资产标准化： ·AI语义映射替代人工比对：某市卫健委想通过全民健康信息平台，为市民提供更加完善的公共服务。但平台涉及几十家医院，存在数据标准不一、数据集成统一复杂等挑战。数睿数据借助60+医疗数据模型知识库，自动识别同义表述并映射标准字段。如市卫健委45家医院 “血糖指标” 的11种说法，AI将单家医院标准化时间从3个月缩至8小时，技术门槛降70%； ·主动规则引擎适配标准迭代：将治理规则与业务场景绑定，医疗ICD编码更新时，AI自动扫描并批量更新，某三甲医院应对 “长新冠” 编码更新，时间从14天缩至40分钟，无需人工操作； ·NLP解析释放非结构化数据价值：通过自然语言处理将病历文本转为结构化数据，某区域医疗数据利用率从30%提至85%，为AI辅助诊断提供支持。 可以看到，数据治理智能化带来了效率的极大提升，并大幅降低了人工操作的环节。但必须说明的是，数据治理智能化的价值并非是为了替代人，而是让治理转为业务支撑，实现 “治理-分析-决策” 一步到位。 2.主动治理：从“消防员”到“领航员” “数用一体化”的另一重要优势是实现了数据的主动治理。很多企业数字治理采用的是事后补救，被动治理为主的模式。在瞬息万变的数字时代，这样的模式很显然是存在巨大隐患的。 继续以卫健委为例，面对医疗数据的高敏感性和频繁更新的规范（如ICD-11编码），smardaten 2.0将治理规则直接嵌入业务场景（如门急诊、住院），利用语义引擎自动化执行转换规则。当标准更新时，系统能自动同步，确保历史数据无需繁琐重映射。实现数据的主动治理标志着从“消防员”到“领航员”的治理范式转变，实现了源头管控和全生命周期的自动化合规。 3.自然语言构建：公民开发的现实图景 2.0时代，数睿数据打造了深度思考引擎的“4+3”应用构建框架、Build Copilot以及Copilot Studio三大核心功能。“4+3”框架基于应用、页面、卡片、组件的软件4层颗粒度，以及数据、样式、逻辑的功能性3元素，对软件进行系统性解构，使AI能快速构建。Copilot智能体则提供智能搭建支持，涵盖需求分析、上下文理解、文档处理、知识库检索、对话流建设等能力，并支持组装式开发与扩展。 例如”智能问数“，用户仅需输入自然语言问题，系统即可自动识别意图，精准定位相关数据资产，并实时生成分析结果（图表/报表）。用户可在对话框中对结果进行交互式调整与优化。所有分析成果均支持一键插入大屏、文档或应用页面，实现高效复用。 “我需要一套MES生产管理系统，包含销售管理、工种管理、计划管理和分析大屏。” 10分钟后，系统自动生成了包含表单、数据分析模型的原型方案和可视化大屏。整个流程中只需要自然语言即可实现。 smardaten2.0展示了惊人的效率提升，在某些场景下，数据驱动AI的应用构建效率最高可提升10倍。更加重要的是，迈入2.0时代，数睿数据那个公民开发应用的梦想，开始照进了现实。 让“沉睡”的金融数据流动，化“数据孤岛”为“数据赋能” 我们再以一个银行的合作案例作为切口，窥探“数用一体化”在金融行业的实战情况。 该行曾深陷 “建用分离” 困境：12套异构系统形成数据孤岛，“企业客户” 在不同系统中被称为 “对公账户主体”“合作单位”“授信对象” 等，字段歧义导致数据无法互通；同时，原有CRM功能简陋，厂商响应业务需求需2个月，远跟不上大宗商品业务的迭代速度。 在smardaten2.0上，破局路径彻底颠覆了传统“先集中再治理”的模式： ☆AI驱动的“边治理边联通” smardaten2.0依托金融知识库与AI语义引擎，对分散数据实施 “动态标准化”。AI能快速识别12套系统的异构字段关联，48小时就完成了传统3周才能搞定的跨系统数据映射，自动生成统一的 “企业客户” 数据资产目录。 更重要的是，治理规则和业务场景深度绑定：比如在 “跨境贷款审批” 时，平台预设了征信、纳税证明等校验规则，AI实时扫描数据，若发现贷款申请缺 “海关进出口数据”，会自动补全并标准化，让数据在流动中完成80%的标准化，打破了治理和应用脱节的问题。 ☆数据直接“生长”出应用 治理后的标准化数据并非静态存于仓库，而是应用构建的 “活素材”。当业务人员提出 “对公客户分层管理模块（含资质评分、业务往来分析、风险预警大屏）” 需求时，平台基于治理后的客户数据，自动调用相关模型和算法，1小时内就能生成应用原型，全程无需技术人员，业务人员用自然语言指令即可完成。 更关键的是 “应用反哺治理” 闭环，当业务新增 “绿色信贷客户” 标签，平台自动识别补充 “企业环保认证”“碳排放数据” 等字段，AI实时从环保局、碳交易所抓取并标准化数据，同步更新到客户分层模型。“治理支撑应用迭代、应用驱动治理深化” 的循环，让该行CRM响应周期从2个月缩至72小时，客户数据调用效率提升90%，充分体现了 “数用一体” 核心价值 —— 数据是应用中持续进化的 “活性要素”，非 “治理完再搬运” 的静态资产 。 基于一体化平台，该行此前“沉睡”的数据，经汇总统一治理后，开始在系统与应用间高效“流动”，驱动数据分析与新业务构建，成为其从“数据孤岛”向“数据赋能”跃迁的战略支点。 数据护城河决定AI时代胜负 数睿数据是国内最早一批将AI技术与数据分析、软件开发结合的科技公司之一，它的发展历程是两次AI浪潮叠加向前的一个缩影。从smardaten2.0上，除了技术的升级之外，我们还看到了一个“以数据为中心的人工智能”模式，正在成型。可以看到，当前很多大模型公司最大的发展问题不在模型身上，而是来自数据生态的结构性塌陷。 如果把视角放置在数据与AI的整个产业中，数睿数据带来了三个重要变化。 1、从“单点优化”到“全链条协同”，加速了数据决策的效率。由于数据被动态激活，以数据为核心的决策成为现实，企业得以从“事后报表”升级为“实时决策”，从“人工分析”进化为“AI协同”，最终实现数据价值指数级释放; 2、重构了数据治理的内生驱动力，使数据治理从 “成本中心” 转向 “价值中心”; 3、形成三位一体的数智体系，确立“数据即资产、应用即组装、AI即业务搭档”的融合生态。 随着大模型技术的快速、持续发展，赛道将会变得越来越拥挤，市场正在迎来重新洗牌的局面。正如我们开头所讲的Scale AI，其创始人说：“大型语言模型（LLM）竞争中的护城河在哪里，我认为数据是少数几个可以产生可持续壁垒的领域之一。” Meta的天价收购并非孤例，它昭示着一个新时代的开启：在模型军备竞赛之外，一场围绕高质量数据获取与高效治理 的“暗战”已然打响。能否穿透“硅幕”，构建强大的数据护城河，将直接决定企业乃至国家在AI时代的竞争力。处理好数据与大模型的关系，不仅是赢得竞赛的秘钥，更是拥抱智能未来的基石。 举报/反馈"
    },
    {
      "doc_id": 16820,
      "title": "大模型是“练兵”,推理才是“实战”:AI落地的硬仗才刚开始",
      "time": "2024-06-27T00:00:00+00:00",
      "content": "站在2025年中，回顾半年来大模型的发展，以年初DeepSeek爆火为标志，大模型快速蜕变角色，走出实验室，真正融入企业核心业务系统，在政务、金融、医疗、能源等领域加速落地。 随着大模型走向深度应用，CTO从关注基础模型转向推理引擎，推理过程中的资源消耗，每一度电、每一块钱、每一分钟所能产出的Token数量，正在成为衡量一家公司在AI时代先进性的关键指标。 怎么用推理引擎提升推理效率、榨干每一块算力的价值、尽可能降低推理成本，已经成为CTO们必须解决的问题。 01 大模型跑不动，是因为推理引擎不给力 什么是推理引擎？ 简单来说就是一套专门负责让大模型“跑”起来的系统，既负责“怎么算”，又负责“在哪算”和“算得多快”，尽可能提高大模型推理的响应速度、并发能力和算力资源利用率。 如果说大模型是发动机，推理引擎就是动力总成，决定了发动机在不同道路、不同油品、不同气候下是否能高效运转。调校得当，就能低延迟、高吞吐、低成本；调校不佳，再强的模型也可能“烧油多、输出低”。 大约从2023年开始，推理引擎开始作为一个独立赛道兴起，陆续出现了TGI、vLLM、TensorRT、SGLang等面向推理效率优化的开源项目。彼时业界的注意力还停留在“大炼模型”上，对推理引擎的需要求不高——能用就行。 2025年初是一个分水岭。 DeepSeek为代表的一批大模型开源后，企业对AI的态度由观望转向行动，纷纷采购算力、治理数据、微调模型，落地部署时却发现：推理响应慢、吞吐跟不上、成本高昂。 90%的算力花在了推理上，结果又贵又慢，连“谢谢”都不敢多说一句，几乎谈不上性价比。 大模型推理到底难在哪里呢？答案是效果、性能、成本的“不可能三角”。 想要效果好，就得用更大的模型、更高的精度、更长的上下文，但算力开销就上去了；想要跑得快、响应快，就要用缓存、做批处理、图优化，可能影响模型输出的质量；想要成本低，就要压缩模型、降低显存、用更便宜的算力，又可能会牺牲推理的性能或准确率。 企业的CTO们在为大模型推理焦虑时，推理引擎赛道也“热闹”了起来，不少在AI应用上“抢跑”的大厂，同样意识到了推理引擎的短板，试图将自己摸索出的经验，做成标准化产品和服务，帮企业压下这笔越来越沉重的应用账。 比如英伟达发布了推理框架Dynamo；AWS的SageMaker提供了多项增强功能提高大模型推理的吞吐量、延迟和可用性；京东云推出了JoyBuilder推理引擎，可将推理成本降低90%…… 一句话来总结：大模型能力再强，没有高效的推理引擎，就像一辆发动机不行的跑车，只能原地轰油门。 02 为了推理快、省、稳，大厂都在死磕工程创新 过去为了提高推理能力，思路主要放在模型上，通过剪枝、蒸馏、量化等技术给大模型“瘦身”。越来越多企业发现，如果推理过程上存在太多短板，模型再怎么轻，推理的效能也上不去，必须要优化推理流程。 在理解工程创新的思路前，先把大模型的推理过程拆解一下： 第一阶段（Prefill）：先听懂你在说什么。 就像人聊天前要先把对方说的话听清楚、理解透，大模型的第一步，就是认真“读题”，一字一句地“消化”，并在脑子里画好一套“思考地图”（KVCache）。 第二个阶段（Decode）：一字一句地回答你。 不是一下子把答案全说完，而是一字一句地往下写，每写一个字，都会根据刚才的思路更新一下自己的“思路地图”，确保后面写的内容更连贯、更合理。 AWS、京东云、英伟达、谷歌云等，都在“死磕”工程创新。 比如优化“思考地图”，如果“思考地图”又大又乱，占了GPU大量空间还查得慢，就会成为性能瓶颈。 AWS SageMaker和谷歌云Vertex AI的做法是给“思考地图”建了一个“缓存共享中心”，动态调度显存资源：谁先用、谁能共用、谁暂时搁置，都安排得明明白白，尽可能让GPU的价值“压榨到极致”。 京东云JoyBuilder推理引擎和英伟达的Dynamo，则进一步给出一种“以存代算”的解法：直接把“思考地图”从GPU挪出去。其中京东云通过自研的云海AI存储，支持PB级缓存扩展，并配合高效检索算法与负载感知调度，直接将多轮对话和长文本处理的响应时延压缩了60%。 再比如将“听”和“说”分离，相当于开会时让“准备”和“发言”同步进行，避免出现“干等闲耗”的场景。 其中AWS不只实现了“听”和“说”分离，还改变了大模型说话的方式，不再是“想到哪说到哪”，而是提前整理好了大纲，省下了大量来回思考的时间。 京东云JoyBuilder推理引擎的方案稍有不同：第一招和AWS相似，整体吞吐提升了30%以上；第二招是将“听”和“说”交给不同的GPU处理，两边像流水线一样并行工作，中间用“传送带”快速传递信息，大幅提升了推理吞吐量。 对CTO们而言，技术大厂的深度参与，不失为一个好消息，相当于是把推理引擎打磨成了能直接用的高性能“电子电气架构”。 03 异构算力是挑战，也是低成本取胜的机会 我们在和几位CTO沟通时，除了普遍焦虑的推理性能，还涉及到另一个问题——异构算力。 随着大模型应用的深入，以CPU为中心的架构在支持AI原生应用上面临挑战，需要以GPU为中心重塑基础设施；此外，面对激增的推理需求，计算资源持续增加，企业需要思考资源投入产出的问题，都指向需要一套AI Native的基础设施。 而异构算力，通俗来说就是将不同品牌的芯片“拼着用”。就像是一支临时组成的军队，语言、指令、作战逻辑全都不统一。以至于一位CTO打趣说：“我们要想打仗，得先发明统一的语言和作战地图。” vLLM、SGLang等比较热门的开源引擎，目前都还停留在同类型GPU之间高效调度，对“异构”集群依然捉襟见肘。但国内的研究机构和科技大厂都已经试图解决：怎样让不同芯片“听得懂一个指挥”，各司其职、取长补短。 一种主流思路是“把大锅饭变自助餐”。 过去用GPU跑模型，就像是大锅饭，一整张显卡只能给一个任务用，哪怕只吃了一口，剩下的资源也不能被别人接着用。就像京东云JoyBuilder推理引擎的策略是把异构算力资源统一管理，把一张GPU“切成很多小份”（1%），显存也能按MB级别来分，按需分给多个模型、多个任务使用，谁需要多少就用多少，GPU利用率最高可提升70%。 还有一种思路是把“拼芯片”和“拆流程”结合起来。 比如在MoE模型的部署上，京东云JoyBuilder推理引擎可以将不同专家部署在不同GPU上，让每个GPU干最擅长的活。甚至可以将“输入”部署在擅长高吞吐的昇腾集群，将“输出”部署在N卡上确保低延迟，充分利用不同算力的优势。 对于CTO们来说，在“推理成本决定最终胜利”的大模型竞赛中，异构算力是挑战，同样也是机会。 04 高性能低成本，大模型推理正在重塑AI生产力 经历了一段时间的高歌猛进后，越来越多企业对大模型的诉求，正在从“不能没有”转向要落地、要价值、要增长。我们看到，大模型已经在营销推广、协同办公、客户服务等场景深度应用，成为新的增长引擎。 例如在零售场景，包括面向用户的AI生成商品图、AI营销内容生成、AI数字人，面向管理的AI客服与售后管理、AI经营托管、AI仓配优化，以及配送环节的自动分拣机器人、自动驾驶等需求。 JoyBuilder推理引擎源于京东自身复杂业务场景打磨，基于企业级的AI Native架构，正在广泛服务于内外部众多业务场景。 京东透露了一组数据：目前推理框架已经在内部多个场景应用，在可交互式导购、商品对比、商品总结、购物建议等环节，大幅提升了响应速度，节省了计算成本，同时还有效助力了用户的活跃度；在核心的商品理解环节，也有效提升了大模型的理解能力和信息处理能力，模型推理成本最高可节省70%。 除了服务于京东内部，京东云推理引擎也广泛服务于外部产业客户，提供高性能、低成本的大模型服务。 在行业实践中，京东云成功支持某新能源汽车头部厂商、某全球新能源科技领导企业，打造覆盖全集团的智能计算底座，实现千卡级AI算力集群的精细化管理。技术上一方面创新多元算力调度，显著提升GPU利用率，另一方面创建全生命周期AI开发环境，实现开箱即用，大幅提升研发效率。 目前，该平台已支撑起企业智能驾驶研发、人形机器人等20余个核心场景，成为集团的“数智发动机”。预计一年内，两家企业大模型训练周期将缩短40%，每年节省的算力成本相当于新建两座数据中心。 05 写在最后 尽管推理引擎已经在性能压榨、资源调度和成本控制等方面取得了初步成果，但真正的竞争才刚刚开始。 尤其是在异构能力方面，无论是多种芯片的适配整合，还是对不同模型结构、大小、任务类型的统一支持，当前的技术体系还远未成熟。同时也意味着，谁能率先构建起灵活、高效、可持续的推理能力，谁就有可能在AI大规模落地的浪潮中占据先机。 这是一场跨硬件、跨模型、跨场景的系统性挑战，也将是未来十年AI竞赛的核心主战场。 举报/反馈"
    },
    {
      "doc_id": 16821,
      "title": "专题:2025大模型行业报告:能力边界与商业落地洞察",
      "time": "2024-06-27T00:00:00+00:00",
      "content": "原文链接：https://tecdat.cn/?p=42678 大模型技术正经历从“参数竞赛”到“场景落地”的关键转折。2024年高考数学测试中，主流大模型平均分仅达70%，GPT-4o得分42分的表现暴露出逻辑推理的本质缺陷；而中国智能算力以33.9%的年复合增长率飙升至2027年的1117.4 EFLOPS，又彰显着产业对算力基础设施的迫切需求。这种“能力瓶颈”与“算力爆炸”的矛盾，构成了2025年大模型行业发展的核心命题。当工具调用准确率与人类表现仍存在27.6%的差距，当金融业智算网络需要支撑万亿参数模型的200Gbps通信需求，行业正站在技术可行性与商业价值的十字路口，亟待以数据驱动的视角重构发展路径。 本报告汇总解读基于《复旦大学：2025年大模型能力来源与边界报告》《小七姐：表达力&大模型生产力——与大模型的语言游乐场报告》《北京金融科技产业联盟：金融业AI大模型智算网络研究报告》《国家工业信息安全发展研究中心&联想集团：2025大模型2.0产业发展报告：商业落地创涌而现》及文末200+份行业研究报告的数据，最新报告合集及解读实时更新已分享在交流群，阅读原文进群咨询、定制数据报告和600+行业人士共同交流和成长。 一、技术边界与能力图谱：从参数敏感性到推理天花板 大模型的能力基座建立在对训练数据的统计学习之上，但核心参数的微小变动会引发性能断崖式下跌。复旦大学研究显示，修改LLaMA2-13B语言核心区1维参数后，困惑度（PPL）从5.877骤升至3.76×10^8，而调整非核心区参数仅使PPL波动至5.914，这种“维度依赖”特性揭示了模型对关键语义表征的极端敏感性。 表：2024年大模型高考数学推理能力实测 测试模型 新I卷得分 新II卷得分 核心错误类型 Qwen2-72b 57/78.08% 46.5/63.7% 计算过程与答案矛盾、输入格式敏感 讯飞星火 52/71.23% 47.5/65.07% 复杂逻辑链断裂 GPT-4o 42/57.53% 45.5/62.33% 语义干扰导致结果偏差 这种局限性在专业领域更为显著。当移除Base-7B模型的阿拉伯语言区域后，其Arabic-MMLU得分从25.6暴跌至1.5，而越南语言区域破坏实验中，模型在中文任务中仍保持61.5%的准确率，印证了语言能力的区域化分布特征。在乘法任务测试中，GPT4零-shot对简单运算保持100%准确率，但面对OOD样本时准确率骤降至0，暴露了归纳推理能力的本质缺陷。图表1：大模型参数修改对性能的影响 图表数据及PDF模板已分享到会员群 二、产业落地的算力基座与网络架构 算力需求的指数级增长倒逼基础设施升级。从GPT-1的1P算力到ChatGPT的3120P，四年间训练算力需求增长3000倍，工商银行的实践表明，千亿参数模型千卡并行训练时，张量并行通信量达567GB/迭代，迫使金融行业构建“高性能连接+高效率传输”的智算网络架构。北京金融科技产业联盟提出的四层技术体系已在行业落地：工商银行通过RoCE网络实现存储交换网络的自主替代，将网络级联端口负载差异从5%-33%优化至12%-16%，AI集合通信带宽吞吐提升24%；邮储银行部署的200G RoCE网络支持万卡扩展，结合控制器调优算法避免训练拥塞，使断点续训效率提升35%。表：金融业智算网络关键技术指标 技术维度 传统网络指标 智算网络目标 典型案例效果 带宽利用率 <40% >90% 工商银行负载均衡优化后提升24% 故障收敛时间 百毫秒级 亚毫秒级 数据面快速恢复技术实现0.8ms收敛 安全加密等级 AES-128 抗量子加密 网存联动防止数据泄露 图表2：中国智能算力规模预测（2020-2027） 图表数据及PDF模板已分享到会员群 三、商业场景的价值释放与生态构建 大模型2.0时代的核心突破在于从“通用能力”向“场景定制”的转型。联想集团的实践显示，通过“定场景-轻量微调-开发插件”五步法则，企业智能体在营销场景中使销售转化率提升600%，从0.28%跃升至1.93%；顺丰科技的智能通系统将关务规则解读效率提升50%，运维成本降低50%，体现了行业数据与大模型融合的商业价值。个人应用领域，AIPC等终端设备正成为大模型落地的新载体。本地部署的个人大模型在100词以内的短文本任务中保持92.5%-97.5%的准确率，而工具调用场景中，GPT-4在Clean条件下的80%准确率仍与人类88.57%的表现存在差距，提示词工程从“结构化指令”向“模糊引导”的进化成为关键突破口。小七姐提出的“关系性互动”模型显示，通过融入“认知行为启发”的提示策略，可使大模型输出的专业度提升37%。表：企业大模型典型场景价值量化 应用领域 效率提升指标 成本下降指标 代表案例 智能营销 转化率提升600% 获客成本降低42% 联想MarTech平台 供应链管理 物流路径优化28% 库存周转率提升15% 顺丰智能通系统 生产制造 质检效率提升300% 误判率降至0.3% 联想AOI光学检测系统 四、未来趋势与破局路径 行业正迈向“去概率化”与“目标驱动”的技术新范式。一方面，检索增强生成（RAG）架构使模型输出的可解释性提升40%，工商银行在风控场景中通过外挂知识库将幻觉率降至1.2%；另一方面，目标驱动架构使大模型在复杂任务中表现出规划能力，Qwen2.5通过“子目标设定-逆向推理”机制，在数学问题解决中超越传统模型23个百分点。图表3：大模型技术成熟度对比 图表数据及PDF模板已分享到会员群面对万亿参数模型的算力挑战，混合异构计算成为必然选择。国家工业信息安全发展研究中心预测，2025年超节点技术将突破万卡集群瓶颈，而金融行业正探索“算网存”协同架构，通过光模块降速自愈、芯片故障快切等技术提升系统可用性。当个人大模型与企业智能体形成生态闭环，大模型行业将真正跨越技术鸿沟，实现从“生产力工具”到“创新引擎”的质变。 本专题内的参考报告（PDF）目录 2025大模型原理、技术与应用：从GPT到DeepSeek 报告2025-06-17 遥感大模型：综述与未来设想 报告2025-06-09 2025大模型翻译技术及产业应用蓝皮书 报告2025-06-02 金融业AI大模型智算网络研究报告 报告2025-06-02 表达力&大模型生产力——与大模型的语言游乐场 报告2025-05-28 2025年大模型能力来源与边界报告 报告2025-05-23 2025大模型2.0产业发展报告：商业落地创涌而现 报告2025-05-22 DeepSeek消费电子行业大模型新型应用最佳实践分享 报告2025-05-21 质量大模型及其在接口测试场景下的实践 报告2025-05-20 2025年医疗大模型研究报告-新质生产力大模型在各医疗场景的赋能实践 报告2025-05-15 2025年DeepSeek洞察与大模型应用-人工智能技术发展与应用实践... 报告2025-05-12 2025私域大模型部署白皮书 报告2025-05-11 DeepSeek等大模型工具使用手册（实战篇） 报告2025-05-07 2025年大模型平台落地实践研究报告 报告2025-05-07 从运维提效到LLMOps：如何用DeepSeek铺就大模型可观测性进阶... 报告2025-05-06。。。。。。 。"
    },
    {
      "doc_id": 16822,
      "title": "2025大模型2.0:GPT到DeepSeek技术演进与产业落地报告",
      "time": "2024-06-27T00:00:00+00:00",
      "content": "原文链接：https://tecdat.cn/?p=42738 当OpenAI在2023年推出ChatGPT时，业界或许未曾预料到，短短两年后大模型会以“2.0”形态重塑产业逻辑。本报告汇总解读基于国家工业信息安全发展研究中心与联想集团联合发布的《2025大模型2.0产业发展报告》，以及哈工大计算学部人工智能学院关于DeepSeek系列模型的技术白皮书，深入剖析大模型从“技术验证”向“商业落地”跃迁的关键节点。数据显示，中国智能算力规模正以33.9%的复合增长率狂奔，预计2027年达1117.4 EFLOPS，这种算力基座的夯实，为DeepSeek-R1等新型模型突破“推理天花板”提供了可能。 大模型1.0时代的“参数竞赛”已演变为2.0时代的“效能博弈”。报告洞察到，DeepSeek-V3以560万美元成本完成6710亿参数训练，仅为Llama 405B模型1/10的投入，这种“算力效率革命”正在打破行业垄断。从企业智能体实践到个人终端升级，大模型正以“混合人工智能”架构渗透生产生活——联想“擎天3.0”平台已在智能客服场景实现运维成本降低50%，而DeepSeek-R1在AIME数学竞赛中79.8%的通过率，更印证了推理能力向人类专家级的逼近。 本报告洞察基于《国家工业信息安全发展研究中心、联想集团：2025大模型2.0产业发展报告》及文末200+份人工智能行业研究报告的数据，最新报告合集及解读实时更新已分享在交流群，阅读原文进群咨询、定制数据报告和600+行业人士共同交流和成长。 一、大模型技术演进：从概率生成到推理优先的范式革命 1.1 技术代际跃迁：从GPT到DeepSeek的架构突破 大模型的进化轨迹呈现清晰的技术脉络：2018年GPT-1以Transformer架构开启预训练时代，2020年GPT-3凭借1750亿参数展现“少样本学习”潜力，但传统LLM的“概率生成”本质，导致其在AIME数学题中出现“铅笔比烤箱重”的逻辑谬误。这种局限性催生了DeepSeek-R1的“推理优先”架构——通过GRPO（分组相对策略优化）算法，该模型在AIME 2024测试中实现79.8%的通过率，较GPT-4o的39.2%提升近一倍（见下图）。 模型 MMLU(Pass@1) AIME 2024(Pass@1) Codeforces(Rating) DeepSeek-R1 90.8 79.8 2029 GPT-4o 87.2 39.2 1134 Claude-3.5 88.3 16.0 717 OpenAI o1-121 91.8 79.2 2061 DeepSeek-R1推理能力对比表图表数据及PDF模板已分享到会员群这种突破源于三重技术创新：一是SFT（监督微调）学习推理格式，使模型掌握数学证明的逻辑链条；二是RL（强化学习）习得推理策略，通过“准确率奖励+格式奖励”双机制优化输出；三是MTP（多词元预测）模块，将传统自回归生成的“逐词猜测”升级为“多词预演”，使Codeforces编程评级达2029分，逼近人类顶级选手水平。 1.2 成本革命：异构计算与算法压缩的双重奏 大模型产业化的核心障碍之一是“天价训练成本”。Llama 405B模型需30.8百万GPU小时、6160万美元投入，这种投入强度令中小企业望而却步。DeepSeek-V3通过“MoE稀疏专家混合+FP8混合精度训练”，将6710亿参数模型的训练成本控制在560万美元，仅为Llama同规模模型的1/10（见下图）。 模型名称 总参数量(十亿) 训练成本(百万美元) 训练卡时(百万小时) DeepSeek-V3 671 5.6 2.8 Llama 405B 405 61.6 30.8 Llama 70B 70 2.4 1.7 大模型训练成本对比表图表数据及PDF模板已分享到会员群具体来看，DeepSeekMoE架构将稀疏门控机制与跨节点All-All通信结合，使专家利用率提升3倍；FP8混合精度训练通过动态缩放因子，在保持精度的同时减少40%内存占用；DualPipe流水线技术则实现前向传播与反向传播的重叠计算，硬件利用率突破90%。这种“算法+硬件”的协同优化，使大模型部署从“云端专属”走向“边缘可用”。 二、产业生态重构：从算力基座到智能体落地的全链条变革 2.1 算力基础设施：智能算力的爆发与异构融合 中国智能算力正经历“指数级增长”：2022年111.7 EFLOPS的规模，预计到2027年将达1117.4 EFLOPS，5年10倍增长的背后，是“通用算力+图形算力+智能算力”的混合架构普及（见下图）。 年份 算力规模(EFLOPS) 2022 111.7 2023 180.0* 2024 280.0* 2025 430.0* 2026 650.0* 2027 1117.4 中国智能算力规模预测表图表数据及PDF模板已分享到会员群这种算力进化呈现三个特征：一是GPU/NPU成为主流，2027年智能算力占比将超70%；二是“私有云+公有云”混合部署成为企业首选，联想“臻算服务2.0”已实现算力按需订阅；三是边缘算力崛起，AIPC、AI Phone等终端嵌入专用AI芯片，使个人大模型本地推理成为可能。 2.2 企业智能体实践：从场景验证到价值闭环 大模型2.0的商业价值在企业场景中集中释放。联想通过“五步走”方法构建智能体：定场景（如智能质检）→轻量微调→开发插件→知识整理→提示词生成，在笔记本屏幕检测场景中，大模型辅助AOI系统实现每小时300台的检测速度，误判率低于0.1%。更深层的变革发生在生产关系层面：某烟草工厂通过智能体实现制丝生产线水分稳态预测，工艺稳定性提升15%；顺丰科技的AI Agent驱动物流路线优化，运输成本降低12%。这些案例印证了报告提出的“全栈智能化”路径——从“大模型+场景微调”到“大模型+企业私域知识库+场景闭环”，企业正通过智能体重构研发、生产、供应链全流程。 三、未来趋势：从技术突破到伦理框架的多维探索 3.1 技术演进方向：去概率化与目标驱动架构 大模型2.0的未来呈现三大趋势：其一是“去概率化”，通过RAG（检索增强生成）+知识图谱架构，解决传统LLM的“幻觉问题”，DeepSeek-R1-Zero已实现“无监督推理”；其二是“目标驱动架构”，模型从“被动回答”进化为“主动规划”，如医疗智能体可根据患者病史自动生成诊断路径；其三是“轻量化部署”，通过模型压缩技术，30亿参数模型已能在消费级终端流畅运行。 3.2 产业落地挑战：安全与伦理的平衡术 随着大模型渗透金融、医疗等关键领域，“安全-效率”的平衡成为必修课。《生成式人工智能服务管理暂行办法》的出台，标志着监管从“技术放任”转向“合规引导”。企业实践中，联想通过“数据加密+联邦学习”确保训练数据安全，某三甲医院的“本草”医学大模型则建立“伦理审查委员会”，对癌症诊断等敏感场景实施人工复核。这种平衡需要技术与制度双重保障：技术上，差分隐私、同态加密等确保数据可用不可见；制度上，建立“模型备案-效果评估-风险预警”全流程管理。正如报告强调，大模型的可持续发展，离不开“创新活力”与“安全底线”的动态平衡。 文末：本专题内的参考报告（PDF）目录 《国家工业信息安全发展研究中心、联想集团：2025大模型2.0产业发展报告》 《哈工大计算学部人工智能学院：大模型原理、技术与应用——从GPT到DeepSeek报告》 2025年中国银行业大模型应用跟踪报告 报告2025-06-18 2025大模型、Agent、具身智能及人形机器人学习全路径规划报告 报告2025-06-17 中文大模型基准测评2025年5月报告 报告2025-06-17 2025大模型原理、技术与应用：从GPT到DeepSeek 报告2025-06-17 遥感大模型：综述与未来设想 报告2025-06-09 2025大模型翻译技术及产业应用蓝皮书 报告2025-06-02 金融业AI大模型智算网络研究报告 报告2025-06-02 表达力&大模型生产力——与大模型的语言游乐场 报告2025-05-28"
    },
    {
      "doc_id": 16825,
      "title": "京东外卖拟投入20亿元为达标骑手送15万台二轮车;腾讯元宝上线图片...",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "京东外卖拟投入20亿元为达标骑手送15万台二轮车 7月16日消息，京东黑板报消息，截至二季度末，京东外卖全职骑手规模已突破15万人。京东外卖后续将投入20亿元为全职骑手升级福利，除五险一金长期保障外，寒暑季每月将为全职骑手发放专项津贴，还特别准备15万台“赤甲光刃X1”炫酷二轮车为骑手升级装备。骑手可联系站长购车，签收后使用新车90天内跑够3000单，平台返购车款，首批活动率先在北京、长沙、南京开启，后续将逐步开放至全国。 腾讯元宝上线图片AI编辑能力 7月16日，腾讯元宝正式上线图片AI编辑能力，用户输入一句话，可让元宝自动帮助P图、换背景、加光效，甚至生成风格化大片。据介绍，除了基础编辑，元宝还支持将图片转化为像素风、动漫、水彩、国风等风格化作品，用于朋友圈晒图、梗图制作、创意写真等内容创作场景。目前，该功能已在元宝手机端、电脑版和网页版同步开放。同时，元宝内的混元、DeepSeek两大模型均已支持该功能，所有用户免费使用。 中国一汽与阿里巴巴联合实验室正式揭牌，共研汽车行业大模型 7月16日消息，中国一汽与阿里云在长春成立联合实验室，基于通义千问大模型研发汽车行业专属大模型，并推动其在移动出行、企业智能运营等全场景落地。双方将通过优化算力架构、数据治理、模型训练等核心技术，提升汽车企业在研发、制造、服务等领域的智能化水平，并探索「具身智能」与「智能工业」等前沿方向。此外，双方还将共建人才培养体系，支持 AI 人才梯队建设，并已推出行业首个大模型 BI 应用和企业级智能体。 钟薛高已被申请破产，雪糕刺客钟薛高资不抵债 7月16日消息，钟薛高食品（上海）有限公司新增破产审查案件，申请人为上海臻料贸易有限公司，经办法院为上海市第三中级人民法院。据案件公告显示，因法院在执行中发现钟薛高不能清偿到期债务，并且资产不足以清偿全部债务，经债权人申请，法院中止执行，并将被执行人的案件移送进行破产立案审查。公开资料显示，钟薛高2018年于线上平台起家，陆续推出了多款单价50元以上的雪糕产品，最高的雪糕单价可达66元，后因“雪糕刺客”标签登上热搜。目前，钟薛高线上平台仅剩轻牛乳、可可等3种口味的雪糕在售。 京东健康体检中心（亦庄店）医疗美容科的服务项目上线京东App 近日，京东健康体检中心（亦庄店）医疗美容科的服务项目上线京东App。据了解，京东健康体检中心（亦庄店）拥有门诊部医疗机构资质。自2023年7月开业以来，除体检服务之外，还陆续开设了内外科、口腔科、中医科等特色门诊。本次增设的医疗美容科，将进一步丰富京东健康体检中心的医疗服务项目，让专业的诊疗服务以更优质的体验、更便捷的方式，来满足用户的个性化健康需求。 举报/反馈"
    },
    {
      "doc_id": 16830,
      "title": "腾讯App元宝发布2.0:基于新一代大模型混元Turbo,内置AI搜索",
      "time": "2024-11-14T00:00:00+00:00",
      "content": "IT之家 11 月 14 日消息，IT之家从腾讯混元获悉，腾讯元宝 2.0 版本今日正式上线，带来界面、模型、体验等方面的升级。 据介绍，界面方面的升级包括更新对话列表，支持历史使用资产沉淀，用户可更轻松地查找历史对话和用过的智能体；新增 AI 应用专属板块，精选 AI 搜索、AI 阅读、创意绘画、灵感图库、AI 美照五大应用，以及“应用广场”可提供类型丰富多样的智能体。此外，AI 搜索功能除微信公众号外，还升级整合微信视频号、QQ 音乐等信息资源，提供更加智能、便捷的搜索服务。 同时，混元模型架构也迎来升级：基于新一代大模型 \"混元 turbo\"，性能大幅提升，训练和推理效率提升一倍；支持任意长宽比及最高 7K 分辨率图片的理解分析；文生图方面，语义理解、画面质感与真实性方面也将迎来全面提升。 此外，元宝 2.0 将融入腾讯文档、电脑管家、搜狗输入法等生态产品。例如，在腾讯元宝中使用“AI 写作”生成文章后，点击“去腾讯文档编辑”即可无缝衔接到腾讯文档编辑环节，再使用 AI 文档助手优化调整。 举报/反馈"
    },
    {
      "doc_id": 16839,
      "title": "从“小透明”到“榜二”:投流3亿元、产品2天一更,腾讯押注元宝",
      "time": "2024-03-05T00:00:00+00:00",
      "content": "“免费满血高速DeepSeek体验，推荐腾讯元宝。”自今年2月以来，腾讯元宝的广告覆盖腾讯视频、搜狗、豆瓣、B站等各大腾讯系及非腾讯系平台。 腾讯元宝这一投放覆盖面堪比去年的Kimi。3月5日，《每日经济新闻》记者从AppGrowing平台（国内移动广告数据分析平台）处查询发现，2025年2月，在按投放金额排名的应用推广中，腾讯元宝排名第12，也是AI（人工智能）大模型App第一名。根据该App在所投放媒体的刊例价和广告创意数进行估算，腾讯元宝投放金额预计约3亿元。 除了投流以外，腾讯在本轮DeepSeek和AI热潮中，反应速度和实际行动较以往明显不同，对元宝的支援力度越来越大，重视程度也越来越高。在多重因素加持下，原本无论是在腾讯内部还是AI大模型App中都是“小透明”的腾讯元宝，一跃成为腾讯内部和App排行榜的顶流。 近日，腾讯元宝在中国区苹果免费App下载排行榜的第一、第二之间来回变动，曾短暂超越DeepSeek登顶榜首。3月5日，腾讯元宝最新排名是第二，位于DeepSeek和豆包之间。 图片来源：截图 从“反应过慢”到2天一更 前两年大模型狂热时，腾讯一直被市场认为是互联网大厂中反应较慢、最不着急的。2023年9月，腾讯才推出通用的混元大模型，远迟于阿里和百度。腾讯元宝的发布则是在2024年年中，彼时，百度的文心一言、字节跳动的豆包、阿里巴巴的通义千问、月之暗面的Kimi等均已发布多时。 此后，腾讯元宝在大模型App中成为“小透明”，腾讯方面也未大力推进元宝的更新或迭代。但其他大模型App虽领先，却未有现象级或超级应用的出现，直到DeepSeek空降。 腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生曾在2023年表示，对于大模型这个链条如此之长、（对）技术和算力要求如此之高的产品，不急于争一朝一夕。“大模型是一场马拉松，现在可能才跑到一公里。” 打破格局意味着有重塑和超车的可能。而腾讯这次不再慢吞吞，而是迅速反应，元宝是互联网大厂AI大模型App中率先接入DeepSeek的，而豆包和Kimi至今尚未接入DeepSeek。 今年春节后，腾讯全线产品都在推进智能化升级，元宝、QQ浏览器、腾讯文档、腾讯地图、QQ音乐等都宣布同时支持混元大模型和DeepSeek-R1模型“双引擎”。 腾讯云官方发布的信息显示，自今年2月份开始，腾讯元宝进行了密集的更新迭代，几乎是2天一更。 2月13日，腾讯元宝接入DeepSeek-R1满血版，同时支持混元和DeepSeek两大模型；2月17日，腾讯元宝灰度上线深度思考模型“混元T1”；2月18日，腾讯元宝紧急支持微信搜索，支持更多用户使用DeepSeek；2月19日，腾讯元宝全量上线深度思考模型“混元T1”；2月21日，DeepSeek和混元两大模型均能理解图片信息；2月23日，腾讯元宝上线了图片分享功能；2月25日，腾讯元宝支持一键将对话导出为长图；3月1日，腾讯上线腾讯元宝电脑版，同时，腾讯混元上线了“快思考”大模型Turbo S，吐字速度提升一倍，首字时延降低44%。 另外，对腾讯元宝引流有巨大帮助的就是接入微信端。可供佐证的是，微信搜索上线“AI搜索”功能并接入DeepSeek-R1，在灰度测试不到一天的时间，就出现因服务器繁忙无法正常使用的情况，用户对DeepSeek模型的使用热情远超预期。 近期，腾讯元宝还入驻微信生活服务“九宫格”，提供元宝下载入口。 3亿元投流背后的大力押注 腾讯对元宝的大力押注背后，是互联网大厂对AI的又一轮加码。由此，腾讯元宝的投流力度达到前所未有。 在多重因素加持下，2月22日，腾讯元宝首次超越豆包，升至中国区苹果免费App下载排行榜第二。3月3日，又成功超过了DeepSeek，登顶榜首。腾讯元宝从第二名升至第一名，只用了不到10天。 值得注意的是，在腾讯元宝大力投流的时候，未接入DeepSeek的豆包和Kimi的投流力度未有增加，Kimi仍处于低位。AppGrowing平台显示，2月，Kimi的预估投放金额为4351万元，豆包约为2793万元。 除了产品外，腾讯的内部架构也迅速出现调整，AI战略正在加速快跑，产品新矩阵正在逐步浮出水面。 继腾讯元宝从TEG（技术工程事业群）转入CSIG（腾讯云与产业事业群）之后，QQ浏览器、搜狗输入法、ima等更多产品和应用也将汇入CSIG，共同成为腾讯面向大模型时代打出的全新产品组合。 相应地，组织架构也有一系列的调整，QQ浏览器、搜狗输入法、ima等产品所在的团队和组织将从PCG（平台与内容事业群）调整至CSIG。腾讯内部人士表示，腾讯正在以高效的组织变革，持续推动AI时代的产品布局和升级。 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 16844,
      "title": "腾讯混元再升级,推出大模型App“腾讯元宝”",
      "time": "2024-05-30T00:00:00+00:00",
      "content": "腾讯混元再升级，推出大模型App“腾讯元宝” 2024-05-30 16:56:21来源：央广网 5月30日，腾讯宣布旗下混元大模型全面升级，基于混元大模型的App“腾讯元宝”正式上线，苹果及安卓应用商店均可下载。 相比此前测试阶段的混元小程序版本，面向工作效率场景，腾讯元宝提供了AI搜索、AI总结、AI写作等核心能力；面向日常生活场景，元宝的玩法也更加丰富，提供了多个特色AI应用，并新增了创建个人智能体等玩法。 “腾讯做大模型不争一时之先。”腾讯云副总裁、腾讯混元大模型负责人刘煜宏表示：“过去的一年，我们持续推进腾讯混元大模型的能力爬坡，在丰富、海量的业务场景中打磨技术，同时洞察用户的真实需求，希望腾讯元宝可以成为用户生活中的好伙伴、好帮手，最终服务于每个普通人的生活。” 当前，大模型仍在快速发展期，从模型能力到应用落地存在较大“时延”。数据显示，当前人们使用大模型相关产品时，有超过 65%的需求，集中在工作/学习效率场景，但相关的AI产品解决方案尚不成熟。 针对效率场景的三大核心需求：信息获取、处理和生产，腾讯元宝均进行了产品化探索。在AI 搜索方面，腾讯元宝接入了微信搜一搜、搜狗搜索等搜索引擎，并通过AI搜索增强，提升时新类和知识类问题效果，比传统搜索更有效率；同时，内容覆盖微信公众号等腾讯生态内容及互联网权威信源，答案准确性更高；此外，元宝还会提供所引用的参考资料，并给出相关推荐，方便快速溯源及延伸阅读。 在AI总结方面，元宝可上传最多10个PDF、word、txt等多种格式的文档，并能够一次性解析多个微信公众号链接、网址，支持256K的原生窗口上下文，相当于一本《三国演义》，或是英文原版的《哈利波特》全集。无论是希望快速了解一本书或是一个新领域，还是处理复杂繁冗的报告、文献，元宝都能帮上忙。 在AI写作方面，元宝不仅支持多轮问答，还能够将对话的内容整理成报告，按照要求进行结构化输出，大大提升信息从获取到处理再到生产的效率。 除了满足效率需要，腾讯元宝在日常生活场景，也提供了丰富的应用及玩法。“发现”栏目全面升级，上线了百变AI头像、口语陪练、超能翻译官等多个特色应用，均免费开放。只需一张照片，用户就可以在百变AI头像里体验多种风格；超能翻译官能够识别 15 种主流语言，翻译文本、图片与文件，还支持中英文同声传译；口语陪练则像一位专属私人外教，在陪练的同时给到口语改善建议，帮助用户学习与提升。 同时，元宝也支持用户根据个性化需求，快速创建个人专属的智能体，赋予角色设定，或让AI自动生成智能体相关信息，并复刻自己的音色。结合腾讯生态场景，元宝还将于近期推出腾讯新闻哥、《庆余年》主题等特色智能体。 中国科学院大数据专家李猛表示：“腾讯元宝是一款功能强大、易于使用的AI助手产品，为用户带来了便利和高效的智能体验。能够理解自然语言，并提供智能化的回答和建议，这在很多场景下为用户节省了大量时间和精力。” 除在元宝上提供自定义智能体外，腾讯混元也在积极布局智能体生态，面向开发者和企业推出了一站式智能体创作与分发平台腾讯元器。目前，腾讯元器已经全量面向用户开放。 腾讯元器提供丰富的官方插件和知识库，支持用户低门槛创建定制化的智能体，可一键分发至腾讯元宝、微信客服、QQ、腾讯云等腾讯生态渠道，并将于 6 月支持分发至微信公众号和小程序，混元模型资源全部免费。同时，元器也支持用户以API形式将智能体分发至各类场景，免费token额度从此前的100万提升至1个亿。 腾讯元宝产品能力升级的背后，是混元底层模型的持续迭代。 自 2023 年 9 月首次亮相以来，腾讯混元大模型的参数规模已从千亿升级至万亿，预训练语料从万亿升级至7 万亿tokens，并率先升级为多专家模型结构（MoE），整体性能相比Dense 版本提升超50%。除不断提升通用大模型能力外，腾讯混元也支持角色扮演、FunctionCall、代码生成等领域能力，数理能力提升 50 %。 在多模态方面，腾讯混元文生图大模型是业内首个中文原生DiT架构模型，采用了Sora、Stable Diffusion 3等行业顶尖产品的同款架构，生成效果相比上代提升超 20%。目前，该模型已经全面开源，在Github获得 2000+star，相关能力也全面融入腾讯元宝。 此外，腾讯混元大模型在视频、3D生成等方面也持续探索，目前已经支持16s视频生成，单图仅需30秒即可生成3D模型，相关能力也将于后续在元宝中上线。 目前，腾讯内部有超 600 个业务及场景都已经接入腾讯混元，腾讯广告、微信读书、腾讯会议、腾讯文档、腾讯客服等，都已经基于混元实现了智能化升级。腾讯广泛的应用场景，也进一步反哺了大模型能力的提升。 据了解，为了满足开发者及企业客户对于通用模型能力的需求，腾讯混元大模型已通过腾讯云对外开放，可通过API调用，也可以作为基底模型，为不同产业场景构建专属应用。 编辑:万玉航 更多精彩资讯请在应用市场下载“央广网”客户端。欢迎提供新闻线索，24小时报料热线400-800-0088；消费者也可通过央广网“啄木鸟消费者投诉平台”线上投诉。版权声明：本文章版权归属央广网所有，未经授权不得转载。转载请联系：cnrbanquan@cnr.cn，不尊重原创的行为我们将追究责任。 热榜 23岁男子在海南潜水失联十余天 官方通报2025-07-24 11:08:37棉密码回应“卫生巾被曝检出致癌物”：所有产品均严格遵循国家相关法律法规及标准2025-07-24 18:16:49江苏丹阳杜宾犬事件后续：小区仍无监管2025-07-25 00:30:51四川古蔺龙山镇边坡垮塌搜救结束 3人遇难2025-07-24 14:35:33警惕虚假招生信息 云南两所高校紧急声明2025-07-24 11:50:40 长按二维码关注精彩内容 专题 更多>>"
    },
    {
      "doc_id": 16845,
      "title": "AI助手App“腾讯元宝”上线 大模型应用走向何方?",
      "time": "2024-05-31T00:00:00+00:00",
      "content": "来源：证券日报 本报记者 李豪悦 5月30日，腾讯上线基于自研混元大模型的C端AI助手App“腾讯元宝”。公开数据显示，截至2024年4月份，中国的大模型数量已近200个，通用大模型数量40个左右，包括百度的文心一言、字节跳动的豆包、科大讯飞的星火、阿里巴巴的通义千问、腾讯的混元、华为的盘古等。 相比其他大厂的C端应用，“腾讯元宝”有何特别之处？随着各大科技巨头的应用产品陆续发布，大模型应用的下一步将如何发展？“超级应用”又将于何时问世？ 成本更低、上限更高 事实上，腾讯此前已在网页和小程序端推出了腾讯混元助手。相比之前的产品，“腾讯元宝”针对信息获取、处理和生产三大核心需求，均进行了产品化探索。而此次“腾讯元宝”产品能力升级的背后，是腾讯混元底层模型的持续迭代，大模型效果提升了50%。 据腾讯云副总裁、腾讯混元大模型负责人刘煜宏介绍，腾讯内部有超600个业务及场景都已经接入腾讯混元，腾讯广告、微信读书、腾讯会议、腾讯文档、腾讯客服等均已经基于混元实现了智能化升级。腾讯广泛的应用场景，也进一步反哺了大模型能力的提升。“具体到工作中，目前大概23%的代码是混元大模型生成的。混元在腾讯日均调用达到2亿次。” 腾讯曾披露混元大模型为业务增收的效果——促进广告收入同比增长20%，2023年第三季度相关业务收入增至257.2亿元。 对于混元大模型在行业中的地位，刘煜宏表示：“第一，腾讯产品或工程能力较强，能力同等情况下我们有更低的成本；第二，腾讯产品体系最全，对应用领域的适配度更强；第三，我们发布产品的时间比较晚，但是技术演进方面一点不落后，上限更高，能够处理更复杂的一些指令。” 探索“超级应用” 尽管国内大模型数量已近200个，但业内的共识是，整个AI大模型行业仍处于初级阶段。 “大模型在国内渗透率不足1%。”刘煜宏表示，渗透率低一方面是用户认知仍在建立，另一方面是AI产品解决方案不够成熟。 在此背景下，国内科技巨头更倾向于自己是在投资未来的“超级应用”。 百度创始人、董事长兼首席执行官李彦宏今年5月份对外表示，中国AI与西方的最大区别在于应用。“中国有数百个基础模型，但人们越来越多地在讨论什么是AI时代的‘超级应用’。应用驱动了中国AI的快速发展。” AI领域的“超级应用”应该是什么样子的？好比微信之于熟人社交，抖音之于短视频。如果从这个角度看，国内科技巨头的C端应用虽然已经陆续发布，但距离“超级应用”仍有较远的距离。 “目前AI圈子里的共识是‘超级应用’还没有出现，各大公司都在探索。”蓝色光标BLUE AI项目中心负责人李林波表示。 李彦宏表示，应用的进步可以推动基础模型的创新，也有助于加快从互联网时代向人工智能时代的转变。在基础模型的数据训练方面，“超级应用”诞生后，可以促进大量数据生成，为大模型提供更加充沛的训练数据。 而超级应用的诞生方向，目前也没有一个准确的判断。从国内科技巨头眼下推出的应用所覆盖的领域以及投资方向看，企业更倾向于广撒网。 赛智产业研究院副院长邓道正告诉《证券日报》记者，要成为生成式AI“超级应用”，需要能够帮助解决复杂问题，并在实际应用中展现出显著效果和广泛影响力，通常需要具备几个特点：一是创新性，需要对新技术、新方法具有探索和创新，能够开辟新的应用场景；二是影响力，能够在各领域产生广泛的社会和经济影响，提升效率、降低成本、改善生活质量；三是高性能，“超级应用”需要大模型在性能上达到一定的标准，能够在实际应用中快速响应、准确判断，并为用户提供高质量的服务；四是可扩展性，“超级应用”需要适应不同的应用场景和数据集，具备可扩展性和可定制性，以适应不同的需求和挑战。 “‘超级应用’是多方面综合作用的结果，需要在技术、数据、算力、资金、政策、应用、安全等多方面加强支持。”邓道正进一步表示。 举报/反馈"
    },
    {
      "doc_id": 16846,
      "title": "腾讯上线大模型App“腾讯元宝”",
      "time": "2024-05-30T00:00:00+00:00",
      "content": "5 月 30 日，腾讯宣布旗下混元大模型全面升级，基于混元大模型的App“腾讯元宝”正式上线，苹果及安卓应用商店均可下载。 相比此前测试阶段的混元小程序版本，面向工作效率场景，腾讯元宝提供了AI搜索、AI总结、AI写作等核心能力；面向日常生活场景，元宝的玩法也更加丰富，提供了多个特色AI应用，并新增了创建个人智能体等玩法。 比如，在AI写作方面，元宝不仅支持多轮问答，还能够将对话的内容整理成报告，按照要求进行结构化输出。此外，只需一张照片，用户就可以在百变AI头像里体验多种风格；超能翻译官能够识别 15 种主流语言，翻译文本、图片与文件，还支持中英文同声传译。 据悉，自 2023 年 9 月首次亮相以来，腾讯混元大模型的参数规模已从千亿升级至万亿。在多模态方面，腾讯混元大模型在视频、3D生成等方面也持续探索，目前已经支持16s视频生成，单图仅需30秒即可生成3D模型，相关能力也将于后续在元宝中上线。 文/北京青年报记者 温婧 编辑/樊宏伟 举报/反馈"
    },
    {
      "doc_id": 16847,
      "title": "“百模大战”生变 巨头集体转向开源",
      "time": "2024-07-05T00:00:00+00:00",
      "content": "中经记者 秦枭 北京报道 大模型行业正在从“参数竞赛”向“生态共建”转变。近日，华为正式宣布开源盘古70亿参数的稠密模型、盘古Pro MoE 720亿参数的混合专家模型和基于昇腾的模型推理技术。百度也宣布同步开源文心大模型 4.5 系列 10 款模型，而在此前，腾讯、智谱、月之暗面等大模型厂商也将自家的大模型开源。 多位业内人士在接受《中国经营报》记者采访时表示，模型开源，不是免费的午餐，而是平台战争的入场券。对大模型企业来说，模型本身不是护城河，生态才是。尤其是在“模型能力高度趋同”的今天，谁能先构建起一整套“可调用、可调优、可部署”的模型体系，谁就掌握了议价权。更进一步看，开源其实也是降低竞争焦虑的一种方式：把基础层共享出去，大家比拼的不是“参数数值”，而是“产业落地能力”。这反而让真正有工程能力和行业经验的厂商有了更多主导权。 巨头竞相开源 2025年上半年最后一天，国内人工智能领域迎来开源生态的集中爆发。华为与百度两大科技巨头同时公布开源计划——华为正式开源部分盘古大模型体系，百度则推出文心大模型4.5系列的开源方案。 据悉，华为此次开源的盘古 Pro MoE 模型基于分组混合专家模型（Mixture of Grouped Experts, MoGE）架构构建，总参数量达720亿，激活参数量为160亿，并针对昇腾 300I Duo 和 800I A2 平台进行了系统优化。 在华为宣布开源部分盘古大模型的同天，百度也宣布在中国正式开源文心大模型4.5系列模型，涵盖47亿、3亿激活参数的混合专家（MoE）模型与0.3亿参数的稠密型模型等10款模型，实现预训练权重和推理代码完全开源。 值得注意的是，百度此前一直是闭源路线的坚持者，DeepSeek的爆火出圈促使百度在今年年初的时候便宣布将在未来几个月中陆续推出文心大模型4.5系列，并于6月30日起正式开源。 事实上，自今年年初以来，多家大模型厂商已纷纷转向开源。百度和华为的此次举措是国内科技企业开源战略的进一步延续。在此之前，阿里巴巴已通过发布多个版本的开源大模型以及运营魔搭社区，成功构建起较为完善的开源生态系统；腾讯的混元大模型也早已开源了其混合推理 MoE 模型 Hunyuan-A13B 以及 3D 生成模型等。 所谓的开源大模型，是指“你可以免费查看源代码、修改代码、使用模型”，并且在大多数情况下，这些模型都是免费提供的。那么，为什么动辄耗费数千万元进行训练的大模型会选择“白送”呢？ 商业顾问、企业战略专家霍虹屹分析道，当下这波大模型开源潮，并非偶然爆发，而是多重因素共振的结果。其一是国际技术潮流的推动。OpenAI、Meta、Mistral 等海外厂商已率先释放了大量开源模型，不仅提升了模型能力的“基准线”，也迫使国内厂商加速响应，避免在生态构建上落于人后。在这种环境下，“不开源，等于放弃开发者”。 “以DeepSeek为代表的开源模型的成功，给闭源厂商带来了巨大压力。”萨摩耶云科技集团首席经济学家郑磊直言，“其开源模式吸引了大量用户和开发者，提升了行业基础标准，迫使其他厂商重新审视自身商业模式，纷纷加入开源阵营。开源可以让厂商在行业内树立良好的形象，提升自身的影响力和话语权。通过开源，厂商可以展示其技术实力和创新能力，吸引更多合作伙伴和用户。” 天使投资人、资深人工智能专家郭涛则认为，当前大模型“开源潮”的兴起是技术、市场与政策协同作用的结果。技术层面，大模型参数规模突破百亿级后，训练与部署的工程化能力趋于成熟，开源的技术风险显著降低；同时，混合专家架构的优化使得模型性能与资源利用率提升，为开源提供了技术可行性。 霍虹屹补充道，对大多数企业来说，闭源大模型训练成本高、门槛重，而开源模型则提供了“即插即用”的基座，降低了“跑通第一步”的试错成本。特别是盘古和文心4.5的开源，不仅带来了参数规模与推理技术的双向突破，更通过昇腾、昆仑芯等软硬协同，试图以中国本土化能力建立“新标准”。 技术平权还是洗牌加速？ 然而，在数字经济时代，开源模式正逐渐展现出其独特的商业价值。尽管开源意味着将技术源代码公开，看似与商业体系中保护知识产权、追求利润最大化的原则相悖。 霍虹屹认为，开源看似与“闭环盈利”背道而驰，实则是一种长期价值的重新布局。在AI领域，“闭源等于产品”，“开源等于生态”。闭源适合做封闭系统、标准化服务；而开源，更适合打造平台级入口与开发者网络。这是一个“牺牲部分边际利润，换取生态控制权”的战略决策。 郭涛表示，创业公司与开发者社区将成为直接受益者。中小企业可基于开源模型快速开发垂直领域应用（如医疗、教育），绕过从零研发大模型的高昂成本与技术壁垒；开发者则通过微调、场景化适配等操作，推动技术落地并反哺生态，形成“技术民主化”红利。云服务商与硬件厂商（如华为昇腾、阿里云等）亦会受益，开源模型需依托算力平台运行，间接拉动云服务与专用硬件需求，同时通过模型优化强化自身技术优势。传统行业巨头（如金融、制造业企业）则可通过定制化开源模型提升业务效率，加速数字化转型。 不仅如此，在业内人士看来，大模型厂商通过开源吸引开发者生态，可快速扩大市场影响力并抢占行业标准制定权，或将进一步加剧大模型的“洗牌”。 壹通数字技术公司罗富国认为，开源潮也将促使行业进入新一轮洗牌期。一方面，开源使得技术门槛降低，新玩家更容易进入市场，加剧市场竞争；另一方面，厂商需要不断提升自身技术实力和服务质量，以期在开源生态中占据优势地位。 那些能够快速适应开源趋势、优化技术和服务的厂商，将在竞争中脱颖而出；而那些技术滞后、生态建设不足的厂商，则可能面临被市场淘汰的风险。 在霍虹屹看来，行业洗牌大概率会发生，一些仅仅拥有参数优势但缺乏生态托举的模型厂商，将逐步边缘化；而真正能将开源模型打造成“二次开发工具箱”的平台，将获得持续的竞争力。在这场开源竞赛中，未来赢家的画像可能是：一方面拥有强大底座能力（硬件、框架、推理引擎），另一方面则要有开放的生态策略（模型版本更新快、社区参与度高、工具链丰富）。模型能力，不再是门槛，而是入口。 举报/反馈"
    },
    {
      "doc_id": 16849,
      "title": "大厂AI人才争夺战升级",
      "time": "2024-06-16T00:00:00+00:00",
      "content": "作者 | 黄昱 编辑 | 王小娟 在争夺AI技术话语权的关键时期，科技巨头们正以近乎军备竞赛的姿态争夺AI人才。今年以来，战火更持续升级。 华尔街见闻获悉，6月16日，腾讯发起算法大赛，拿出数百万丰厚奖金池和校招Offer吸引全球人才，其中冠军团队将获得200万元奖金，前十强选手可直接获得腾讯核心业务部门录用机会。 这是继腾讯4月份启动史上最大规模招聘计划之后，首次通过有丰厚奖励的比赛来招揽AI人才。 据悉，此次算法大赛由腾讯广告主办，以体现行业前沿AI技术的“全模态生成式推荐”为赛题，也是国内首个生成式推荐算法大赛。 腾讯在AI上的投入决心有目共睹。 3月的业绩会上，腾讯曾宣布，在去年767亿元资本开支创历史新高的基础上，会在2025年进一步增加资本支出。在研发方面，将继续投资自研模型，并加速各个业务集团的 AI 应用开发；同时，腾讯还将在市场营销方面进行投资，以提高用户对新AI产品，比如说元宝的认知和采用率。 今年第一季度，腾讯资本开支达274.8亿元，同比增长91%，占营收15%；此外，腾讯的一般及行政开支同比增长36%至336亿元，这部分增长除了因为一笔40亿元的海外收购外，主要来自AI相关业务增加的研发开支。 腾讯董事会主席兼首席执行官马化腾表示：“我们相信，在AI战略投入阶段，现有高质量收入带来的经营杠杆，将有助于消化这些AI相关投入产生的额外成本，保持财务稳健。” 财报显示，今年一季度，腾讯实现营收1800.2亿元，同比增长13%；Non-IFRS（非国际会计准则）归母净利润为613.29亿元，同比增长22%。 经过过去两三年的“收敛聚焦”后，在AI的驱动下，腾讯已经进入新一轮扩张周期。 而要想在这场全球AI竞赛中拔得头筹，人才可以说是最重要的竞争力。 腾讯也必然要招揽更多AI人才。4月17日，腾讯宣布启动史上最大就业计划，三年内将新增 28000个实习岗位并加大转化录用，其中仅 2025年，就将迎来 10000名校招实习生，有六成面向技术人才开放。 腾讯方面表示，在大模型加速落地的背景下，腾讯加大了人工智能、大数据、云计算、游戏引擎、数字内容等技术类岗位的招聘力度，技术类岗位“扩招”力度空前。 6月12日，面向全球招募顶尖技术学生，腾讯又启动了“青云计划”，重点支持十大前沿技术领域的人才培养。 据悉，“青云人才”入选后，将会匹配专属岗位导师、发展导师、项目顾问，且有个人定制的成长培养计划，匹配学术顶会、科技大会、跨界科研交流等专属资源，全面助力成长。 同时，腾讯将为这批技术人才提供上不封顶的薪酬，和优先落户、租房等多项专属生活福利。 当然，不只腾讯，今年以来，科技巨头纷纷加码AI人才争夺。 6月15日，百度官方透露，正式启动面向2026届毕业生的大规模AI人才招聘。据了解，本届招聘计划的岗位数量较往年扩增超过60%，涵盖百度23个核心业务部门和11类技术研究方向，是百度最大规模的顶尖AI人才招聘。 为了招纳到顶尖的校园人才，百度也提出了offer薪资上不封顶的条件。 此外，在阿里国际今年4月启动的2026届校招中，80%为AI岗位，包括AI算法、研发、AI产品经理等。同时，阿里国际首次启动了面向全球的头部AI科技人才培养计划Bravo102，该计划打破传统的校招体系，面试通过后可反选项目和团队，入职后享受晋升绿色通道。 5月，京东也推出“顶尖青年技术天才计划”，面向全球高校本硕博毕业生及毕业两年内的技术人才开放招募，薪酬不设上限，研究方向涵盖多模态大模型与应用、AI Infra等方向。 国际巨头Meta 最近也传出消息，其正向少数顶尖 AI 研究员抛出了极具吸引力的丰厚薪酬，试图借此打造超级智能 AI。 在ChatGPT掀起AI大模型浪潮两年多后，AI应用正迎来前所未有的爆发，人才竞争的激烈也可想而知。 人才解决方案提供商翰德（Hudson）近日发布《2025人才趋势报告》指出，AI的突破性进展将人才需求推至新高，高端AI人才争夺战进入白热化阶段，顶尖人才稀缺性进一步加剧。 翰德数据显示，今年春节后，AI方向的招聘量同比增长约25%，尤其是算法工程、算法优化、AI基础设施相关方向的招聘热度持续飙升。 在此背景下，AI人才的供需比仅为0.5，这意味着每两个AI岗位仅能匹配到一位合适的候选人。特别是在强化学习、大模型算法、多模态算法等方向，顶尖研究员和工程师供不应求。 这种供需失衡也直接导致顶尖人才掌握了自主定价权。 据翰德数据，行业前20%的顶尖AI人才在跳槽时薪资涨幅可达30%-50%，其中强化学习领域的顶尖研究员和工程师更是成为头部企业争夺的焦点。同时，那些在国际顶刊发表论文的作者在人才市场中占据主导地位，其议价能力远超其他竞争者。 就连AI相关岗位的实习生也身价大涨，月入过万十分常见。 在此背景下，为了招揽AI人才，腾讯、百度、京东等提出薪酬不设上限的做法也是必须摆出来的筹码。 这场AI竞赛已经进入淘汰赛阶段，要想成为最终的赢家，所有公司都必须拿出足够的诚意，去招揽世界上最顶尖的人才。 本文来自华尔街见闻，欢迎下载APP查看更多 举报/反馈"
    },
    {
      "doc_id": 16854,
      "title": "大模型厂商“智能体大战”升级:腾讯云如何卡位B端赛道",
      "time": "2024-05-24T00:00:00+00:00",
      "content": "本报（chinatimes.net.cn）记者卢晓 北京报道 从为自己点一杯咖啡到让客户快递顺利下单，作为AI应用的一个重要方向，智能体不仅日渐渗透进人们的日常生活，也越来越多地出现在工作场景中。 5月21日，腾讯宣布腾讯云大模型知识引擎全面升级为“腾讯云智能体开发平台”。腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生当天还表示，随着AI的持续落地，每个企业都将成为AI公司；每个人都将是AI加持的“超级个体”。 在这背后，面向B端市场的智能体已经成为大模型厂商们的竞争焦点。他们现在比拼的是谁能帮助庞大的中小企业们更快地建立起更好用的智能体，为他们增加更多的“虚拟好员工”。 加码B端市场 据腾讯方面介绍，腾讯云智能体开发平台首次实现了零代码支持多智能体的转交协同方式，进一步降低了智能体搭建的门槛。而面向确定性比较高的执行流程，用户也可以采用工作流模式，拖拉拽各种原子能力，让智能体基于固定流程运行，得到更确定性的结果。 “腾讯云智能体开发平台的定位是为客户搭建更强大、更复杂的智能体应用。”5月21日，腾讯云副总裁、腾讯云智能负责人、腾讯优图实验室负责人吴运声在接受《华夏时报》等媒体记者采访时这样说。 他认为，在 ToB 场景下，Agent 的本质是一种新的应用形态。它和传统软件最核心的区别在于，它具备自主规划能力，可以根据用户的自然语言指令，自主调用工具，甚至多个 Agent 协同完成一个复杂任务。这种范式和过去软件预设流程有本质不同。 需要提及的是，据记者了解，腾讯混元大模型团队此前已经推出过智能体开放平台“元器”。吴运声当天对本报记者表示，这两者是面向不同用户群的产品形态，“元器”偏C端，主要是跟“元宝”结合，用来为个人用户或轻量开发者提供智能体定制能力，而“腾讯云智能体开发平台”则是面向B端的企业级平台。 在推出智能体平台背后，腾讯大模型正在迅速迭代和开源。据记者了解，早在去年下半年，腾讯就大力投入了深度思考模型的路线攻关，混元T1自年初上线元宝App后，持续快速迭代。基于混元TurboS基座，腾讯新推出视觉深度推理模型混元T1 Vision和端到端语音通话模型混元Voice，近期还将推出实时视频通话AI体验。 腾讯云副总裁、腾讯混元大模型技术负责人王迪还介绍，目前混元已实现图像、视频、3D、文本等在内的全模态开源，未来将推出多尺寸混合推理模型，从0.5B到32B的dense模型，以及激活13B的MoE模型，适配企业与端侧需求。混元图像、视频、3D等多模态基础模型及配套插件模型也将持续开源。 智能体竞赛打响 随着智能体逐渐在汽车、 金融、 文旅 、消费电子 、医药连锁、零售等行业落地，大模型厂商围绕智能体的发力早已开始。 今年4月，阿里云百炼宣布上线业界首个全生命周期MCP服务，无需用户管理资源、开发部署、工程运维等工作，5分钟即可快速搭建一个连接MCP服务的智能体。百度创始人李彦宏去年11月在百度世界2024大会的发言中就称，智能体是AI应用的最主流形态，即将迎来爆发点。 对于大模型厂商在智能体领域的集体发力，吴运声对本报记者表示，这源于大家都看到智能体技术快速发展，尤其是智能体具备自我规划和调用工具完成复杂任务的能力在不断增强，此外应用业务的发展需求随着技术提升也在增长，智能体能够更好地满足客户复杂多样的场景需求，“市场多家竞品百花齐放是好事，有利于技术发展。” 他同时表示，腾讯自身专注的是如何构建能力更强、更丰富的智能体应用，这需要调用多种已有能力和不同模型，“技术节奏的加快是被真实业务需求推动的。我们过去很多年的能力积累，现在正好借助大模型、Agent等最新范式重新激活，用更智能、更高效的方式去解决问题。” 据记者了解，腾讯今年一季度已经进行了一系列AI相关的组织架构变化。公开资料显示，今年2月，继腾讯元宝从TEG（技术工程事业群）转入CSIG（腾讯云与产业事业群）之后，QQ浏览器、搜狗输入法、AI智能工作台ima等产品应用和团队也将汇入CSIG。在5月21日的采访中，吴运声也提及，“不管是办公还是生活场景，浏览器都是非常核心的交互工具，如果智能体具备了使用浏览器的能力，那它的‘行为边界’就大大拓展了，可以覆盖很多真实场景。这也是我们平台赋予开发者和客户‘想象空间’的关键。” 他当天还透露，未来腾讯也在研发本地电脑的沙箱能力（Computer Use 插件），让智能体可以操作本地软件、编辑文档、调用工具，就像一个“虚拟操作员”，“你设想一下，如果一个Agent不仅能上网，还能帮你打开Excel自动填报表格、用Photoshop批量裁剪图片，那它在企业内部的价值就会非常大。” 不过对于智能体的发展现状，深度科技研究院院长张孝荣对《华夏时报》记者表示，如何让用户觉得有价值并产生粘性，是智能体发展的关键挑战，其他还包括安全性与伦理问题、计算资源消耗、复杂工具使用以及多智能体交互机制等。他认为，智能体商业化进程还面临成本挑战，特别是在智能体交互过程中出现的错误循环和高token消耗问题。 责任编辑：黄兴利 主编：寒丰 举报/反馈"
    },
    {
      "doc_id": 16855,
      "title": "AI战场,腾讯向左,阿里向右",
      "time": "2024-05-23T00:00:00+00:00",
      "content": "文 | kiki 作为中国两家公开表示「追求AGI」的科技大厂，腾讯和阿里成为了「互联网大厂派」中对AI投入最激进的两个典型案例。 这几天，腾讯前脚在北京开了今年的AI产业应用峰会，把主题定位「全面拥抱AI」，阿里云后脚就开了中企出海大会，继续展露全球化的野心。 特别是自DeepSeek「掀桌」的三个多月里，腾讯和阿里的共同动作体现在三方面： 一是自上而下快速决策承接DeepSeek流量，让这一超级入口「为我所用」； 二是推动整体业务AI化，阿里巴巴董事会主席蔡崇信此前在510阿里日亲友见面会上表示，阿里要把AI融入每一块业务、每一块环节，未来三到五年，所有业务都应以AI为驱动； 三是AI的早期红利也已反应在基本面上。据最新的财报业绩和电话会，AI给两家科技大厂的基本面带来实质性贡献，比如，阿里的电商和云，腾讯的广告和游戏。 但两家科技巨头的AI路线也出现明显的分野。 我们试图以从业务基本盘、应用逻辑和组织人才三个层面，结合腾讯和阿里的最新财报，拆解它们的不同。 1、AI基本盘不同：阿里要入口，腾讯要故事 相比2024年大模型战场上的高调的刷榜评分，2025年，来自DeepSeek的「暴击」，彻底调转了腾讯和阿里的AI布局风向。 一年前，尽管已提出「用户为先，AI驱动」的战略，但市场对阿里的AI布局理解为「微软+OpenAI」，彼时竞技场上最耀眼的还是「大模型六小龙」们，而腾讯在AI上过于谨慎克制的投入难免让人想起库克和他的苹果——有天然的流量入口，但对AI呈现明显的防守态势。 DeepSeek如同一条鲶鱼，彻底搅活了大模型这池春水，也刷新了人们对两家科技大厂的认知。 一方面，腾讯和阿里因此变得更开放，也更激进，两家企业高管均在2025年对外释放极为强烈的AI乐观主义，马化腾甚至在财报电话会上直言：“未来应用大发展的机会已经到来”。 另一方面，开源带来的技术平权，DeepSeek以「低成本、高效率」的新技术范式让下游应用开发变得更具性价比。这之中，阿里Qwen的出圈赚足了开发者的好感，腾讯则在加速已有应用场景和AI原生应用的开发更新速度。 但尽管步调类似，双方的意图则全然不同——阿里要的是AI入口，腾讯要的则是AI故事。 这种差异当然取决于它们的基本盘。 阿里目前电商业务（淘天+阿里国际）依旧贡献了接近六成的收入，淘天更是贡献了阿里的主要利润。 但电商已是存量市场，并不占据主要的用户入口，蔡崇信此前也强调，电商是一个垂类，有更多其他的互联网公司占据了对用户的入口。“阿里能聚焦在AI上的话，能够对整个入口的突破，也许可以把新的入口用AI的方式做出来，让阿里增加更多的用户”。 阿里近期与美图的合作也印证了对「流量的渴求」。阿里以2.5亿美元可转债的形式投资美图，美图则承诺未来三年向阿里采购不低于5.6亿元的云服务。 而另一边以广告和游戏为现金牛业务的腾讯，并不像阿里拥有「云+AI」顺畅的成长性逻辑，因此向AI要增长，显然也是向未来要成长性。 今年的两次财报电话会上，腾讯高管都主动披露了Agent相关进度，马化腾就提到：“每个人都可以做通用的智能体AI，微信有可能形成独特Agent AI生态，与微信生态系统的独特组成部分相连接，包括社交图谱、内容生态系统（如公众号、视频号），以及微信内数百万个小程序。” 当然这些都只是AI长期叙事，阿里能否造出AI时代的新入口，腾讯能否讲出如Agent一样的新故事，这些决定了两家巨头是否能成为一家「AI公司」。 2、做AI应用的方法论不同：阿里「合」，腾讯「分」 腾讯和阿里对AI的大笔投入，对外展现出的长期耐心，似乎让互联网大厂重回曾经的「古典时代」。 一边的马化腾在内部频繁提及「Debug」文化，另一边是频繁现身阿里的马云，有阿里员工甚至调侃：“马云出现越频繁，阿里的日子越好。” 移动互联网时代，一句「技术看百度，产品看腾讯，运营看阿里」曾总结了大厂各自的生态位，但在AI时代，一切都变了。 重新找到新生态位的关键之一，无疑就在AI应用侧。 阿里巴巴集团CEO吴泳铭对AI领域的两个最新研判也都关于「应用」，他提到，一是在大中型企业，AI应用开始从内部系统向用户侧场景渗透；二是积极使用AI产品的客户，从大中型企业延展到大量中小企业。 「吴妈」的话翻译过来，就是BC两端，软硬两侧，AI的扩散和渗透都在加速。 但具体在AI应用侧，腾讯和阿里是两种截然不同的做应用逻辑。 阿里自上而下，腾讯自下而上；阿里「合」，腾讯「分」。 从去年年底，大厂均开启了新一轮的组织架构调整，一致的共识是从「模应一体」转向将应用与基础模型分离。 去年年底，阿里将通义千问一分为二，模型层留在阿里云，而2C产品则从分到了阿里信息智能事业群。今年开始，腾讯先是将元宝应用团队从腾讯混元所处的TEG（技术工程事业群）产品团队并入到CSIG（云与智慧产业事业群），2月，QQ浏览器、搜狗输入法、ima等更多产品和应用也汇入了CSIG。 模型和应用分开，并不奇怪，本质上是专业化分工的体现。 但阿里在专业分工中呈现出「自上而下」的「合」。 阿里云CTO周靖人在接受晚点采访时提到，尽管分工更清晰，但协作很紧密。虎嗅此前也提到，「吴妈」也会频繁参与到基础模型团队的业务沟通之中，并密切留意模型团队的各种进展，另一年阿里「AI to C」的扛旗者吴嘉也直接向「吴妈」汇报。 从阿里AI原生产品的整合中也能看出，此前通义团队推出的AI原生产品通义听悟迅速被集成进夸克，目前在AI应用侧，阿里有通义APP和夸克两个C端产品，双方间尽管在产品定位上有类似，但在「合」的大思路下，并不排除未来打通和整合的可能。 相比之下，有着充足C端经验的腾讯，其AI产品呈现出「自下而上」的特点，因此AI探索相对独立，但也更佛系。 腾讯的AI原生工具ima就是一个典型案例，ima产品团队提到，团队起初的主要开发者来自QQ浏览器，项目最初启动在去年7月，用不到半年的时间跻身腾讯的明星产品之列。 几天前，腾讯又推动另一个应用入口的AI化——QQ浏览器宣布升级为AI浏览器，参考管理层在财报点会上对Agent的表述，腾讯在应用端的AI创新尝试都还在继续，公司高层也曾表态，针对开发独立的AI工具产品，在资源保障的前提下，将不设算力和人力限制。 3、管理AI的人不同：阿里的「铁三角」，腾讯靠老人坐镇 基本盘的差异，做应用逻辑的分化下，腾讯和阿里在AI战场上的差异化还在于管理AI的人不同。 随着通义大模型和夸克走向台前，阿里的AI军团形成了一个以吴妈为核心，周靖人和吴嘉为左右的「铁三角」，这符合阿里过去「转型先选将」的逻辑。 周靖人目前既是阿里云的CTO，也领导阿里通义实验室全盘，他加入接近10年，曾是阿里算法的头号负责人，2022年他正式成为阿里云CTO，公开报道中周靖人被形容为一个懂研究、能做产品，也能带队伍的全能选手。 吴嘉则是阿里的「校招生」，曾在阿里云做了七年的研发，随后其几乎做遍了阿里的创新业务，在他手中孵化出了阿里的C端产品夸克，他也是阿里内部少数从0到一做出C端产品的「少壮派」，外界认为，他的优势除了懂技术外，还在于能理解年轻用户的想法。 周靖人和吴嘉的共同点也类似，他们都懂技术和产品，也有丰富的一线管理经验，更为重要的是，他们都是「懂云」的人。 另一边的腾讯AI，则由十几年的老腾讯人管理。 CSIG由「腾讯云之父」汤道生领导，今年是这位中国香港人加入腾讯的20年，他曾推动QQ、QQ空间等社交产品的技术架构升级，具备to B和to C双重经验，也亲历了腾讯在社交、to B等领域的战役。 对外，汤道生给媒体留下的印象是温和，甚至不时有些幽默感，对内，他曾多次扮演腾讯业务「拓荒者」的角色，擅长把控方向，做取舍、够开放。 大模型端，腾讯混元团队目前的负责人是腾讯集团副总裁、TEG副总裁蒋杰，他在2012年加入腾讯，此前曾在传统IT行业、阿里巴巴分别工作过五年，加入腾讯后，他主要负责大数据平台和广告平台的技术研发。 今年4月，TEG架构升级，成立大语言模型部、多模态模型部等多个部门，均向蒋杰汇报。 蒋杰公开采访并不多，但从其个人文章来看，他是一个擅长将技术回归到业务终局的管理者。他曾在《大模型时代：广告系统的量变与质变》中谈及大模型对广告行业的改变，提到自己对模型的思考： “模型永远无法端到端解决所有问题，投放广告本身不是目的，广告的目的是最后的销售，作为品牌、代理商，则要从关注广告投放的过程中解放出来，更多来思考如何满足消费者的本质需求......从管理过程到管理终局。” 而在应用侧，随着腾讯将元宝并入CSIG，腾讯会议负责人吴祖榕的标签又多了一个——元宝负责人。 吴祖榕毕业于南京大学，2005年毕业加入腾讯，也是一位20年的老腾讯人，2017年，时任增值产品部助理总经理的吴祖榕轮岗到腾讯多媒体视频实验室，参与了腾讯完整的音视频技术栈研发，也为后续他从0到1孵化腾讯会议这一明星产品做了铺垫。 吴祖榕和吴嘉的经历也十分类似——他们都是大厂自家人，一毕业就经历了大厂的锤炼，都在内部作出过成功的明星产品。 迄今为止，阿里成立26年，腾讯成立27年，它们随着中国互联网的发展，形成了自身独特的管理模式和企业文化，这些基因持续影响它们在AI牌桌上的身位，有优势，也有劣势。 阿里和腾讯也互为一面镜子，马云重提阿里的创业文化，马化腾号召每个腾讯人保持「Debug的精神」，两家企业也仍在持续探索AI的新机会。 参考资料： 1、腾讯文化：“在腾讯我们为什么这么看重Debug？” 2、光子星球：阿里AI，“吴妈”的一场服从性测试 3、晚点：字节阿里腾讯的 AI 人才竞赛：2330个究者背后的共识与分歧"
    },
    {
      "doc_id": 16857,
      "title": "腾讯大模型战略首次全景亮相",
      "time": "2024-05-21T00:00:00+00:00",
      "content": "腾讯的大模型战略第一次全景亮相。5月21日，在2025腾讯云AI产业应用峰会上，从自研的混元大模型、到AI云基础设施，再到智能体开发工具、知识库以及面向场景的应用，腾讯大模型宣布矩阵产品全面升级。 “随着AI的持续落地，每个企业都将成为AI公司，每个人都将是AI加持的超级个体。”腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生表示，过去一年，公司各项业务已经全面拥抱AI，同时看到了产业对大模型的庞大用量和深切诉求。 基于不断提升的大模型能力，智能体成为今年大模型领域各家最关注的方向。腾讯云大模型知识引擎也宣布升级为“腾讯云智能体开发平台”。升级后的平台，能快速激活私域知识，并构建企业专属智能体。 具体来看，这一智能体目前主要针对企业，能从复杂 Excel 表中提取精准答案，用户通过自然语言即可完成数据查询，秒级返回结果；支持从文档中自动生成问答，降低人工运营成本；还可以实现文档间差异比对，自动高亮增删改内容，支持“一键处理”如保留、合并、删除等操作。 “大模型‘智商’再高，如果没有学过相应的知识，也无法很好地解决问题。”腾讯有关负责人认为，“大模型+知识库”是当前AI落地的最优路径之一。记者注意到，除智能体外，该公司也正在知识库赛道上持续加码。 来源：北京日报客户端 记者：袁璐 举报/反馈"
    },
    {
      "doc_id": 16858,
      "title": "腾讯大模型战略首次全景亮相:自研混元大模型、知识库、智能体...",
      "time": "2024-05-21T00:00:00+00:00",
      "content": "央广网北京5月21日消息 腾讯的大模型战略第一次全景亮相。5月21日，在2025腾讯云AI产业应用峰会上，从自研的混元大模型、到AI云基础设施，再到智能体开发工具、知识库以及面向场景的应用，腾讯大模型矩阵产品全面升级。腾讯正通过持续打磨技术和产品能力，为企业和用户在大模型时代打造真正“好用的 AI”。 腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生 腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生表示，随着AI的持续落地，每个企业都将成为AI公司；每个人都将是AI加持的“超级个体”。 他强调，过去一年，腾讯的各项业务已经全面拥抱AI，同时看到了产业对大模型的庞大用量和深切诉求。未来，腾讯将持续加速大模型创新、加速智能体应用、加速知识库建设、加速基础设施升级，推动AI技术走进千行百业，也走进每个人的生活。 混元快速迭代跻身全球前八，全面开源多尺寸模型 在疯狂卷技术的全球大模型角逐中，腾讯混元正小步快跑、快速迭代，技术能力持续提升。 汤道生在会上宣布，在全球公认的权威大语言模型评测平台Chatbot Arena上，混元TurboS排名已攀升至全球前八，国内仅次于DeepSeek。其中，代码、数学等理科能力，混元TurboS也进入全球前十。 早在去年下半年，腾讯就大力投入了深度思考模型的路线攻关，混元T1自年初上线元宝App后，持续快速迭代。基于TurboS基座，腾讯新推出视觉深度推理模型混元T1 Vision和端到端语音通话模型混元Voice，近期将推出实时视频通话AI体验。 今年以来，混元的迭代速度明显加快。在多模态生成领域，混元图像 2.0 率先实现“毫秒级”生图，混元3D v2.5凭借业界首创的稀疏3D原生架构，实现了可控性与超高清生成能力的代际飞跃。凭借技术的领先性和开放的生态，混元3D赢得了开源社区的高度认可，Hugging Face模型下载量超160万。 腾讯云副总裁、腾讯混元大模型技术负责人王迪 腾讯云副总裁、腾讯混元大模型技术负责人王迪介绍，目前，混元已实现图像、视频、3D、文本等在内的全模态开源，未来将推出多尺寸混合推理模型，从0.5B到32B的dense模型，以及激活13B的MoE模型，适配企业与端侧需求。混元图像、视频、3D等多模态基础模型及配套插件模型也将持续开源。 全面升级腾讯云智能体开发平台，加速智能体落地 基于不断提升的大模型能力，智能体成为今年大模型领域各家最关注的方向。腾讯云早前已经推出了大模型知识引擎，以RAG为技术为核心，帮助企业构建大模型应用，已经积累下一批企业级用户。 在本次大会上，腾讯云大模型知识引擎全面升级为“腾讯云智能体开发平台”。升级后的平台，整合腾讯云行业领先的RAG（检索增强生成）技术、全面的 Agent（智能体）能力以及实战打磨出来的贴合用户需求的功能，帮助企业快速激活私域知识、构建专属智能体。 基于腾讯云智能体开发平台，用户可以让Agent自主拆解任务和规划路径，主动选择和调用工具。平台首次实现了零代码支持多Agent的转交协同方式，进一步降低了智能体搭建的门槛。面向确定性比较高的执行流程，用户也可以采用工作流模式，拖拉拽各种原子能力，让Agent基于固定流程运行，得到更确定性的结果。 腾讯云副总裁、腾讯云智能负责人、腾讯优图实验室负责人吴运声 腾讯云副总裁、腾讯云智能负责人、腾讯优图实验室负责人吴运声表示，知识库、插件工具、Multi-Agent框架等正在驱动着智能体不断升级，成为懂企业知识、能调用工具、自主执行复杂任务的得力助手。 从企业到个人，乐享+ima知识库“混合双打” 大模型“智商”再高，如果没有学过相应的知识，也无法很好地解决问题。腾讯认为，“大模型+知识库”是当前AI落地的最佳路径。 腾讯在知识库赛道上持续加码。会上，腾讯宣布升级知识库系列产品，基于腾讯乐享和腾讯ima，为企业用户、组织和个人用户提供高效的知识管理体验。ima面向个人及专业用户、乐享面向企业用户，满足不同场景和用户的需求。 腾讯ima作为一款以知识库为核心的AI工作台，可辅助用户完成课程作业、论文写作、方案策划、工作总结等日常学习和工作任务，并长期沉淀为个人智能化的知识库，高度适配政务、法律、教育等知识驱动领域。 而腾讯乐享正式升级为乐享知识库，在知识整合沉淀、知识更新、权限管理、AI问答等层面为企业用户提供服务，提升知识流转效率。目前，腾讯乐享已经累计服务了超30万客户，包括比亚迪、中国五环、友邦保险、北京大学、清华大学、新东方、多乐士、科沃斯、同程旅行、用友畅捷通等各行业公司。 AI infra、营销增长、智能开发、办公协同，大模型工具箱持续升级 无论是应用层还是模型层，均依赖性能领先的算力，智能时代的云计算正在从“资源供给”向“智能服务”转型。当前，腾讯云智算系列产品瞄准AI应用和模型爆发对基础设施带来的全新挑战，在效能、可靠性、易用性三大方向上全面提升，为大模型和应用提供坚实基础设施。 AI技术的发展，也在反哺研发工作环节。腾讯云代码助手CodeBuddy全新升级，推出Craft软件开发智能体，开发者用自然语言讲出需求，Craft就能够自动拆解任务、设计模块、生成代码，并自我纠错，这意味着开发者“一句话开发应用”变为现实，同时升级了代码补全、工程理解，代码测试等功能。 营销增长方面，腾讯企点营销云正式发布“营销云智能体”，以Multi-Agent架构为核心，将腾讯积累多年的AI能力与营销方法论深度融合，实现从人群洞察、商品匹配、内容生成到效果追踪的全链路智能决策。 腾讯系办公协同产品也迎来智能升级。腾讯文档企业版AI助手可实现文档快速总结和问答，以及直接智能生成Word、PPT等可编辑内容；腾讯会议AI小助手Pro也即将接入 DeepSeek ，支持混元、DeepSeek双模型自由切换，助力会前准备、会中决策、会后纪要生成；腾讯电子签实现AI驱动的合同管理闭环；腾讯问卷通过AI提升问卷生成、数据分析及访谈洞察效率；腾讯云ChatBI新增智能洞察与波动归因功能，进一步简化数据分析。 更多精彩资讯请在应用市场下载“央广网”客户端。欢迎提供新闻线索，24小时报料热线400-800-0088；消费者也可通过央广网“啄木鸟消费者投诉平台”线上投诉。版权声明：本文章版权归属央广网所有，未经授权不得转载。转载请联系：cnrbanquan@cnr.cn，不尊重原创的行为我们将追究责任。 举报/反馈"
    },
    {
      "doc_id": 16860,
      "title": "腾讯元宝接入QQ音乐 搜索歌曲可直接播放",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "观点网讯：7月18日，腾讯控股旗下AI助手“腾讯元宝”宣布完成与QQ音乐的功能整合，用户可在元宝APP内直接搜索并播放QQ音乐曲库中的歌曲，无需跳转外部应用。 此次接入后，元宝的搜索框支持输入歌名、歌手或专辑关键词，系统返回结果后用户可一键播放完整曲目。该功能目前覆盖QQ音乐全量版权内容，并同步支持会员与非会员用户的差异化音质选择。 免责声明：本文内容与数据由观点根据公开信息整理，不构成投资建议，使用前请核实。 本文源自：观点网 举报/反馈"
    },
    {
      "doc_id": 16861,
      "title": "腾讯元宝接入QQ音乐 搜到音乐即可直接听",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "每经快讯，7月18日，据腾讯元宝微信公众号消息，腾讯元宝宣布已接入QQ音乐，在元宝APP中搜到歌名后即可直接点、直接听。 每日经济新闻 举报/反馈"
    },
    {
      "doc_id": 16871,
      "title": "元宝深度融入微信",
      "time": "2024-04-17T00:00:00+00:00",
      "content": "作者 | 黄昱 编辑 | 王小娟 作为腾讯旗下首个AI原生APP，以及其抢夺下一代超级流量入口的先锋，元宝要成为超13亿用户的微信聊天搭子了。 华尔街见闻发现，4月16日，微信已悄然上线了AI助手元宝。用户通过搜索“元宝”，即可直接添加其为微信好友，然后能通过聊天界面直接与其进行互动。 这一举措，不仅可以进一步丰富微信的AI功能，让元宝深度融入到微信中，更将是对元宝的又一波引流。 据“元宝”微信账号介绍，其是腾讯元宝APP入驻微信的AI助手，搭载混元和DeepSeek双模引擎，无缝衔接微信生态。 不过从功能上来看，这个“聊天搭子”仅是元宝APP的简化版，目前支持一键解析公众号文章、图片和文档服务。同时，在回答用户问题时，它会以口语化的语言简要短评，然后对于复杂问题，会通过链接的方式给出更详细的回复，并在文末附上元宝APP的下载入口。 显然，目前在微信生态中，元宝还是以AI聊天助手的角色存在，尚未有AI Agent方面的能力体现，如外界畅想通过AI Agent功能可以调用微信生态中的小程序、公众号、微信小店等诸多服务和功能。 作为腾讯生态的核心入口，微信在功能优化上一向谨慎，其实，上个月微信就上线测试“元宝”账号，但当时的名称为“元宝红包封面助手”， 它可以用来制作红包封面，且同样支持解读公众号文章、分析文件与图片，但回答内容都是以链接分享的形式。 元宝如今正式进入微信聊天列表，算是微信在功能调整上作出的一次重大变动。 DeepSeek在今年春节爆火后，AI应用来到破局的关键节点，在积极拥抱DeepSeek的同时，推广元宝也已经成为腾讯集团级别的战略。 转变去年低调的作风，元宝今年开始大手笔投流买量。2月下旬开始，元宝的广告几乎遍布腾讯系App在内的所有平台， 以及B站、知乎、小红书等外部渠道。到3月份，元宝更是开始下乡“刷墙”宣传。 据DataEye数据，从2月18日开始，腾讯元宝投放量激增，由此前的日素材量2000组左右攀升至月底超过1.7万组，从在豆包、Kimi三家中垫底的位置冲到头部，相反的是, Kimi投放力度大幅下滑，从此前的日素材投放量2万组左右到接近停滞。 除了大量的广告投入外，元宝同时通过自身产品功能的快速迭代来抢占市场，包括上线深度思考模型“混元T1”、上线快思考大模型混元Turbo S、上线电脑版，以及支持上传、导出腾讯文档等。 据华尔街见闻了解，元宝一度在35天更新了30个版本。 在这样的大力投入下，效果立竿见影。3月3日，腾讯元宝APP在中国区苹果应用商店免费App下载排行榜上，超越DeepSeek跃升至第一，而豆包位居第四，要知道在2月13日，元宝在这一榜单上的位置还在100名之外。 在3月19日的腾讯业绩会上，腾讯总裁刘炽平透露，作为启动，腾讯确实给元宝有很大的投流，在这个过程中也在密切关注留存率的问题，现阶段留存率还是相当不错的，从2月到3月，元宝的日活跃用户 （DAU ）增长了20倍，成为了中国 DAU 排名第三的 AI 原生移动应用。 QuestMobile发布的《2025第一季度AI应用市场竞争分析》也显示，截至2025年3月，AI原生APP行业DeepSeek以1.94亿月活登顶，豆包、元宝紧随其后，月活分别为1.16亿和4164万。 短短三个月，AI原生APP格局已然大洗牌，TOP3应用从2024年底的豆包、Kimi智能助手、文小言变更为DeepSeek、豆包、元宝。 不过，与DeepSeek、豆包相比，腾讯元宝的月活数据还是存在不小差距。 元宝的投流还在继续，但相比前不久的高峰点，显然已经减少了很多。 此外，华尔街见闻注意到，4月17日，元宝APP在中国区苹果应用商店免费App下载排行榜上排名回落到了第十名的位置，豆包和DeepSeek分别排名第一和第三。 可见，要想成为AI超级应用，元宝虽然背靠腾讯，但依然面临不小的挑战。 刘炽平也指出，元宝未来肯定不是纯粹靠投流来获得用户，未来会在元宝中加入很多各种各样的功能，让它变成一个更智能的AI助手，并且让元宝和腾讯现有的产品进行有机联动。 腾讯在AI上投入决心不小。 在上个月的业绩会上，腾讯宣布，在去年767亿元资本开支创历史新高的基础上，会在2025年进一步增加资本支出，在研发方面，将继续投资自研模型，并加速各个业务集团的 AI 应用开发。同时，腾讯还将在市场营销方面进行投资，以提高用户对新AI产品，比如说元宝的认知和采用率。 而要在这场AI军备赛中拔得头筹，腾讯也必然需要招揽更多AI人才。4月17日，腾讯宣布启动史上最大就业计划，三年内将新增 28000个实习岗位并加大转化录用，其中仅 2025年，就将迎来 10000名校招实习生，有六成面向技术人才开放。 腾讯方面表示，在大模型加速落地的背景下，腾讯加大了人工智能、大数据、云计算、游戏引擎、数字内容等技术类岗位的招聘力度，技术类岗位“扩招”力度空前。 抓住AI应用爆发的机遇期，腾讯已经火力全开。 本文来自华尔街见闻，欢迎下载APP查看更多 举报/反馈"
    },
    {
      "doc_id": 16875,
      "title": "「产业互联网周报」中国石油发布330亿参数昆仑大模型;腾讯HR助手...",
      "time": "2024-09-02T00:00:00+00:00",
      "content": "图片来源@pixabay 【产业互联网周报是由钛媒体TMTpost发布的特色产品，将整合本周最重要的企业级服务、云计算、大数据领域的前沿趋势、重磅政策及行研报告。】 财报季 三六零：上半年净亏损3.41亿元 三六零发布2024年半年度报告，报告期内，公司实现营业收入36.92亿元，同比减少18.02%；归属于母公司所有者的净亏损3.41亿元。 中芯国际：上半年净利润16.46亿元，同比下降45.1% 中芯国际发布2024年半年度报告，报告期内，公司实现营业收入262.69亿元，同比增长23.2%；归属于上市公司股东的净利润16.46亿元，同比下降45.1%。 达梦数据上半年报：营收3.5亿元、净利润1亿元 达梦数据披露2024年半年度报告。2024年上半年，公司实现营业收入3.52亿元，同比增长22.41%；归母净利润1.03亿元，同比增长40.68%；扣非净利润9516.74万元，同比增长43.09%；经营活动产生的现金流量净额为684万元，同比下降80.16%。 商汤科技上半年营收同比增长21%、毛利润近8亿元 商汤科技公布半年报业绩。2024年上半年，商汤集团实现收入17.4亿元，同比增长21%；其中生成式AI板块业务收入近11亿元，同比劲增256%，占公司总收入的六成以上。盈利方面，公司报告期内实现毛利润近8亿元，同比增长18%，毛利率为44%。 星环科技上半年报：营收1.4亿元、亏损逾1.9亿元 星环科技发布2024年半年报。报告显示，公司上半年营业收入为1.40亿元，同比增长1.58%；归母净利润为-1.91亿元，同比下降0.89%；扣非归母净利润为-2.06亿元，同比增长2.02%。 会畅上半年报：营收2.34亿元、净利润1727万元 会畅通讯发布2024年半年度报告。报告期内，公司实现营业收入2.34亿元，同比下滑5.51%；实现归属于上市公司股东的净利润1726.59万元，同比增长984.68%；主要原因为在全球经济增速放缓背景下，公司积极推进降本增效销售费用比上年同期下降40.88%，管理费用比上年同期下降24.26%。 金蝶国际：耗资约1240万港元回购200万股 金蝶国际软件集团有限公司发布公告称，当日回购了200万股普通股，占已发行股份的0.06%，回购价格介于每股6.11港元至6.22港元之间，总代价为1240.14万港元。此次回购的股份拟注销。 Salesforce二季财报超预期，营收93.3亿美元，CFO韦弗将离职 Salesforce发布第二财季业绩，营收93.3亿美元，高于预期的92.3亿美元，同比增长8%。同时，Salesforce上调了全年利润预期，预计2025财年调整后每股收益为10.03美元至10.11美元，营收为377亿美元至380亿美元。 此外，Salesforce首席财务官Amy Weaver将离职，在继任者任命前她将继续担任该职位，之后作为顾问留在公司。Salesforce将考虑内部和外部候选人。本季度，Salesforce表示秋季将测试面向商家的Einstein Copilot，其CEO贝尼奥夫还大力宣传了公司的Agentforce人工智能产品，并批评微软的产品让客户失望。 英伟达：Blackwell芯片将在Q4量产和发货，预计季度收入将达数十亿美元 英伟达称，Blackwell样品正在交付给合作伙伴和客户；Blackwell芯片将在四季度开始量产，并在四季度开始发货；预计第四财季Blackwell收入将达到数十亿美元；市场对Blackwell的期望是不可思议的；Hopper需求强劲，预计2025财年下半年出货量将增加。 CrowdStrike第二财季净利润大幅增至4669万美元 美国电脑安全技术公司CrowdStrike（众击）公布2025财年第二季度财务业绩。第二财季，公司总营收为9.64亿美元，同比增长32%；净利润为4669万美元，上年同期为847.6万美元。今年7月19日，一次大范围的电脑软件和云服务宕机影响多国航空公司、电信公司以及电视台等，导致这些公司的服务中断。“众击”首席执行官库尔茨表示，该公司对微软“视窗”系统的一个更新存在缺陷。集团面临包括达美航空在内的公司索偿。 国内新闻 中国石油发布330亿参数昆仑大模型 330亿参数昆仑大模型建设成果发布会在北京举办。由中国石油、中国移动、华为公司和科大讯飞共同推出的能源行业大模型——昆仑大模型发布阶段性成果，并展示了地震解释大模型应用、测井处理解释大模型应用、员工助手应用、行业大家应用等最新场景应用。据悉，昆仑大模型已于8月23日通过了国家生成式人工智能服务备案，是中国能源化工行业首个通过备案的大模型。 钛媒体独家 | 腾讯HR助手将整体退出市场 有海报显示，腾讯HR助手将自9月30日从企微应用市场下架，并提供免费三个月的延长期以供用户完成数据备份。对此，钛媒体App以用户身份致电腾讯HR助手客服，客服表示该消息为真，并称“腾讯HR助手此次是整体下架，退出市场”。不过，钛媒体App发现腾讯HR助手目前仍可进行下单付费，腾讯HR助手-自选版资费为4元/人/年，对此客服表示，现在不建议购买，“到期之后，有问题时找不到客服、找不到售后、找不到运维，是没办法解决的。” 对标GPT-4o语音产品，国内首个极速超拟人交互技术上线 科大讯飞星火极速超拟人交互技术正式上线讯飞星火APP，现已开放体验。据了解，这是国内首个对标GPT-4o语音的产品，该产品在响应和打断速度、情绪感知情感共鸣、语音可控表达、人设扮演四个方面实现突破，整体交互体验更自然。 高瓴今年已投37个项目，将持续投早投小投硬核 钛媒体在中国基金合伙人峰会上获悉，高瓴今年以来投出了37笔。近年备受关注的人形机器人企业智元机器人、大模型公司MiniMax等，高瓴都是最早一轮投资人。高瓴创始合伙人李良在会上表示，投资早期创新是高瓴的传统，其在2014年最早投资的百济神州，在本月发布的财报中迎来了扭亏为盈的转折点，同比业绩增长65%，单颗药收入超10亿美元；近期IPO备案获批的地平线也是高瓴的天使轮投资企业。“高瓴将继续投早、投小、投硬核”。 阿里巴巴正式完成双重上市 阿里巴巴集团在港交所发布公告，自愿将本公司于香港联交所第二上市地位变更为主要上市地位的转换于今日生效，公司现为于香港联交所及纽约证券交易所双重主要上市的公司。这也意味着，阿里巴巴于中国香港联交所上市的普通股及于纽交所上市的美国存托股持续可予转换。 据了解，此前，阿里巴巴曾在今年5月发布2024财年年报时透露，预计将于2024年8月底完成香港主要上市转换。8月23日，阿里巴巴集团发布公告，宣布新增香港为主要上市地。阿里在香港双重主要上市不涉及新股发行和融资。 字节跳动成立大模型研究院？知情人士称公司未决定建立独立机构 有消息称，字节跳动正在秘密筹备成立大模型研究院，并积极招揽人才。对此，钛媒体App从知情人士处获悉，字节跳动有加强大模型相关研究的长期计划，但并未决定建立独立机构。另外，前零一万物技术联创黄文灏已加入字节跳动，负责技术项目管理和规划，汇报给字节跳动大模型负责人朱文佳。 国家数据局：公共数据、企业数据两份开发利用文件年内出台 从国家数据局最新了解到，有关公共数据、企业数据资源开发利用的两份文件将于今年年内陆续出台，个人数据资源开发利用的相关政策也在加紧研究当中，未来将通过更有针对性、更具操作性的政策指引，让企业有感、市场有感。国家数据局表示，党的二十届三中全会首次提出培育全国一体化数据市场，并就加快建立数据相关制度规则提出了明确要求。目前，国家数据局正在分类施策推进数据资源开发利用。 国家数据局还表示，从目前来看，企业数据资源价值潜力还有较大释放空间，接下来将加强保护企业合法数据权益、推动企业数据共享开放、促进中小企业用数创新、提升数据合规治理效能，同时进一步健全由市场评价贡献、按贡献决定报酬的机制，增强企业数据资源开发利用的内生动力。 IBM中国区裁员超1000人？钛媒体独家获悉赔偿方案 IBM中国方面确认，IBM将彻底关闭中国研发部门，涉及员工数量超过1000人。对此，IBM对钛媒体App回应此次人事变动时表示：IBM会根据需要调整运营，为客户提供最佳服务，这些变化不会影响我们为大中华区客户提供支持的能力。 钛媒体独家从IBM被裁员工处获悉，被裁员工被通知最后工作日为10月31日，其中在9月13日签订离职协议的员工可获得N+3的赔偿，9月20日前签订离职协议的员工将获得N+1的赔偿，此次裁员涉及IBM中国研发中心和中国系统中心全部员工。 华为上半年销售收入4175亿元 华为发布2024年上半年经营业绩，整体经营稳健，结果符合预期。上半年，公司实现销售收入4,175亿人民币，同比增长34.3%，净利润率13.2%。华为轮值董事长徐直军表示：“集团整体经营情况符合预期。我们将贯彻全流程‘高质量’的公司战略，持续优化产业组合，增强发展韧性，建设繁荣产业生态，为客户贡献更有竞争力的产品和解决方案。” 海外动态 ABB宣布收购德国福德世集团 ABB宣布，已签署协议收购能源和工业领域先进测量与分析解决方案供应商福德世集团。福德世集团总部位于德国马克兰施泰特，拥有3000平方米的制造工厂，并在德国、荷兰和中国设有分支机构，为应对各行业在环境、检测和认证方面的挑战提供解决方案。 亚马逊新版Alexa据悉将主要由Anthropic的AI模型提供支持 相关报道援引知情人士称，亚马逊新版Alexa将主要由Anthropic的AI模型提供支持，而非亚马逊自家的AI模型。新版Alexa预计将于10月发布。亚马逊发言人对此表示：“我们使用许多不同的技术为Alexa提供动力。” 谷歌据悉考虑在越南建设超大规模数据中心 相关报道援引知情人士称，谷歌考虑在越南胡志明市附近建设一座超大规模数据中心，或于2027年完工。据悉，内部洽谈正在进行中，知情人士并未透露这笔潜在投资的规模。 聊天机器人初创公司Character.AI解雇了至少5%的员工 有媒体报道称，聊天机器人初创公司Character.AI解雇了至少5%的员工，被解雇的员工大多负责这家初创公司的营销和招聘工作。发言人表示：“我们正在重新调整公司重点，以确保所有职位都符合我们打造个性化AI（人工智能）产品的新方向。因此，我们稍微减少了员工人数。”但该发言人没有透露被裁员工的具体人数。 Perplexity计划在四季度开始投放广告 Perplexity AI上周四宣布，计划于第四季度在其搜索应用程序上投放广告。据知情人士声称，在广告方面，Perplexity将采用一种名为CPM（每千次展示成本）的模式，价格将超过50美元。Perplexity在其推介材料中表示，其主要广告类别最初将包括科技、健康和制药、艺术和娱乐、金融以及食品和饮料等主题。广告商将能够赞助答案下方的，并在答案右侧购买“相关问题”展示广告。 融资并购 联易融战略收购拜特，推动智慧司库建设 联易融科技集团（下称“联易融”）与深圳市拜特科技股份有限公司（下称“拜特”）有关股东举行战略并购合作签约仪式。双方签署股权收购意向书，联易融拟收购拜特目前控股股东所持股权，在本次交易完成后，联易融将成为拜特控股股东。此次战略收购旨在整合双方在资金管理和供应链金融科技领域的核心优势，共同助力客户构建世界一流的财务管理平台，推动央国企及大中型民营企业客户的智慧司库管理体系建设。 Dify.AI获阿里等入股 苏州语灵人工智能科技有限公司（Dify.AI）发生工商变更，新增浙江阿里巴巴云计算有限公司、苏州元之芯贰期创业投资合伙企业（有限合伙）为股东，注册资本由约115.79万人民币增至约143.63万元。 EasyYa易芽获1.5亿元C轮融资，中金资本领投 跨境电商供应链平台EasyYa易芽宣布完成1.5亿元C轮融资，本轮融资由中金资本旗下中金天姥览盛基金战略领投，金沙江联合资本、广州天河基金、北京源壹等跟投。新一轮融资将主要用于优化“易芽有单”工厂智联SaaS系统，拓展TikTok等新平台选品工具，持续扩张海外市场并布局多样化的渠道体系。 AI芯片独角兽燧原科技筹备IPO 据证监会官网披露，燧原科技上市辅导备案获受理，辅导机构为中金公司，计划在A股进行IPO。 燧原科技成立于2018年8月，六年内已完成十轮融资，累计融资额近70亿元，背后知名投资机构云集，其中腾讯连续六轮参投。据近期胡润研究院发布《2024全球独角兽榜》，燧原科技估值160亿元，排名全球第482位。 Codeium获得1.5亿美元C轮融资 美国AI编程初创公司宣布已完成1.5亿美元C轮融资,本次融资由知名风投公司General Catalyst领投。Codeium是一家人工智能编码工具包提供商，其开发了一个以安全为重点的LLM工具包，可以根据代码库提供智能代码建议。目前该公司的估值已经达到12.5亿美元。 政策&趋势 工信部部长金壮龙：推动人工智能赋能新型工业化 工业和信息化部党组书记、部长金壮龙表示，将把建设制造强国同发展数字经济、产业信息化等有机结合，提升产业体系现代化水平。一是加快制造业数字化转型。二是推动人工智能赋能新型工业化。以智能制造为主攻方向，夯实算力、算法、数据等技术底座，培育若干通用大模型和行业大模型。开展“人工智能+制造”行动，大力发展智能产品，推广智能化软件应用，促进家电、手机等消费终端向强智能升级。三是大力发展新一代信息技术产业。四是推动信息通信业高质量发展。 IDC：2023中国AI软件市场规模377亿元 国际数据公司（IDC）于近日发布了《中国人工智能软件市场份额，2023：大模型带来新生机》。IDC报告数据显示，2023年中国人工智能软件市场规模达377.4亿元人民币，相比2022年上升26.2%。一方面，市场的确受疫情发展影响；另一方面，人工智能的产业落地达到了阶段性的瓶颈期。 埃森哲：中国企业加大数字化投入，利用AI投入制造、财务、供应链 8月21日，埃森哲发布的《2024中国企业数字化转型指数》指出，更多的中国企业计划加大数字化领域的投入，利用人工智能等技术进行持续转型。 研究表明，近六成（59%）的受访企业表示，计划在未来一年对数字化转型项目增加投资，揭示了企业对技术创新的强劲需求。越来越多的企业计划借助以人工智能为代表的先进技术重塑各项职能，其中制造（48%）、财务（45%）和供应链（42%）成为三大重点关注领域。 2024年第二季度全球云收入达790亿美元 Synergy Research Group最新发布的第二季度数据显示，按季度收入计算，亚马逊(Amazon)、微软(Microsoft)和谷歌(Google)显然是全球云市场的领导者，市场份额分别为32%、23%和12%，而其他公司的市场份额都没有超过4%。在这三家公司之后是阿里巴巴、甲骨文和Salesforce。 Synergy数据显示，第二季度云基础设施服务收入(包括IaaS、PaaS和托管私有云服务)为790亿美元，过去12个月的收入达到2970亿美元。公共IaaS和PaaS服务继续占大部分。 从地理上看，美国仍然是迄今为止最大的云市场，紧随其后的是中国。中国本身就遥遥领先于其他国家，包括日本、英国、德国和印度。按地区划分，美国实际上比整个亚太地区大得多。美国、中国、亚太地区和欧洲合计占全球市场的90%以上。 2024年第二季度AI PC出货量为880万台 根据Canalys的最新数据，2024年第二季度，支持人工智能的个人电脑的出货量为880万台。这些设备被定义为包括专用AI工作负载(如NPU)的芯片组的台式机和笔记本电脑。支持人工智能的个人电脑出货量占本季度个人电脑总出货量的14%。随着所有主要处理器供应商的人工智能PC路线图正在顺利进行，设备可用性和最终用户采用率将在2024年下半年及以后大幅提升。 举报/反馈"
    },
    {
      "doc_id": 16876,
      "title": "腾讯版“GPTs”和助手App将上线,内部600个业务已接大模型|最前线",
      "time": "2024-05-21T00:00:00+00:00",
      "content": "作者 | 邓咏仪 编辑 | 苏建勋 本周可能是AI领域的”黄道吉日“。继OpenAI、谷歌、字节的AI产品发布后，本周最后一位选手——腾讯，也终于上场。 5月17日，腾讯在生成式AI产业应用峰会上，集中披露了包括底层的通用模型、行业大模型的能力升级，以及多个新产品。 腾讯版”GPTs“上线，以及独立入口终于出现 发布会上，吸引了众多目光的，当属新推出的智能体产品“腾讯元器”。 元器 来源：腾讯 可以说，这是一个腾讯版的“GPTs”。企业和开发者可以基于腾讯元器，使用腾讯官方的插件和知识库直接创建智能体。开发完成后，将智能体一键分发到QQ、微信客服、腾讯云等渠道上。 生态也是老生常谈的话题。等到大家都把智能体发布到平台上，腾讯也会一定扶持。创作者在腾讯元器上创建的智能体，可以分发到QQ，优质智能体有机会获得流量扶持。 对话，是大模型使用的最直接形态。从ChatGPT引爆生成式AI浪潮之后，腾讯在AI大模型上的进展，有无可能，以及怎么和社交生态（微信、QQ）如何联动——可以说是业界最为关心的问题。 这次“腾讯元器”的发布，掀起了面纱的一角。 不过参照前人经验，OpenAI发布后不久，就先用GPT Plugin（插件）的形式做第三方生态，而后过渡到2023年11月就上线的GPT Store，一上线就已经有数百万个GPTs。不过，很多GPTs都是ChatGPT的简单套壳，模仿成本极低，因此GPTs的使用情况也不尽如人意。腾讯要想做好智能体生态，也会面临不小挑战。 目前，元器还没有全量对外开放，但可以申请内测：https://yuanqi.tencent.com/my-creation 来源：腾讯 另外一个重要预告则是，腾讯将于月底推出全新的助手App“腾讯元宝”——这也是一个有入口级别意义的发布。 此前，“混元”的C端入口，只有小程序端的“混元助手”和PC端的网站，但一直没有一个统一的移动端入口。 而由于月底才推出，这次的发布会上，腾讯仅简单介绍了元宝App首批上线的功能，包括AI搜索、翻译、文档总结、口语陪练等等。 如今腾讯终于官宣App端，隐隐透露着C端AI产品入口的竞争——环顾行业，百度有“文心一言”、阿里有“通义千问”，创业公司阵营里则有Moonshot的Kimi、智谱AI的“智谱清言”。可以预见，围绕C端用户的使用场景，2024年的AI助手领域将有不小的风浪。 底层大模型更新：256k长文本、文生图模型开源 从去年发布底层的混元大模型后，腾讯的更新一直保持不疾不徐的状态。总体上看，当前的混元采用混合专家模型 (MoE) 结构，模型总体性能相比上一代提升了50%，部分中文能力已追平GPT-4。 各项能力也终于赶上来了，比如此前大厂和创业公司纷纷开始卷起来的”长文本“。 这一次发布中，”混元“也正式发布了256k版本，具备处理超过38万字符的超长文本能力。 在长文输入场景，腾讯混元目前的大海捞针（经典的长文本测试，将一段信息放在一段长文本中的任意位置，检测大模型的回答准确率如何）指标，达到99.9%。 如果给混元256k版本输入一本《三国演义》，字数达数十万字，那么，大模型则能识别出小说中的关键人物和事件情节，甚至对于天气、角色着装等细节描述，也能提供精确的信息。 在对话应用场景中，该模型能够“记忆”更多的对话内容，有效避免“忘记”信息等问题，也能更“聪明”地结合上下文进行分析，为对话参与者提供更为精确的反馈，辅助其决策。 来源：腾讯 当前，面对不同的应用需求，“混元”当前也提供了hunyuan-pro、hunyuan-standard、hunyuan-lite三个模型尺寸，面向企业、个人开发者全面开放。 而在峰会前几天，5月14日，腾讯还官宣了另一个重要发布：混元文生图大模型全面升级并对外开源——包含模型权重、推理代码、模型算法等完整模型，可供企业与个人开发者免费商用。 这也是国内首个中文原生的开源文生图模型，与Sora采用一致的DiT架构，是文生图、文生视频的重要基础。 已接入600多个腾讯内部业务和场景 从去年9月正式推出“混元”大模型以来，腾讯在AI领域一直都是走更稳健的路线——先从内部业务做起，等到能力成熟，再推向产业。 从内部看，腾讯“AI化”可以说颇为迅速。今年年初，腾讯高级执行副总裁接受36氪采访时就提及，腾讯内部已经有300多个业务接入大模型。到了今天，这个数字变成了超过600。 就以腾讯的AI代码助手为例，现在在腾讯集团内部，就已经实现了50%以上的开发岗员工覆盖，其代码生成率达30%以上，研发效能提升了20%以上。 而腾讯生态内部有丰富多元的内容、社交、游戏业务。在大模型的加持下，许多业务也有了不少有趣的进展。 比如近期传播甚广的“AI问书”，就是微信读书基于混元大模型推出的功能——用户如果不愿意读一整本书，现在就能以对话形式，问AI这本书是关于什么主题的，真正实现“量子速读”。 来源：微信读书 而结合了AI大模型能力后，不少腾讯系产品也都看到了可观的增长。比如，腾讯会议中推出的“AI小助手”就是典型例子——通过简单自然的指令，AI小助手可以完成发言提醒、观点总结、会议纪要等能力，大幅度提升会议效率。过去四个月，腾讯会议AI小助手的用户日调用量增长了20倍。 现在，腾讯现在已经逐渐转向外部，加快产业落地的脚步。一个明显的标志是，腾讯云这次发布了PaaS层的三个新引擎：大模型知识引擎、图像创作引擎和视频创作引擎。 以知识引擎为例，一家叫“圆心惠保”的保险公司，就通过这个引擎，开发出面向保险代理人的高效惠民智囊——可以自动生成产品知识问答和安抚话术，用来和客户沟通，实现人均提效50%。 这几项能力在云计算时代就已经具备，但通过和大模型的结合，能够覆盖的场景更多了——比如，基于腾讯混元视频生成大模型技术，用户现在就能输入视频，马上生成特定风格的视频。生成后的视频画面流畅自然，时序一致性强。 类似这样的能力通过api的形式输出，开发者就能给予腾讯的开发平台，开发功能更丰富的应用。 总体而言，在产品矩阵上，如今国内几家大厂对AI的投入力度都不小，To B和To C齐头并进，但在具体路线上，已经有了隐约的分野。 比如，同样是进展谨慎的字节，从这周发布的产品来看，其整体战略就更偏向C端——从“豆包”这个名字用在大模型和App上就可见一斑。并且，字节同样沿用了App工厂的打法，基于豆包开发了一大批To C App。 而腾讯则是走更偏产业的路线，“产业实用”的战略已然明确，当前，腾讯的行业大模型已经在金融、医疗、教育、汽车、能源等20多个行业落地。 “大模型的打造只是起点，把技术落地到产业场景，创造价值才是目标”。腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生在会上表示。 举报/反馈"
    },
    {
      "doc_id": 16878,
      "title": "大模型落地竞赛打响:腾讯加速AI产业化,5分钟可开发一款AI应用",
      "time": "2024-05-22T00:00:00+00:00",
      "content": "自去年9月发布混元大模型后，腾讯大模型迎来最大一次升级。 5月17日，在“腾讯云生成式AI产业应用峰会”上，腾讯披露混元大模型的一系列新的进展，包括智能体平台“腾讯元器”、三款PaaS工具引擎，以及行业大模型的最新能力升级。 2024年被普遍认为是国产AI大模型全面商业落地的元年，各大互联网厂商的落地之战打响，竞争日渐白热化，甚至打起了价格战。最近一个月时间内，国内外大厂以及智谱AI、零一万物等创业企业都接连推出和迭代重磅AI大模型版本，字节跳动、阿里、百度加入了价格战。 在落地路径上，腾讯与其他大模型厂商稍显不同——与单个的C端大模型应用相比，腾讯更重视B端即产业应用的落地。 2023年6月，腾讯云率先发布行业大模型，让市场看到了这家互联网大厂对大模型在产业落地的思考：通过聚焦产业场景，以解决痛点为目标，推动前沿创新加速落地，助力企业降本增效。 3个月后，直接面向C端用户使用的混元大模型才正式发布，腾讯进一步强调“大模型的打造只是起点，把技术落地到产业场景、创造价值才是目标。” 腾讯集团高级执行副总裁、CISG（云与智慧产业事业群）CEO 汤道生在此次会上指出，腾讯始终以“产业实用”作为公司发展大模型的核心战略。目前，腾讯推出的行业大模型已在金融、医疗、教育、汽车、能源等20多个行业落地。 同时，混元大模型也在加速落地。据悉，混元已经在腾讯内部600多个业务和场景中落地测试。汤道生以腾讯会议为例，基于混元的AI小助手上线后，用户只需要简单的指令，就可以完成发言提醒、观点总结、会议纪要等能力，大幅度提升会议效率，且过去四个月，用户日调用量增长了20倍。 在大模型落地的过程之中，场景选择、需求匹配、结果准确性、数据保密、落地成本、技术门槛的挑战仍在不断涌现。汤道生总结道，腾将通过打造高性能的模型、高效率的工具平台、高敏捷的场景应用、高可用的算力基础设施，以及强安全的模型环境，构建离产业最近的AI。 腾讯混元应用加速 讨论大模型落地前提，必须保证基础模型能力的领先。跟大部分厂商一样，腾讯也在持续升级混元的技术实力。 一方面，腾讯通过率先采用MoE（Mixture of Experts）架构，将混元大模型扩展至万亿级参数规模。升级过后，混元的总体性能相比上一代提升了50%，部分中文能力已追平GPT-4，在“时新”问题的回答表现上也有较大提升。 混元亦在多模态方面取得一定进展。据腾讯集团副总裁蒋杰透露，在AI生图领域，腾讯混元文生图基础架构已全面升级至Sora同款的DiT架构，具备了多轮绘图能力。 在视频生成领域，蒋杰指出，腾讯混元支持文生视频、图生视频、图文生视频、视频生视频等多种视频生成能力，视频生成长度可达16秒。预计在三季度推出的下一代文生视频模型，有望能够生成30秒以上视频。 为进一步降低应用门槛，让大模型变得更为“实用”，腾讯开始加快对外输出大模型能力的脚步。 如腾讯混元发布了智能体平台“腾讯元器”，帮助用户以极低的门槛创建专属AI智能体，并支持一键分发至QQ、微信客服、腾讯云等渠道。这被普遍视为腾讯版的“GPTs”。 今年1月，OpenAI发布GPTs时，市场曾一度将其视为人工智能领域的“iPhone时刻”，有望帮助大模型技术真正实现破圈。但如今回看，它的进展并未如预期般奏效。 腾讯混元模型应用负责人张锋指出，智能体仍是时代前沿产品，市场的接受需要一个过程。同时，智能体的流行与否和模型基础能力息息相关。“伴随着基础模型能力的提升，智能体的构建也会更加满足用户需要。” 腾讯云这次还发布了PaaS层的三个新引擎工具。腾讯云副总裁、腾讯云智能负责人吴运声表示，通过PaaS接入大模型，可实现数据工程、模型精调、应用开发的流程简化，进而助力企业更高效、简单地将大模型能力应用于生产、销售和服务等场景。 以大模型知识引擎为例，这是一款基于大语言模型的知识应用开发平台。通过腾讯打造的“模块化”应用模板，基层人员只需要用自然语言，在5分钟内就可以开发出一款知识服务应用，快速在客服营销、企业知识社区等各种与人连接的业务场景落地。 而图像、视频创作引擎，将通过大模型全面提高素材生成效率。如“图像创作引擎”可为企业客户提供AI写真、线稿生图、图像风格化等能力；“视频创作引擎”可提供视频转译、视频风格化、画布拓展等多种功能。 此外，算力基础亦是市场能否更大规模运营大模型能力的关键。腾讯云通过自研星脉网络3.2T通信带宽和统一的接入层能力，打造了一个可以支持超过10万张卡并行计算，并且能够兼容多种GPU生态的算力集群。 吴运声透露，通过自研的星脉高性能计算网络，腾讯算力成本低于外购的相关网络设备，叠加使用Angel训练推理平台，使训练和推理过程中资源可更高效利用。 另据时代财经获悉，包括MiniMax、百川等在内，90%的头部大模型企业都已在腾讯云上打造大模型。 蒋杰还在会上透露，面向C端的助手App“腾讯元宝”将于5月底上线，首批上线功能包括AI搜索、翻译、文档总结、口语陪练等，但更多的消息暂未披露。 在此之前，混元的C端入口只有小程序“混元助手”和网站，缺乏统一的移动端入口。坐拥腾讯系强大的流量池，“腾讯元宝”有望为大模型的C端应用带来新的突破。 回应价格战：更关注技术能力发展 5月15日，字节发布豆包大模型，其主力模型在企业市场的定价为0.0008元/千tokens（文本单位），较行业平均价格便宜99.3%。以此计算，用户仅需一块钱就能买到主力大模型的125万tokens。 字节激进的举动引发了市场对于大模型“价格战”开打的猜想，在此之前已有多家厂商宣布下调模型调用成本。 5月13日，OpenAI发布GPT-4o，价格仅为GPT-4 Turbo的一半，输入、输出每百万 tokens收费5美元、15美元。差不多是同一时间，智谱也在大模型开放平台上线新的价格体系，入门级产品 GLM-3 Turbo 模型调用价格下调80%，每百万tokens只需一元。 5月21日，阿里云旗下的通义千问同样选择跟进，其主力模型API输入价格从0.02元/千tokens降至0.0005元/千tokens，直降97%。这意味着，1块钱可以买200万tokens，甚至低过字节的豆包。 同日，百度智能云官微宣布，文心大模型两大主力模型全面免费，立即生效。据悉，百度宣布免费的两款大模型分别为今年3月推出的两款轻量级大模型ERNIE Speed、ERNIE Lite，支持8K、128k上下文长度。 竞争对手纷纷降价，腾讯不免也会被拉来比较。 对此，吴运声对时代财经等媒体回应指出，腾讯大模型的底层能力和构建工具链仍在快速迭代过程中。未来腾讯会把核心精力放在产品和技术能力发展上，致力于为客户创造价值，让大模型能够在生产环境中实际应用起来。 “相信我们一定能为客户提供有竞争力的模型和产品。”吴运声说。 有大模型行业从业者向时代财经分析称，“当下国产大模型仍以快速迭代自身能力为主，并同步推进产业应用的逐渐落地。在这个阶段降成本优化价格有些为时过早，待到大模型能力和应用场景皆已逐渐成熟的时候，再打价格战更为合适。” 从这个角度来看，大模型厂商们持续迭代模型能力，并开拓更多应用场景或许更为重要。 而在谈及大模型推广难题时，吴运声指出，过去一年，大模型在落地过程中遇到的一个重要挑战，是需求和能力匹配的问题。“很多客户对于大模型有很高的预期，业务的很多需求想通过大模型一下子全部解决，这个在现阶段较难实现，还是需要在场景快速验证、分阶段推进。” 此外，还有技术使用门槛过高的挑战以及安全合规的挑战。在吴运声看来，只有帮助企业减少对技术人才及专业技术能力依赖，让一线生产、经营人员也能“零门槛”用上大模型，才能加速生产经验与模型技术的融合。 从智能体到PaaS引擎工具，再到C端App，强调“产业实用”的腾讯正在做出诸多探索，试图通过各类创新产品推动大模型在各行各业更广泛的运用。但现阶段，大模型最好的商业路径是什么，腾讯等大厂们仍需探索。 当谈及相关应用和大模型结合的ROI时，张锋指出当前腾讯大模型应用仍在探索阶段，相关业务场景以创新技术为主。 “现在最关键的问题还是怎么将生成式AI技术跟客户需求做更好的结合，其他的东西才会被带动起来。”在回应团队KPI的问题时，吴运声如是说。 本文源自：时代财经 作者：谢斯临 举报/反馈"
    },
    {
      "doc_id": 16885,
      "title": "从Grok 4到Kimi K2 “地表最强大模型”到底强在哪?",
      "time": "2025-07-17T00:00:00+00:00",
      "content": "来源：IT时报 大力依然出奇迹 作者／ IT时报记者 郝俊慧 编辑／ 郝俊慧 孙妍 全球大模型公司都喜欢“扎堆”发布新品。 最近一周，两个超大规模的大模型先后更新：先是马斯克旗下人工智能公司xAI正式推出Grok 4，并宣称Grok 4为“全球最强大的AI模型”；后有月之暗面在7月11日深夜直接开源Kimi K2，在编程、智能体、工具调用三项基准测试中，是目前表现最好的开源模型。 事实证明，至少在现阶段，“大力出奇迹”依然是AI大模型能力跃迁遵循的规律：尽管没有公布，但坊间普遍猜测Grok 4用了20万张H100，而Kimi K2的1TB参数是目前全球开源大模型中最大的参数规模。 那么，这两个“最强”大模型，究竟有哪些厉害的杀招？ Kimi K2 智能体调用迈出第一步 沉寂许久之后，月之暗面终于拿出了大招——Kimi K2。官方发布的数据显示，Kimi K2是一个万亿（1TB）参数规模的混合专家（MoE）模型，激活参数32B，并在SWE Bench Verified（代码智能体评估基准）、Tau2（评估 AI Agent 在现实场景中的性能和可靠性）、AceBench（评估大型语言模型在工具使用中的学习能力）等基准性能测试中，Kimi K2均取得开源模型中的SOTA （目前最高水平）成绩。 在Kimi K2的自述文件中，尤其强调模型在前沿知识、推理和编码任务中表现出色，并声称针对Agent代理能力做了优化，专为工具使用、推理和自主解决问题而设计。 大模型和智能体的区别是什么？在测试Kimi K2的智能体能力前，这是道必答题。 简单理解，大语言模型像一本“百科全书”，知识丰富，但需要人工查阅和应用；而智能体像你的“秘书”，它不仅知道答案，还能主动订餐厅、安排会议，也就是说，它“动手”能力比较强，可以跨平台调用其他App的能力。此前爆火一时的Manus、各品牌AI手机里的小助手，都属于智能体。 从官方放出的案例来看，作为一个基础大模型，Kimi K2迈出了智能体化的第一步。“我想去看Coldplay乐队的巡演，每次行程的预算为5000美元，包含所有费用。您能帮我规划所有事宜吗？……”在一长串Prompt（提示词）之后，Kimi K2不仅根据要求给出了完整的行程规划，完成演唱会所在城市的机酒与旅游规划，还自动将行程计入了使用者的谷歌日历。 记者也在Kimi K2中尝试让它提供一个8月“上海往返东京”的旅行规划，而且要求价格最合算，它不仅规划了具体行程，同时给出了价格最低的行程安排，以及航空公司和另一个机票比价网站的链接，但可能并没有给出明确的“订票”指示，Kimi K2并没有像演示中那样直接打开另一个网站进行操作。 不过相较于其他基础大模型，这已经是进步了。同样的需求，记者给到了DeepSeek、元宝和豆包，尽管它们也都给出了完整的规划，但并没有给出可执行的答案，仍以趋势类的建议为主，比如“7月中下旬预订最佳”，而不是直接给出一个确切的答案，比如到底哪几天最便宜，或者买哪个航空公司的机票，DeepSeek给出的答案甚至远高于正常票价。 官方文件表示，Kimi K2现已具备稳定的复杂指令解析能力，可将需求自动拆解为一系列格式规范、可直接执行的ToolCall（通用模型调用外部工具的字典）结构。你可以将其无缝接入各种Agent（智能体）/Coding（编码）框架，完成复杂任务或自动化编码，而且Agent能力已可通过API使用。 点评 显然，Kimi K2希望实现的是模型即Agent，或者可以说，它仍走在AGI的道路上，尽管目前能力还很稚嫩，但或许是Kimi另辟蹊径的开始。 不过，Kimi K2现在最大的问题应该是算力，记者刚测试了不到10个问题，对话框便显示，“当前模型对话次数已达到上限，可切换为其他模型继续对话”。 或许这也是月之暗面选择将Kimi K2开源的原因之一，毕竟不是谁都有xAI、字节、腾讯等大厂充沛的算力，这也说明直接面向C端用户不再是月之暗面的主攻方向。不如做一个“好用”的开源基座模型，从而借助社区力量完善自己的技术生态，并倒逼自己以更高的技术标准做出更好的模型。 Grok 4 数理化“遥遥领先” 却做不好“伦理题”? “所有学科碾压博士！”被马斯克称为“全球最聪明”的Grok 4，是妥妥的“Scaling Law（尺度定律）”代言人、土豪家的“富公子哥”，有着传说中的20万张英伟达H100、1.7TB参数（也有传闻说2.4TB）和100倍于Grok 2的训练数据，以及碾压所有其他大模型的基准测试成绩，再加上顶配版（SuperGrok Heavy）300美元（约等于2150元人民币）的月费，直接将所有人的期待拉满。 可刚刚过了两天，Grok 4便接连被曝“翻车”：7月8日，有媒体称，Grok参考马斯克掌管的社交媒体平台X用户发布的内容，生成一系列“反犹主义”言论，其中包括赞扬希特勒；知名的网络技术作家、Web框架Flask之父Simon Willison也发现，当涉及敏感议题时，Grok会搜索马斯克的推文，而fast.ai的创始研究员、昆士兰大学的名誉教授Jeremy Howard复刻了Simon Willison的实验后，更是发现64条消息中54条都是马斯克的观点。 有人说，Grok 4的营销策略，“就像特斯拉初期的自动驾驶策略——先画饼，后填坑”，但也有人认为，这些所谓的“翻车”都是个别现象，整体而言，Grok 4的能力普遍高于其他主流基础模型，压力已经给到了迟迟未露面的谷歌Gemini 3和OpenAI的GPT-5。 无论如何，先来看看Grok 4的基准测试数据。 最引人瞩目的自然是HLE（Humanity’s Last Exam人类最终测试），这项包含3000道高难度题目的多模态基准测试，是2025年初由全球近千名科学家共同打造而成。此前SOTA模型，如OpenAI的o3和谷歌的Gemini 2.5 pro得分徘徊在22%左右，Grok 4在同样不调用工具时得分是25.4%，可启用工具后，便快速上升至38.6%，而SuperGrok Heavy更是飙至44.4%。 在一些常规测试，比如GPQA（科学、数学、历史、常识）、AIME25（数学）、LCB（Live Code Bench 编程）、USAMO25（数学）等榜单中，Grok 4的成绩均有碾压性的表现，甚至在AIME25获得满分。 不过，从实测结果看，Grok 4的缺点也十分明显。 首先是编程能力远不及其做数学题的能力。有知乎网友用同样的编程任务测试了GPT-4、Claude4和Grok4，结果是GPT-4代码结构清晰，逻辑完整；Claude4不仅代码质量高，还有详细的注释；Grok 4基础功能能实现，但代码冗余，优化空间很大，“简单的算法题还能应付，但涉及复杂的系统设计、代码优化，就明显力不从心了”。 其次，256K Token的上下文窗口长度也称不上惊艳，远低于Gemini 2.5 Pro的1000K Token上下文窗口。不过，有网友实测表示，Grok4和SuperGrok Heavy完全可以替代o3-pro，后者幻觉率较高，而Grok 4就像是接入了o3的搜索和工具调用能力的Gemini 2.5 Pro，输出风格正常，搜索能力在线，而且还可以搜索X最新的帖子，当然“价格也贵了50%”。 不过，马斯克在发布会上公布，专用编码模型预计在8月发布，编码效果应该会有些惊喜。此外，9月多模态智能体将上线，10月会推出视频生成模型，都还是很值得期待的。 点评 Grok 4此次展现出的最重要创新，无疑是多智能体协同（Multi-Agent Collaboration），也即“多智能体内生化”（Multi-Agent Internalization）。 不同于传统模型“先训练后调用工具”的方式，Grok 4的多智能体协同机制在训练阶段就将工具调用能力嵌入模型的底层架构，智能体可以像人类使用手机应用一样调用“代码执行器”“网络检索工具”“数据分析模块”等工具，让多个独立的人工智能代理（Agent）并行处理任务，相互交叉验证并整合结果，以提供更准确、更高效的解决方案。 目前，SuperGrok Heavy版本支持最多四个独立智能体同时处理同一任务。每个智能体可以从不同角度分析问题，生成各自的解决方案，然后再彼此进行交叉验证，通过比较和评估，找出最优解。比如在量子物理题解中，便出现“3个智能体分别用弦理论、量子场论、经典力学推导，最终融合出更简洁统一公式”的案例。 不过，这种方式是典型的“富人游戏”，多智能体协作需要极高的计算资源，Grok 4的训练计算量是Grok 2的100倍、Grok 3的10倍，如此昂贵的使用成本，即便是马斯克也不再“大方”，相较Grok 3发布后的慷慨免费体验，Grok 4从一开始便是收费服务，普通版月租30美元，Heavy版月租300美元。 从一开始猛烈抨击OpenAI“忘记初心”到现在的“最贵大模型”，很多时候，马斯克的“AI平权”，听听也就罢了。 排版／ 季嘉颖 图片／ 月之暗面 xAI 来源／《IT时报》公众号vittimes 举报/反馈"
    },
    {
      "doc_id": 16902,
      "title": "阿里、百度、腾讯官宣!上线DeepSeek大模型",
      "time": "2024-02-04T00:00:00+00:00",
      "content": "近日，百度智能云、华为云、阿里云、腾讯云、360数字安全、云轴科技等多个平台宣布上线DeepSeek大模型，网友可以在各大平台上调用DeepSeek-R1、DeepSeek-V3等模型。 百度智能云、阿里云同日宣布 上架DeepSeek模型 2月3日晚间，百度智能云宣布，百度智能云千帆平台已正式上架DeepSeek-R1和 DeepSeek-V3模型，推出了超低价格方案，还可享受限时免费服务，登录百度智能云千帆ModelBuilder即可快速体验。 百度智能云称，此次接入的模型已全面融合千帆推理链路，集成百度独家内容安全算子，实现模型安全增强与企业级高可用保障，同时支持完善的BLS日志分析和BCM告警，助力用户安全、稳定地构建智能应用。 据了解，该模型限时免费2周，截止时间为2月18日24:00。限免配额是1000RPM&10000TPM，调用Tokens无上限。 记者登录了百度智能云网站，只需要点击在线体验，进行实名认证，在“模型广场”就可以调用DeepSeek-R1和DeepSeek-V3模型。据介绍，该模型由杭州深度求索人工智能基础技术研究有限公司自研，在数学、代码、自然语言推理等任务上性能表现优异。 记者尝试了一下DeepSeek-R1和DeepSeek-V3模型的“文本对话”功能，非常方便好用。 同样在2月3日，阿里云也宣布，阿里云PAI Model Gallery支持云上一键部署DeepSeek-V3、DeepSeek-R1。在该平台上，用户可以零代码实现从训练到部署再到推理的全过程，简化模型开发流程，为开发者和企业用户带来了更快、更高效、更便捷的AI开发和应用体验。 已有多家平台宣布上线DeepSeek模型 随着DeepSeek于2024年12月上线并开源 DeepSeek V3/ R1/Janus Pro，近期已有华为云、腾讯云、360数字安全、云轴科技ZStack等多个平台宣布上线DeepSeek大模型。 2月1日，据华为云官方公众号，DeepSeek-R1开源后引发全球用户和开发者关注。经过硅基流动和华为云团队连日攻坚，现在，双方联合首发并上线基于华为云昇腾云服务的DeepSeek R1/V3推理服务。得益于自研推理加速引擎加持，硅基流动和华为云昇腾云服务支持部署的DeepSeek模型可获得持平全球高端GPU部署模型的效果。 2月2日，腾讯云宣布，DeepSeek-R1大模型一键部署至腾讯云「HAI」上，开发者仅需3分钟就能接入调用。简单来说，通过「HAI」，开发者可以省去买卡、装驱动、配网络、配存储、装环境、装框架、下载模型等繁琐步骤，只需两步即可调用DeepSeek-R1模型。 2月2日，360数字安全称，近日，360数字安全集团宣布其安全大模型正式接入DeepSeek，将以DeepSeek为安全大模型基座，发挥360安全大数据优势，通过继续强化学习等技术手段，训练出“DeepSeek版”安全大模型，让安全真正做到“自动驾驶”。 2月2日，云轴科技ZStack宣布AI Infra平台ZStack智塔全面支持企业私有化部署 DeepSeek V3/R1/ Janus Pro三种模型，并可基于海光、昇腾、英伟达、英特尔等多种国内外 CPU/GPU 适配，将充分发挥DeepSeek开源模型和低成本高性能特点，助力企业级AI应用进一步落地。其中：V3适用于通用型自然语言处理任务，R1专注于复杂推理任务，而Janus Pro则擅长多模态理解与生成，可满足企业不同AI场景的需求。 海外方面，目前亚马逊AWS、微软Azure、英伟达等全球多家科技厂商陆续宣布接入DeepSeek模型。 举报/反馈"
    },
    {
      "doc_id": 16903,
      "title": "腾讯混元大模型的视频生成功能将于12月3日上线",
      "time": "2024-11-29T00:00:00+00:00",
      "content": "观点网讯：11月29日消息，腾讯混元大模型的视频生成功能将于12月3日上线，可在腾讯元宝App中申请试用，企业客户可通过腾讯云接入，API内测申请也已开放。 另外，腾讯还计划开源该130亿参数量的视频生成大模型。 据过往报道，今年9月，腾讯发布了新一代大模型腾讯混元Turbo，采用MoE架构，比上一代产品推理效率提升100%，推理成本降低50%。 本文源自：观点网 举报/反馈"
    },
    {
      "doc_id": 16920,
      "title": "腾讯的“大模型宝宝”,能长成杀手级应用吗?",
      "time": "2024-06-22T00:00:00+00:00",
      "content": "原创 陈月芹 经济观察报 王昕称，元宝的产品定位是面向更多普通人的AI产品，而非高高在上的、非常小众的、为极客圈定制的产品。元宝团队从解决工作和生活中的高频需求入手，并希望通过其他AI能力给更多普通人的生活提供帮助。 作者：陈月芹 封图：图虫创意 如果中国未来会出现一款AI领域的杀手级应用（Killer APP），它最有可能花落谁家？ 它可能出自“APP工厂”字节跳动、在AI上长期且重金投入的百度、深耕云计算业务的阿里巴巴等互联网巨头，也可能来自打造了爆款C端（个人用户端）应用Kimi的月之暗面、“希望能够在起步阶段就做出超级应用”的百川智能等AI新贵。 这些AI行业的新老玩家，从2023年以来陆续发布多款C端AI应用。然而，坐拥微信、QQ两大国民级应用的腾讯并不急于出手，它基于混元大模型打造的第一款C端AI应用腾讯元宝，历经近半年时间打磨，最终于5月30日发布。 姗姗来迟的腾讯元宝，囊括了AI搜索、AI总结、AI写作、绘画、创意头像、识图、口语陪练、翻译等市面上常见的功能，并接入了腾讯庞大的内容生态体系。但AI同行乃至用户似乎对元宝有着更高的期待，有从业者感慨，元宝与其他C端AI应用相比，并无显著差异，没有带来引领行业潮流的新体验。 衔着金钥匙出生的元宝，为何着眼于看似普通的功能？背靠腾讯这棵大树，它的成长计划是什么？6月14日，腾讯混元产品总监王昕在接受经济观察报独家专访时回应了上述问题。 王昕称，元宝的产品定位是面向更多普通人的AI产品，而非高高在上的、非常小众的、为极客圈定制的产品。元宝团队从解决工作和生活中的高频需求入手，并希望通过其他AI能力给更多普通人的生活提供帮助。 谈及元宝的未来规划，王昕说，眼下，元宝团队的工作重点是获取用户，根据真实用户的使用反馈，调整模型和产品策略。在AI大模型这条足够长的雪道上，元宝的成长不急于一时。 |对话| 元宝的诞生 经济观察报：为什么取名为“元宝”？ 王昕：这跟产品定位有关系，我们不希望做出来的东西，是一款高高在上的、非常小众的、为极客圈定制的产品。元宝可以理解为混元大模型的宝宝，这个名字我们觉得会更可爱、好记。 经济观察报：元宝解决了用户的哪些问题或痛点？ 王昕：在工作和生活两个大的场景，用户的需求没有变化过，主要是信息获取与生成、内容消费、搜寻服务。我们根据这些需求，通过AI赋能的方式一个个切入。我们希望做一个用户需要的产品，当场景和解决方案覆盖得越来越多时，用户的满意度自然就会提升。 经济观察报：在元宝首批上线的AI搜索、AI总结、创意头像、口语陪练等功能中，哪些功能的使用频率更高？ 王昕：元宝现在主打的人群或者场景是工作（效率提升类）偏多一点，其中的AI搜索是一个比较高频的功能。在泛生活化、泛娱乐化的场景中，百变AI头像、口语教练和超能翻译官也是元宝的“拳头”级应用。 经济观察报：为什么选择了这几个功能作为首批推出的应用？ 王昕：我们内部有一套“握手机制”，它来自三个维度： 第一个维度是最重要的用户诉求。有数据显示，一个人每天在互联网上搜索频率极高，因此我们会先定义用户有哪些高频诉求。第二个维度叫做模型尖刀。当用户有了这个诉求，我们通过现在腾讯混元大模型的能力把它实现得更好。第三个维度要看腾讯的产品与内容矩阵，我们做了这些能力，有没有可能协同更多业务和场景，实现多赢。 选择这几个功能是三方“握手”的过程。 经济观察报：总结起来就是用户诉求、产品能力和腾讯自己的优势。那为什么最后具体选择了工作、生活这两个板块和多个子功能？ 王昕：一个新生的事物或者一种新生的能力，还是要从高频用户开始切入。一般来说，他们对于工作效率提升的诉求会更强烈。同时，这些用户也是他们周边生活半径里互联网产品的意见领袖，会产生传播效应。所以我们先瞄准了高频用户。 这里的高频用户，首先是18岁—35岁、高学历的人群，再慢慢往下拆分，主要是职场人士或高学历学生人群；再去拆分他们在工作、学习、日常生活中有哪些需求，用元宝怎么来满足，因此我们开发出了翻译、文字处理等功能。 经济观察报：腾讯云副总裁、腾讯混元大模型负责人刘煜宏曾说，希望腾讯元宝最终服务于每个普通人的生活。低使用门槛是元宝的其中一个定位吗？ 王昕：在产品愿景里，低使用门槛是元宝甚至腾讯做的所有产品的一个指导方针。我们会通过极简式的交互，让用户知道大模型产品大概是什么，只需要让用户简单地点击，而不是较高门槛地去输入一大堆字。 背靠腾讯内容生态 经济观察报：元宝的核心功能之一是AI搜索。它在搜索方面有什么优势？ 王昕：大模型本身最重要的是总结能力、自学泛化能力，但做搜索本身，不论是AI搜索，还是传统搜索，信息源要准确、不泛滥。微信公众号是整个中文语料里最好的信息源，微信公众号的优质文章便是元宝的优质语料。 经济观察报：外界十分关心元宝跟腾讯生态怎么结合。元宝在腾讯内部打通其他业务的难点在哪里？ 王昕：元宝接入了微信搜索、搜狗搜索等搜索引擎，可以覆盖微信公众号等腾讯生态的资讯和内容。 业务之间打不打得通，根本上要解决一个问题：如何实现双赢？怎样既能实现对方业务的成功，又能让元宝实现更好的用户体验。 经济观察报：除了微信，还有哪些业务可以结合？ 王昕：腾讯生态不只有微信，腾讯视频、腾讯体育等都是我们在合作的兄弟团队。 AI可以给内容粉丝群体带来更多互动，比如角色模型。以近期热播剧《庆余年2》为例，我们通过混元的努力，例如通过投喂小说等做训练和学习，训练出了林婉儿、范闲等人物的角色模型。当粉丝跟元宝中的角色模型互动时，他们能够明显地体验到对方的性格、倾向、说话的方式。 “犟宝” 经济观察报：我同时向元宝等国内外主流大模型产品提问“单词straw-berry中有几个r”，得到的答案都是2个。为什么它们在这种基础功能上也会出现错误？ 王昕：大模型因为幻觉偶尔会出现错误，但这些错误会被技术团队在训练中逐步修正。 经济观察报：然后我依次向元宝提问“正确答案不是3个吗？不是6个吗？”元宝重新分析后，明确回复是3个r。而当我问其他大模型产品同样的问题时，多数大模型产品都会顺着提问者的说法，将答案改为6个r。 王昕：元宝的个性有一点犟，我们内部还叫它“犟宝”。当它重新分析后，确定自己的答案是对的，会反驳提问者：“我已经分析了每个字符，我确定我的答案是对的。”“犟”的前提是回答的精准性。因为现在很多用户会诱导模型，比如问“你确定1+1等于2吗”，很多模型一下子就会“滑跪”：“对不起，我算错了，1+1等于3。”元宝会告诉你：“我确定就是2。”它会坚持自己的判断。 经济观察报：有些用户也经常“刁难”元宝，比如在腾讯今年第一季度财务业绩公布前夕，他们提前问元宝腾讯该季度的业绩，有时候会获得一个不准确的答案。 王昕：这是一个时间幻觉。我们也在逐步训练元宝，一是要让模型知道还没有发生的事情，你就是不知道的。 二是在模型的生成过程中，当时间的插件或指数不是很准确时，模型的信息源应该更卡时间。比如用户问“昨晚欧冠谁夺冠了”，这里的时间参数不够精准，模型就会到处搜，可能搜到去年、前年的欧冠冠军，那就有可能增加幻觉的可能性。 更多想象 经济观察报：从元宝的项目立项到正式上线期间，国内外互联网大厂纷纷发布自己的大模型产品，这段时间你们团队经受了哪些压力？ 王昕：公司管理层给团队的价值观方向非常明确：不争一时之先。元宝的内测版本今年初就出来了，在这个过程中迭代了近40个版本，直到它变成现在的状态。当然元宝现在可能还会有小失误，但整体的准确率已经很高了。我们觉得AI大模型是一条很长的雪道。此时急于一时，没有太大的意义。 经济观察报：元宝还有哪些想象力，比如文生视频什么时候上线？ 王昕：我们只是还没有把文生视频功能包装成独立的应用或者放到元宝里。但文生视频的能力我们早就开发出来了，我们只是想找到一个更好的用户切入口。 视频可以有两个落地方向。一个是专业场景下的创作，赋能专业人士或设计师、新媒体、自媒体等的创作过程；第二是对普通用户来说，大模型可以像PS图片功能一样，未来通过视频风格化做一些泛娱乐尝试。 经济观察报：元宝近期是否有商业化计划？ 王昕：放眼C端AI产品，整个行业都处在非常早期的阶段。ToB（面向企业用户）侧的商业化相对而言走得更靠前一点，因为它确实在解决生产端的问题，比如AI作图会提升美工的生产效率。 消失的证券营业部 原标题：《腾讯的“大模型宝宝”，能长成杀手级应用吗？》 阅读原文"
    },
    {
      "doc_id": 16925,
      "title": "腾讯元宝APP入驻微信,用户可通过聊天界面体验元宝AI服务",
      "time": "2024-04-16T00:00:00+00:00",
      "content": "蓝鲸新闻4月16日讯 4月16日，腾讯旗下元宝APP正式入驻微信，用户现可直接在微信聊天界面中体验元宝AI服务。据“元宝”账号介绍，其搭载混元和DeepSeek双模引擎，无缝衔接微信生态，提供一键解析公众号文章、图片和文档服务。该账号前身为“元宝红包封面助手”，于今年春节期间上线。（蓝鲸新闻 朱俊熹） 举报/反馈"
    },
    {
      "doc_id": 16937,
      "title": "AI大模型正为线下商业注入“云智融合”的新动能丨一克商评",
      "time": "2025-07-19T00:00:00+00:00",
      "content": "封面新闻记者 欧阳宏宇 雷强 凯德集团（中国）与阿里云深化合作，推动AI技术在智慧商业地产落地 7月16日，凯德集团（中国）与阿里云在杭州签署合作备忘录。双方将围绕AI、大数据和ESG三方面深化合作。通义大模型将用于提升凯德在中国的购物中心、酒店等多类智慧商业的运营效率和客户体验。据阿里云智能集团首席战略官郑俊芳透露，很高兴与凯德集团（中国）进一步合作，共同推动云和AI技术与线下智慧地产融合，提升运营效率和客户体验。 点评：头部商业地产商与顶尖科技平台强强联合，标志着商业地产数字化转型迈入深水区。其示范效应将推动AI大模型在实体商业的规模化落地，加速全行业智能化升级进程。此次合作以AI、大数据、ESG为核心抓手，特别是通义大模型的落地应用，直击行业痛点。通过智能技术重构购物中心、酒店等场景的运营逻辑与客户体验，为线下商业注入“云智融合”的新动能。未来商业空间的竞争，必将是科技赋能深度与场景创新广度的双重较量。 小米深圳总部正式开园 7月18日，继北京、武汉、南京之后，小米全国第四个区域总部——小米深圳总部正式开园。据了解，作为小米深圳总部的主体建筑，小米深圳大厦坐落于深圳南山区后海金融商务区的核心区域，总建筑面积为4.6万平方米，毗邻深圳人才公园、深圳湾万象城、华润大厦等标志性建筑。 点评：背靠深圳强大的科技创新生态和产业链优势，小米深圳总部主要集中是技术研发的核心职能，从区域划分来讲承接着大湾区的资源禀赋。在全球化战略的布局下，科技创新成为小米对外输出的重要保障。随着深圳总部的启用，小米将进一步整合区域资源，加速技术创新与产业升级，为全球化的深根和布局贡献更多智力支持。 我国L2级辅助驾驶渗透率超50%，AI驱动汽车行业新竞赛 “目前围绕智能化的全球竞争已全面展开，我国L2级辅助驾驶渗透率已超过50%，位列全球最高。同时，泊车辅助驾驶技术等新兴技术在中高端车型的渗透率也超过20%。”7月18日，中国电动汽车百人会副理事长兼秘书长张永伟表示，中国汽车产业在电动化上实现了换道超车，智能化上实现了终端先行，但仍需巩固优势。这意味着，在中国汽车市场上，每卖出两辆新车，就有至少一辆搭载了L2级辅助驾驶技术。事实上，随着今年比亚迪“全民智驾”口号的喊出，辅助驾驶的声量达到了一个新高潮，并逐渐成为消费者购车时的重要考虑因素。 点评：我国L2级辅助驾驶渗透率突破50%大关，这意味着每售出两辆新车，至少有一辆搭载此项技术。这不仅是数据的里程碑，更是中国汽车产业从电动化“换道超车”后，在智能化赛道上确立终端先行优势的有力明证。比亚迪“全民智驾”战略的推进，更将辅助驾驶从高端配置推向大众核心需求，显著抬升了消费者购车标准的分水岭。 腾讯元宝宣布打通QQ音乐 7月18日，腾讯元宝宣布打通QQ音乐。产品界面显示，首次点击下划线歌曲名时，会提示关联QQ音乐账号，授权完成后便可在元宝内直接播放，不会中断对话。目前，该功能已在腾讯元宝手机版上线。今年以来，腾讯元宝已与腾讯文档、腾讯地图、腾讯新闻、微信读书、起点读书等多个产品打通，实现一站式的点击下划线跳转阅读书籍、地图导航等体验。 点评：当轻点歌曲便能唤醒音乐的旋律，用户甚至无需跳出对话框，这看似微小的“丝滑体验”，实则是腾讯生态协同的关键落子。音乐功能的接入更具象征意义。作为高频且自带情感连接的内容形态，QQ音乐的打通不仅完善了元宝的娱乐服务能力，更悄然改变了用户习惯——当搜索歌曲、追更小说、查阅资料都能在对话框内闭环完成，元宝正从“工具”蜕变为连接数字生活的神经中枢。 举报/反馈"
    },
    {
      "doc_id": 16947,
      "title": "腾讯大模型战略首次全景亮相 混元快思考模型跻身全球第八",
      "time": "2024-05-21T00:00:00+00:00",
      "content": "中国日报5月21日电（记者 程钰）腾讯的大模型战略第一次全景亮相。5月21日，在2025腾讯云AI产业应用峰会上，从自研的混元大模型、到AI云基础设施，再到智能体开发工具、知识库以及面向场景的应用，腾讯大模型矩阵产品全面升级。腾讯正通过持续打磨技术和产品能力，为企业和用户在大模型时代打造真正“好用的 AI”。 腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生 腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生表示，随着AI的持续落地，每个企业都将成为AI公司；每个人都将是AI加持的“超级个体”。 他强调，过去一年，腾讯的各项业务已经全面拥抱AI，同时看到了产业对大模型的庞大用量和深切诉求。未来，腾讯将持续加速大模型创新、加速智能体应用、加速知识库建设、加速基础设施升级，推动AI技术走进千行百业，也走进每个人的生活。 混元快速迭代跻身全球前八，全面开源多尺寸模型 在疯狂卷技术的全球大模型角逐中，腾讯混元正小步快跑、快速迭代，技术能力持续提升。 汤道生在会上宣布，在全球公认的权威大语言模型评测平台Chatbot Arena上，混元TurboS排名已攀升至全球前八，国内仅次于DeepSeek。其中，代码、数学等理科能力，混元TurboS也进入全球前十。 早在去年下半年，腾讯就大力投入了深度思考模型的路线攻关，混元T1自年初上线元宝App后，持续快速迭代。基于TurboS基座，腾讯新推出视觉深度推理模型混元T1 Vision和端到端语音通话模型混元Voice，近期将推出实时视频通话AI体验。 今年以来，混元的迭代速度明显加快。在多模态生成领域，混元图像 2.0 率先实现“毫秒级”生图，混元3D v2.5凭借业界首创的稀疏3D原生架构，实现了可控性与超高清生成能力的代际飞跃。凭借技术的领先性和开放的生态，混元3D赢得了开源社区的高度认可，Hugging Face模型下载量超160万。 腾讯云副总裁、腾讯混元大模型技术负责人王迪介绍，目前，混元已实现图像、视频、3D、文本等在内的全模态开源，未来将推出多尺寸混合推理模型，从0.5B到32B的dense模型，以及激活13B的MoE模型，适配企业与端侧需求。混元图像、视频、3D等多模态基础模型及配套插件模型也将持续开源。 来源：中国日报网 举报/反馈"
    },
    {
      "doc_id": 16965,
      "title": "腾讯、阿里开启AI变现长跑",
      "time": "2024-05-16T00:00:00+00:00",
      "content": "当全球AI竞赛进入深水区，中国科技巨头的战略路径差异正逐渐清晰。 5月15日，阿里巴巴集团发布的2025财年Q4及全年业绩显示，该季度内，阿里巴巴集团收入2364.54亿元，同比增长7%；经调整EBITA（非公认会计准则指标）同比增长36%至326.16亿元；非公认会计准则净利润为298.47亿元，同比增长22%。 “AI驱动”持续释放发展动能，核心业务增长继续提速。在千行百业强劲的AI需求推动下，AI相关产品收入连续七个季度实现三位数增长，带动阿里云季度收入增长加速至18%，阿里云2025财年全年收入突破双位数增长。 就在一天前，腾讯发布了财报，AI同样是其中的高频词。腾讯董事会主席兼首席执行官马化腾表示，AI能力已经对效果广告与长青游戏等业务产生了实质性的贡献，亦加大了对元宝应用与微信内的AI等新AI机遇的投入。 今年AI投入显著加码，最新财报显示，腾讯资本开支同比增长91%，阿里资本开支同比增长168%。未来，两大巨头显然选择继续加注。上一财季阿里宣布未来三年投入3800亿元用于AI及云基础设施建设，腾讯预计今年资本开支将逼近千亿元。 管理层仍坚信，短期阵痛是为长期领跑AI时代必须支付的“门票”。 AI推动增长 AI驱动是财报中的亮点，但阿里和腾讯的路径有所差别。 阿里的AI战略更偏向“基础设施+开源生态”。尽管阿里没有微信、抖音这样的超级C端流量入口，但其核心优势在于阿里云——国内市场份额最高的公有云服务商。 过去一年，阿里云收入增速从3%加速至本季度的18%。2025财年全年，阿里云收入达到1180亿元，年度收入同比增幅达到了11%。这一反弹得益于AI热潮的推动，大模型快速发展显著拉动了云计算需求。 财报表示，阿里云增长势头主要由更快的公共云收入增长带动，包括AI相关产品的采用增加。该季度内，AI相关产品收入连续第七个季度保持三位数的同比增长。 财报显示，AI相关产品在众多的行业垂直领域获得更广泛应用，包括互联网、零售、制造业和媒体，并越来越侧重于增值应用。 在电话会上，阿里巴巴集团CEO吴泳铭还分享了AI领域的两大最新趋势：一是在大中型企业，AI应用开始从内部系统向用户侧场景渗透；二是积极使用AI产品的客户，从大中型企业延展到大量中小企业。 据悉，近期，宝马、中国联通、中国移动等众多行业头部客户与阿里巴巴达成AI领域战略合作，中国工商银行正式选择阿里云PolarDB数据库作为其全行级交易型分布式数据库。 相比之下，腾讯更多聚焦于C端市场，AI应用实现了全场景的用户覆盖。原生AI产品如“元宝”借助混元大模型与DeepSeek双引擎驱动，用户规模迅速增长，2月至3月，腾讯元宝日活激增超20倍，成为了中国DAU排名第三的AI产品。 腾讯的核心产品也纷纷借助AI技术升级，微信、QQ、腾讯文档、QQ浏览器、腾讯会议、理财通等产品已通过AI能力深度整合，智能化体验持续升级。 与此同时，过去几个月里，AI也在更深入地整合到大厂的各项业务中。 目前来看，腾讯在2025年一季度的财报展现了AI战略的初步成效，其技术投入已开始反哺核心业务。例如，在营销服务业务上，AI驱动的智能投放系统显著提升了广告匹配精准度，带动营销服务收入同比增长20%至319亿元，连续十个季度保持两位数增长。 在游戏领域，AI技术的应用进一步增强了用户黏性，如《和平精英》引入DeepSeek大模型，推出AI助手和AI队友，优化玩家体验并提升活跃度。 再看阿里，本季度，淘天AI驱动的广告工具“全站推广”在商家的渗透率提升，令商家的市场营销效率得到提升；阿里巴巴国际站面向海外买家推出的原生AI应用Accio企业用户已超百万；截至5月初，闲鱼全线AI产品已覆盖近2200万用户，通过智能托管服务累计售出的GMV已达6.4亿元。 可以看出，AI正成为大厂存量业务效率提升与体验革新的关键变量。 持续投入 大厂对AI的投入还在继续。 吴泳铭自2023年上任后便确立“用户为先，AI驱动”双核心战略，并在2024年剥离银泰、高鑫零售等非核心资产，将资源聚焦于电商与云计算。5月15日，在2025财年Q4季度财报分析师电话会上，阿里巴巴表示，集团剔除大润发和银泰外整体收入同比增长10%。 上一财季，阿里宣布未来三年投入3800亿元用于AI及云基础设施建设，这一金额超过过去十年总和，重点投向算力中心、基础模型平台及业务AI化转型。 财报显示，本季度阿里资本开支继续保持高强度，支持AI在千行百业加速应用落地。阿里在2024年四季度的单季度资本开支已经来到了317.7亿，同比增长259%，2025年一季度更是高达859.7亿元，同比增长168%。 腾讯在AI领域的投入力度也在过去一年显著增加。2024年四季度，腾讯资本开支同比增长386%至365.8亿元，全年资本开支767.6亿元创历史新高，占总营收的11.6%。 进入2025年，这一趋势仍在延续，一季度腾讯资本开支274.8亿元，同比增幅达91%，占营收的15%，重点投向算力基础设施、大模型研发及人才储备。 腾讯计划在2025年进一步增加资本支出，并预计资本支出将占收入的“低两位数百分比”。这意味着2025年腾讯的资本开支可能接近千亿元的水平。 尽管AI投入带来了显著的业绩提升，但市场仍对大厂的高资本开支与短期盈利压力存在担忧。AI相关研发开支的激增以及GPU等硬件投入的持续高位，可能对自由现金流造成短期压力。 财报显示，阿里巴巴该财年经营活动现金流净额为1635.09亿元，同比下降10%；自由现金流为738.70亿元，同比下降53%，阿里巴巴在财报中表示，主要归因于云基础设施支出增加。 不过，阿里管理层在财报会议中强调，截至季度末，净现金水位为3664亿元，折合505亿美元。“强劲的净现金水位和健康的经营现金流，让我们有足够的信心和资源，加大对云和AI基础设施的投入，把握持续强劲的市场需求和最新的AI技术所带来的巨大增长潜力。” 腾讯管理层则强调，现有高质量收入（如游戏、广告、金融科技）的经营杠杆能够消化AI投入的额外成本。 以元宝为例，腾讯在报告期加大了对元宝的营销投入，但整体销售及市场开支只增长4%至79亿元，并且占收入的百分比从去年同期的5%下降至4%。这是因为部分营销投入增长被新游戏发布的广告开支减少所抵消。 “我们相信，在AI战略投入阶段，现有高质量收入带来的经营杆杆，将有助于消化这些AI相关投入产生的额外成本，保持财务稳健。同时我们预期，这些战略性的AI投入将为用户与社会创造价值，并为我们产生长期、可观的增量回报。”马化腾表示。 无论是腾讯还是阿里，未来对于AI的投入不会减速。从财报数据也可以看出，AI不再是“未来的故事”，而是实实在在的业绩驱动力。然而，这场“长跑”才刚刚开始。 大厂们正站在一个技术周期与商业周期交汇的关键节点，能否将其在各领域的庞大资源整合为统一的AI竞争力，将决定它们能否在下一个十年继续领跑。 举报/反馈"
    },
    {
      "doc_id": 16968,
      "title": "腾讯在AI上花冒了吗?",
      "time": "2024-05-15T00:00:00+00:00",
      "content": "文 | 电厂，作者 | 何畅，编辑 | 高宇雷 DeepSeek爆火之后，AI就时刻牵动着中国互联网公司股东们的心——业务完全不沾边或涉及太少，那么这家公司的想象力堪忧；基础建设方面投入过多，数字挂出来影响到利润率和现金流，又要为股东回报发愁。 腾讯属于后者。5月14日，腾讯发布2025年第一季度业绩，总收入为1800亿元，同比增长13%；非国际财务报告准则下归母净利润为613亿元，同比增长22%。其中，AI不仅与游戏、社交、广告等业务关联，也再次成为分析师们提问的焦点。 就在这个季度，腾讯举集团之力推广旗下AI助手产品腾讯元宝，并对相关团队进行了重组。此前隶属于TEG（技术工程事业群）的腾讯元宝被转入CSIG（腾讯云与产业事业群），与混元大模型技术研发体系分开；QQ浏览器、搜狗输入法、ima等产品和应用也从PCG（平台与内容事业群）调整至CSIG。自此，快速的产品创新和深度的模型研发分属于两个事业群，思路和架构上都更加清晰了。 尽管腾讯肯定了AI对业务产生的实质性贡献，但谈AI创造规模化收益还为时尚早。毕竟，现在还处于一个非常早期的阶段，能做的是投入、浇灌、培养，“加速激发用户需求”，而不是急着获利、收割。腾讯董事会主席兼首席执行官马化腾表示：“在AI战略投入阶段，现有高质量收入带来的经营杠杆，将有助于消化这些AI相关投入产生的额外成本，保持财务稳健。”利润表现会不会承压，就要看游戏、广告这些“传统业务”到底能翻出什么新花样了。 游戏支棱了，但依赖“熟脸” 2025年第一季度，腾讯游戏收入为595亿元，同比增长21%，延续了20%以上的同比增长；本土市场与海外市场都没有掉链子，增速一起加快。 春节假期叠加季节因素，这一季度是本土市场游戏的旺季，收入同比增长24%至429亿元。过去的一年里，在经历了运营模式和策略玩法的调整之后，《王者荣耀》和《和平精英》两款长青游戏越来越“支棱”了。通过推出蛇年限定时装、热门模式的升级与返场，加上IP联名和城市文旅联动，老游戏依然对用户展现出了极大的吸引力。此外，《DNF》手游和《三角洲行动》也有所贡献，但前者的收入和流水可能在第二季度出现回落——2024年5月上线，第二季度面临的基数太高了。 国际市场游戏表现同样强劲，收入为166亿元，同比增长23%，主要得益于《荒野乱斗》《部落冲突：皇室战争》《PUBG》手游的收入提升。在感谢Supercell之外，和本土市场游戏一样，增长还是依赖长青游戏，兜兜转转依然是你。 AI能力正在渗透至腾讯的各项业务，游戏是其中的重点。腾讯首席战略官James Michelle进一步解释了AI对长青游戏的贡献，主要是MOBA游戏（大型多人在线竞技游戏），这也是腾讯本土市场游戏收入的主要来源。“我们可以通过多种方式在游戏中部署AI，其中最有趣的包括利用AI帮助新手玩家训练、陪伴现有玩家以及防止作弊和黑客攻击等，这些都尤为重要。” 除了游戏，增值服务的另一个组成部分是社交网络，本季度收入为326亿元，同比增长7%，主要来自腾讯音乐付费会员收入增长、手游虚拟道具销售和小游戏平台服务费增长。腾讯视频、腾讯音乐付费会员数分别为1.17亿、1.23亿，环比上一季度微增，这一次至少没有流失。 广告发力，微信电商空间大 “三驾马车”之一的广告，取得319亿元收入，虽然对比容纳了双11大促的上一季度，环比下滑9%，同比却上涨了20%，增速加快。腾讯给出的原因是，广告主对视频号、小程序结合微信搜一搜广告库存的需求强劲、AI对于广告平台的升级、微信交易生态系统的优化。 简单来说，是微信生态的助力。James Michelle表示，公司并没有增加广告库存，“流量增长和广告技术改进是关键”。此前，腾讯管理层一直在强调，腾讯对于微信生态广告加载率的控制，可以说与字节跳动的态度形成了鲜明的对比，目前视频号广告加载率在3%至4%。正如James Michelle所说“我们甚至不一定希望看到增速持续加快”，“对我们而言，更重要的是确保未来有很长的‘跑道’，让这一增长区间持续多年，而非几个季度”。 重视用户体验，这无可厚非。但腾讯广告推送的精准程度尚有待加强，AI能否拓展广告收入的提升空间，仍然以技术迭代为核心。同时，腾讯总裁刘炽平认为，如果能够在微信生态内构建更强的交易闭环，“比如广告点击后直接促成小程序交易”，广告客户的投放意愿和单次点击价值将显著提升。 抖音做电商的出发点，其实正是以更高的变现效率卖广告。让别人做，不如看别人跑通之后自己上手。春节期间，微信小店“送礼物”小试牛刀，而在财报发布当天，腾讯微信事业群成立电商产品部，负责微信内交易模式的探索，微信开放平台基础部更名为开放平台部，这也被外界视为电商优先级上升的信号。不过，刘炽平称，这只是因为规模扩大进行的拆分和独立，不是重大调整，不必过度解读。 来源：腾讯广告微信公众号 即便如此，微信电商还是被赋予了更多的遐想。2025年以来，微信小店在持续完善功能的同时，大力拓展新商家入驻并提供相应的激励措施，以加大商品库，吸引更多成交。至于商家是否会因为电商业务的发展而在这里持续投放广告，还需要时间证明。至少现在，腾讯已经开始期待“内循环”了。 最后一驾马车是金融科技及企业服务，同比5%的收入增速虽然无法与游戏和广告相比，但毕竟回暖了。其中，金融科技服务收入的增长源自消费贷款服务和理财服务收入的增长，企业服务收入的增长与云服务收入及商家技术服务费的增长有关。从这个角度来看，电商业务的进步也将拉动支付和企业服务收入。 AI投入，脚步不能停 2025年第一季度，使用过腾讯旗下产品的用户，应该都直接或间接地认识了腾讯元宝。营销力度的加大，让这款产品的广告短时间内密集地出现在微信朋友圈、搜狗输入法弹窗、腾讯视频首页广告以及微信“九宫格”，B站、豆瓣、虎扑等平台，甚至是腾讯体育NBA节目的主持人口播。 推广带来了下载量的攀升，上一季度的财报电话会议上，刘炽平透露，2月至3月，腾讯元宝日活跃用户数量激增超过20倍。不过，或许是腾讯元宝的外部推广占比较小、大多集中在腾讯体系内部资源，第一季度的费用增长并不十分激进，销售支出同比增长4%。 关于腾讯元宝的后续计划，公司层面释放出的信号是，为其提供更多与微信生态的链接，这也是基于社交属性出发的优势。刘炽平认为，产品还“处于非常早期的开发阶段”，或许在几个季度后，会有更多系统性的进展可以汇报。除了现有业务AI化、推进多场景应用的加速融合，腾讯也在迭代升级自研的混元大模型，2025年相继推出了深度思考模型T1、快思考基座模型Turbo S。 当然，升级背后，算力加码、人力也要随之加码。同期，腾讯一般及行政支出同比增长36%至336亿元，不过这里有40亿元花在了育碧的重组上；研发开支也同比增加超过40亿元，达到189亿元——其中，雇员福利开支超过150亿元，由于腾讯没有大幅扩招计划，所以原因在于AI人才比较昂贵，而这已经是同比增速放缓的情况。 2024年第四季度，受AI发展影响，腾讯资本开支达到390亿元，直接给了股东当头一棒。而在2025年第一季度，这个数字环比下降但同比接近翻倍，达到275亿元，主要包括对IT基础设施（电脑设备、零配件及软件）、数据中心、土地使用权、办公园区及知识产权（不包括媒体内容）的投入。 此前，按照腾讯收入与资本支出增长的预期计算，2025年全年的资本支出有望接近千亿元水平，在第一季度已经前置消耗了超过四分之一。合理猜想，这或许涉及到芯片限购以前的购入和储备。毕竟，刘炽平也承认“我们面临的局面充满动态变化”。 另外，新业务的投入与产出存在时间错配，考虑到腾讯的过往经验，James Michelle给出的参考区间是一到两年。也就是说，接下来的一年多时间里，腾讯还将继续走在对AI投入的道路上，静候开花结果，股东需要沉得住气。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    },
    {
      "doc_id": 16989,
      "title": "电费直降40%!盛隆电气2025将推两大AI新品,DeepEnergy开启能源...",
      "time": "2025-07-18T00:00:00+00:00",
      "content": "极目新闻记者 刘闪 何佳仪 7月17日，中国北京第三届链博会现场，智能用电龙头企业盛隆电气举行新技术成果分享会，宣布2025年将推出两款深度融合自研专业AI大模型DeepEnergy的划时代产品——AI-iPanel 2025配电设备与AI-iDrip 2025智慧能源管理系统。 这两款产品将引领电力能源行业正式迈入“AI深度驱动”的新纪元，其核心价值在于直接、显著降低用户初始投资成本，并直接、大幅节约长期能源运行费用，颠覆了行业传统认知与设计理念。 10年从数字化运维到AI节能 投资成本降15%，空调电费减40% “今年是iPanel与iDrip发布十周年。十年前，我们用数字化技术帮助用户进入智能化时代，降低用户后期运维成本，”盛隆电气集团光谷电气副总裁张立辉表示，“十年后的今天，AI-iPanel 2025与AI-iDrip 2025又将引领行业AI革命，将AI算法与电力能源工程实际场景深度结合，为用户在投资成本及能源运行方面创造巨大价值。” 盛隆电气集团光谷电气产品经理胡佳介绍，AI-iPanel 2025的核心亮点在于其与DeepEnergy模型深度融合，带来两大颠覆性优势：首先是显著降低初始投资成本——依托DeepEnergy驱动的AI优化设计，实现高度智能化集成管理，直接为用户降低15%的投资成本。同时，AI模型还能精准预测用户未来电力负荷需求，对变压器及负载进行智能动态优化调配，降低线损耗率，从而有效降低能耗。 即将问世的AI-iDrip 2025也凭借DeepEnergy模型大大降低建筑能耗。比如夏日空调用电高峰，AI优化运行节能模型可精准预测大楼每天不同时段的冷气需求，并结合电价高低时段和空调主机的运行效率规律，自动计算出最优方案，提高冷源系统运行能效比。 用户仅需极低投入甚至零新增硬件投入，即可实现平均节约空调系统电费20%、最高可达40%的显著收益。其技术核心已从过去的数字孪生、预警控制，全面转向“实打实的AI节能”，带来可量化、高回报的能源成本削减，颠覆了传统楼宇自控系统及盛隆自身过往的iDrip技术。 46年行业经验厚积薄发 DeepEnergy破解电力能源难题 DeepEnergy是支撑AI-iPanel 2025与AI-iDrip 2025的核心技术引擎。与DeepSeek等通用大语言模型不同，DeepEnergy是专为解决用户端电力能源运行难题而研发的专业AI模型。 DeepEnergy融合了大量盛隆自主研发的专业AI算法，深刻理解电力能源内在运行规律和物理机理；同时基于盛隆46年在行业积累的海量实际运行数据，进行持续训练与迭代，确保模型预测精准、优化可靠；直接面向用户配电优化、能源高效运行等核心业务需求，提供切实可行的AI解决方案。目前，DeepEnergy模型已具备在包括DeepSeek在内的主流AI平台上的部署能力。 作为电气行业智能化引领者，盛隆电气始终坚持自主创新，引领行业发展。2016年在市场上首家推出具有自主知识产权的智能品牌柜iPanel，拥有100余项专利与软件著作权，三项关键智能化技术位居行业第一，两项关键安全参数达到行业最高水平，引领行业转型升级。如今，盛隆“智”造已成功应用于比亚迪集团、海口美兰国际机场以及缅甸时代广场等国内外项目。 （来源：极目新闻） 更多精彩资讯请在应用市场下载“极目新闻”客户端，未经授权请勿转载，欢迎提供新闻线索，一经采纳即付报酬。 举报/反馈"
    },
    {
      "doc_id": 16992,
      "title": "DeepSeek流量暴跌?AI大模型全球霸主离奇遇冷,外媒曝出真相",
      "time": "2024-07-04T00:00:00+00:00",
      "content": "编辑：Aeneas 好困 【新智元导读】曾以低价高性能震撼市场的DeepSeek，为何在自家平台遇冷，市场份额下滑？背后隐藏的「Token经济学」和这场精心策划的战略转移，正悄然改变着AI的价值链与分发模式。 最近，全世界的大厂都在蠢蠢欲动了！ GPT-5、Grok 4，甚至Claude，都已经纷纷有了消息，一场恶战仿佛就在眼前！ DeepSeek这边，似乎也有新动静了。 就在昨天，一个疑似DeepSeek的新模型现身LM Arena。 也有人猜测，这个模型更可能是DeepSeek V4，而DeepSeek R2会稍后发布。 套路很可能和之前是一样的，先在第一个月发布V3，然后在下个月发布R1。 所以，曾经轰动全球AI圈的中国大模型DeepSeek R1，如今怎样了？ 到今天为止，DeepSeek R1已经发布超过150天了。 当时一经问世，它就以OpenAI同等级的推理能力和低90%的价格而迅速出圈，甚至一度撼动了西方的资本市场。 可是如今，它在用户留存和官网流量上却双双遇冷，市场份额持续下滑。 DeepSeek就这样昙花一现，红极一时后迅速衰落了？ 其实不然，在这背后，其实隐藏着另一条增长曲线—— 在第三方平台上，R1已经成爆炸性增长，这背后，正是折射出AI模型分发与价值链的悄然变革。 SemiAnalysis今天发布的这篇文章，挖出了不少一手的内幕信息。 DeepSeek，盛极而衰？ DeepSeek发布后，消费者应用的流量一度激增，市场份额也随之急剧上升。 为此，SemiAnalysis做出了下面这份统计曲线。 当然，他们也承认，由于中国的用户活动数据难以追踪，且西方实验室在中国无法运营，下面这些数据实际上低估了DeepSeek的总覆盖范围。 不过即便如此，曾经它爆炸性的增长势头也未能跟上其他AI应用的步伐，可以确定，DeepSeek的市场份额此后已然下滑。 而在网络浏览器流量方面，它的数据就更为惨淡了：绝对流量一直在下降，但其他顶尖模型的用户数却噌噌飞涨，十分可观。 不过，虽然DeepSeek自家托管模型的用户增长乏力，但在第三方平台那里，就完全是冰火两重天了。 可以看到，R1和V3模型的总使用量一直在持续快速增长，自R1首次发布以来，已经增长将近20倍！ 如果进一步深挖数据，就会发现：只看由DeepSeek自己托管的那部分Token流量，那它在总Token中的份额的确是逐月下降的。 那么，问题来了：为何在DeepSeek模型本身越来越受欢迎、官方价格非常低廉的情况下，用户反而从DeepSeek自家的网页应用和API流失，转向了其他开源提供商呢？ SemiAnalysis点出了问题关键—— 答案就在于「Token经济学」，以及在平衡模型服务的各项KPI时所做的无数权衡。 这些权衡意味着，每个Token的价格并非一个孤立的数字，而是模型提供商根据其硬件和模型配置，在对各项KPI进行决策后得出的最终结果。 Token经济学基础 我们都知道，Token是构成AI模型的基本单元。AI模型通过读取以Token为单位的互联网信息进行学习，并以文本、音频、图像或行为指令等Token形式生成输出。 所谓Token，就是像「fan」、「tas」、「tic」这样的小文本片段。LLM在处理文本时，并非针对完整的单词或字母，而是对这些片段进行计数和处理。 这些Token，便是老黄口中数据中心「AI工厂」的输入和输出。 如同实体工厂一样，AI工厂也遵循一个「P x Q」（价格 x 数量）的公式来盈利：其中，P代表每个 Token的价格，Q代表输入和输出Token的总量。 但与普通工厂不同，Token的价格是一个可变参数，模型服务商可以根据其他属性来设定这个价格。 以下，就是几个关键的性能指标（KPI）。 延迟（Latency）或首个Token输出时间（Time-to-First-Token） 指模型生成第一个Token所需的时长。这也可以理解为模型完成「预填充」阶段（即将输入提示词编码到KVCache中）并开始在「解码」阶段生成第一个Token所需的时间。 吞吐量（Throughput）或交互速度（Interactivity） 指生成每个Token的速度，通常以「每个用户每秒可生成的Token数量」来衡量。 当然，有些服务商也会使用其倒数——即生成每个输出Token的平均间隔时间（Time Per Output Token, TPOT）。 人类的阅读速度约为每秒3-5个单词，而大部分模型服务商设定的输出速度约为每秒20-60个Token。 上下文窗口（Context Window） 指在模型「遗忘」对话的早期部分、并清除旧的Token之前，其「短期记忆」中能够容纳的Token数量。 不同的应用场景需要大小各异的上下文窗口。 例如，分析大型文档和代码库时，就需要更大的上下文窗口，以确保模型能够对海量数据进行连贯的推理。 对于任何一个给定的模型，你都可以通过调控这三大KPI，设定出几乎任何价位的单位Token价格。 因此，单纯基于「每百万Token的价格」（$/Mtok）来讨论优劣，并没有什么意义，因为这种方式忽略了具体工作负载的性质，以及用户对Token的实际需求。 DeepSeek的策略权衡 所以，DeepSeek在R1模型服务上采用了何种Token经济学策略，以至于市场份额会不断流失？ 通过对比延迟与价格的关系图，可以看到，在同等延迟水平上，DeepSeek的自有服务已不再是价格最低的选择。 事实上，DeepSeek之所以能提供如此低廉的价格，一个重要原因在于，用户等待数秒后，才能收到模型返回的第一个Token。 相比之下，其他服务商的延迟会短得多，价格却几乎没有差别。 也就是说，Token消费者只需花费2-4美元，就能从Parasail或Friendli这类服务商那里，获得近乎零延迟的体验。 同样，微软Azure的服务价格虽比DeepSeek高2.5倍，但延迟却减少了整整25秒。 这样看来，DeepSeek现在面临的处境就尤为严峻了。 原因在于，现在几乎所有托管R1 0528模型的实例都实现了低于5秒的延迟。 沿用同一图表，但这次我们将上下文窗口的大小用气泡面积来表示。 从中可以看到，DeepSeek为了用有限的推理算力资源来提供低价模型，所做的另一项权衡。 他们采用的64K上下文窗口，几乎是主流模型服务商中最小的之一。 较小的上下文窗口限制了编程等场景的发挥，因为这类任务需要模型能够连贯地记忆代码库中的大量Token，才能进行有效推理。 从图表中可见，若花费同样的价格，用户可以从Lambda和Nebius等服务商那里获得超过2.5倍的上下文窗口大小。 如果深入硬件层面，在AMD和英伟达芯片上对DeepSeek V3模型的基准测试，就可以看清服务商是如何确定其「每百万Token价格」（$/Mtok）的—— 模型服务商会通过在单个GPU或GPU集群上同时处理更多用户的请求（即「批处理」），来降低单位Token的总成本。 这种做法的直接后果，就是终端用户需要承受更高的延迟和更慢的吞吐量，从而导致用户体验急剧下降。 之所以DeepSeek完全不关心用户的体验到底如何，实际上是一种主动作出的战略选择。 毕竟，从终端用户身上赚钱，或是通过聊天应用和API来消耗大量Token，并不是他们的兴趣所在。 这家公司的唯一焦点就是实现AGI！ 而通过采用极高批处理方式，DeepSeek可以最大限度地减少用于模型推理和对外服务的计算资源消耗，从而将尽可能多的算力保留在公司内部，从而用于研发。 另外还有一点：出口管制也限制了中国AI生态系统在模型服务方面的能力。 因此，对DeepSeek而言，开源就是最合乎逻辑的选择：将宝贵的计算资源留作内部使用，同时让其他云服务商去托管其模型，以此赢得全球市场的认知度和用户基础。 不过，SemiAnalysis也承认，这却并没有削弱中国公司训练模型的能力——无论是腾讯、阿里、百度，还是小红书最近发布的新模型，都证明了这一点。 Anthropic也一样？ 和DeepSeek一样，Anthropic的算力也是同样受限的。 可以看到，它产品研发的重心显然放在了编程上，而且已经在Cursor等应用中大放异彩。 Cursor的用户使用情况，就是评判模型优劣的终极试金石，因为它直接反映了用户最关心的两个问题——成本与体验。 而如今，Anthropic的模型已雄踞榜首超过一年——在瞬息万变的AI行业里，这个时长仿佛已经如十年。 而在Cursor上大获成功后，Anthropic立马顺势推出了Claude Code，一款集成在终端里的编程工具。 它的用户量一路飙升，将OpenAI的Codex模型远远甩在身后。 为了对达Claude Code，谷歌也紧急发布了Gemini CLI。 它与Claude Code功能相似，但因为背靠谷歌TPU，却有非凡的算力优势——用户能免费使用的额度，几乎无上限。 不过，尽管Claude Code的性能和设计都十分出色，价格却不菲。 Anthropic在编程上的成功，反而给公司带来了巨大压力——他们在算力上已经捉襟见肘。 这一点，在Claude 4 Sonnet的API输出速度上就已经体现得淋漓尽致。自发布以来，它的生成速度已下降了40%，略高于每秒45个Token。 背后的原因，也和DeepSeek如出一辙——为了在有限的算力下处理所有涌入的请求，他们不得不提高批处理的速率。 此外，编程类的使用场景往往涉及更长的对话和更多的Token数量，这就进一步加剧了算力的紧张状况。 无论是何种原因，像o3和Gemini 2.5 Pro这类对标模型的运行速度要快得多，这也反映出OpenAI和谷歌所拥有的算力规模要庞大得多。 现在，Anthropic正集中精力获取更多算力，已经和亚马逊达成了协议。它将获得超过五十万枚Trainium芯片，用于模型训练和推理。 另外，Claude 4模型并非在AWS Trainium上预训练的，而是在GPU和TPU上训练。 速度劣势可由效率弥补 Claude 的生成速度虽然暴露了其算力上的局限，但总体而言，Anthropic的用户体验（UX）要优于 DeepSeek。 首先，其速度虽然偏低，但仍快于DeepSeek的每秒25个Token。 其次，Anthropic的模型回答同一个问题所需的Token数量远少于其他模型。 这意味着，尽管生成速度不占优，用户实际感受到的端到端响应时间反而显著缩短了。 值得一提的是，在所有领先的推理模型中，Claude的总输出Token量是最低的。 相比之下，Gemini 2.5 Pro和DeepSeek R1 0528等模型的输出内容，「啰嗦」程度都是Claude的三倍以上。 Token经济学的这一方面揭示出，服务商正在从多个维度上改进模型，其目标不再仅仅是提升智能水平，而是致力于提高「每单位Token所承载的智能」。 随着Cursor、Windsurf、Replit、Perplexity等一大批「GPT套壳」应用（或称由AI Token驱动的应用）迅速流行并获得主流市场的认可。 我们看到，越来越多的公司开始效仿Anthropic的模式，专注于将Token作为一种服务来销售，而不是像ChatGPT那样以月度订阅的方式打包。 参考资料： https://semianalysis.com/2025/07/03/deepseek-debrief-128-days-later/ 举报/反馈"
    },
    {
      "doc_id": 16993,
      "title": "2025年,AI大模型在企业场景走到哪了?",
      "time": "2024-06-20T00:00:00+00:00",
      "content": "文 | A16Z，转译 | 产业家 企业部署 AI 不再是试验项目，而是战略行动。预算已经常态化、模型选择多元化、采购流程标准化、AI 应用开始系统落地。尽管产业需求和企业需求碎片化，但这正是企业拥抱的方向。一些关键厂商正在脱颖而出，企业也越来越多选择成品应用以加速落地。 市场形态愈加接近传统软件，但变化节奏与复杂性却完全不同——这是 AI 的特有节奏。 2025年，AI大模型在企业场景的落地走到哪了？ 过去一年，AI在企业中的地位发生了根本性转变。它不再是创新实验室里一场场孤立的试验，也不仅是技术部门热衷的“新玩具”，而是真正走入了核心业务系统，成为IT和经营预算中不可或缺的一部分。 这是一场静悄悄却迅猛的演进：AI模型变得更多样，采购流程愈发严谨，企业不再“自己造轮子”，而是开始像采购传统软件那样，有条不紊地选择、部署、评估人工智能服务。技术领导者们正变得越来越成熟——他们明白，不同模型适配不同任务，用例碎片化是常态，而高质量的AI原生应用，正在快速超越传统软件厂商。 近日，A16z发布了一份主题为《AI技术在企业场景落地》的调研报告，报告基于与20多位企业买家的深度访谈和100位CIO的调研，全面回顾了企业在2025年如何部署、采购、集成和规划AI。 这份报告背后对应的是一个新的观点，即：AI不再是“是否值得尝试”的问题，而是“如何规模化落地”的现实挑战。 AI落地到底如何？又或者说，AI在企业场景中到底该如何落地？怎样更好的落地？可以说，它是一份调查，也更是一面全球企业落地AI的镜子。 让我们一起来走进这份报告。 以下为报告原文（部分语句做可读性调整）： 一年前，我们总结了企业在构建与采购生成式 AI（Gen AI）方面面临的 16 项变革。时至今日，形势已然大变。为此，我们重访了 20 多位企业买家，并调研了横跨 15 个行业的 100 位 CIO，试图帮助创业者了解企业客户在 2025 年及未来如何使用、采购与规划 AI。 尽管 AI 世界瞬息万变，过去一年市场格局的演进仍然超出了我们的预期： 1、企业 AI 预算持续超标增长，从试点项目跃升为 IT 和业务核心预算的一部分。 2、企业在“多模型组合”上的运用日益成熟，开始注重性能与成本的平衡。OpenAI、谷歌和 Anthropic 是闭源市场的主力，而 Meta 与 Mistral 成为开源阵营的热门选择。 3、AI 模型采购流程日趋接近传统软件采购：评估更严、托管更讲究、标准化测试更受重视。与此同时，更复杂的 AI 工作流也在推高模型替换成本。 4、AI 应用生态逐渐成型：标准化应用开始取代定制开发，AI 原生的第三方应用迎来爆发增长。 本报告将围绕企业在预算分配、模型选择、采购流程与应用使用四大维度的最新趋势，帮助创业者更细致地理解企业客户真正关注的重点。 一、预算：AI 支出超出预期，并持续增长 1. AI 预算增长远超预期，且毫无放缓迹象 企业对大语言模型（LLM）的投入已大幅超出去年原本就很高的预算预期，且预计未来一年将继续增长，平均增幅约为 75%。正如一位 CIO 所说：“我 2023 年一整年的支出，现在一周就能用完。” 预算上升的原因有二：一方面，企业持续发掘更多内部用例，推动员工广泛采用；另一方面，越来越多的企业开始部署面向客户的 AI 应用，尤其是科技创新型企业，这些场景的投入呈指数级扩展。一家大型科技公司表示：“去年我们主要专注于内部效率提升，今年的重点将转向面向客户的 Gen AI，投入会大大增加。” 2. AI 正式纳入核心预算，结束“试验期” 一年前，企业在 LLM 上的支出中仍有约 25% 来自创新专项预算；如今，这一比例降至 7%。企业普遍将 AI 模型和应用的费用纳入常规 IT 与业务部门预算，体现出 AI 不再是探索性项目，而是业务运转的“基础设施”。 一位 CTO 指出：“我们的产品正在陆续集成 AI 功能，相关支出也自然水涨船高。”这意味着，AI 融入主流预算的趋势还将进一步加速。 二、模型：多模型策略成为主流，三大厂商初步确立领先地位 3. 多模型时代已成常态，“差异化”而非“同质化”成驱动力 当前市面上已存在多个性能出色的 LLM，企业开始在实际生产中部署多种模型。虽然避免供应商绑定是一个重要原因，但更根本的动因是：不同模型在不同用例中的表现差异越来越显著。 本年度调查中，37% 的企业正在使用五种及以上的模型，较去年的 29% 明显增长。 虽然模型在某些通用评估中得分相近，但企业用户发现，其实际效果差异不容忽视。例如，Anthropic 的 Claude 更擅长细粒度代码补全，而 Gemini 更适用于系统设计和架构。在基于文本的任务中，用户反馈 Anthropic的语言流畅性和内容生成更强，而 OpenAI 的模型更适合复杂问答任务。 这种差异促使企业采用“多模型最佳实践”，既保障性能优化，又降低对单一厂商的依赖。我们预判这种策略将在未来继续主导企业的模型部署路径。 4. 模型格局仍激烈，但三大厂商初显优势 虽然企业在实验和生产中持续试用多个模型，但市场上已出现三个领先者：OpenAI 保持市场份额领先，谷歌和 Anthropic 则在过去一年迅速追赶。 具体来看： （1）OpenAI：其模型组合被广泛应用，GPT-4o 是最常部署到生产环境中的模型，推理模型 o3 也引发高度关注。67% 的OpenAI 用户在生产中部署了非前沿模型，这一比例远高于谷歌（41%）和 Anthropic（27%）。 （2）谷歌：在大型企业中表现更突出，得益于 GCP 客户基础和品牌信任。Gemini 2.5 不仅具备顶级上下文窗口，在性价比上也具明显优势——Gemini 2.5 Flash 每百万 Token 成本为 0.26 美元，远低于 GPT-4.1 mini 的 0.70 美元。 （3）Anthropic：在技术前沿型企业（如软件公司与初创企业）中受到高度青睐。其在代码相关任务中的表现尤为突出，是增长最快的 AI 编码应用背后的核心引擎。 此外，开源模型如Llama 与 Mistral 更受大型企业青睐，主要出于数据安全、合规和可定制性考虑。新玩家 xAI 的 Grok 模型也开始受到广泛关注，市场仍充满变数。 5. 对于中小型模型而言，闭源模型的性价比优势愈发明显 如前所述，模型成本正以每年一个数量级的速度下降。在这一趋势下，闭源模型（尤其是中小型模型）的性能/成本比正变得越来越有吸引力。 目前在这一领域表现领先的是 xAI 的 Grok 3 mini 和谷歌的 Gemini 2.5 Flash。例如，一些客户表示，出于成本考量及生态系统集成便利，他们更倾向选择闭源模型。 正如一位客户坦言：“现在的定价已经非常诱人，而我们已经深度嵌入谷歌生态，从 G Suite 到数据库都在使用，他们的企业服务经验对我们来说很有价值。”另一位客户则更直白地总结道：“Gemini 很便宜。” 这反映出闭源模型在中低成本场景中正逐步赢得市场。 6. 随着模型能力增强，微调的重要性正在下降 随着模型智能水平和上下文窗口显著提升，企业发现，实现优异性能已不再依赖微调，而是更多依靠高效的 Prompt 工程。 某家企业观察道：“我们不再需要提取训练数据去微调模型，只要把它放进一个足够长的上下文窗口，结果几乎一样好。” 这一转变带来两个重要影响： （1）降低使用成本：Prompt 工程成本远低于微调； （2）降低供应商绑定风险：Prompt 可轻松迁移至其他模型，而微调后的模型往往存在迁移困难和高前期投入。 不过，在某些超特定用例中，微调仍不可或缺。比如，一家流媒体公司就针对视频搜索中的查询增强，对开源模型进行了微调，以适应领域语言。 此外，若强化微调（Reinforcement Fine-tuning）等新方法在实验室外得到广泛应用，微调在未来也可能迎来新一轮增长。 总体而言，大多数企业在常规场景中对微调的 ROI 预期已经下降，且更倾向于在成本敏感型场景中选用开源模型。 7. 企业对“推理模型”前景乐观，正积极准备规模化部署 推理模型（Reasoning Models）能够让大语言模型更准确地完成更复杂的任务，从而显著扩大 LLM 的可用场景。尽管目前多数企业仍处于测试阶段，尚未正式上线部署，但对于其潜力普遍持乐观态度。 一位高管表示：“推理模型能帮助我们解决更多新型、复杂的任务场景，我预计它的使用量很快会出现大幅增长。只是目前我们还处于早期测试阶段。” 在早期使用者中，OpenAI的推理模型表现最为突出。尽管 DeepSeek 在行业中也有不少关注，但在生产部署方面，OpenAI 的优势非常明显：本次调研显示，有 23% 的企业已在生产中使用 OpenAI 的 o3 模型，而使用DeepSeek 的仅为 3%。不过，DeepSeek 在初创企业中的采用率相对更高，企业市场渗透仍较低。 随着推理能力逐步融合进企业应用主流程，其影响力有望迅速放大。 三、采购：企业AI 采购流程趋于成熟，正全面借鉴传统软件采购机制 8. 模型采购流程日趋规范，成本敏感度提升 当前，企业在选择模型时已普遍采用系统性的评估框架。在我们访谈中，安全性和成本与准确性、可靠性一样，成为模型采购的核心考量。正如一位企业负责人所言：“现在大多数模型的基础能力都够用，价格反而成了更重要的因素。” 此外，企业在“用例-模型”匹配上也日益专业化： （1）对于关键场景或对性能要求高的任务，企业更倾向于选择具有强品牌背书的顶级模型； （2）对于内部或低风险任务，企业更多以“成本导向”作决策。 9. 企业对模型厂商信任度显著提升，托管策略更加多元 过去一年，企业与模型厂商之间的信任明显提升。虽然仍有一部分企业偏好通过现有云服务关系托管模型（如通过 AWS 使用 OpenAI），但越来越多的企业选择直接与模型提供方合作，或通过 Databricks 等平台托管，尤其是在模型并未由主力云厂商托管时。 正如一位受访者所说：“我们想第一时间用上最新最强的模型，预览版本也很关键。”相较去年“尽可能绕回主云厂商”的策略，这种直接托管趋势是一个显著转变。 10. 随着任务复杂性上升，模型切换成本也在快速上涨 去年，不少企业在设计AI 应用时刻意降低切换成本，希望模型“来去自如”。但随着“代理式工作流”的兴起，这一策略开始失效。 代理工作流通常涉及多步骤协作，模型之间的替换将牵一发而动全身。企业在构建提示语、设计护栏、验证质量方面投入大量资源后，更不愿意轻易更换模型。 一位 CIO 总结得非常直接：“我们所有提示都为 OpenAI 优化过了，每个 prompt 都有特定的结构和细节。要切到另一个模型，不仅要重新调教所有提示，还可能影响整个工作流的稳定性。” 11. 外部评估基准日渐成为“模型采购的第一道筛选” 随着模型数量激增，企业采购者也越来越依赖类似 Gartner 魔力象限那样的外部评价体系，如 LM Arena。这类评估为模型采购提供了初筛参考。 尽管企业仍高度重视内部基准测试、金标数据集和开发者反馈，但外部指标正在成为“第一道门槛”。不过，企业普遍强调：外部 benchmark 只是评估的一部分，真正决定性因素仍然来自实际试用和员工反馈。 四、应用：AI 应用加速落地，企业从“自建”转向“采购” 12. 企业从“自己开发”向“购买成品”大幅转变 AI 应用生态正在迅速成熟。过去一年，企业从“自己构建”向“采购专业第三方应用”的转变非常明显。 原因主要有两个： （1）性能与成本的动态差异使持续评估和调优成为必要，而这通常更适合由专业团队而非内部团队执行； （2）AI 领域演进迅速，内部自研工具难以长期维护，且未必构成竞争优势，反而降低了“自建”的性价比。 例如，在客户支持场景中，超过 90% 的受访 CIO 表示正在测试第三方应用。一家上市金融科技企业曾尝试自研客户服务系统，但最终决定转向采购成熟方案。这一趋势在医疗等高风险行业尚未完全展开，因数据隐私与合规仍是首要考量。 13. “按结果计费”仍不被 CIO 广泛接受 尽管“按效果付费”被广泛讨论，但企业在实践中仍有诸多顾虑——例如结果定义模糊、归因困难、成本不可控等。多数 CIO 表示：他们更倾向于按使用量计费的方式，因为这更直观、可预测、可控。 14. 软件开发成为首个“杀手级”AI 应用场景 虽然 AI 已在内部搜索、数据分析、客户服务等多个领域落地，但软件开发的应用爆发最为显著。这得益于三重利好： （1）模型能力显著提升； （2）现成工具质量极高； （3）投资回报率直接可见，适用行业广泛。 一家高增长 SaaS 公司 CTO 表示，他们现在近 90% 的代码由 Cursor 和 Claude Code 生成——而一年前使用 GitHub Copilot 时，仅占比 10-15%。这种跃迁式采用虽仍属于前沿现象，但可能正是企业界未来的风向标。 15. Prosumer 市场（生产者消费者融合）拉动应用早期增长 强消费品牌带动企业采购决策的现象再次上演。 ChatGPT 是典型案例：许多 CIO 表示购买企业版 ChatGPT 是因为“员工用得惯、喜欢、信得过”。从生产者市场向企业端的自然延伸，加速了新一代 AI 应用的增长。 16. AI 原生应用的速度与质量正在超越传统巨头 虽然传统厂商拥有渠道优势和品牌信任，但在产品质量与迭代速度上，AI 原生公司已开始超越。例如在编码工具领域，Cursor 这类专为 AI 场景构建的工具，让用户对传统的 GitHub Copilot 明显“不再满意”。 一位公共安全行业 CIO点出：“第一代和第二代 AI 编码工具差异极大。新一代原生产品更智能，也更实用。” 展望未来：企业级AI 的“试验时代”已经结束 企业部署 AI 不再是试验项目，而是战略行动。预算已经常态化、模型选择多元化、采购流程标准化、AI 应用开始系统落地。尽管用例碎片化，但这正是企业拥抱的方向。一些关键厂商正在脱颖而出，企业也越来越多选择成品应用以加速落地。 市场形态愈加接近传统软件，但变化节奏与复杂性却完全不同——这是 AI 的特有节奏。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 举报/反馈"
    }
  ]
}